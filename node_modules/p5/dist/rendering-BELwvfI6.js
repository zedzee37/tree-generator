import { e as CORNER, i as CORNERS, C as CENTER, ap as COVER, aq as CONTAIN, R as RIGHT, ar as BOTTOM, u as BLEND, as as FILL, a1 as IMAGE, at as CLAMP, z as WEBGL2, j as ROUND, o as POINTS, L as LINES, p as TRIANGLES, a0 as WEBGL, $ as BLUR, a6 as DARKEST, a7 as LIGHTEST, ai as ADD, a5 as SUBTRACT, ab as SCREEN, aa as EXCLUSION, ac as REPLACE, a9 as MULTIPLY, a4 as REMOVE, ah as BURN, ad as OVERLAY, ae as HARD_LIGHT, af as SOFT_LIGHT, ag as DODGE, au as UNSIGNED_INT, av as UNSIGNED_BYTE, Z as THRESHOLD, _ as INVERT, K as OPAQUE, U as POSTERIZE, V as DILATE, Y as ERODE, X as GRAY, v as constants, aw as SIMPLE, ax as FULL, f as TWO_PI, O as OPEN, N as NORMAL, n as CLOSE, aj as PIE, ak as CHORD, T as TEXTURE, P as P2D, ay as NEAREST, az as REPEAT, aA as MIRROR, aB as FLOAT, aC as LINEAR, aD as HALF_FLOAT } from './constants-8IpwyBct.js';
import { C as Color, c as creatingReading, h as RGBA, R as RGB } from './creating_reading-BdolPjuO.js';
import { Element } from './dom/p5.Element.js';
import { R as Renderer, I as Image } from './p5.Renderer-DoDzbpcT.js';
import './dom/p5.MediaElement.js';
import primitives from './shape/2d_primitives.js';
import attributes from './shape/attributes.js';
import curves from './shape/curves.js';
import vertex from './shape/vertex.js';
import setting from './color/setting.js';
import * as omggif from 'omggif';
import canvas from './core/helpers.js';
import { parse } from './io/csv.js';
import { _checkFileExtension, downloadFile } from './io/utilities.js';
import { GIFEncoder, quantize, nearestColorIndex } from 'gifenc';
import pixels from './image/pixels.js';
import transform from './core/transform.js';
import GeometryBuilder from './webgl/GeometryBuilder.js';
import './math/p5.Matrix.js';
import { Vector } from './math/p5.Vector.js';
import { Quat } from './webgl/p5.Quat.js';
import { Matrix } from './math/Matrices/Matrix.js';
import { RenderBuffer } from './webgl/p5.RenderBuffer.js';
import { DataArray } from './webgl/p5.DataArray.js';
import { ShapeBuilder } from './webgl/ShapeBuilder.js';
import { GeometryBufferCache } from './webgl/GeometryBufferCache.js';
import { filterParamDefaults } from './image/const.js';
import customShapes, { PrimitiveToVerticesConverter } from './shape/custom_shapes.js';
import { Geometry } from './webgl/p5.Geometry.js';
import trigonometry from './math/trigonometry.js';

/**
 * @module Image
 * @submodule Image
 * @for p5
 * @requires core
 */


function image(p5, fn){
  /**
   * Creates a new <a href="#/p5.Image">p5.Image</a> object.
   *
   * `createImage()` uses the `width` and `height` parameters to set the new
   * <a href="#/p5.Image">p5.Image</a> object's dimensions in pixels. The new
   * <a href="#/p5.Image">p5.Image</a> can be modified by updating its
   * <a href="#/p5.Image/pixels">pixels</a> array or by calling its
   * <a href="#/p5.Image/get">get()</a> and
   * <a href="#/p5.Image/set">set()</a> methods. The
   * <a href="#/p5.Image/loadPixels">loadPixels()</a> method must be called
   * before reading or modifying pixel values. The
   * <a href="#/p5.Image/updatePixels">updatePixels()</a> method must be called
   * for updates to take effect.
   *
   * Note: The new <a href="#/p5.Image">p5.Image</a> object is transparent by
   * default.
   *
   * @method createImage
   * @param  {Integer} width  width in pixels.
   * @param  {Integer} height height in pixels.
   * @return {p5.Image}       new <a href="#/p5.Image">p5.Image</a> object.
   *
   * @example
   * <div>
   * <code>
   * function setup() {
   *   createCanvas(100, 100);
   *
   *   background(200);
   *
   *   // Create a p5.Image object.
   *   let img = createImage(66, 66);
   *
   *   // Load the image's pixels into memory.
   *   img.loadPixels();
   *
   *   // Set all the image's pixels to black.
   *   for (let x = 0; x < img.width; x += 1) {
   *     for (let y = 0; y < img.height; y += 1) {
   *       img.set(x, y, 0);
   *     }
   *   }
   *
   *   // Update the image's pixel values.
   *   img.updatePixels();
   *
   *   // Draw the image.
   *   image(img, 17, 17);
   *
   *   describe('A black square drawn in the middle of a gray square.');
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * function setup() {
   *   createCanvas(100, 100);
   *
   *   background(200);
   *
   *   // Create a p5.Image object.
   *   let img = createImage(66, 66);
   *
   *   // Load the image's pixels into memory.
   *   img.loadPixels();
   *
   *   // Create a color gradient.
   *   for (let x = 0; x < img.width; x += 1) {
   *     for (let y = 0; y < img.height; y += 1) {
   *       // Calculate the transparency.
   *       let a = map(x, 0, img.width, 0, 255);
   *
   *       // Create a p5.Color object.
   *       let c = color(0, a);
   *
   *       // Set the pixel's color.
   *       img.set(x, y, c);
   *     }
   *   }
   *
   *   // Update the image's pixels.
   *   img.updatePixels();
   *
   *   // Display the image.
   *   image(img, 17, 17);
   *
   *   describe('A square with a horizontal color gradient that transitions from gray to black.');
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * function setup() {
   *   createCanvas(100, 100);
   *
   *   background(200);
   *
   *   // Create a p5.Image object.
   *   let img = createImage(66, 66);
   *
   *   // Load the pixels into memory.
   *   img.loadPixels();
   *   // Get the current pixel density.
   *   let d = pixelDensity();
   *
   *   // Calculate the pixel that is halfway through the image's pixel array.
   *   let halfImage = 4 * (d * img.width) * (d * img.height / 2);
   *
   *   // Set half of the image's pixels to black.
   *   for (let i = 0; i < halfImage; i += 4) {
   *     // Red.
   *     img.pixels[i] = 0;
   *     // Green.
   *     img.pixels[i + 1] = 0;
   *     // Blue.
   *     img.pixels[i + 2] = 0;
   *     // Alpha.
   *     img.pixels[i + 3] = 255;
   *   }
   *
   *   // Update the image's pixels.
   *   img.updatePixels();
   *
   *   // Display the image.
   *   image(img, 17, 17);
   *
   *   describe('A black square drawn in the middle of a gray square.');
   * }
   * </code>
   * </div>
   */
  fn.createImage = function(width, height) {
    // p5._validateParameters('createImage', arguments);
    return new p5.Image(width, height);
  };

  /**
   * Saves the current canvas as an image.
   *
   * By default, `saveCanvas()` saves the canvas as a PNG image called
   * `untitled.png`.
   *
   * The first parameter, `filename`, is optional. It's a string that sets the
   * file's name. If a file extension is included, as in
   * `saveCanvas('drawing.png')`, then the image will be saved using that
   * format.
   *
   * The second parameter, `extension`, is also optional. It sets the files format.
   * Either `'png'`, `'webp'`, or `'jpg'` can be used. For example, `saveCanvas('drawing', 'jpg')`
   * saves the canvas to a file called `drawing.jpg`.
   *
   * Note: The browser will either save the file immediately or prompt the user
   * with a dialogue window.
   *
   *  @method saveCanvas
   *  @param  {p5.Framebuffer|p5.Element|HTMLCanvasElement} selectedCanvas   reference to a
   *                                                          specific HTML5 canvas element.
   *  @param  {String} [filename]  file name. Defaults to 'untitled'.
   *  @param  {String} [extension] file extension, either 'png', 'webp', or 'jpg'. Defaults to 'png'.
   *
   *  @example
   * <div class='norender'>
   * <code>
   * function setup() {
   *   createCanvas(100, 100);
   *   background(255);
   *
   *   // Save the canvas to 'untitled.png'.
   *   saveCanvas();
   *
   *   describe('A white square.');
   * }
   * </code>
   * </div>
   *
   * <div class='norender'>
   * <code>
   * function setup() {
   *   createCanvas(100, 100);
   *
   *   background(255);
   *
   *   // Save the canvas to 'myCanvas.jpg'.
   *   saveCanvas('myCanvas.jpg');
   *
   *   describe('A white square.');
   * }
   * </code>
   * </div>
   *
   * <div class='norender'>
   * <code>
   * function setup() {
   *   createCanvas(100, 100);
   *
   *   background(255);
   *
   *   // Save the canvas to 'myCanvas.jpg'.
   *   saveCanvas('myCanvas', 'jpg');
   *
   *   describe('A white square.');
   * }
   * </code>
   * </div>
   *
   * <div class='norender'>
   * <code>
   * function setup() {
   *   let cnv = createCanvas(100, 100);
   *
   *   background(255);
   *
   *   // Save the canvas to 'untitled.png'.
   *   saveCanvas(cnv);
   *
   *   describe('A white square.');
   * }
   * </code>
   * </div>
   *
   * <div class='norender'>
   * <code>
   * function setup() {
   *   let cnv = createCanvas(100, 100);
   *
   *   background(255);
   *
   *   // Save the canvas to 'myCanvas.jpg'.
   *   saveCanvas(cnv, 'myCanvas.jpg');
   *
   *   describe('A white square.');
   * }
   * </code>
   * </div>
   *
   * <div class='norender'>
   * <code>
   * function setup() {
   *   let cnv = createCanvas(100, 100);
   *
   *   background(255);
   *
   *   // Save the canvas to 'myCanvas.jpg'.
   *   saveCanvas(cnv, 'myCanvas', 'jpg');
   *
   *   describe('A white square.');
   * }
   * </code>
   * </div>
   */
  /**
   *  @method saveCanvas
   *  @param  {String} [filename]
   *  @param  {String} [extension]
   */
  fn.saveCanvas = function(...args) {
    // copy arguments to array
    let htmlCanvas, filename, extension, temporaryGraphics;

    if (args[0] instanceof HTMLCanvasElement) {
      htmlCanvas = args[0];
      args.shift();
    } else if (args[0] instanceof Element) {
      htmlCanvas = args[0].elt;
      args.shift();
    } else if (args[0] instanceof Framebuffer) {
      const framebuffer = args[0];
      temporaryGraphics = this.createGraphics(framebuffer.width,
        framebuffer.height);
      temporaryGraphics.pixelDensity(framebuffer.pixelDensity());
      framebuffer.loadPixels();
      temporaryGraphics.loadPixels();
      temporaryGraphics.pixels.set(framebuffer.pixels);
      temporaryGraphics.updatePixels();

      htmlCanvas = temporaryGraphics._renderer.canvas;
      args.shift();
    } else {
      htmlCanvas = this._curElement && this._curElement.elt;
    }

    if (args.length >= 1) {
      filename = args[0];
    }
    if (args.length >= 2) {
      extension = args[1];
    }

    extension =
      extension ||
      fn._checkFileExtension(filename, extension)[1] ||
      'png';

    let mimeType;
    switch (extension) {
      default:
        //case 'png':
        mimeType = 'image/png';
        break;
      case 'webp':
        mimeType = 'image/webp';
        break;
      case 'jpeg':
      case 'jpg':
        mimeType = 'image/jpeg';
        break;
    }

    htmlCanvas.toBlob(blob => {
      fn.downloadFile(blob, filename, extension);
      if(temporaryGraphics) temporaryGraphics.remove();
    }, mimeType);
  };

  // this is the old saveGif, left here for compatibility purposes
  // the only place I found it being used was on image/p5.Image.js, on the
  // save function. that has been changed to use this function.
  fn.encodeAndDownloadGif = function(pImg, filename) {
    const props = pImg.gifProperties;

    //convert loopLimit back into Netscape Block formatting
    let loopLimit = props.loopLimit;
    if (loopLimit === 1) {
      loopLimit = null;
    } else if (loopLimit === null) {
      loopLimit = 0;
    }
    const buffer = new Uint8Array(pImg.width * pImg.height * props.numFrames);

    const allFramesPixelColors = [];

    // Used to determine the occurrence of unique palettes and the frames
    // which use them
    const paletteFreqsAndFrames = {};

    // Pass 1:
    //loop over frames and get the frequency of each palette
    for (let i = 0; i < props.numFrames; i++) {
      const paletteSet = new Set();
      const data = props.frames[i].image.data;
      const dataLength = data.length;
      // The color for each pixel in this frame ( for easier lookup later )
      const pixelColors = new Uint32Array(pImg.width * pImg.height);
      for (let j = 0, k = 0; j < dataLength; j += 4, k++) {
        const r = data[j + 0];
        const g = data[j + 1];
        const b = data[j + 2];
        const color = (r << 16) | (g << 8) | (b << 0);
        paletteSet.add(color);

        // What color does this pixel have in this frame ?
        pixelColors[k] = color;
      }

      // A way to put use the entire palette as an object key
      const paletteStr = [...paletteSet].sort().toString();
      if (paletteFreqsAndFrames[paletteStr] === undefined) {
        paletteFreqsAndFrames[paletteStr] = { freq: 1, frames: [i] };
      } else {
        paletteFreqsAndFrames[paletteStr].freq += 1;
        paletteFreqsAndFrames[paletteStr].frames.push(i);
      }

      allFramesPixelColors.push(pixelColors);
    }

    let framesUsingGlobalPalette = [];

    // Now to build the global palette
    // Sort all the unique palettes in descending order of their occurrence
    const palettesSortedByFreq = Object.keys(paletteFreqsAndFrames).sort(function(
      a,
      b
    ) {
      return paletteFreqsAndFrames[b].freq - paletteFreqsAndFrames[a].freq;
    });

    // The initial global palette is the one with the most occurrence
    const globalPalette = palettesSortedByFreq[0]
      .split(',')
      .map(a => parseInt(a));

    framesUsingGlobalPalette = framesUsingGlobalPalette.concat(
      paletteFreqsAndFrames[globalPalette].frames
    );

    const globalPaletteSet = new Set(globalPalette);

    // Build a more complete global palette
    // Iterate over the remaining palettes in the order of
    // their occurrence and see if the colors in this palette which are
    // not in the global palette can be added there, while keeping the length
    // of the global palette <= 256
    for (let i = 1; i < palettesSortedByFreq.length; i++) {
      const palette = palettesSortedByFreq[i].split(',').map(a => parseInt(a));

      const difference = palette.filter(x => !globalPaletteSet.has(x));
      if (globalPalette.length + difference.length <= 256) {
        for (let j = 0; j < difference.length; j++) {
          globalPalette.push(difference[j]);
          globalPaletteSet.add(difference[j]);
        }

        // All frames using this palette now use the global palette
        framesUsingGlobalPalette = framesUsingGlobalPalette.concat(
          paletteFreqsAndFrames[palettesSortedByFreq[i]].frames
        );
      }
    }

    framesUsingGlobalPalette = new Set(framesUsingGlobalPalette);

    // Build a lookup table of the index of each color in the global palette
    // Maps a color to its index
    const globalIndicesLookup = {};
    for (let i = 0; i < globalPalette.length; i++) {
      if (!globalIndicesLookup[globalPalette[i]]) {
        globalIndicesLookup[globalPalette[i]] = i;
      }
    }

    // force palette to be power of 2
    let powof2 = 1;
    while (powof2 < globalPalette.length) {
      powof2 <<= 1;
    }
    globalPalette.length = powof2;

    // global opts
    const opts = {
      loop: loopLimit,
      palette: new Uint32Array(globalPalette)
    };
    const gifWriter = new omggif.GifWriter(buffer, pImg.width, pImg.height, opts);
    let previousFrame = {};

    // Pass 2
    // Determine if the frame needs a local palette
    // Also apply transparency optimization. This function will often blow up
    // the size of a GIF if not for transparency. If a pixel in one frame has
    // the same color in the previous frame, that pixel can be marked as
    // transparent. We decide one particular color as transparent and make all
    // transparent pixels take this color. This helps in later in compression.
    for (let i = 0; i < props.numFrames; i++) {
      const localPaletteRequired = !framesUsingGlobalPalette.has(i);
      const palette = localPaletteRequired ? [] : globalPalette;
      const pixelPaletteIndex = new Uint8Array(pImg.width * pImg.height);

      // Lookup table mapping color to its indices
      const colorIndicesLookup = {};

      // All the colors that cannot be marked transparent in this frame
      const cannotBeTransparent = new Set();

      allFramesPixelColors[i].forEach((color, k) => {
        if (localPaletteRequired) {
          if (colorIndicesLookup[color] === undefined) {
            colorIndicesLookup[color] = palette.length;
            palette.push(color);
          }
          pixelPaletteIndex[k] = colorIndicesLookup[color];
        } else {
          pixelPaletteIndex[k] = globalIndicesLookup[color];
        }

        if (i > 0) {
          // If even one pixel of this color has changed in this frame
          // from the previous frame, we cannot mark it as transparent
          if (allFramesPixelColors[i - 1][k] !== color) {
            cannotBeTransparent.add(color);
          }
        }
      });

      const frameOpts = {};

      // Transparency optimization
      const canBeTransparent = palette.filter(a => !cannotBeTransparent.has(a));
      if (canBeTransparent.length > 0) {
        // Select a color to mark as transparent
        const transparent = canBeTransparent[0];
        const transparentIndex = localPaletteRequired
          ? colorIndicesLookup[transparent]
          : globalIndicesLookup[transparent];
        if (i > 0) {
          for (let k = 0; k < allFramesPixelColors[i].length; k++) {
            // If this pixel in this frame has the same color in previous frame
            if (allFramesPixelColors[i - 1][k] === allFramesPixelColors[i][k]) {
              pixelPaletteIndex[k] = transparentIndex;
            }
          }
          frameOpts.transparent = transparentIndex;
          // If this frame has any transparency, do not dispose the previous frame
          previousFrame.frameOpts.disposal = 1;
        }
      }
      frameOpts.delay = props.frames[i].delay / 10; // Move timing back into GIF formatting
      if (localPaletteRequired) {
        // force palette to be power of 2
        let powof2 = 1;
        while (powof2 < palette.length) {
          powof2 <<= 1;
        }
        palette.length = powof2;
        frameOpts.palette = new Uint32Array(palette);
      }
      if (i > 0) {
        // add the frame that came before the current one
        gifWriter.addFrame(
          0,
          0,
          pImg.width,
          pImg.height,
          previousFrame.pixelPaletteIndex,
          previousFrame.frameOpts
        );
      }
      // previous frame object should now have details of this frame
      previousFrame = {
        pixelPaletteIndex,
        frameOpts
      };
    }

    previousFrame.frameOpts.disposal = 1;
    // add the last frame
    gifWriter.addFrame(
      0,
      0,
      pImg.width,
      pImg.height,
      previousFrame.pixelPaletteIndex,
      previousFrame.frameOpts
    );

    const extension = 'gif';
    const blob = new Blob([buffer.slice(0, gifWriter.end())], {
      type: 'image/gif'
    });
    fn.downloadFile(blob, filename, extension);
  };

  /**
   * Captures a sequence of frames from the canvas that can be saved as images.
   *
   * `saveFrames()` creates an array of frame objects. Each frame is stored as
   * an object with its file type, file name, and image data as a string. For
   * example, the first saved frame might have the following properties:
   *
   * `{ ext: 'png', filenmame: 'frame0', imageData: 'data:image/octet-stream;base64, abc123' }`.
   *
   * The first parameter, `filename`, sets the prefix for the file names. For
   * example, setting the prefix to `'frame'` would generate the image files
   * `frame0.png`, `frame1.png`, and so on.
   *
   * The second parameter, `extension`, sets the file type to either `'png'` or
   * `'jpg'`.
   *
   * The third parameter, `duration`, sets the duration to record in seconds.
   * The maximum duration is 15 seconds.
   *
   * The fourth parameter, `framerate`, sets the number of frames to record per
   * second. The maximum frame rate value is 22. Limits are placed on `duration`
   * and `framerate` to avoid using too much memory. Recording large canvases
   * can easily crash sketches or even web browsers.
   *
   * The fifth parameter, `callback`, is optional. If a function is passed,
   * image files won't be saved by default. The callback function can be used
   * to process an array containing the data for each captured frame. The array
   * of image data contains a sequence of objects with three properties for each
   * frame: `imageData`, `filename`, and `extension`.
   *
   * Note: Frames are downloaded as individual image files by default.
   *
   * @method saveFrames
   * @param  {String}   filename  prefix of file name.
   * @param  {String}   extension file extension, either 'jpg' or 'png'.
   * @param  {Number}   duration  duration in seconds to record. This parameter will be constrained to be less or equal to 15.
   * @param  {Number}   framerate number of frames to save per second. This parameter will be constrained to be less or equal to 22.
   * @param  {function(Array)} [callback] callback function that will be executed
                                    to handle the image data. This function
                                    should accept an array as argument. The
                                    array will contain the specified number of
                                    frames of objects. Each object has three
                                    properties: `imageData`, `filename`, and `extension`.
   * @example
   * <div>
   * <code>
   * function setup() {
   *   createCanvas(100, 100);
   *
   *   describe('A square repeatedly changes color from blue to pink.');
   * }
   *
   * function draw() {
   *   let r = frameCount % 255;
   *   let g = 50;
   *   let b = 100;
   *   background(r, g, b);
   * }
   *
   * // Save the frames when the user presses the 's' key.
   * function keyPressed() {
   *   if (key === 's') {
   *     saveFrames('frame', 'png', 1, 5);
   *   }
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * function setup() {
   *   createCanvas(100, 100);
   *
   *   describe('A square repeatedly changes color from blue to pink.');
   * }
   *
   * function draw() {
   *   let r = frameCount % 255;
   *   let g = 50;
   *   let b = 100;
   *   background(r, g, b);
   * }
   *
   * // Print 5 frames when the user presses the mouse.
   * function mousePressed() {
   *   saveFrames('frame', 'png', 1, 5, printFrames);
   * }
   *
   * // Prints an array of objects containing raw image data, filenames, and extensions.
   * function printFrames(frames) {
   *   for (let frame of frames) {
   *     print(frame);
   *   }
   * }
   * </code>
   * </div>
   */
  fn.saveFrames = function(fName, ext, _duration, _fps, callback) {
    // p5._validateParameters('saveFrames', arguments);
    let duration = _duration || 3;
    duration = Math.max(Math.min(duration, 15), 0);
    duration = duration * 1000;
    let fps = _fps || 15;
    fps = Math.max(Math.min(fps, 22), 0);
    let count = 0;

    const makeFrame = fn._makeFrame;
    const cnv = this._curElement.elt;
    let frames = [];
    const frameFactory = setInterval(() => {
      frames.push(makeFrame(fName + count, ext, cnv));
      count++;
    }, 1000 / fps);

    setTimeout(() => {
      clearInterval(frameFactory);
      if (callback) {
        callback(frames);
      } else {
        for (const f of frames) {
          fn.downloadFile(f.imageData, f.filename, f.ext);
        }
      }
      frames = []; // clear frames
    }, duration + 0.01);
  };

  fn._makeFrame = function(filename, extension, _cnv) {
    let cnv;
    if (this) {
      cnv = this._curElement.elt;
    } else {
      cnv = _cnv;
    }
    let mimeType;
    if (!extension) {
      extension = 'png';
      mimeType = 'image/png';
    } else {
      switch (extension.toLowerCase()) {
        case 'png':
          mimeType = 'image/png';
          break;
        case 'jpeg':
          mimeType = 'image/jpeg';
          break;
        case 'jpg':
          mimeType = 'image/jpeg';
          break;
        default:
          mimeType = 'image/png';
          break;
      }
    }
    const downloadMime = 'image/octet-stream';
    let imageData = cnv.toDataURL(mimeType);
    imageData = imageData.replace(mimeType, downloadMime);

    const thisFrame = {};
    thisFrame.imageData = imageData;
    thisFrame.filename = filename;
    thisFrame.ext = extension;
    return thisFrame;
  };
}

if(typeof p5 !== 'undefined'){
  image(p5, p5.prototype);
}

/**
 * @module IO
 * @submodule Input
 * @for p5
 * @requires core
 */


class HTTPError extends Error {
  status;
  response;
  ok;
}

async function request(path, type){
  try {
    const res = await fetch(path);

    if (res.ok) {
      let data;
      switch(type) {
        case 'json':
          data = await res.json();
          break;
        case 'text':
          data = await res.text();
          break;
        case 'arrayBuffer':
          data = await res.arrayBuffer();
          break;
        case 'blob':
          data = await res.blob();
          break;
        case 'bytes':
          // TODO: Chrome does not implement res.bytes() yet
          if(res.bytes){
            data = await res.bytes();
          }else {
            const d = await res.arrayBuffer();
            data = new Uint8Array(d);
          }
          break;
        default:
          throw new Error('Unsupported response type');
      }

      return { data, headers: res.headers };

    } else {
      const err = new HTTPError(res.statusText);
      err.status = res.status;
      err.response = res;
      err.ok = false;

      throw err;
    }

  } catch(err) {
    // Handle both fetch error and HTTP error
    if (err instanceof TypeError) {
      console.log('You may have encountered a CORS error');
    } else if (err instanceof HTTPError) {
      console.log('You have encountered a HTTP error');
    } else if (err instanceof SyntaxError) {
      console.log('There is an error parsing the response to requested data structure');
    }

    throw err;
  }
}

function files(p5, fn){
  /**
   * Loads a JSON file to create an `Object`.
   *
   * JavaScript Object Notation
   * (<a href="https://developer.mozilla.org/en-US/docs/Glossary/JSON" target="_blank">JSON</a>)
   * is a standard format for sending data between applications. The format is
   * based on JavaScript objects which have keys and values. JSON files store
   * data in an object with strings as keys. Values can be strings, numbers,
   * Booleans, arrays, `null`, or other objects.
   *
   * The first parameter, `path`, is a string with the path to the file.
   * Paths to local files should be relative, as in
   * `loadJSON('assets/data.json')`. URLs such as
   * `'https://example.com/data.json'` may be blocked due to browser security.
   * The `path` parameter can also be defined as a [`Request`](https://developer.mozilla.org/en-US/docs/Web/API/Request)
   * object for more advanced usage.
   *
   * The second parameter, `successCallback`, is optional. If a function is
   * passed, as in `loadJSON('assets/data.json', handleData)`, then the
   * `handleData()` function will be called once the data loads. The object
   * created from the JSON data will be passed to `handleData()` as its only argument.
   * The return value of the `handleData()` function will be used as the final return
   * value of `loadJSON('assets/data.json', handleData)`.
   *
   * The third parameter, `failureCallback`, is also optional. If a function is
   * passed, as in `loadJSON('assets/data.json', handleData, handleFailure)`,
   * then the `handleFailure()` function will be called if an error occurs while
   * loading. The `Error` object will be passed to `handleFailure()` as its only
   * argument. The return value of the `handleFailure()` function will be used as the
   * final return value of `loadJSON('assets/data.json', handleData, handleFailure)`.
   *
   * This function returns a `Promise` and should be used in an `async` setup with
   * `await`. See the examples for the usage syntax.
   *
   * @method loadJSON
   * @param  {String|Request} path path of the JSON file to be loaded.
   * @param  {Function} [successCallback] function to call once the data is loaded. Will be passed the object.
   * @param  {Function} [errorCallback] function to call if the data fails to load. Will be passed an `Error` event object.
   * @return {Promise<Object>} object containing the loaded data.
   *
   * @example
   *
   * <div>
   * <code>
   * let myData;
   *
   * async function setup() {
   *   myData = await loadJSON('assets/data.json');
   *   createCanvas(100, 100);
   *
   *   background(200);
   *
   *   // Style the circle.
   *   fill(myData.color);
   *   noStroke();
   *
   *   // Draw the circle.
   *   circle(myData.x, myData.y, myData.d);
   *
   *   describe('A pink circle on a gray background.');
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * let myData;
   *
   * async function setup() {
   *   myData = await loadJSON('assets/data.json');
   *   createCanvas(100, 100);
   *
   *   background(200);
   *
   *   // Create a p5.Color object and make it transparent.
   *   let c = color(myData.color);
   *   c.setAlpha(80);
   *
   *   // Style the circles.
   *   fill(c);
   *   noStroke();
   *
   *   // Iterate over the myData.bubbles array.
   *   for (let b of myData.bubbles) {
   *     // Draw a circle for each bubble.
   *     circle(b.x, b.y, b.d);
   *   }
   *
   *   describe('Several pink bubbles floating in a blue sky.');
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * let myData;
   *
   * async function setup() {
   *   myData = await loadJSON('https://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/all_day.geojson');
   *   createCanvas(100, 100);
   *
   *   background(200);
   *
   *   // Get data about the most recent earthquake.
   *   let quake = myData.features[0].properties;
   *
   *   // Draw a circle based on the earthquake's magnitude.
   *   circle(50, 50, quake.mag * 10);
   *
   *   // Style the text.
   *   textAlign(LEFT, CENTER);
   *   textFont('Courier New');
   *   textSize(11);
   *
   *   // Display the earthquake's location.
   *   text(quake.place, 5, 80, 100);
   *
   *   describe(`A white circle on a gray background. The text "${quake.place}" is written beneath the circle.`);
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * let bigQuake;
   *
   * // Load the GeoJSON and preprocess it.
   * async function setup() {
   *   await loadJSON(
   *     'https://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/all_day.geojson',
   *     handleData
   *   );
   *
   *   createCanvas(100, 100);
   *
   *   background(200);
   *
   *   // Draw a circle based on the earthquake's magnitude.
   *   circle(50, 50, bigQuake.mag * 10);
   *
   *   // Style the text.
   *   textAlign(LEFT, CENTER);
   *   textFont('Courier New');
   *   textSize(11);
   *
   *   // Display the earthquake's location.
   *   text(bigQuake.place, 5, 80, 100);
   *
   *   describe(`A white circle on a gray background. The text "${bigQuake.place}" is written beneath the circle.`);
   * }
   *
   * // Find the biggest recent earthquake.
   * function handleData(data) {
   *   let maxMag = 0;
   *   // Iterate over the earthquakes array.
   *   for (let quake of data.features) {
   *     // Reassign bigQuake if a larger
   *     // magnitude quake is found.
   *     if (quake.properties.mag > maxMag) {
   *       bigQuake = quake.properties;
   *     }
   *   }
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * let bigQuake;
   *
   * // Load the GeoJSON and preprocess it.
   * async function setup() {
   *   await loadJSON(
   *     'https://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/all_day.geojson',
   *     handleData,
   *     handleError
   *   );
   *
   *   createCanvas(100, 100);
   *
   *   background(200);
   *
   *   // Draw a circle based on the earthquake's magnitude.
   *   circle(50, 50, bigQuake.mag * 10);
   *
   *   // Style the text.
   *   textAlign(LEFT, CENTER);
   *   textFont('Courier New');
   *   textSize(11);
   *
   *   // Display the earthquake's location.
   *   text(bigQuake.place, 5, 80, 100);
   *
   *   describe(`A white circle on a gray background. The text "${bigQuake.place}" is written beneath the circle.`);
   * }
   *
   * // Find the biggest recent earthquake.
   * function handleData(data) {
   *   let maxMag = 0;
   *   // Iterate over the earthquakes array.
   *   for (let quake of data.features) {
   *     // Reassign bigQuake if a larger
   *     // magnitude quake is found.
   *     if (quake.properties.mag > maxMag) {
   *       bigQuake = quake.properties;
   *     }
   *   }
   * }
   *
   * // Log any errors to the console.
   * function handleError(error) {
   *   console.log('Oops!', error);
   * }
   * </code>
   * </div>
   */
  fn.loadJSON = async function (path, successCallback, errorCallback) {
    // p5._validateParameters('loadJSON', arguments);

    try{
      const { data } = await request(path, 'json');
      if (successCallback) return successCallback(data);
      return data;
    } catch(err) {
      p5._friendlyFileLoadError(5, path);
      if(errorCallback) {
        return errorCallback(err);
      } else {
        throw err;
      }
    }
  };

  /**
   * Loads a text file to create an `Array`.
   *
   * The first parameter, `path`, is always a string with the path to the file.
   * Paths to local files should be relative, as in
   * `loadStrings('assets/data.txt')`. URLs such as
   * `'https://example.com/data.txt'` may be blocked due to browser security.
   * The `path` parameter can also be defined as a [`Request`](https://developer.mozilla.org/en-US/docs/Web/API/Request)
   * object for more advanced usage.
   *
   * The second parameter, `successCallback`, is optional. If a function is
   * passed, as in `loadStrings('assets/data.txt', handleData)`, then the
   * `handleData()` function will be called once the data loads. The array
   * created from the text data will be passed to `handleData()` as its only
   * argument. The return value of the `handleData()` function will be used as
   * the final return value of `loadStrings('assets/data.txt', handleData)`.
   *
   * The third parameter, `failureCallback`, is also optional. If a function is
   * passed, as in `loadStrings('assets/data.txt', handleData, handleFailure)`,
   * then the `handleFailure()` function will be called if an error occurs while
   * loading. The `Error` object will be passed to `handleFailure()` as its only
   * argument. The return value of the `handleFailure()` function will be used as
   * the final return value of `loadStrings('assets/data.txt', handleData, handleFailure)`.
   *
   * This function returns a `Promise` and should be used in an `async` setup with
   * `await`. See the examples for the usage syntax.
   *
   * @method loadStrings
   * @param  {String|Request} path path of the text file to be loaded.
   * @param  {Function} [successCallback] function to call once the data is
   *                                      loaded. Will be passed the array.
   * @param  {Function} [errorCallback] function to call if the data fails to
   *                                    load. Will be passed an `Error` event
   *                                    object.
   * @return {Promise<String[]>} new array containing the loaded text.
   *
   * @example
   *
   * <div>
   * <code>
   * let myData;
   *
   * async function setup() {
   *   myData = await loadStrings('assets/test.txt');
   *
   *   createCanvas(100, 100);
   *
   *   background(200);
   *
   *   // Select a random line from the text.
   *   let phrase = random(myData);
   *
   *   // Style the text.
   *   textAlign(LEFT, CENTER);
   *   textFont('Courier New');
   *   textSize(12);
   *
   *   // Display the text.
   *   text(phrase, 10, 50, 90);
   *
   *   describe(`The text "${phrase}" written in black on a gray background.`);
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * let lastLine;
   *
   * // Load the text and preprocess it.
   * async function setup() {
   *   await loadStrings('assets/test.txt', handleData);
   *
   *   createCanvas(100, 100);
   *
   *   background(200);
   *
   *   // Style the text.
   *   textAlign(LEFT, CENTER);
   *   textFont('Courier New');
   *   textSize(12);
   *
   *   // Display the text.
   *   text(lastLine, 10, 50, 90);
   *
   *   describe('The text "I talk like an orange" written in black on a gray background.');
   * }
   *
   * // Select the last line from the text.
   * function handleData(data) {
   *   lastLine = data[data.length - 1];
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * let lastLine;
   *
   * // Load the text and preprocess it.
   * async function setup() {
   *   await loadStrings('assets/test.txt', handleData, handleError);
   *
   *   createCanvas(100, 100);
   *
   *   background(200);
   *
   *   // Style the text.
   *   textAlign(LEFT, CENTER);
   *   textFont('Courier New');
   *   textSize(12);
   *
   *   // Display the text.
   *   text(lastLine, 10, 50, 90);
   *
   *   describe('The text "I talk like an orange" written in black on a gray background.');
   * }
   *
   * // Select the last line from the text.
   * function handleData(data) {
   *   lastLine = data[data.length - 1];
   * }
   *
   * // Log any errors to the console.
   * function handleError(error) {
   *   console.error('Oops!', error);
   * }
   * </code>
   * </div>
   */
  fn.loadStrings = async function (path, successCallback, errorCallback) {
    // p5._validateParameters('loadStrings', arguments);

    try{
      let { data } = await request(path, 'text');
      data = data.split(/\r?\n/);

      if (successCallback) return successCallback(data);
      return data;
    } catch(err) {
      p5._friendlyFileLoadError(3, path);
      if(errorCallback) {
        return errorCallback(err);
      } else {
        throw err;
      }
    }
  };

  /**
   * Reads the contents of a file or URL and creates a <a href="#/p5.Table">p5.Table</a> object with
   * its values. If a file is specified, it must be located in the sketch's
   * "data" folder. The filename parameter can also be a URL to a file found
   * online. By default, the file is assumed to be comma-separated (in CSV
   * format). Table only looks for a header row if the 'header' option is
   * included.
   *
   * This function returns a `Promise` and should be used in an `async` setup with
   * `await`. See the examples for the usage syntax.
   *
   * All files loaded and saved use UTF-8 encoding. This method is suitable for fetching files up to size of 64MB.
   *
   * @method loadTable
   * @deprecated p5.Table will be removed in a future version of p5.js to make way for a new, friendlier version :)
   * @param  {String|Request} filename    name of the file or URL to load
   * @param  {String}         [separator] the separator character used by the file, defaults to `','`
   * @param  {String}         [header]    "header" to indicate table has header row
   * @param  {Function}       [callback]  function to be executed after
   *                                      <a href="#/p5/loadTable">loadTable()</a> completes. On success, the
   *                                      <a href="#/p5.Table">Table</a> object is passed in as the
   *                                      first argument.
   * @param  {Function}  [errorCallback]  function to be executed if
   *                                      there is an error, response is passed
   *                                      in as first argument
   * @return {Promise<Object>}            <a href="#/p5.Table">Table</a> object containing data
   *
   * @example
   * <div class='norender'>
   * <code>
   * let table;
   *
   * async function setup() {
   *   // Create a 200x200 canvas
   *   createCanvas(200, 200);
   *
   *   // Load the CSV file with a header row
   *   table = await loadTable('assets/mammals.csv', ',', 'header');
   *
   *   // Get the second row (index 1)
   *   let row = table.getRow(1);
   *
   *   // Set text properties
   *   fill(0);       // Set text color to black
   *   textSize(16);  // Adjust text size as needed
   *
   *   // Display each column value in the row on the canvas.
   *   // Using an offset for y-position so each value appears on a new line.
   *   for (let c = 0; c < table.getColumnCount(); c++) {
   *     text(row.getString(c), 10, 30 + c * 20);
   *   }
   * }
   * </code>
   * </div>
   */
  fn.loadTable = async function (path, separator, header, successCallback, errorCallback) {
    if(typeof arguments[arguments.length-1] === 'function'){
      if(typeof arguments[arguments.length-2] === 'function'){
        successCallback = arguments[arguments.length-2];
        errorCallback = arguments[arguments.length-1];
      }else {
        successCallback = arguments[arguments.length-1];
      }
    }

    if(typeof separator !== 'string') separator = ',';
    if(typeof header === 'function') header = false;

    try{
      let { data } = await request(path, 'text');

      let ret = new p5.Table();
      data = parse(data, {
        separator
      });

      if(header){
        ret.columns = data.shift();
      }else {
        ret.columns = Array(data[0].length).fill(null);
      }

      data.forEach((line) => {
        const row = new p5.TableRow(line);
        ret.addRow(row);
      });

      if (successCallback) {
        return successCallback(ret);
      } else {
        return ret;
      }
    } catch(err) {
      p5._friendlyFileLoadError(2, path);
      if(errorCallback) {
        return errorCallback(err);
      } else {
        throw err;
      }
    }
  };

  /**
   * Loads an XML file to create a <a href="#/p5.XML">p5.XML</a> object.
   *
   * Extensible Markup Language
   * (<a href="https://developer.mozilla.org/en-US/docs/Web/XML/XML_introduction" target="_blank">XML</a>)
   * is a standard format for sending data between applications. Like HTML, the
   * XML format is based on tags and attributes, as in
   * `&lt;time units="s"&gt;1234&lt;/time&gt;`.
   *
   * The first parameter, `path`, is always a string with the path to the file.
   * Paths to local files should be relative, as in
   * `loadXML('assets/data.xml')`. URLs such as `'https://example.com/data.xml'`
   * may be blocked due to browser security. The `path` parameter can also be defined
   * as a [`Request`](https://developer.mozilla.org/en-US/docs/Web/API/Request)
   * object for more advanced usage.
   *
   * The second parameter, `successCallback`, is optional. If a function is
   * passed, as in `loadXML('assets/data.xml', handleData)`, then the
   * `handleData()` function will be called once the data loads. The
   * <a href="#/p5.XML">p5.XML</a> object created from the data will be passed
   * to `handleData()` as its only argument. The return value of the `handleData()`
   * function will be used as the final return value of `loadXML('assets/data.xml', handleData)`.
   *
   * The third parameter, `failureCallback`, is also optional. If a function is
   * passed, as in `loadXML('assets/data.xml', handleData, handleFailure)`, then
   * the `handleFailure()` function will be called if an error occurs while
   * loading. The `Error` object will be passed to `handleFailure()` as its only
   * argument. The return value of the `handleFailure()` function will be used as the
   * final return value of `loadXML('assets/data.xml', handleData, handleFailure)`.
   *
   * This function returns a `Promise` and should be used in an `async` setup with
   * `await`. See the examples for the usage syntax.
   *
   * @method loadXML
   * @param  {String|Request} path        path of the XML file to be loaded.
   * @param  {Function} [successCallback] function to call once the data is
   *                                      loaded. Will be passed the
   *                                      <a href="#/p5.XML">p5.XML</a> object.
   * @param  {Function} [errorCallback] function to call if the data fails to
   *                                    load. Will be passed an `Error` event
   *                                    object.
   * @return {Promise<p5.XML>} XML data loaded into a <a href="#/p5.XML">p5.XML</a>
   *                  object.
   *
   * @example
   * <div>
   * <code>
   * let myXML;
   *
   * // Load the XML and create a p5.XML object.
   * async function setup() {
   *   myXML = await loadXML('assets/animals.xml');
   *
   *   createCanvas(100, 100);
   *
   *   background(200);
   *
   *   // Get an array with all mammal tags.
   *   let mammals = myXML.getChildren('mammal');
   *
   *   // Style the text.
   *   textAlign(LEFT, CENTER);
   *   textFont('Courier New');
   *   textSize(14);
   *
   *   // Iterate over the mammals array.
   *   for (let i = 0; i < mammals.length; i += 1) {
   *
   *     // Calculate the y-coordinate.
   *     let y = (i + 1) * 25;
   *
   *     // Get the mammal's common name.
   *     let name = mammals[i].getContent();
   *
   *     // Display the mammal's name.
   *     text(name, 20, y);
   *   }
   *
   *   describe(
   *     'The words "Goat", "Leopard", and "Zebra" written on three separate lines. The text is black on a gray background.'
   *   );
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * let lastMammal;
   *
   * // Load the XML and create a p5.XML object.
   * async function setup() {
   *   await loadXML('assets/animals.xml', handleData);
   *
   *   createCanvas(100, 100);
   *
   *   background(200);
   *
   *   // Style the text.
   *   textAlign(CENTER, CENTER);
   *   textFont('Courier New');
   *   textSize(16);
   *
   *   // Display the content of the last mammal element.
   *   text(lastMammal, 50, 50);
   *
   *   describe('The word "Zebra" written in black on a gray background.');
   * }
   *
   * // Get the content of the last mammal element.
   * function handleData(data) {
   *   // Get an array with all mammal elements.
   *   let mammals = data.getChildren('mammal');
   *
   *   // Get the content of the last mammal.
   *   lastMammal = mammals[mammals.length - 1].getContent();
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * let lastMammal;
   *
   * // Load the XML and preprocess it.
   * async function setup() {
   *   await loadXML('assets/animals.xml', handleData, handleError);
   *
   *   createCanvas(100, 100);
   *
   *   background(200);
   *
   *   // Style the text.
   *   textAlign(CENTER, CENTER);
   *   textFont('Courier New');
   *   textSize(16);
   *
   *   // Display the content of the last mammal element.
   *   text(lastMammal, 50, 50);
   *
   *   describe('The word "Zebra" written in black on a gray background.');
   * }
   *
   * // Get the content of the last mammal element.
   * function handleData(data) {
   *   // Get an array with all mammal elements.
   *   let mammals = data.getChildren('mammal');
   *
   *   // Get the content of the last mammal.
   *   lastMammal = mammals[mammals.length - 1].getContent();
   * }
   *
   * // Log any errors to the console.
   * function handleError(error) {
   *   console.error('Oops!', error);
   * }
   * </code>
   * </div>
   */
  fn.loadXML = async function (path, successCallback, errorCallback) {
    try{
      const parser = new DOMParser();

      let { data } = await request(path, 'text');
      const parsedDOM = parser.parseFromString(data, 'application/xml');
      data = new p5.XML(parsedDOM);

      if (successCallback) return successCallback(data);
      return data;
    } catch(err) {
      p5._friendlyFileLoadError(1, path);
      if(errorCallback) {
        return errorCallback(err);
      } else {
        throw err;
      }
    }
  };

  /**
   * This method is suitable for fetching files up to size of 64MB.
   *
   * @method loadBytes
   * @param {String|Request}   file            name of the file or URL to load
   * @param {Function} [callback]      function to be executed after <a href="#/p5/loadBytes">loadBytes()</a>
   *                                    completes
   * @param {Function} [errorCallback] function to be executed if there
   *                                    is an error
   * @returns {Promise<Uint8Array>} a Uint8Array containing the loaded buffer
   *
   * @example
   *
   * <div>
   * <code>
   * let data;
   *
   * async function setup() {
   * createCanvas(100, 100); // Create a canvas
   * data = await loadBytes('assets/mammals.xml'); // Load the bytes from the XML file
   *
   * background(255); // Set a white background
   * fill(0);       // Set text color to black
   *
   * // Display the first 5 byte values on the canvas in hexadecimal format
   * for (let i = 0; i < 5; i++) {
   * let byteHex = data[i].toString(16);
   * text(byteHex, 10, 18 * (i + 1)); // Adjust spacing as needed
   * }
   *
   * describe('no image displayed, displays first 5 bytes of mammals.xml in hexadecimal format');
   * }
   * </code>
   * </div>
   */

  fn.loadBytes = async function (path, successCallback, errorCallback) {
    try{
      let { data } = await request(path, 'arrayBuffer');
      data = new Uint8Array(data);
      if (successCallback) return successCallback(data);
      return data;
    } catch(err) {
      p5._friendlyFileLoadError(6, path);
      if(errorCallback) {
        return errorCallback(err);
      } else {
        throw err;
      }
    }
  };

  /**
   * Loads a file at the given path as a Blob, then returns the resulting data or
   * passes it to a success callback function, if provided. On load, this function
   * returns a `Promise` that resolves to a Blob containing the file data.
   *
   * @method loadBlob
   * @param {String|Request} path - The path or Request object pointing to the file
   *                                you want to load.
   * @param {Function} [successCallback] - Optional. A function to be called if the
   *                                       file successfully loads, receiving the
   *                                       resulting Blob as its only argument.
   * @param {Function} [errorCallback] - Optional. A function to be called if an
   *                                     error occurs during loading; receives the
   *                                     error object as its only argument.
   * @returns {Promise<Blob>} A promise that resolves with the loaded Blob.
   *
   * @example
   * <div>
   * <code>
   * let myBlob;
   *
   * async function setup() {
   *   createCanvas(200, 200);
   *   background(220);
   *   try {
   *     // 1. Load an image file as a Blob.
   *     myBlob = await loadBlob('assets/flower-1.png');
   *
   *     // 2. Convert the Blob into an object URL.
   *     const objectUrl = URL.createObjectURL(myBlob);
   *
   *     // 3. Load that object URL into a p5.Image.
   *     loadImage(objectUrl, (img) => {
   *       // 4. Display the loaded image.
   *       image(img, 0, 0, width, height);
   *     });
   *   } catch (err) {
   *     console.error('Error loading blob:', err);
   *   }
   * }
   * </code>
   * </div>
   */
  fn.loadBlob = async function(path, successCallback, errorCallback) {
    try{
      const { data } = await request(path, 'blob');
      if (successCallback) return successCallback(data);
      return data;
    } catch(err) {
      if(errorCallback) {
        return errorCallback(err);
      } else {
        throw err;
      }
    }
  };

  /**
   * Method for executing an HTTP GET request. If data type is not specified,
   * it will default to `'text'`. This is equivalent to
   * calling <code>httpDo(path, 'GET')</code>. The 'binary' datatype will return
   * a Blob object, and the 'arrayBuffer' datatype will return an ArrayBuffer
   * which can be used to initialize typed arrays (such as Uint8Array).
   *
   * @method httpGet
   * @param  {String|Request}        path       name of the file or url to load
   * @param  {String}        [datatype] "json", "jsonp", "binary", "arrayBuffer",
   *                                    "xml", or "text"
   * @param  {Function}      [callback] function to be executed after
   *                                    <a href="#/p5/httpGet">httpGet()</a> completes, data is passed in
   *                                    as first argument
   * @param  {Function}      [errorCallback] function to be executed if
   *                                    there is an error, response is passed
   *                                    in as first argument
   * @return {Promise} A promise that resolves with the data when the operation
   *                   completes successfully or rejects with the error after
   *                   one occurs.
   * @example
   * <div class='norender'><code>
   * // Examples use USGS Earthquake API:
   * //   https://earthquake.usgs.gov/fdsnws/event/1/#methods
   * let earthquakes;
   * async function setup() {
   *   // Get the most recent earthquake in the database
   *   let url =
      'https://earthquake.usgs.gov/fdsnws/event/1/query?' +
   *     'format=geojson&limit=1&orderby=time';
   *   earthquakes = await httpGet(url, 'json');
   * }
   *
   * function draw() {
   *   if (!earthquakes) {
   *     // Wait until the earthquake data has loaded before drawing.
   *     return;
   *   }
   *   background(200);
   *   // Get the magnitude and name of the earthquake out of the loaded JSON
   *   let earthquakeMag = earthquakes.features[0].properties.mag;
   *   let earthquakeName = earthquakes.features[0].properties.place;
   *   ellipse(width / 2, height / 2, earthquakeMag * 10, earthquakeMag * 10);
   *   textAlign(CENTER);
   *   text(earthquakeName, 0, height - 30, width, 30);
   *   noLoop();
   * }
   * </code></div>
   */
  /**
   * @method httpGet
   * @param  {String|Request}  path
   * @param  {Function}        callback
   * @param  {Function}        [errorCallback]
   * @return {Promise}
   */
  fn.httpGet = async function (path, datatype='text', successCallback, errorCallback) {
    // p5._validateParameters('httpGet', arguments);

    if (typeof datatype === 'function') {
      errorCallback = successCallback;
      successCallback = datatype;
      datatype = 'text';
    }

    // This is like a more primitive version of the other load functions.
    // If the user wanted to customize more behavior, pass in Request to path.

    return this.httpDo(path, 'GET', datatype, successCallback, errorCallback);
  };

  /**
   * Method for executing an HTTP POST request. If data type is not specified,
   * it will default to `'text'`. This is equivalent to
   * calling <code>httpDo(path, 'POST')</code>.
   *
   * @method httpPost
   * @param  {String|Request} path       name of the file or url to load
   * @param  {Object|Boolean} [data]     param data passed sent with request
   * @param  {String}         [datatype] "json", "jsonp", "xml", or "text".
   *                                    If omitted, <a href="#/p5/httpPost">httpPost()</a> will guess.
   * @param  {Function}       [callback] function to be executed after
   *                                     <a href="#/p5/httpPost">httpPost()</a> completes, data is passed in
   *                                     as first argument
   * @param  {Function}       [errorCallback] function to be executed if
   *                                          there is an error, response is passed
   *                                          in as first argument
   * @return {Promise} A promise that resolves with the data when the operation
   *                   completes successfully or rejects with the error after
   *                   one occurs.
   *
   * @example
   * <div>
   * <code>
   * // Examples use jsonplaceholder.typicode.com for a Mock Data API
   *
   * let url = 'https://jsonplaceholder.typicode.com/posts';
   * let postData = { userId: 1, title: 'p5 Clicked!', body: 'p5.js is very cool.' };
   *
   * function setup() {
   *   createCanvas(100, 100);
   *   background(200);
   * }
   *
   * function mousePressed() {
   *   httpPost(url, postData, 'json', function(result) {
   *     strokeWeight(2);
   *     text(result.body, mouseX, mouseY);
   *   });
   * }
   * </code>
   * </div>
   *
   * <div><code>
   * let url = 'ttps://invalidURL'; // A bad URL that will cause errors
   * let postData = { title: 'p5 Clicked!', body: 'p5.js is very cool.' };
   *
   * function setup() {
   *   createCanvas(100, 100);
   *   background(200);
   * }
   *
   * function mousePressed() {
   *   httpPost(
   *     url,
   *     postData,
   *     'json',
   *     function(result) {
   *       // ... won't be called
   *     },
   *     function(error) {
   *       strokeWeight(2);
   *       text(error.toString(), mouseX, mouseY);
   *     }
   *   );
   * }
   * </code></div>
   */
  /**
   * @method httpPost
   * @param  {String|Request}    path
   * @param  {Object|Boolean}    data
   * @param  {Function}         [callback]
   * @param  {Function}         [errorCallback]
   * @return {Promise}
   */
  /**
   * @method httpPost
   * @param  {String|Request}    path
   * @param  {Function}         [callback]
   * @param  {Function}         [errorCallback]
   * @return {Promise}
   */
  fn.httpPost = async function (path, data, datatype='text', successCallback, errorCallback) {
    // p5._validateParameters('httpPost', arguments);

    // This behave similarly to httpGet and additional options should be passed
    // as a `Request`` to path. Both method and body will be overridden.
    // Will try to infer correct Content-Type for given data.

    if (typeof data === 'function') {
      // Assume both data and datatype are functions as data should not be function
      successCallback = data;
      errorCallback = datatype;
      data = undefined;
      datatype = 'text';

    } else if (typeof datatype === 'function') {
      // Data is provided but not datatype\
      errorCallback = successCallback;
      successCallback = datatype;
      datatype = 'text';
    }

    let reqData = data;
    let contentType = 'text/plain';
    // Normalize data
    if(data instanceof p5.XML) {
      reqData = data.serialize();
      contentType = 'application/xml';

    } else if(data instanceof p5.Image) {
      reqData = await data.toBlob();
      contentType = 'image/png';

    } else if (typeof data === 'object') {
      reqData = JSON.stringify(data);
      contentType = 'application/json';
    }

    const requestOptions = {
      method: 'POST',
      body: reqData,
      headers: {
        'Content-Type': contentType
      }
    };

    if (reqData) {
      requestOptions.body = reqData;
    }

    const req = new Request(path, requestOptions);

    return this.httpDo(req, 'POST', datatype, successCallback, errorCallback);
  };

  /**
   * Method for executing an HTTP request. If data type is not specified,
   * it will default to `'text'`.
   *
   * This function is meant for more advanced usage of HTTP requests in p5.js. It is
   * best used when a [`Request`](https://developer.mozilla.org/en-US/docs/Web/API/Request)
   * object is passed to the `path` parameter.
   *
   * This method is suitable for fetching files up to size of 64MB when "GET" is used.
   *
   * @method httpDo
   * @param  {String|Request}   path      name of the file or url to load
   * @param  {String}           [method]    either "GET", "POST", "PUT", "DELETE",
   *                                      or other HTTP request methods
   * @param  {String}          [datatype] "json", "jsonp", "xml", or "text"
   * @param  {Object}          [data]     param data passed sent with request
   * @param  {Function}        [callback] function to be executed after
   *                                      <a href="#/p5/httpGet">httpGet()</a> completes, data is passed in
   *                                      as first argument
   * @param  {Function}        [errorCallback] function to be executed if
   *                                      there is an error, response is passed
   *                                      in as first argument
   * @return {Promise} A promise that resolves with the data when the operation
   *                   completes successfully or rejects with the error after
   *                   one occurs.
   *
   * @example
   * <div>
   * <code>
   * // Examples use USGS Earthquake API:
   * // https://earthquake.usgs.gov/fdsnws/event/1/#methods
   *
   * // displays an animation of all USGS earthquakes
   * let earthquakes;
   * let eqFeatureIndex = 0;
   *
   * function setup() {
   *  createCanvas(100,100);
   * 
   *   let url = 'https://earthquake.usgs.gov/fdsnws/event/1/query?format=geojson';
   * 
   *   const req = new Request(url, {
   *    method: 'GET',
   *    headers: {authorization: 'Bearer secretKey'}
   *  });
   *  // httpDo(path, method, datatype, success, error) 
   * 
   *   httpDo(
   *     req,
   *     'GET',
   *    'json',
   *     res => {
   *      earthquakes = res;
   *     },
   *    err => {
   *      console.error('Error loading data:', err);
   *    }
   *  );
   * }
   * 
   * function draw() {
   *   // wait until the data is loaded
   *   if (!earthquakes || !earthquakes.features[eqFeatureIndex]) {
   *     return;
   *   }
   *   clear();
   *
   *   let feature = earthquakes.features[eqFeatureIndex];
   *   let mag = feature.properties.mag;
   *   let rad = mag / 11 * ((width + height) / 2);
   *   fill(255, 0, 0, 100);
   *   ellipse(width / 2 + random(-2, 2), height / 2 + random(-2, 2), rad, rad);
   *
   *   if (eqFeatureIndex >= earthquakes.features.length) {
   *     eqFeatureIndex = 0;
   *   } else {
   *     eqFeatureIndex += 1;
   *   }
   * }
   * </code>
   * </div>
   */
  /**
   * @method httpDo
   * @param  {String|Request}    path
   * @param  {Function}         [callback]
   * @param  {Function}         [errorCallback]
   * @return {Promise}
   */
  fn.httpDo = async function (path, method, datatype, successCallback, errorCallback) {
    // This behave similarly to httpGet but even more primitive. The user
    // will most likely want to pass in a Request to path, the only convenience
    // is that datatype will be taken into account to parse the response.

    if(typeof datatype === 'function'){
      errorCallback = successCallback;
      successCallback = datatype;
      datatype = undefined;
    }

    // Try to infer data type if it is defined
    if(!datatype){
      const extension = typeof path === 'string' ?
        path.split(".").pop() :
        path.url.split(".").pop();
      switch(extension) {
        case 'json':
          datatype = 'json';
          break;

        case 'jpg':
        case 'jpeg':
        case 'png':
        case 'webp':
        case 'gif':
          datatype = 'blob';
          break;

        case 'xml':
          // NOTE: still need to normalize type handling/mapping
          // datatype = 'xml';
        case 'txt':
        default:
          datatype = 'text';
      }
    }

    const req = new Request(path, {
      method
    });

    try{
      const { data } = await request(req, datatype);
      if (successCallback) {
        return successCallback(data);
      } else {
        return data;
      }
    } catch(err) {
      if(errorCallback) {
        return errorCallback(err);
      } else {
        throw err;
      }
    }
  };

  /**
   * @module IO
   * @submodule Output
   * @for p5
   */
  // private array of p5.PrintWriter objects
  fn._pWriters = [];

  /**
   * Creates a new <a href="#/p5.PrintWriter">p5.PrintWriter</a> object.
   *
   * <a href="#/p5.PrintWriter">p5.PrintWriter</a> objects provide a way to
   * save a sequence of text data, called the *print stream*, to the user's
   * computer. They're low-level objects that enable precise control of text
   * output. Functions such as
   * <a href="#/p5/saveStrings">saveStrings()</a> and
   * <a href="#/p5/saveJSON">saveJSON()</a> are easier to use for simple file
   * saving.
   *
   * The first parameter, `filename`, is the name of the file to be written. If
   * a string is passed, as in `createWriter('words.txt')`, a new
   * <a href="#/p5.PrintWriter">p5.PrintWriter</a> object will be created that
   * writes to a file named `words.txt`.
   *
   * The second parameter, `extension`, is optional. If a string is passed, as
   * in `createWriter('words', 'csv')`, the first parameter will be interpreted
   * as the file name and the second parameter as the extension.
   *
   * @method createWriter
   * @param {String} name name of the file to create.
   * @param {String} [extension] format to use for the file.
   * @return {p5.PrintWriter} stream for writing data.
   *
   * @example
   * <div>
   * <code>
   * function setup() {
   *   createCanvas(100, 100);
   *
   *   background(200);
   *
   *   // Style the text.
   *   textAlign(LEFT, CENTER);
   *   textFont('Courier New');
   *   textSize(12);
   *
   *   // Display instructions.
   *   text('Double-click to save', 5, 50, 90);
   *
   *   describe('The text "Double-click to save" written in black on a gray background.');
   * }
   *
   * // Save the file when the user double-clicks.
   * function doubleClicked() {
   *   if (mouseX > 0 && mouseX < 100 && mouseY > 0 && mouseY < 100) {
   *     // Create a p5.PrintWriter object.
   *     let myWriter = createWriter('xo.txt');
   *
   *     // Add some lines to the print stream.
   *     myWriter.print('XOO');
   *     myWriter.print('OXO');
   *     myWriter.print('OOX');
   *
   *     // Save the file and close the print stream.
   *     myWriter.close();
   *   }
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * function setup() {
   *   createCanvas(100, 100);
   *
   *   background(200);
   *
   *   // Style the text.
   *   textAlign(LEFT, CENTER);
   *   textFont('Courier New');
   *   textSize(12);
   *
   *   // Display instructions.
   *   text('Double-click to save', 5, 50, 90);
   *
   *   describe('The text "Double-click to save" written in black on a gray background.');
   * }
   *
   * // Save the file when the user double-clicks.
   * function doubleClicked() {
   *   if (mouseX > 0 && mouseX < 100 && mouseY > 0 && mouseY < 100) {
   *     // Create a p5.PrintWriter object.
   *     // Use the file format .csv.
   *     let myWriter = createWriter('mauna_loa_co2', 'csv');
   *
   *     // Add some lines to the print stream.
   *     myWriter.print('date,ppm_co2');
   *     myWriter.print('1960-01-01,316.43');
   *     myWriter.print('1970-01-01,325.06');
   *     myWriter.print('1980-01-01,337.9');
   *     myWriter.print('1990-01-01,353.86');
   *     myWriter.print('2000-01-01,369.45');
   *     myWriter.print('2020-01-01,413.61');
   *
   *     // Save the file and close the print stream.
   *     myWriter.close();
   *   }
   * }
   * </code>
   * </div>
   */
  fn.createWriter = function (name, extension) {
    let newPW;
    // check that it doesn't already exist
    for (const i in fn._pWriters) {
      if (fn._pWriters[i].name === name) {
        // if a p5.PrintWriter w/ this name already exists...
        // return fn._pWriters[i]; // return it w/ contents intact.
        // or, could return a new, empty one with a unique name:
        newPW = new p5.PrintWriter(name + this.millis(), extension);
        fn._pWriters.push(newPW);
        return newPW;
      }
    }
    newPW = new p5.PrintWriter(name, extension);
    fn._pWriters.push(newPW);
    return newPW;
  };

  /**
   * A class to describe a print stream.
   *
   * Each `p5.PrintWriter` object provides a way to save a sequence of text
   * data, called the *print stream*, to the user's computer. It's a low-level
   * object that enables precise control of text output. Functions such as
   * <a href="#/p5/saveStrings">saveStrings()</a> and
   * <a href="#/p5/saveJSON">saveJSON()</a> are easier to use for simple file
   * saving.
   *
   * Note: <a href="#/p5/createWriter">createWriter()</a> is the recommended way
   * to make an instance of this class.
   *
   * @class p5.PrintWriter
   * @param  {String} filename name of the file to create.
   * @param  {String} [extension] format to use for the file.
   *
   * @example
   * <div>
   * <code>
   * function setup() {
   *   createCanvas(100, 100);
   *
   *   background(200);
   *
   *   // Style the text.
   *   textAlign(LEFT, CENTER);
   *   textFont('Courier New');
   *   textSize(12);
   *
   *   // Display instructions.
   *   text('Double-click to save', 5, 50, 90);
   *
   *   describe('The text "Double-click to save" written in black on a gray background.');
   * }
   *
   * // Save the file when the user double-clicks.
   * function doubleClicked() {
   *   // Create a p5.PrintWriter object.
   *   let myWriter = createWriter('xo.txt');
   *
   *   // Add some lines to the print stream.
   *   myWriter.print('XOO');
   *   myWriter.print('OXO');
   *   myWriter.print('OOX');
   *
   *   // Save the file and close the print stream.
   *   myWriter.close();
   * }
   * </code>
   * </div>
   */
  p5.PrintWriter = function (filename, extension) {
    let self = this;
    this.name = filename;
    this.content = '';

    /**
     * Writes data to the print stream without adding new lines.
     *
     * The parameter, `data`, is the data to write. `data` can be a number or
     * string, as in `myWriter.write('hi')`, or an array of numbers and strings,
     * as in `myWriter.write([1, 2, 3])`. A comma will be inserted between array
     * array elements when they're added to the print stream.
     *
     * @method write
     * @param {String|Number|Array} data data to be written as a string, number,
     *                                   or array of strings and numbers.
     *
     * @example
     * <div>
     * <code>
     * function setup() {
     *   createCanvas(100, 100);
     *
     *   background(200);
     *
     *   // Style the text.
     *   textAlign(LEFT, CENTER);
     *   textFont('Courier New');
     *   textSize(12);
     *
     *   // Display instructions.
     *   text('Double-click to save', 5, 50, 90);
     *
     *   describe('The text "Double-click to save" written in black on a gray background.');
     * }
     *
     * // Save the file when the user double-clicks.
     * function doubleClicked() {
     *   // Create a p5.PrintWriter object.
     *   let myWriter = createWriter('numbers.txt');
     *
     *   // Add some data to the print stream.
     *   myWriter.write('1,2,3,');
     *   myWriter.write(['4', '5', '6']);
     *
     *   // Save the file and close the print stream.
     *   myWriter.close();
     * }
     * </code>
     * </div>
     */
    this.write = function (data) {
      this.content += data;
    };

    /**
     * Writes data to the print stream with new lines added.
     *
     * The parameter, `data`, is the data to write. `data` can be a number or
     * string, as in `myWriter.print('hi')`, or an array of numbers and strings,
     * as in `myWriter.print([1, 2, 3])`. A comma will be inserted between array
     * array elements when they're added to the print stream.
     *
     * @method print
     * @param {String|Number|Array} data data to be written as a string, number,
     *                                   or array of strings and numbers.
     *
     * @example
     * <div>
     * <code>
     * function setup() {
     *   createCanvas(100, 100);
     *
     *   background(200);
     *
     *   // Style the text.
     *   textAlign(LEFT, CENTER);
     *   textFont('Courier New');
     *   textSize(12);
     *
     *   // Display instructions.
     *   text('Double-click to save', 5, 50, 90);
     *
     *   describe('The text "Double-click to save" written in black on a gray background.');
     * }
     *
     * // Save the file when the user double-clicks.
     * function doubleClicked() {
     *   // Create a p5.PrintWriter object.
     *   let myWriter = createWriter('numbers.txt');
     *
     *   // Add some data to the print stream.
     *   myWriter.print('1,2,3,');
     *   myWriter.print(['4', '5', '6']);
     *
     *   // Save the file and close the print stream.
     *   myWriter.close();
     * }
     * </code>
     * </div>
     */
    this.print = function (data) {
      this.content += `${data}\n`;
    };

    /**
     * Clears all data from the print stream.
     *
     * @method clear
     *
     * @example
     * <div>
     * <code>
     * function setup() {
     *   createCanvas(100, 100);
     *
     *   background(200);
     *
     *   // Style the text.
     *   textAlign(LEFT, CENTER);
     *   textFont('Courier New');
     *   textSize(12);
     *
     *   // Display instructions.
     *   text('Double-click to save', 5, 50, 90);
     *
     *   describe('The text "Double-click to save" written in black on a gray background.');
     * }
     *
     * // Save the file when the user double-clicks.
     * function doubleClicked() {
     *   // Create a p5.PrintWriter object.
     *   let myWriter = createWriter('numbers.txt');
     *
     *   // Add some data to the print stream.
     *   myWriter.print('Hello p5*js!');
     *
     *   // Clear the print stream.
     *   myWriter.clear();
     *
     *   // Save the file and close the print stream.
     *   myWriter.close();
     * }
     * </code>
     * </div>
     */
    this.clear = function () {
      this.content = '';
    };

    /**
     * Saves the file and closes the print stream.
     *
     * @method close
     *
     * @example
     * <div>
     * <code>
     * function setup() {
     *   createCanvas(100, 100);
     *
     *   background(200);
     *
     *   // Style the text.
     *   textAlign(LEFT, CENTER);
     *   textFont('Courier New');
     *   textSize(12);
     *
     *   // Display instructions.
     *   text('Double-click to save', 5, 50, 90);
     *
     *   describe('The text "Double-click to save" written in black on a gray background.');
     * }
     *
     * // Save the file when the user double-clicks.
     * function doubleClicked() {
     *   // Create a p5.PrintWriter object.
     *   let myWriter = createWriter('cat.txt');
     *
     *   // Add some data to the print stream.
     *   // ASCII art courtesy Wikipedia:
     *   // https://en.wikipedia.org/wiki/ASCII_art
     *   myWriter.print(' (\\_/) ');
     *   myWriter.print("(='.'=)");
     *   myWriter.print('(")_(")');
     *
     *   // Save the file and close the print stream.
     *   myWriter.close();
     * }
     * </code>
     * </div>
     */
    this.close = function () {
      // convert String to Array for the writeFile Blob
      const arr = [];
      arr.push(this.content);
      fn.writeFile(arr, filename, extension);
      // remove from _pWriters array and delete self
      for (const i in fn._pWriters) {
        if (fn._pWriters[i].name === this.name) {
          // remove from _pWriters array
          fn._pWriters.splice(i, 1);
        }
      }
      self.clear();
      self = {};
    };
  };

  /**
   * @module IO
   * @submodule Output
   * @for p5
   */

  // object, filename, options --> saveJSON, saveStrings,
  // filename, [extension] [canvas] --> saveImage

  /**
   *  Saves a given element(image, text, json, csv, wav, or html) to the client's
   *  computer. The first parameter can be a pointer to element we want to save.
   *  The element can be one of <a href="#/p5.Element">p5.Element</a>,an Array of
   *  Strings, an Array of JSON, a JSON object, a <a href="#/p5.Table">p5.Table
   *  </a>, a <a href="#/p5.Image">p5.Image</a>, or a p5.SoundFile (requires
   *  p5.sound). The second parameter is a filename (including extension).The
   *  third parameter is for options specific to this type of object. This method
   *  will save a file that fits the given parameters.
   *  If it is called without specifying an element, by default it will save the
   *  whole canvas as an image file. You can optionally specify a filename as
   *  the first parameter in such a case.
   *  **Note that it is not recommended to
   *  call this method within draw, as it will open a new save dialog on every
   *  render.**
   *
   * @method save
   * @param  {Object|String} [objectOrFilename]  If filename is provided, will
   *                                             save canvas as an image with
   *                                             either png or jpg extension
   *                                             depending on the filename.
   *                                             If object is provided, will
   *                                             save depending on the object
   *                                             and filename (see examples
   *                                             above).
   * @param  {String} [filename] If an object is provided as the first
   *                               parameter, then the second parameter
   *                               indicates the filename,
   *                               and should include an appropriate
   *                               file extension (see examples above).
   * @param  {Boolean|String} [options]  Additional options depend on
   *                            filetype. For example, when saving JSON,
   *                            <code>true</code> indicates that the
   *                            output will be optimized for filesize,
   *                            rather than readability.
   *
   * @example
   * <div class="norender"><code>
   * // Saves the canvas as an image
   * cnv = createCanvas(300, 300);
   * save(cnv, 'myCanvas.jpg');
   *
   * // Saves the canvas as an image by default
   * save('myCanvas.jpg');
   * describe('An example for saving a canvas as an image.');
   * </code></div>
   *
   * <div class="norender"><code>
   * // Saves p5.Image as an image
   * img = createImage(10, 10);
   * save(img, 'myImage.png');
   * describe('An example for saving a p5.Image element as an image.');
   * </code></div>
   *
   * <div class="norender"><code>
   * // Saves p5.Renderer object as an image
   * obj = createGraphics(100, 100);
   * save(obj, 'myObject.png');
   * describe('An example for saving a p5.Renderer element.');
   * </code></div>
   *
   * <div class="norender"><code>
   * let myTable = new p5.Table();
   * // Saves table as html file
   * save(myTable, 'myTable.html');
   *
   * // Comma Separated Values
   * save(myTable, 'myTable.csv');
   *
   * // Tab Separated Values
   * save(myTable, 'myTable.tsv');
   *
   * describe(`An example showing how to save a table in formats of
   *   HTML, CSV and TSV.`);
   * </code></div>
   *
   * <div class="norender"><code>
   * let myJSON = { a: 1, b: true };
   *
   * // Saves pretty JSON
   * save(myJSON, 'my.json');
   *
   * // Optimizes JSON filesize
   * save(myJSON, 'my.json', true);
   *
   * describe('An example for saving JSON to a txt file with some extra arguments.');
   * </code></div>
   *
   * <div class="norender"><code>
   * // Saves array of strings to text file with line breaks after each item
   * let arrayOfStrings = ['a', 'b'];
   * save(arrayOfStrings, 'my.txt');
   * describe(`An example for saving an array of strings to text file
   *   with line breaks.`);
   * </code></div>
   */
  fn.save = function (object, _filename, _options) {
    // TODO: parameters is not used correctly
    // parse the arguments and figure out which things we are saving
    const args = arguments;
    // =================================================
    // OPTION 1: saveCanvas...

    // if no arguments are provided, save canvas
    const cnv = this._curElement ? this._curElement.elt : this.elt;
    if (args.length === 0) {
      fn.saveCanvas(cnv);
      return;

    } else if (args[0] instanceof Renderer || args[0] instanceof Graphics) {
      // otherwise, parse the arguments
      // if first param is a p5Graphics, then saveCanvas
      fn.saveCanvas(args[0].canvas, args[1], args[2]);
      return;

    } else if (args.length === 1 && typeof args[0] === 'string') {
      // if 1st param is String and only one arg, assume it is canvas filename
      fn.saveCanvas(cnv, args[0]);

    } else {
      // =================================================
      // OPTION 2: extension clarifies saveStrings vs. saveJSON
      const extension = _checkFileExtension(args[1], args[2])[1];
      switch (extension) {
        case 'json':
          fn.saveJSON(args[0], args[1], args[2]);
          return;
        case 'txt':
          fn.saveStrings(args[0], args[1], args[2]);
          return;
        // =================================================
        // OPTION 3: decide based on object...
        default:
          if (args[0] instanceof Array) {
            fn.saveStrings(args[0], args[1], args[2]);
          } else if (args[0] instanceof p5.Table) {
            fn.saveTable(args[0], args[1], args[2]);
          } else if (args[0] instanceof p5.Image) {
            fn.saveCanvas(args[0].canvas, args[1]);
          } else if (args[0] instanceof p5.SoundFile) {
            fn.saveSound(args[0], args[1], args[2], args[3]);
          }
      }
    }
  };

  /**
   * Saves an `Object` or `Array` to a JSON file.
   *
   * JavaScript Object Notation
   * (<a href="https://developer.mozilla.org/en-US/docs/Glossary/JSON" target="_blank">JSON</a>)
   * is a standard format for sending data between applications. The format is
   * based on JavaScript objects which have keys and values. JSON files store
   * data in an object with strings as keys. Values can be strings, numbers,
   * Booleans, arrays, `null`, or other objects.
   *
   * The first parameter, `json`, is the data to save. The data can be an array,
   * as in `[1, 2, 3]`, or an object, as in
   * `{ x: 50, y: 50, color: 'deeppink' }`.
   *
   * The second parameter, `filename`, is a string that sets the file's name.
   * For example, calling `saveJSON([1, 2, 3], 'data.json')` saves the array
   * `[1, 2, 3]` to a file called `data.json` on the user's computer.
   *
   * The third parameter, `optimize`, is optional. If `true` is passed, as in
   * `saveJSON([1, 2, 3], 'data.json', true)`, then all unneeded whitespace will
   * be removed to reduce the file size.
   *
   * Note: The browser will either save the file immediately or prompt the user
   * with a dialogue window.
   *
   * @method saveJSON
   * @param  {Array|Object} json data to save.
   * @param  {String} filename name of the file to be saved.
   * @param  {Boolean} [optimize] whether to trim unneeded whitespace. Defaults
   *                              to `true`.
   *
   * @example
   * <div>
   * <code>
   * function setup() {
   *   createCanvas(100, 100);
   *
   *   background(200);
   *
   *   // Style the text.
   *   textAlign(LEFT, CENTER);
   *   textFont('Courier New');
   *   textSize(12);
   *
   *   // Display instructions.
   *   text('Double-click to save', 5, 50, 90);
   *
   *   describe('The text "Double-click to save" written in black on a gray background.');
   * }
   *
   * // Save the file when the user double-clicks.
   * function doubleClicked() {
   *   if (mouseX > 0 && mouseX < 100 && mouseY > 0 && mouseY < 100) {
   *     // Create an array.
   *     let data = [1, 2, 3];
   *
   *     // Save the JSON file.
   *     saveJSON(data, 'numbers.json');
   *   }
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * function setup() {
   *   createCanvas(100, 100);
   *
   *   background(200);
   *
   *   // Style the text.
   *   textAlign(LEFT, CENTER);
   *   textFont('Courier New');
   *   textSize(12);
   *
   *   // Display instructions.
   *   text('Double-click to save', 5, 50, 90);
   *
   *   describe('The text "Double-click to save" written in black on a gray background.');
   * }
   *
   * // Save the file when the user double-clicks.
   * function doubleClicked() {
   *   if (mouseX > 0 && mouseX < 100 && mouseY > 0 && mouseY < 100) {
   *     // Create an object.
   *     let data = { x: mouseX, y: mouseY };
   *
   *     // Save the JSON file.
   *     saveJSON(data, 'state.json');
   *   }
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * function setup() {
   *   createCanvas(100, 100);
   *
   *   background(200);
   *
   *   // Style the text.
   *   textAlign(LEFT, CENTER);
   *   textFont('Courier New');
   *   textSize(12);
   *
   *   // Display instructions.
   *   text('Double-click to save', 5, 50, 90);
   *
   *   describe('The text "Double-click to save" written in black on a gray background.');
   * }
   *
   * // Save the file when the user double-clicks.
   * function doubleClicked() {
   *   if (mouseX > 0 && mouseX < 100 && mouseY > 0 && mouseY < 100) {
   *     // Create an object.
   *     let data = { x: mouseX, y: mouseY };
   *
   *     // Save the JSON file and reduce its size.
   *     saveJSON(data, 'state.json', true);
   *   }
   * }
   * </code>
   * </div>
   */
  fn.saveJSON = function (json, filename, optimize) {
    // p5._validateParameters('saveJSON', arguments);
    let stringify;
    if (optimize) {
      stringify = JSON.stringify(json);
    } else {
      stringify = JSON.stringify(json, undefined, 2);
    }
    this.saveStrings(stringify.split('\n'), filename, 'json');
  };

  /**
   * Saves an `Array` of `String`s to a file, one per line.
   *
   * The first parameter, `list`, is an array with the strings to save.
   *
   * The second parameter, `filename`, is a string that sets the file's name.
   * For example, calling `saveStrings(['0', '01', '011'], 'data.txt')` saves
   * the array `['0', '01', '011']` to a file called `data.txt` on the user's
   * computer.
   *
   * The third parameter, `extension`, is optional. If a string is passed, as in
   * `saveStrings(['0', '01', '0`1'], 'data', 'txt')`, the second parameter will
   * be interpreted as the file name and the third parameter as the extension.
   *
   * The fourth parameter, `isCRLF`, is also optional, If `true` is passed, as
   * in `saveStrings(['0', '01', '011'], 'data', 'txt', true)`, then two
   * characters, `\r\n` , will be added to the end of each string to create new
   * lines in the saved file. `\r` is a carriage return (CR) and `\n` is a line
   * feed (LF). By default, only `\n` (line feed) is added to each string in
   * order to create new lines.
   *
   * Note: The browser will either save the file immediately or prompt the user
   * with a dialogue window.
   *
   *  @method saveStrings
   *  @param  {String[]} list data to save.
   *  @param  {String} filename name of file to be saved.
   *  @param  {String} [extension] format to use for the file.
   *  @param  {Boolean} [isCRLF] whether to add `\r\n` to the end of each
   *                             string. Defaults to `false`.
   *
   * @example
   * <div>
   * <code>
   * function setup() {
   *   createCanvas(100, 100);
   *
   *   background(200);
   *
   *   // Style the text.
   *   textAlign(LEFT, CENTER);
   *   textFont('Courier New');
   *   textSize(12);
   *
   *   // Display instructions.
   *   text('Double-click to save', 5, 50, 90);
   *
   *   describe('The text "Double-click to save" written in black on a gray background.');
   * }
   *
   * // Save the file when the user double-clicks.
   * function doubleClicked() {
   *   if (mouseX > 0 && mouseX < 100 && mouseY > 0 && mouseY < 100) {
   *     // Create an array.
   *     let data = ['0', '01', '011'];
   *
   *     // Save the text file.
   *     saveStrings(data, 'data.txt');
   *   }
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * function setup() {
   *   createCanvas(100, 100);
   *
   *   background(200);
   *
   *   // Style the text.
   *   textAlign(LEFT, CENTER);
   *   textFont('Courier New');
   *   textSize(12);
   *
   *   // Display instructions.
   *   text('Double-click to save', 5, 50, 90);
   *
   *   describe('The text "Double-click to save" written in black on a gray background.');
   * }
   *
   * // Save the file when the user double-clicks.
   * function doubleClicked() {
   *   if (mouseX > 0 && mouseX < 100 && mouseY > 0 && mouseY < 100) {
   *     // Create an array.
   *     // ASCII art courtesy Wikipedia:
   *     // https://en.wikipedia.org/wiki/ASCII_art
   *     let data = [' (\\_/) ', "(='.'=)", '(")_(")'];
   *
   *     // Save the text file.
   *     saveStrings(data, 'cat', 'txt');
   *   }
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * function setup() {
   *   createCanvas(100, 100);
   *
   *   background(200);
   *
   *   // Style the text.
   *   textAlign(LEFT, CENTER);
   *   textFont('Courier New');
   *   textSize(12);
   *
   *   // Display instructions.
   *   text('Double-click to save', 5, 50, 90);
   *
   *   describe('The text "Double-click to save" written in black on a gray background.');
   * }
   *
   * // Save the file when the user double-clicks.
   * function doubleClicked() {
   *   if (mouseX > 0 && mouseX < 100 && mouseY > 0 && mouseY < 100) {
   *     // Create an array.
   *     //   +--+
   *     //  /  /|
   *     // +--+ +
   *     // |  |/
   *     // +--+
   *     let data = ['  +--+', ' /  /|', '+--+ +', '|  |/', '+--+'];
   *
   *     // Save the text file.
   *     // Use CRLF for line endings.
   *     saveStrings(data, 'box', 'txt', true);
   *   }
   * }
   * </code>
   * </div>
   */
  fn.saveStrings = function (list, filename, extension, isCRLF) {
    // p5._validateParameters('saveStrings', arguments);
    const ext = extension || 'txt';
    const pWriter = new p5.PrintWriter(filename, ext);
    for (let item of list) {
      isCRLF ? pWriter.write(item + '\r\n') : pWriter.write(item + '\n');
    }
    pWriter.close();
    pWriter.clear();
  };

  // =======
  // HELPERS
  // =======

  function escapeHelper(content) {
    return content
      .replace(/&/g, '&amp;')
      .replace(/</g, '&lt;')
      .replace(/>/g, '&gt;')
      .replace(/"/g, '&quot;')
      .replace(/'/g, '&#039;');
  }

  /**
   *  Writes the contents of a <a href="#/p5.Table">Table</a> object to a file. Defaults to a
   *  text file with comma-separated-values ('csv') but can also
   *  use tab separation ('tsv'), or generate an HTML table ('html').
   *  The file saving process and location of the saved file will
   *  vary between web browsers.
   *
   *  @method saveTable
   * @deprecated p5.Table will be removed in a future version of p5.js to make way for a new, friendlier version :)
   *  @param  {p5.Table} Table  the <a href="#/p5.Table">Table</a> object to save to a file
   *  @param  {String} filename the filename to which the Table should be saved
   *  @param  {String} [options]  can be one of "tsv", "csv", or "html"
   *  @example
   *  <div><code>
   * let table;
   *
   * function setup() {
   *   table = new p5.Table();
   *
   *   table.addColumn('id');
   *   table.addColumn('species');
   *   table.addColumn('name');
   *
   *   let newRow = table.addRow();
   *   newRow.setNum('id', table.getRowCount() - 1);
   *   newRow.setString('species', 'Panthera leo');
   *   newRow.setString('name', 'Lion');
   *
   *   // To save, un-comment next line then click 'run'
   *   // saveTable(table, 'new.csv');
   *
   *   describe('no image displayed');
   * }
   *
   * // Saves the following to a file called 'new.csv':
   * // id,species,name
   * // 0,Panthera leo,Lion
   * </code></div>
   */
  fn.saveTable = function (table, filename, options) {
    // p5._validateParameters('saveTable', arguments);
    let ext;
    if (options === undefined) {
      ext = filename.substring(filename.lastIndexOf('.') + 1, filename.length);
      if(ext === filename) ext = 'csv';
    } else {
      ext = options;
    }
    const pWriter = this.createWriter(filename, ext);

    const header = table.columns;

    let sep = ','; // default to CSV
    if (ext === 'tsv') {
      sep = '\t';
    }
    if (ext !== 'html') {
      const output = table.toString(sep);
      pWriter.write(output);
    } else {
      // otherwise, make HTML
      pWriter.print('<html>');
      pWriter.print('<head>');
      let str = '  <meta http-equiv="content-type" content';
      str += '="text/html;charset=utf-8" />';
      pWriter.print(str);
      pWriter.print('</head>');

      pWriter.print('<body>');
      pWriter.print('  <table>');

      // make header if it has values
      if (header[0] !== '0') {
        pWriter.print('    <tr>');
        for (let k = 0; k < header.length; k++) {
          const e = escapeHelper(header[k]);
          pWriter.print(`      <td>${e}`);
          pWriter.print('      </td>');
        }
        pWriter.print('    </tr>');
      }

      // make rows
      for (let row = 0; row < table.rows.length; row++) {
        pWriter.print('    <tr>');
        for (let col = 0; col < table.columns.length; col++) {
          const entry = table.rows[row].getString(col);
          const htmlEntry = escapeHelper(entry);
          pWriter.print(`      <td>${htmlEntry}`);
          pWriter.print('      </td>');
        }
        pWriter.print('    </tr>');
      }
      pWriter.print('  </table>');
      pWriter.print('</body>');
      pWriter.print('</html>');
    }
    // close and clear the pWriter
    pWriter.close();
    pWriter.clear();
  }; // end saveTable()

  /**
   *  Generate a blob of file data as a url to prepare for download.
   *  Accepts an array of data, a filename, and an extension (optional).
   *  This is a private function because it does not do any formatting,
   *  but it is used by <a href="#/p5/saveStrings">saveStrings</a>, <a href="#/p5/saveJSON">saveJSON</a>, <a href="#/p5/saveTable">saveTable</a> etc.
   *
   *  @param  {Array} dataToDownload
   *  @param  {String} filename
   *  @param  {String} [extension]
   *  @private
   */
  fn.writeFile = function (dataToDownload, filename, extension) {
    let type = 'application/octet-stream';
    if (fn._isSafari()) {
      type = 'text/plain';
    }
    const blob = new Blob(dataToDownload, {
      type
    });
    fn.downloadFile(blob, filename, extension);
  };

  /**
   *  Forces download. Accepts a url to filedata/blob, a filename,
   *  and an extension (optional).
   *  This is a private function because it does not do any formatting,
   *  but it is used by <a href="#/p5/saveStrings">saveStrings</a>, <a href="#/p5/saveJSON">saveJSON</a>, <a href="#/p5/saveTable">saveTable</a> etc.
   *
   *  @method downloadFile
   *  @private
   *  @param  {String|Blob} data    either an href generated by createObjectURL,
   *                                or a Blob object containing the data
   *  @param  {String} [filename]
   *  @param  {String} [extension]
   */
  fn.downloadFile = downloadFile;

  /**
   *  Returns a file extension, or another string
   *  if the provided parameter has no extension.
   *
   *  @param   {String} filename
   *  @param   {String} [extension]
   *  @return  {String[]} [fileName, fileExtension]
   *
   *  @private
   */
  fn._checkFileExtension = _checkFileExtension;

  /**
   *  Returns true if the browser is Safari, false if not.
   *  Safari makes trouble for downloading files.
   *
   *  @return  {Boolean} [description]
   *  @private
   */
  fn._isSafari = function () {
    // The following line is CC BY SA 3 by user Fregante https://stackoverflow.com/a/23522755
    return /^((?!chrome|android).)*safari/i.test(navigator.userAgent);
  };
}

if(typeof p5 !== 'undefined'){
  files(p5, p5.prototype);
}

/**
 * @module Image
 * @submodule Loading & Displaying
 * @for p5
 * @requires core
 */


function loadingDisplaying(p5, fn){
  /**
   * Loads an image to create a <a href="#/p5.Image">p5.Image</a> object.
   *
   * `loadImage()` interprets the first parameter one of three ways. If the path
   * to an image file is provided, `loadImage()` will load it. Paths to local
   * files should be relative, such as `'assets/thundercat.jpg'`. URLs such as
   * `'https://example.com/thundercat.jpg'` may be blocked due to browser
   * security. Raw image data can also be passed as a base64 encoded image in
   * the form `'data:image/png;base64,arandomsequenceofcharacters'`. The `path`
   * parameter can also be defined as a [`Request`](https://developer.mozilla.org/en-US/docs/Web/API/Request)
   * object for more advanced usage.
   *
   * The second parameter is optional. If a function is passed, it will be
   * called once the image has loaded. The callback function can optionally use
   * the new <a href="#/p5.Image">p5.Image</a> object. The return value of the
   * function will be used as the final return value of `loadImage()`.
   *
   * The third parameter is also optional. If a function is passed, it will be
   * called if the image fails to load. The callback function can optionally use
   * the event error. The return value of the function will be used as the final
   * return value of `loadImage()`.
   *
   * This function returns a `Promise` and should be used in an `async` setup with
   * `await`. See the examples for the usage syntax.
   *
   * @method loadImage
   * @param  {String|Request}      path  path of the image to be loaded or base64 encoded image.
   * @param  {function(p5.Image)} [successCallback] function called with
   *                               <a href="#/p5.Image">p5.Image</a> once it
   *                               loads.
   * @param  {function(Event)}    [failureCallback] function called with event
   *                               error if the image fails to load.
   * @return {Promise<p5.Image>}   the <a href="#/p5.Image">p5.Image</a> object.
   *
   * @example
   * <div>
   * <code>
   * let img;
   *
   * // Load the image and create a p5.Image object.
   * async function setup() {
   *   img = await loadImage('assets/laDefense.jpg');
   *   createCanvas(100, 100);
   *
   *   // Draw the image.
   *   image(img, 0, 0);
   *
   *   describe('Image of the underside of a white umbrella and a gridded ceiling.');
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * async function setup() {
   *   // Call handleImage() once the image loads.
   *   await loadImage('assets/laDefense.jpg', handleImage);
   *
   *   describe('Image of the underside of a white umbrella and a gridded ceiling.');
   * }
   *
   * // Display the image.
   * function handleImage(img) {
   *   image(img, 0, 0);
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * async function setup() {
   *   // Call handleImage() once the image loads or
   *   // call handleError() if an error occurs.
   *   await loadImage('assets/laDefense.jpg', handleImage, handleError);
   * }
   *
   * // Display the image.
   * function handleImage(img) {
   *   image(img, 0, 0);
   *
   *   describe('Image of the underside of a white umbrella and a gridded ceiling.');
   * }
   *
   * // Log the error.
   * function handleError(event) {
   *   console.error('Oops!', event);
   * }
   * </code>
   * </div>
   */
  fn.loadImage = async function(
    path,
    successCallback,
    failureCallback
  ) {
    // p5._validateParameters('loadImage', arguments);

    try{
      let pImg = new p5.Image(1, 1, this);

      const req = new Request(path, {
        method: 'GET',
        mode: 'cors'
      });

      const { data, headers } = await request(req, 'bytes');

      // GIF section
      const contentType = headers.get('content-type');

      if (contentType === null) {
        console.warn(
          'The image you loaded does not have a Content-Type header. If you are using the online editor consider reuploading the asset.'
        );
      }

      if (contentType && contentType.includes('image/gif')) {
        await _createGif(
          data,
          pImg
        );

      } else {
        // Non-GIF Section
        const blob = new Blob([data]);
        const img = await createImageBitmap(blob);

        pImg.width = pImg.canvas.width = img.width;
        pImg.height = pImg.canvas.height = img.height;

        // Draw the image into the backing canvas of the p5.Image
        pImg.drawingContext.drawImage(img, 0, 0);
      }

      pImg.modified = true;

      if(successCallback){
        return successCallback(pImg);
      }else {
        return pImg;
      }

    } catch(err) {
      p5._friendlyFileLoadError(0, path);
      if (typeof failureCallback === 'function') {
        return failureCallback(err);
      } else {
        throw err;
      }
    }
  };

  /**
   * Generates a gif from a sketch and saves it to a file.
   *
   * `saveGif()` may be called in <a href="#/p5/setup">setup()</a> or at any
   * point while a sketch is running.
   *
   * The first parameter, `fileName`, sets the gif's file name.
   *
   * The second parameter, `duration`, sets the gif's duration in seconds.
   *
   * The third parameter, `options`, is optional. If an object is passed,
   * `saveGif()` will use its properties to customize the gif. `saveGif()`
   * recognizes the properties `delay`, `units`, `silent`,
   * `notificationDuration`, and `notificationID`.
   *
   * @method saveGif
   * @param  {String} filename file name of gif.
   * @param  {Number} duration duration in seconds to capture from the sketch.
   * @param  {Object} [options] an object that can contain five more properties:
   *                  `delay`, a Number specifying how much time to wait before recording;
   *                  `units`, a String that can be either 'seconds' or 'frames'. By default it's 'seconds;
   *                  `silent`, a Boolean that defines presence of progress notifications. By default its `false`;
   *                  `notificationDuration`, a Number that defines how long in seconds the final notification
   *                  will live. By default it's `0`, meaning the notification will never be removed;
   *                  `notificationID`, a String that specifies the id of the notification's DOM element. By default its `'progressBar`.
   *
   * @example
   * <div>
   * <code>
   * function setup() {
   *   createCanvas(100, 100);
   *
   *   describe('A circle drawn in the middle of a gray square. The circle changes color from black to white, then repeats.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Style the circle.
   *   let c = frameCount % 255;
   *   fill(c);
   *
   *   // Display the circle.
   *   circle(50, 50, 25);
   * }
   *
   * // Save a 5-second gif when the user presses the 's' key.
   * function keyPressed() {
   *   if (key === 's') {
   *     saveGif('mySketch', 5);
   *   }
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * function setup() {
   *   createCanvas(100, 100);
   *
   *   describe('A circle drawn in the middle of a gray square. The circle changes color from black to white, then repeats.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Style the circle.
   *   let c = frameCount % 255;
   *   fill(c);
   *
   *   // Display the circle.
   *   circle(50, 50, 25);
   * }
   *
   * // Save a 5-second gif when the user presses the 's' key.
   * // Wait 1 second after the key press before recording.
   * function keyPressed() {
   *   if (key === 's') {
   *     saveGif('mySketch', 5, { delay: 1 });
   *   }
   * }
   * </code>
   * </div>
   */
  fn.saveGif = async function(
    fileName,
    duration,
    options = {
      delay: 0,
      units: 'seconds',
      silent: false,
      notificationDuration: 0,
      notificationID: 'progressBar'
    }
  ) {
    // validate parameters
    if (typeof fileName !== 'string') {
      throw TypeError('fileName parameter must be a string');
    }
    if (typeof duration !== 'number') {
      throw TypeError('Duration parameter must be a number');
    }

    // extract variables for more comfortable use
    const delay = (options && options.delay) || 0;  // in seconds
    const units = (options && options.units) || 'seconds';  // either 'seconds' or 'frames'
    const silent = (options && options.silent) || false;
    const notificationDuration = (options && options.notificationDuration) || 0;
    const notificationID = (options && options.notificationID) || 'progressBar';

    // if arguments in the options object are not correct, cancel operation
    if (typeof delay !== 'number') {
      throw TypeError('Delay parameter must be a number');
    }
    // if units is not seconds nor frames, throw error
    if (units !== 'seconds' && units !== 'frames') {
      throw TypeError('Units parameter must be either "frames" or "seconds"');
    }

    if (typeof silent !== 'boolean') {
      throw TypeError('Silent parameter must be a boolean');
    }

    if (typeof notificationDuration !== 'number') {
      throw TypeError('Notification duration parameter must be a number');
    }

    if (typeof notificationID !== 'string') {
      throw TypeError('Notification ID parameter must be a string');
    }

    this._recording = true;

    // get the project's framerate
    let _frameRate = this._targetFrameRate;
    // if it is undefined or some non useful value, assume it's 60
    if (_frameRate === Infinity || _frameRate === undefined || _frameRate === 0) {
      _frameRate = 60;
    }

    // calculate frame delay based on frameRate

    // this delay has nothing to do with the
    // delay in options, but rather is the delay
    // we have to specify to the gif encoder between frames.
    let gifFrameDelay = 1 / _frameRate * 1000;

    // constrain it to be always greater than 20,
    // otherwise it won't work in some browsers and systems
    // reference: https://stackoverflow.com/questions/64473278/gif-frame-duration-seems-slower-than-expected
    gifFrameDelay = gifFrameDelay < 20 ? 20 : gifFrameDelay;

    // check the mode we are in and how many frames
    // that duration translates to
    const nFrames = units === 'seconds' ? duration * _frameRate : duration;
    const nFramesDelay = units === 'seconds' ? delay * _frameRate : delay;
    const totalNumberOfFrames = nFrames + nFramesDelay;

    // initialize variables for the frames processing
    let frameIterator = nFramesDelay;
    this.frameCount = frameIterator;

    const lastPixelDensity = this._renderer._pixelDensity;
    this.pixelDensity(1);

    // We first take every frame that we are going to use for the animation
    let frames = [];

    if (document.getElementById(notificationID) !== null)
      document.getElementById(notificationID).remove();

    let p;
    if (!silent){
      p = this.createP('');
      p.id(notificationID);
      p.style('font-size', '16px');
      p.style('font-family', 'Montserrat');
      p.style('background-color', '#ffffffa0');
      p.style('padding', '8px');
      p.style('border-radius', '10px');
      p.position(0, 0);
    }

    let pixels;
    let gl;
    if (this._renderer instanceof p5.RendererGL) {
      // if we have a WEBGL context, initialize the pixels array
      // and the gl context to use them inside the loop
      gl = this.drawingContext;
      pixels = new Uint8Array(gl.drawingBufferWidth * gl.drawingBufferHeight * 4);
    }

    // stop the loop since we are going to manually redraw
    this.noLoop();

    // Defer execution until the rest of the call stack finishes, allowing the
    // rest of `setup` to be called (and, importantly, canvases hidden in setup
    // to be unhidden.)
    //
    // Waiting on this empty promise means we'll continue as soon as setup
    // finishes without waiting for another frame.
    await Promise.resolve();

    while (frameIterator < totalNumberOfFrames) {
      /*
        we draw the next frame. this is important, since
        busy sketches or low end devices might take longer
        to render some frames. So we just wait for the frame
        to be drawn and immediately save it to a buffer and continue
      */
      this.redraw();

      // depending on the context we'll extract the pixels one way
      // or another
      let data = undefined;

      if (this._renderer instanceof p5.RendererGL) {
        pixels = new Uint8Array(
          gl.drawingBufferWidth * gl.drawingBufferHeight * 4
        );
        gl.readPixels(
          0,
          0,
          gl.drawingBufferWidth,
          gl.drawingBufferHeight,
          gl.RGBA,
          gl.UNSIGNED_BYTE,
          pixels
        );

        data = _flipPixels(pixels, this.width, this.height);
      } else {
        data = this.drawingContext.getImageData(0, 0, this.width, this.height)
          .data;
      }

      frames.push(data);
      frameIterator++;

      if (!silent) {
        p.html(
          'Saved frame <b>' +
          frames.length.toString() +
          '</b> out of ' +
          nFrames.toString()
        );
      }
      await new Promise(resolve => setTimeout(resolve, 0));
    }
    if (!silent) p.html('Frames processed, generating color palette...');

    this.loop();
    this.pixelDensity(lastPixelDensity);

    // create the gif encoder and the colorspace format
    const gif = GIFEncoder();

    // calculate the global palette for this set of frames
    const globalPalette = _generateGlobalPalette(frames);

    // Rather than using applyPalette() from the gifenc library, we use our
    // own function to map frame pixels to a palette color. This way, we can
    // cache palette color mappings between frames for extra performance, and
    // use our own caching mechanism to avoid flickering colors from cache
    // key collisions.
    const paletteCache = {};
    const getIndexedFrame = frame => {
      const length = frame.length / 4;
      const index = new Uint8Array(length);
      for (let i = 0; i < length; i++) {
        const key =
          (frame[i * 4] << 24) |
          (frame[i * 4 + 1] << 16) |
          (frame[i * 4 + 2] << 8) |
          frame[i * 4 + 3];
        if (paletteCache[key] === undefined) {
          paletteCache[key] = nearestColorIndex(
            globalPalette,
            frame.slice(i * 4, (i + 1) * 4)
          );
        }
        index[i] = paletteCache[key];
      }
      return index;
    };

    // the way we designed the palette means we always take the last index for transparency
    const transparentIndex = globalPalette.length - 1;

    // we are going to iterate the frames in pairs, n-1 and n
    let prevIndexedFrame = [];
    for (let i = 0; i < frames.length; i++) {
      //const indexedFrame = applyPalette(frames[i], globalPaletteWithoutAlpha, 'rgba565');
      const indexedFrame = getIndexedFrame(frames[i]);

      // Make a copy of the palette-applied frame before editing the original
      // to use transparent pixels
      const originalIndexedFrame = indexedFrame.slice();

      if (i === 0) {
        gif.writeFrame(indexedFrame, this.width, this.height, {
          palette: globalPalette,
          delay: gifFrameDelay,
          dispose: 1
        });
      } else {
        // Matching pixels between frames can be set to full transparency,
        // allowing the previous frame's pixels to show through. We only do
        // this for pixels that get mapped to the same quantized color so that
        // the resulting image would be the same.
        for (let i = 0; i < indexedFrame.length; i++) {
          if (indexedFrame[i] === prevIndexedFrame[i]) {
            indexedFrame[i] = transparentIndex;
          }
        }

        // Write frame into the encoder
        gif.writeFrame(indexedFrame, this.width, this.height, {
          delay: gifFrameDelay,
          transparent: true,
          transparentIndex,
          dispose: 1
        });
      }

      prevIndexedFrame = originalIndexedFrame;

      if (!silent) {
        p.html(
          'Rendered frame <b>' + i.toString() + '</b> out of ' + nFrames.toString()
        );
      }


      // this just makes the process asynchronous, preventing
      // that the encoding locks up the browser
      await new Promise(resolve => setTimeout(resolve, 0));
    }

    gif.finish();

    // Get a direct typed array view into the buffer to avoid copying it
    const buffer = gif.bytesView();
    const extension = 'gif';

    const blob = new Blob([buffer], {
      type: 'image/gif'
    });

    frames = [];
    this._recording = false;
    this.loop();

    if (!silent){
      p.html('Done. Downloading your gif!');
      if(notificationDuration > 0)
        setTimeout(() => p.remove(), notificationDuration * 1000);
    }

    fn.downloadFile(blob, fileName, extension);
  };

  function _flipPixels(pixels, width, height) {
    // extracting the pixels using readPixels returns
    // an upside down image. we have to flip it back
    // first. this solution is proposed by gman on
    // this stack overflow answer:
    // https://stackoverflow.com/questions/41969562/how-can-i-flip-the-result-of-webglrenderingcontext-readpixels

    const halfHeight = parseInt(height / 2);
    const bytesPerRow = width * 4;

    // make a temp buffer to hold one row
    const temp = new Uint8Array(width * 4);
    for (let y = 0; y < halfHeight; ++y) {
      const topOffset = y * bytesPerRow;
      const bottomOffset = (height - y - 1) * bytesPerRow;

      // make copy of a row on the top half
      temp.set(pixels.subarray(topOffset, topOffset + bytesPerRow));

      // copy a row from the bottom half to the top
      pixels.copyWithin(topOffset, bottomOffset, bottomOffset + bytesPerRow);

      // copy the copy of the top half row to the bottom half
      pixels.set(temp, bottomOffset);
    }
    return pixels;
  }

  function _generateGlobalPalette(frames) {
    // make an array the size of every possible color in every possible frame
    // that is: width * height * frames.
    let allColors = new Uint8Array(frames.length * frames[0].length);

    // put every frame one after the other in sequence.
    // this array will hold absolutely every pixel from the animation.
    // the set function on the Uint8Array works super fast tho!
    for (let f = 0; f < frames.length; f++) {
      allColors.set(frames[f], f * frames[0].length);
    }

    // quantize this massive array into 256 colors and return it!
    let colorPalette = quantize(allColors, 256, {
      format: 'rgba4444',
      oneBitAlpha: true
    });

    // when generating the palette, we have to leave space for 1 of the
    // indices to be a random color that does not appear anywhere in our
    // animation to use for transparency purposes. So, if the palette is full
    // (has 256 colors), we overwrite the last one with a random, fully transparent
    // color. Otherwise, we just push a new color into the palette the same way.

    // this guarantees that when using the transparency index, there are no matches
    // between some colors of the animation and the "holes" we want to dig on them,
    // which would cause pieces of some frames to be transparent and thus look glitchy.
    if (colorPalette.length === 256) {
      colorPalette[colorPalette.length - 1] = [
        Math.random() * 255,
        Math.random() * 255,
        Math.random() * 255,
        0
      ];
    } else {
      colorPalette.push([
        Math.random() * 255,
        Math.random() * 255,
        Math.random() * 255,
        0
      ]);
    }
    return colorPalette;
  }

  /**
   * Helper function for loading GIF-based images
   */
  async function _createGif(arrayBuffer, pImg) {
    // TODO: Replace with ImageDecoder once it is widely available
    // https://developer.mozilla.org/en-US/docs/Web/API/ImageDecoder
    const gifReader = new omggif.GifReader(arrayBuffer);
    pImg.width = pImg.canvas.width = gifReader.width;
    pImg.height = pImg.canvas.height = gifReader.height;
    const frames = [];
    const numFrames = gifReader.numFrames();
    let framePixels = new Uint8ClampedArray(pImg.width * pImg.height * 4);

    const loadGIFFrameIntoImage = (frameNum, gifReader) => {
      try {
        gifReader.decodeAndBlitFrameRGBA(frameNum, framePixels);
      } catch (e) {
        p5._friendlyFileLoadError(8, pImg.src);
        throw e;
      }
    };

    for (let j = 0; j < numFrames; j++) {
      const frameInfo = gifReader.frameInfo(j);
      const prevFrameData = pImg.drawingContext.getImageData(
        0,
        0,
        pImg.width,
        pImg.height
      );
      framePixels = prevFrameData.data.slice();
      loadGIFFrameIntoImage(j, gifReader);
      const imageData = new ImageData(framePixels, pImg.width, pImg.height);
      pImg.drawingContext.putImageData(imageData, 0, 0);
      let frameDelay = frameInfo.delay;
      // To maintain the default of 10FPS when frameInfo.delay equals to 0
      if (frameDelay === 0) {
        frameDelay = 10;
      }
      frames.push({
        image: pImg.drawingContext.getImageData(0, 0, pImg.width, pImg.height),
        delay: frameDelay * 10 //GIF stores delay in one-hundredth of a second, shift to ms
      });

      // Some GIFs are encoded so that they expect the previous frame
      // to be under the current frame. This can occur at a sub-frame level
      //
      // Values :    0 -   No disposal specified. The decoder is
      //                   not required to take any action.
      //             1 -   Do not dispose. The graphic is to be left
      //                   in place.
      //             2 -   Restore to background color. The area used by the
      //                   graphic must be restored to the background color.
      //             3 -   Restore to previous. The decoder is required to
      //                   restore the area overwritten by the graphic with
      //                   what was there prior to rendering the graphic.
      //          4-7 -    To be defined.
      if (frameInfo.disposal === 2) {
        // Restore background color
        pImg.drawingContext.clearRect(
          frameInfo.x,
          frameInfo.y,
          frameInfo.width,
          frameInfo.height
        );
      } else if (frameInfo.disposal === 3) {
        // Restore previous
        pImg.drawingContext.putImageData(
          prevFrameData,
          0,
          0,
          frameInfo.x,
          frameInfo.y,
          frameInfo.width,
          frameInfo.height
        );
      }
    }

    //Uses Netscape block encoding
    //to repeat forever, this will be 0
    //to repeat just once, this will be null
    //to repeat N times (1<N), should contain integer for loop number
    //this is changed to more usable values for us
    //to repeat forever, loopCount = null
    //everything else is just the number of loops
    let loopLimit = gifReader.loopCount();
    if (loopLimit === null) {
      loopLimit = 1;
    } else if (loopLimit === 0) {
      loopLimit = null;
    }

    // we used the pImg for painting and saving during load
    // so we have to reset it to the first frame
    pImg.drawingContext.putImageData(frames[0].image, 0, 0);

    if (frames.length > 1) {
      pImg.gifProperties = {
        displayIndex: 0,
        loopLimit,
        loopCount: 0,
        frames,
        numFrames,
        playing: true,
        timeDisplayed: 0,
        lastChangeTime: 0
      };
    }

    return pImg;
  }

  /**
   * @private
   * @param {(LEFT|RIGHT|CENTER)} xAlign either LEFT, RIGHT or CENTER
   * @param {(TOP|BOTTOM|CENTER)} yAlign either TOP, BOTTOM or CENTER
   * @param {Number} dx
   * @param {Number} dy
   * @param {Number} dw
   * @param {Number} dh
   * @param {Number} sw
   * @param {Number} sh
   * @returns {Object}
   */

  function _imageContain(xAlign, yAlign, dx, dy, dw, dh, sw, sh) {
    const r = Math.max(sw / dw, sh / dh);
    const [adjusted_dw, adjusted_dh] = [sw / r, sh / r];
    let x = dx;
    let y = dy;

    if (xAlign === CENTER) {
      x += (dw - adjusted_dw) / 2;
    } else if (xAlign === RIGHT) {
      x += dw - adjusted_dw;
    }

    if (yAlign === CENTER) {
      y += (dh - adjusted_dh) / 2;
    } else if (yAlign === BOTTOM) {
      y += dh - adjusted_dh;
    }
    return { x, y, w: adjusted_dw, h: adjusted_dh };
  }

  /**
   * @private
   * @param {(LEFT|RIGHT|CENTER)} xAlign either LEFT, RIGHT or CENTER
   * @param {(TOP|BOTTOM|CENTER)} yAlign either TOP, BOTTOM or CENTER
   * @param {Number} dw
   * @param {Number} dh
   * @param {Number} sx
   * @param {Number} sy
   * @param {Number} sw
   * @param {Number} sh
   * @returns {Object}
   */
  function _imageCover(xAlign, yAlign, dw, dh, sx, sy, sw, sh) {
    const r = Math.max(dw / sw, dh / sh);
    const [adjusted_sw, adjusted_sh] = [dw / r, dh / r];

    let x = sx;
    let y = sy;

    if (xAlign === CENTER) {
      x += (sw - adjusted_sw) / 2;
    } else if (xAlign === RIGHT) {
      x += sw - adjusted_sw;
    }

    if (yAlign === CENTER) {
      y += (sh - adjusted_sh) / 2;
    } else if (yAlign === BOTTOM) {
      y += sh - adjusted_sh;
    }

    return { x, y, w: adjusted_sw, h: adjusted_sh };
  }

  /**
   * @private
   * @param {(CONTAIN|COVER)} [fit] either CONTAIN or COVER
   * @param {(LEFT|RIGHT|CENTER)} xAlign either LEFT, RIGHT or CENTER
   * @param {(TOP|BOTTOM|CENTER)} yAlign either TOP, BOTTOM or CENTER
   * @param {Number} dx
   * @param {Number} dy
   * @param {Number} dw
   * @param {Number} dh
   * @param {Number} sx
   * @param {Number} sy
   * @param {Number} sw
   * @param {Number} sh
   * @returns {Object}
   */
  function _imageFit(fit, xAlign, yAlign, dx, dy, dw, dh, sx, sy, sw, sh) {
    if (fit === COVER) {
      const { x, y, w, h } = _imageCover(xAlign, yAlign, dw, dh, sx, sy, sw, sh);
      sx = x;
      sy = y;
      sw = w;
      sh = h;
    }

    if (fit === CONTAIN) {
      const { x, y, w, h } = _imageContain(
        xAlign,
        yAlign,
        dx,
        dy,
        dw,
        dh,
        sw,
        sh
      );
      dx = x;
      dy = y;
      dw = w;
      dh = h;
    }
    return { sx, sy, sw, sh, dx, dy, dw, dh };
  }

  /**
   * Validates clipping params. Per drawImage spec sWidth and sHight cannot be
   * negative or greater than image intrinsic width and height
   * @private
   * @param {Number} sVal
   * @param {Number} iVal
   * @returns {Number}
   * @private
   */
  function _sAssign(sVal, iVal) {
    if (sVal > 0 && sVal < iVal) {
      return sVal;
    } else {
      return iVal;
    }
  }

  /**
   * Draws an image to the canvas.
   *
   * The first parameter, `img`, is the source image to be drawn. `img` can be
   * any of the following objects:
   * - <a href="#/p5.Image">p5.Image</a>
   * - <a href="#/p5.Element">p5.Element</a>
   * - <a href="#/p5.Texture">p5.Texture</a>
   * - <a href="#/p5.Framebuffer">p5.Framebuffer</a>
   * - <a href="#/p5.FramebufferTexture">p5.FramebufferTexture</a>
   *
   * The second and third parameters, `dx` and `dy`, set the coordinates of the
   * destination image's top left corner. See
   * <a href="#/p5/imageMode">imageMode()</a> for other ways to position images.
   *
   * ```js example
   * let img;
   *
   * async function setup() {
   *   // Load the image.
   *   img = await loadImage('assets/laDefense.jpg');
   *
   *   createCanvas(100, 100);
   *
   *   background(50);
   *
   *   // Draw the image.
   *   image(img, 0, 0);
   *
   *   describe('An image of the underside of a white umbrella with a gridded ceiling above.');
   * }
   * ```
   *
   * Here's a diagram that explains how optional parameters work in `image()`:
   *
   * <img src="assets/drawImage.png"></img>
   *
   * The fourth and fifth parameters, `dw` and `dh`, are optional. They set the
   * the width and height to draw the destination image. By default, `image()`
   * draws the full source image at its original size.
   *
   * The sixth and seventh parameters, `sx` and `sy`, are also optional.
   * These coordinates define the top left corner of a subsection to draw from
   * the source image.
   *
   * The eighth and ninth parameters, `sw` and `sh`, are also optional.
   * They define the width and height of a subsection to draw from the source
   * image. By default, `image()` draws the full subsection that begins at
   * `(sx, sy)` and extends to the edges of the source image.
   *
   * The ninth parameter, `fit`, is also optional. It enables a subsection of
   * the source image to be drawn without affecting its aspect ratio. If
   * `CONTAIN` is passed, the full subsection will appear within the destination
   * rectangle. If `COVER` is passed, the subsection will completely cover the
   * destination rectangle. This may have the effect of zooming into the
   * subsection.
   *
   * The tenth and eleventh paremeters, `xAlign` and `yAlign`, are also
   * optional. They determine how to align the fitted subsection. `xAlign` can
   * be set to either `LEFT`, `RIGHT`, or `CENTER`. `yAlign` can be set to
   * either `TOP`, `BOTTOM`, or `CENTER`. By default, both `xAlign` and `yAlign`
   * are set to `CENTER`.
   *
   * @method image
   * @param  {p5.Image|p5.Element|p5.Texture|p5.Framebuffer|p5.FramebufferTexture|p5.Renderer|p5.Graphics} img image to display.
   * @param  {Number}   x x-coordinate of the top-left corner of the image.
   * @param  {Number}   y y-coordinate of the top-left corner of the image.
   * @param  {Number}   [width]  width to draw the image.
   * @param  {Number}   [height] height to draw the image.
   *
   * @example
   * <div>
   * <code>
   * let img;
   *
   * async function setup() {
   *   // Load the image.
   *   img = await loadImage('assets/laDefense.jpg');
   *
   *   createCanvas(100, 100);
   *
   *   background(50);
   *
   *   // Draw the image.
   *   image(img, 10, 10);
   *
   *   describe('An image of the underside of a white umbrella with a gridded ceiling above. The image has dark gray borders on its left and top.');
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * let img;
   *
   * async function setup() {
   *   // Load the image.
   *   img = await loadImage('assets/laDefense.jpg');
   *
   *   createCanvas(100, 100);
   *
   *   background(50);
   *
   *   // Draw the image 50x50.
   *   image(img, 0, 0, 50, 50);
   *
   *   describe('An image of the underside of a white umbrella with a gridded ceiling above. The image is drawn in the top left corner of a dark gray square.');
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * let img;
   *
   * async function setup() {
   *   // Load the image.
   *   img = await loadImage('assets/laDefense.jpg');
   *
   *   createCanvas(100, 100);
   *
   *   background(50);
   *
   *   // Draw the center of the image.
   *   image(img, 25, 25, 50, 50, 25, 25, 50, 50);
   *
   *   describe('An image of a gridded ceiling drawn in the center of a dark gray square.');
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * let img;
   *
   * async function setup() {
   *   // Load the image.
   *   img = await loadImage('assets/moonwalk.jpg');
   *   createCanvas(100, 100);
   *
   *   background(50);
   *
   *   // Draw the image and scale it to fit within the canvas.
   *   image(img, 0, 0, width, height, 0, 0, img.width, img.height, CONTAIN);
   *
   *   describe('An image of an astronaut on the moon. The top and bottom borders of the image are dark gray.');
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * let img;
   *
   * async function setup() {
   *   // Load the image.
   *   img = await loadImage('assets/laDefense50.png');
   *
   *   createCanvas(100, 100);
   *
   *   background(50);
   *
   *   // Draw the image and scale it to cover the canvas.
   *   image(img, 0, 0, width, height, 0, 0, img.width, img.height, COVER);
   *
   *   describe('A pixelated image of the underside of a white umbrella with a gridded ceiling above.');
   * }
   * </code>
   * </div>
   */
  /**
   * @method image
   * @param  {p5.Image|p5.Element|p5.Texture|p5.Framebuffer|p5.FramebufferTexture} img
   * @param  {Number}   dx     the x-coordinate of the destination
   *                           rectangle in which to draw the source image
   * @param  {Number}   dy     the y-coordinate of the destination
   *                           rectangle in which to draw the source image
   * @param  {Number}   dWidth  the width of the destination rectangle
   * @param  {Number}   dHeight the height of the destination rectangle
   * @param  {Number}   sx     the x-coordinate of the subsection of the source
   * image to draw into the destination rectangle
   * @param  {Number}   sy     the y-coordinate of the subsection of the source
   * image to draw into the destination rectangle
   * @param {Number}    [sWidth] the width of the subsection of the
   *                           source image to draw into the destination
   *                           rectangle
   * @param {Number}    [sHeight] the height of the subsection of the
   *                            source image to draw into the destination rectangle
   * @param {(CONTAIN|COVER)} [fit] either CONTAIN or COVER
   * @param {(LEFT|RIGHT|CENTER)} [xAlign=CENTER] either LEFT, RIGHT or CENTER default is CENTER
   * @param {(TOP|BOTTOM|CENTER)} [yAlign=CENTER] either TOP, BOTTOM or CENTER default is CENTER
   */
  fn.image = function(
    img,
    dx,
    dy,
    dWidth,
    dHeight,
    sx,
    sy,
    sWidth,
    sHeight,
    fit,
    xAlign,
    yAlign
  ) {
    // set defaults per spec: https://goo.gl/3ykfOq

    // p5._validateParameters('image', arguments);

    let defW = img.width;
    let defH = img.height;
    yAlign = yAlign || CENTER;
    xAlign = xAlign || CENTER;

    if (img.elt) {
      defW = defW !== undefined ? defW : img.elt.width;
      defH = defH !== undefined ? defH : img.elt.height;
    }
    if (img.elt && img.elt.videoWidth && !img.canvas) {
      // video no canvas
      defW = defW !== undefined ? defW : img.elt.videoWidth;
      defH = defH !== undefined ? defH : img.elt.videoHeight;
    }

    let _dx = dx;
    let _dy = dy;
    let _dw = dWidth || defW;
    let _dh = dHeight || defH;
    let _sx = sx || 0;
    let _sy = sy || 0;
    let _sw = sWidth !== undefined ? sWidth : defW;
    let _sh = sHeight !== undefined ? sHeight : defH;

    _sw = _sAssign(_sw, defW);
    _sh = _sAssign(_sh, defH);

    // This part needs cleanup and unit tests
    // see issues https://github.com/processing/p5.js/issues/1741
    // and https://github.com/processing/p5.js/issues/1673
    let pd = 1;

    if (img.elt && !img.canvas && img.elt.style.width) {
      //if img is video and img.elt.size() has been used and
      //no width passed to image()
      if (img.elt.videoWidth && !dWidth) {
        pd = img.elt.videoWidth;
      } else {
        //all other cases
        pd = img.elt.width;
      }
      pd /= parseInt(img.elt.style.width, 10);
    }

    _sx *= pd;
    _sy *= pd;
    _sh *= pd;
    _sw *= pd;

    let vals = canvas.modeAdjust(_dx, _dy, _dw, _dh, this._renderer.states.imageMode);
    vals = _imageFit(
      fit,
      xAlign,
      yAlign,
      vals.x,
      vals.y,
      vals.w,
      vals.h,
      _sx,
      _sy,
      _sw,
      _sh
    );

    // tint the image if there is a tint
    this._renderer.image(
      img,
      vals.sx,
      vals.sy,
      vals.sw,
      vals.sh,
      vals.dx,
      vals.dy,
      vals.dw,
      vals.dh
    );
  };

  /**
   * Tints images using a color.
   *
   * The version of `tint()` with one parameter interprets it one of four ways.
   * If the parameter is a number, it's interpreted as a grayscale value. If the
   * parameter is a string, it's interpreted as a CSS color string. An array of
   * `[R, G, B, A]` values or a <a href="#/p5.Color">p5.Color</a> object can
   * also be used to set the tint color.
   *
   * The version of `tint()` with two parameters uses the first one as a
   * grayscale value and the second as an alpha value. For example, calling
   * `tint(255, 128)` will make an image 50% transparent.
   *
   * The version of `tint()` with three parameters interprets them as RGB or
   * HSB values, depending on the current
   * <a href="#/p5/colorMode">colorMode()</a>. The optional fourth parameter
   * sets the alpha value. For example, `tint(255, 0, 0, 100)` will give images
   * a red tint and make them transparent.
   *
   * @method tint
   * @param  {Number}        v1      red or hue value.
   * @param  {Number}        v2      green or saturation value.
   * @param  {Number}        v3      blue or brightness.
   * @param  {Number}        [alpha]
   *
   * @example
   * <div>
   * <code>
   * let img;
   *
   * async function setup() {
   *   // Load the image.
   *   img = await loadImage('assets/laDefense.jpg');
   *
   *   createCanvas(100, 100);
   *
   *   // Left image.
   *   image(img, 0, 0);
   *
   *   // Right image.
   *   // Tint with a CSS color string.
   *   tint('red');
   *   image(img, 50, 0);
   *
   *   describe('Two images of an umbrella and a ceiling side-by-side. The image on the right has a red tint.');
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * let img;
   *
   * async function setup() {
   *   // Load the image.
   *   img = await loadImage('assets/laDefense.jpg');
   *
   *   createCanvas(100, 100);
   *
   *   // Left image.
   *   image(img, 0, 0);
   *
   *   // Right image.
   *   // Tint with RGB values.
   *   tint(255, 0, 0);
   *   image(img, 50, 0);
   *
   *   describe('Two images of an umbrella and a ceiling side-by-side. The image on the right has a red tint.');
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * let img;
   **
   * async function setup() {
   *   // Load the image.
   *   img = await loadImage('assets/laDefense.jpg');
   *
   *   createCanvas(100, 100);
   *
   *   // Left.
   *   image(img, 0, 0);
   *
   *   // Right.
   *   // Tint with RGBA values.
   *   tint(255, 0, 0, 100);
   *   image(img, 50, 0);
   *
   *   describe('Two images of an umbrella and a ceiling side-by-side. The image on the right has a transparent red tint.');
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * let img;
   *
   * async function setup() {
   *   // Load the image.
   *   img = await loadImage('assets/laDefense.jpg');
   *
   *   createCanvas(100, 100);
   *
   *   // Left.
   *   image(img, 0, 0);
   *
   *   // Right.
   *   // Tint with grayscale and alpha values.
   *   tint(255, 180);
   *   image(img, 50, 0);
   *
   *   describe('Two images of an umbrella and a ceiling side-by-side. The image on the right is transparent.');
   * }
   * </code>
   * </div>
   */
  /**
   * @method tint
   * @param  {String}        value   CSS color string.
   */

  /**
   * @method tint
   * @param  {Number}        gray   grayscale value.
   * @param  {Number}        [alpha]
   */

  /**
   * @method tint
   * @param  {Number[]}      values  array containing the red, green, blue &
   *                                 alpha components of the color.
   */

  /**
   * @method tint
   * @param  {p5.Color}      color   the tint color
   */
  fn.tint = function(...args) {
    // p5._validateParameters('tint', args);
    const c = this.color(...args);
    this._renderer.states.setValue('tint', c._getRGBA([255, 255, 255, 255]));
  };

  /**
   * Removes the current tint set by <a href="#/p5/tint">tint()</a>.
   *
   * `noTint()` restores images to their original colors.
   *
   * @method noTint
   *
   * @example
   * <div>
   * <code>
   * let img;
   *
   * async function setup() {
   *   // Load the image.
   *   img = await loadImage('assets/laDefense.jpg');
   *
   *   createCanvas(100, 100);
   *
   *   // Left.
   *   // Tint with a CSS color string.
   *   tint('red');
   *   image(img, 0, 0);
   *
   *   // Right.
   *   // Remove the tint.
   *   noTint();
   *   image(img, 50, 0);
   *
   *   describe('Two images of an umbrella and a ceiling side-by-side. The image on the left has a red tint.');
   * }
   * </code>
   * </div>
   */
  fn.noTint = function() {
    this._renderer.states.setValue('tint', null);
  };

  /**
   * Apply the current tint color to the input image, return the resulting
   * canvas.
   *
   * @private
   * @param {p5.Image} The image to be tinted
   * @return {canvas} The resulting tinted canvas
   */
  // fn._getTintedImageCanvas =
  //   p5.Renderer2D.prototype._getTintedImageCanvas;

  /**
   * Changes the location from which images are drawn when
   * <a href="#/p5/image">image()</a> is called.
   *
   * By default, the first
   * two parameters of <a href="#/p5/image">image()</a> are the x- and
   * y-coordinates of the image's upper-left corner. The next parameters are
   * its width and height. This is the same as calling `imageMode(CORNER)`.
   *
   * `imageMode(CORNERS)` also uses the first two parameters of
   * <a href="#/p5/image">image()</a> as the x- and y-coordinates of the image's
   * top-left corner. The third and fourth parameters are the coordinates of its
   * bottom-right corner.
   *
   * `imageMode(CENTER)` uses the first two parameters of
   * <a href="#/p5/image">image()</a> as the x- and y-coordinates of the image's
   * center. The next parameters are its width and height.
   *
   * @method imageMode
   * @param {(CORNER|CORNERS|CENTER)} mode either CORNER, CORNERS, or CENTER.
   *
   * @example
   *
   * <div>
   * <code>
   * let img;
   *
   * async function setup() {
   *   // Load the image.
   *   img = await loadImage('assets/bricks.jpg');
   *
   *   createCanvas(100, 100);
   *
   *   background(200);
   *
   *   // Use CORNER mode.
   *   imageMode(CORNER);
   *
   *   // Display the image.
   *   image(img, 10, 10, 50, 50);
   *
   *   describe('A square image of a brick wall is drawn at the top left of a gray square.');
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * let img;
   *
   * async function setup() {
   *   // Load the image.
   *   img = await loadImage('assets/bricks.jpg');
   *
   *   createCanvas(100, 100);
   *
   *   background(200);
   *
   *   // Use CORNERS mode.
   *   imageMode(CORNERS);
   *
   *   // Display the image.
   *   image(img, 10, 10, 90, 40);
   *
   *   describe('An image of a brick wall is drawn on a gray square. The image is squeezed into a small rectangular area.');
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * let img;
   *
   * async function setup() {
   *   // Load the image.
   *   img = await loadImage('assets/bricks.jpg');
   *
   *   createCanvas(100, 100);
   *
   *   background(200);
   *
   *   // Use CENTER mode.
   *   imageMode(CENTER);
   *
   *   // Display the image.
   *   image(img, 50, 50, 80, 80);
   *
   *   describe('A square image of a brick wall is drawn on a gray square.');
   * }
   * </code>
   * </div>
   */
  fn.imageMode = function(m) {
    // p5._validateParameters('imageMode', arguments);
    if (
      m === CORNER ||
      m === CORNERS ||
      m === CENTER
    ) {
      this._renderer.states.setValue('imageMode', m);
    }
  };
}

if(typeof p5 !== 'undefined'){
  loadingDisplaying(p5, p5.prototype);
}

/**
 * @module 3D
 * @submodule Camera
 * @requires core
 */


class Camera {
  constructor(renderer) {
    this._renderer = renderer;

    this.cameraType = 'default';
    this.useLinePerspective = true;
    this.cameraMatrix = new Matrix(4);
    this.projMatrix = new Matrix(4);
    this.yScale = 1;
  }
  /**
   * The cameras x-coordinate.
   *
   * By default, the cameras x-coordinate is set to 0 in "world" space.
   *
   * @property {Number} eyeX
   * @readonly
   *
   * @example
   * <div>
   * <code>
   * let cam;
   * let font;
   *
   * async function setup() {
   *   // Load a font and create a p5.Font object.
   *   font = await loadFont('assets/inconsolata.otf');
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Create a p5.Camera object.
   *   cam = createCamera();
   *
   *   // Set the camera
   *   setCamera(cam);
   *
   *   // Place the camera at the top-center.
   *   cam.setPosition(0, -400, 800);
   *
   *   // Point the camera at the origin.
   *   cam.lookAt(0, 0, 0);
   *
   *   describe(
   *     'A white cube on a gray background. The text "eyeX: 0" is written in black beneath it.'
   *   );
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Style the box.
   *   fill(255);
   *
   *   // Draw the box.
   *   box();
   *
   *   // Style the text.
   *   textAlign(CENTER);
   *   textSize(16);
   *   textFont(font);
   *   fill(0);
   *
   *   // Display the value of eyeX, rounded to the nearest integer.
   *   text(`eyeX: ${round(cam.eyeX)}`, 0, 45);
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * let cam;
   * let font;
   *
   * async function setup() {
   *   // Load a font and create a p5.Font object.
   *   font = await loadFont('assets/inconsolata.otf');
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Create a p5.Camera object.
   *   cam = createCamera();
   *
   *   // Place the camera at the top-center.
   *   cam.setPosition(0, -400, 800);
   *
   *   // Point the camera at the origin.
   *   cam.lookAt(0, 0, 0);
   *
   *   describe(
   *     'A white cube on a gray background. The cube appears to move left and right as the camera moves. The text "eyeX: X" is written in black beneath the cube. X oscillates between -25 and 25.'
   *   );
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Style the box.
   *   fill(255);
   *
   *   // Draw the box.
   *   box();
   *
   *   // Style the text.
   *   textAlign(CENTER);
   *   textSize(16);
   *   textFont(font);
   *   fill(0);
   *
   *   // Calculate the new x-coordinate.
   *   let x = 25 * sin(frameCount * 0.01);
   *
   *   // Set the camera's position.
   *   cam.setPosition(x, -400, 800);
   *
   *   // Display the value of eyeX, rounded to the nearest integer.
   *   text(`eyeX: ${round(cam.eyeX)}`, 0, 45);
   * }
   * </code>
   * </div>
   */

  /**
   * The cameras y-coordinate.
   *
   * By default, the cameras y-coordinate is set to 0 in "world" space.
   *
   * @property {Number} eyeY
   * @readonly
   *
   * @example
   * <div>
   * <code>
   * let cam;
   * let font;
   *
   * async function setup() {
   *   // Load a font and create a p5.Font object.
   *   font = await loadFont('assets/inconsolata.otf');
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Create a p5.Camera object.
   *   cam = createCamera();
   *
   *   // Place the camera at the top-center.
   *   cam.setPosition(0, -400, 800);
   *
   *   // Point the camera at the origin.
   *   cam.lookAt(0, 0, 0);
   *
   *   // Set the camera.
   *   setCamera(cam);
   *
   *   describe(
   *     'A white cube on a gray background. The text "eyeY: -400" is written in black beneath it.'
   *   );
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Style the box.
   *   fill(255);
   *
   *   // Draw the box.
   *   box();
   *
   *   // Style the text.
   *   textAlign(CENTER);
   *   textSize(16);
   *   textFont(font);
   *   fill(0);
   *
   *   // Display the value of eyeY, rounded to the nearest integer.
   *   text(`eyeY: ${round(cam.eyeY)}`, 0, 45);
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * let cam;
   * let font;
   *
   * async function setup() {
   *   // Load a font and create a p5.Font object.
   *   font = await loadFont('assets/inconsolata.otf');
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Create a p5.Camera object.
   *   cam = createCamera();
   *
   *   // Set the camera
   *   setCamera(cam);
   *
   *   // Place the camera at the top-center.
   *   cam.setPosition(0, -400, 800);
   *
   *   // Point the camera at the origin.
   *   cam.lookAt(0, 0, 0);
   *
   *   describe(
   *     'A white cube on a gray background. The cube appears to move up and down as the camera moves. The text "eyeY: Y" is written in black beneath the cube. Y oscillates between -374 and -425.'
   *   );
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Style the box.
   *   fill(255);
   *
   *   // Draw the box.
   *   box();
   *
   *   // Style the text.
   *   textAlign(CENTER);
   *   textSize(16);
   *   textFont(font);
   *   fill(0);
   *
   *   // Calculate the new y-coordinate.
   *   let y = 25 * sin(frameCount * 0.01) - 400;
   *
   *   // Set the camera's position.
   *   cam.setPosition(0, y, 800);
   *
   *   // Display the value of eyeY, rounded to the nearest integer.
   *   text(`eyeY: ${round(cam.eyeY)}`, 0, 45);
   * }
   * </code>
   * </div>
   */

  /**
   * The cameras z-coordinate.
   *
   * By default, the cameras z-coordinate is set to 800 in "world" space.
   *
   * @property {Number} eyeZ
   * @readonly
   *
   * @example
   * <div>
   * <code>
   * let cam;
   * let font;
   *
   * async function setup() {
   *   // Load a font and create a p5.Font object.
   *   font = await loadFont('assets/inconsolata.otf');
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Create a p5.Camera object.
   *   cam = createCamera();
   *
   *   // Set the camera
   *   setCamera(cam);
   *
   *   // Place the camera at the top-center.
   *   cam.setPosition(0, -400, 800);
   *
   *   // Point the camera at the origin.
   *   cam.lookAt(0, 0, 0);
   *
   *   describe(
   *     'A white cube on a gray background. The text "eyeZ: 800" is written in black beneath it.'
   *   );
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Style the box.
   *   fill(255);
   *
   *   // Draw the box.
   *   box();
   *
   *   // Style the text.
   *   textAlign(CENTER);
   *   textSize(16);
   *   textFont(font);
   *   fill(0);
   *
   *   // Display the value of eyeZ, rounded to the nearest integer.
   *   text(`eyeZ: ${round(cam.eyeZ)}`, 0, 45);
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * let cam;
   * let font;
   *
   * async function setup() {
   *   // Load a font and create a p5.Font object.
   *   font = await loadFont('assets/inconsolata.otf');
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Create a p5.Camera object.
   *   cam = createCamera();
   *
   *   // Set the camera
   *   setCamera(cam);
   *
   *   // Place the camera at the top-center.
   *   cam.setPosition(0, -400, 800);
   *
   *   // Point the camera at the origin.
   *   cam.lookAt(0, 0, 0);
   *
   *   describe(
   *     'A white cube on a gray background. The cube appears to move forward and back as the camera moves. The text "eyeZ: Z" is written in black beneath the cube. Z oscillates between 700 and 900.'
   *   );
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Style the box.
   *   fill(255);
   *
   *   // Draw the box.
   *   box();
   *
   *   // Style the text.
   *   textAlign(CENTER);
   *   textSize(16);
   *   textFont(font);
   *   fill(0);
   *
   *   // Calculate the new z-coordinate.
   *   let z = 100 * sin(frameCount * 0.01) + 800;
   *
   *   // Set the camera's position.
   *   cam.setPosition(0, -400, z);
   *
   *   // Display the value of eyeZ, rounded to the nearest integer.
   *   text(`eyeZ: ${round(cam.eyeZ)}`, 0, 45);
   * }
   * </code>
   * </div>
   */

  /**
   * The x-coordinate of the place where the camera looks.
   *
   * By default, the camera looks at the origin `(0, 0, 0)` in "world" space, so
   * `myCamera.centerX` is 0.
   *
   * @property {Number} centerX
   * @readonly
   *
   * @example
   * <div>
   * <code>
   * let cam;
   * let font;
   *
   * async function setup() {
   *   // Load a font and create a p5.Font object.
   *   font = await loadFont('assets/inconsolata.otf');
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Create a p5.Camera object.
   *   cam = createCamera();
   *
   *   // Set the camera
   *   setCamera(cam);
   *
   *   // Place the camera at the top-center.
   *   cam.setPosition(0, -400, 800);
   *
   *   // Point the camera at (10, 20, -30).
   *   cam.lookAt(10, 20, -30);
   *
   *   describe(
   *     'A white cube on a gray background. The text "centerX: 10" is written in black beneath it.'
   *   );
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Style the box.
   *   fill(255);
   *
   *   // Draw the box.
   *   box();
   *
   *   // Style the text.
   *   textAlign(CENTER);
   *   textSize(16);
   *   textFont(font);
   *   fill(0);
   *
   *   // Display the value of centerX, rounded to the nearest integer.
   *   text(`centerX: ${round(cam.centerX)}`, 0, 45);
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * let cam;
   * let font;
   *
   * async function setup() {
   *   // Load a font and create a p5.Font object.
   *   font = await loadFont('assets/inconsolata.otf');
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Create a p5.Camera object.
   *   cam = createCamera();
   *
   *   // Set the camera
   *   setCamera(cam);
   *
   *   // Place the camera at the top-right.
   *   cam.setPosition(100, -400, 800);
   *
   *   // Point the camera at (10, 20, -30).
   *   cam.lookAt(10, 20, -30);
   *
   *   describe(
   *     'A white cube on a gray background. The cube appears to move left and right as the camera shifts its focus. The text "centerX: X" is written in black beneath the cube. X oscillates between -15 and 35.'
   *   );
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Style the box.
   *   fill(255);
   *
   *   // Draw the box.
   *   box();
   *
   *   // Style the text.
   *   textAlign(CENTER);
   *   textSize(16);
   *   textFont(font);
   *   fill(0);
   *
   *   // Calculate the new x-coordinate.
   *   let x = 25 * sin(frameCount * 0.01) + 10;
   *
   *   // Point the camera.
   *   cam.lookAt(x, 20, -30);
   *
   *   // Display the value of centerX, rounded to the nearest integer.
   *   text(`centerX: ${round(cam.centerX)}`, 0, 45);
   * }
   * </code>
   * </div>
   */

  /**
   * The y-coordinate of the place where the camera looks.
   *
   * By default, the camera looks at the origin `(0, 0, 0)` in "world" space, so
   * `myCamera.centerY` is 0.
   *
   * @property {Number} centerY
   * @readonly
   *
   * @example
   * <div>
   * <code>
   * let cam;
   * let font;
   *
   * async function setup() {
   *   // Load a font and create a p5.Font object.
   *   font = await loadFont('assets/inconsolata.otf');
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Create a p5.Camera object.
   *   cam = createCamera();
   *
   *   // Set the camera
   *   setCamera(cam);
   *
   *   // Place the camera at the top-center.
   *   cam.setPosition(0, -400, 800);
   *
   *   // Point the camera at (10, 20, -30).
   *   cam.lookAt(10, 20, -30);
   *
   *   describe(
   *     'A white cube on a gray background. The text "centerY: 20" is written in black beneath it.'
   *   );
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Style the box.
   *   fill(255);
   *
   *   // Draw the box.
   *   box();
   *
   *   // Style the text.
   *   textAlign(CENTER);
   *   textSize(16);
   *   textFont(font);
   *   fill(0);
   *
   *   // Display the value of centerY, rounded to the nearest integer.
   *   text(`centerY: ${round(cam.centerY)}`, 0, 45);
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * let cam;
   * let font;
   *
   * async function setup() {
   *   // Load a font and create a p5.Font object.
   *   font = await loadFont('assets/inconsolata.otf');
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Create a p5.Camera object.
   *   cam = createCamera();
   *
   *   // Set the camera
   *   setCamera(cam);
   *
   *   // Place the camera at the top-right.
   *   cam.setPosition(100, -400, 800);
   *
   *   // Point the camera at (10, 20, -30).
   *   cam.lookAt(10, 20, -30);
   *
   *   describe(
   *     'A white cube on a gray background. The cube appears to move up and down as the camera shifts its focus. The text "centerY: Y" is written in black beneath the cube. Y oscillates between -5 and 45.'
   *   );
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Style the box.
   *   fill(255);
   *
   *   // Draw the box.
   *   box();
   *
   *   // Style the text.
   *   textAlign(CENTER);
   *   textSize(16);
   *   textFont(font);
   *   fill(0);
   *
   *   // Calculate the new y-coordinate.
   *   let y = 25 * sin(frameCount * 0.01) + 20;
   *
   *   // Point the camera.
   *   cam.lookAt(10, y, -30);
   *
   *   // Display the value of centerY, rounded to the nearest integer.
   *   text(`centerY: ${round(cam.centerY)}`, 0, 45);
   * }
   * </code>
   * </div>
   */

  /**
   * The y-coordinate of the place where the camera looks.
   *
   * By default, the camera looks at the origin `(0, 0, 0)` in "world" space, so
   * `myCamera.centerZ` is 0.
   *
   * @property {Number} centerZ
   * @readonly
   *
   * @example
   * <div>
   * <code>
   * let cam;
   * let font;
   *
   * async function setup() {
   *   // Load a font and create a p5.Font object.
   *   font = await loadFont('assets/inconsolata.otf');
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Create a p5.Camera object.
   *   cam = createCamera();
   *
   *   // Set the camera
   *   setCamera(cam);
   *
   *   // Place the camera at the top-center.
   *   cam.setPosition(0, -400, 800);
   *
   *   // Point the camera at (10, 20, -30).
   *   cam.lookAt(10, 20, -30);
   *
   *   describe(
   *     'A white cube on a gray background. The text "centerZ: -30" is written in black beneath it.'
   *   );
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Style the box.
   *   fill(255);
   *
   *   // Draw the box.
   *   box();
   *
   *   // Style the text.
   *   textAlign(CENTER);
   *   textSize(16);
   *   textFont(font);
   *   fill(0);
   *
   *   // Display the value of centerZ, rounded to the nearest integer.
   *   text(`centerZ: ${round(cam.centerZ)}`, 0, 45);
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * let cam;
   * let font;
   *
   * async function setup() {
   *   // Load a font and create a p5.Font object.
   *   font = await loadFont('assets/inconsolata.otf');
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Create a p5.Camera object.
   *   cam = createCamera();
   *
   *   // Place the camera at the top-right.
   *   cam.setPosition(100, -400, 800);
   *
   *   // Point the camera at (10, 20, -30).
   *   cam.lookAt(10, 20, -30);
   *
   *   describe(
   *     'A white cube on a gray background. The cube appears to move forward and back as the camera shifts its focus. The text "centerZ: Z" is written in black beneath the cube. Z oscillates between -55 and -25.'
   *   );
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Style the box.
   *   fill(255);
   *
   *   // Draw the box.
   *   box();
   *
   *   // Style the text.
   *   textAlign(CENTER);
   *   textSize(16);
   *   textFont(font);
   *   fill(0);
   *
   *   // Calculate the new z-coordinate.
   *   let z = 25 * sin(frameCount * 0.01) - 30;
   *
   *   // Point the camera.
   *   cam.lookAt(10, 20, z);
   *
   *   // Display the value of centerZ, rounded to the nearest integer.
   *   text(`centerZ: ${round(cam.centerZ)}`, 0, 45);
   * }
   * </code>
   * </div>
   */

  /**
   * The x-component of the camera's "up" vector.
   *
   * The camera's "up" vector orients its y-axis. By default, the "up" vector is
   * `(0, 1, 0)`, so its x-component is 0 in "local" space.
   *
   * @property {Number} upX
   * @readonly
   *
   * @example
   * <div>
   * <code>
   * let cam;
   * let font;
   *
   * async function setup() {
   *   // Load a font and create a p5.Font object.
   *   font = await loadFont('assets/inconsolata.otf');
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Create a p5.Camera object.
   *   cam = createCamera();
   *
   *   // Set the camera
   *   setCamera(cam);
   *
   *   // Place the camera at the top-right: (100, -400, 800)
   *   // Point it at the origin: (0, 0, 0)
   *   // Set its "up" vector: (0, 1, 0).
   *   cam.camera(100, -400, 800, 0, 0, 0, 0, 1, 0);
   *
   *   describe(
   *     'A white cube on a gray background. The text "upX: 0" is written in black beneath it.'
   *   );
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Style the box.
   *   fill(255);
   *
   *   // Draw the box.
   *   box();
   *
   *   // Style the text.
   *   textAlign(CENTER);
   *   textSize(16);
   *   textFont(font);
   *   fill(0);
   *
   *   // Display the value of upX, rounded to the nearest tenth.
   *   text(`upX: ${round(cam.upX, 1)}`, 0, 45);
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * let cam;
   * let font;
   *
   * async function setup() {
   *   // Load a font and create a p5.Font object.
   *   font = await loadFont('assets/inconsolata.otf');
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Create a p5.Camera object.
   *   cam = createCamera();
   *
   *   // Set the camera
   *   setCamera(cam);
   *
   *   // Place the camera at the top-right: (100, -400, 800)
   *   // Point it at the origin: (0, 0, 0)
   *   // Set its "up" vector: (0, 1, 0).
   *   cam.camera(100, -400, 800, 0, 0, 0, 0, 1, 0);
   *
   *   describe(
   *     'A white cube on a gray background. The cube appears to rock back and forth. The text "upX: X" is written in black beneath it. X oscillates between -1 and 1.'
   *   );
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Style the box.
   *   fill(255);
   *
   *   // Draw the box.
   *   box();
   *
   *   // Style the text.
   *   textAlign(CENTER);
   *   textSize(16);
   *   textFont(font);
   *   fill(0);
   *
   *   // Calculate the x-component.
   *   let x = sin(frameCount * 0.01);
   *
   *   // Update the camera's "up" vector.
   *   cam.camera(100, -400, 800, 0, 0, 0, x, 1, 0);
   *
   *   // Display the value of upX, rounded to the nearest tenth.
   *   text(`upX: ${round(cam.upX, 1)}`, 0, 45);
   * }
   * </code>
   * </div>
   */

  /**
   * The y-component of the camera's "up" vector.
   *
   * The camera's "up" vector orients its y-axis. By default, the "up" vector is
   * `(0, 1, 0)`, so its y-component is 1 in "local" space.
   *
   * @property {Number} upY
   * @readonly
   *
   * @example
   * <div>
   * <code>
   * let cam;
   * let font;
   *
   * async function setup() {
   *   // Load a font and create a p5.Font object.
   *   font = await loadFont('assets/inconsolata.otf');
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Create a p5.Camera object.
   *   cam = createCamera();
   *
   *   // Set the camera
   *   setCamera(cam);
   *
   *   // Place the camera at the top-right: (100, -400, 800)
   *   // Point it at the origin: (0, 0, 0)
   *   // Set its "up" vector: (0, 1, 0).
   *   cam.camera(100, -400, 800, 0, 0, 0, 0, 1, 0);
   *
   *   describe(
   *     'A white cube on a gray background. The text "upY: 1" is written in black beneath it.'
   *   );
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Style the box.
   *   fill(255);
   *
   *   // Draw the box.
   *   box();
   *
   *   // Style the text.
   *   textAlign(CENTER);
   *   textSize(16);
   *   textFont(font);
   *   fill(0);
   *
   *   // Display the value of upY, rounded to the nearest tenth.
   *   text(`upY: ${round(cam.upY, 1)}`, 0, 45);
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * let cam;
   * let font;
   *
   * async function setup() {
   *   // Load a font and create a p5.Font object.
   *   font = await loadFont('assets/inconsolata.otf');
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Create a p5.Camera object.
   *   cam = createCamera();
   *
   *   // Set the camera
   *   setCamera(cam);
   *
   *   // Place the camera at the top-right: (100, -400, 800)
   *   // Point it at the origin: (0, 0, 0)
   *   // Set its "up" vector: (0, 1, 0).
   *   cam.camera(100, -400, 800, 0, 0, 0, 0, 1, 0);
   *
   *   describe(
   *     'A white cube on a gray background. The cube flips upside-down periodically. The text "upY: Y" is written in black beneath it. Y oscillates between -1 and 1.'
   *   );
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Style the box.
   *   fill(255);
   *
   *   // Draw the box.
   *   box();
   *
   *   // Style the text.
   *   textAlign(CENTER);
   *   textSize(16);
   *   textFont(font);
   *   fill(0);
   *
   *   // Calculate the y-component.
   *   let y = sin(frameCount * 0.01);
   *
   *   // Update the camera's "up" vector.
   *   cam.camera(100, -400, 800, 0, 0, 0, 0, y, 0);
   *
   *   // Display the value of upY, rounded to the nearest tenth.
   *   text(`upY: ${round(cam.upY, 1)}`, 0, 45);
   * }
   * </code>
   * </div>
   */

  /**
   * The z-component of the camera's "up" vector.
   *
   * The camera's "up" vector orients its y-axis. By default, the "up" vector is
   * `(0, 1, 0)`, so its z-component is 0 in "local" space.
   *
   * @property {Number} upZ
   * @readonly
   *
   * @example
   * <div>
   * <code>
   * let cam;
   * let font;
   *
   * async function setup() {
   *   // Load a font and create a p5.Font object.
   *   font = await loadFont('assets/inconsolata.otf');
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Create a p5.Camera object.
   *   cam = createCamera();
   *
   *   // Set the camera
   *   setCamera(cam);
   *
   *   // Place the camera at the top-right: (100, -400, 800)
   *   // Point it at the origin: (0, 0, 0)
   *   // Set its "up" vector: (0, 1, 0).
   *   cam.camera(100, -400, 800, 0, 0, 0, 0, 1, 0);
   *
   *   describe(
   *     'A white cube on a gray background. The text "upZ: 0" is written in black beneath it.'
   *   );
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Style the box.
   *   fill(255);
   *
   *   // Draw the box.
   *   box();
   *
   *   // Style the text.
   *   textAlign(CENTER);
   *   textSize(16);
   *   textFont(font);
   *   fill(0);
   *
   *   // Display the value of upZ, rounded to the nearest tenth.
   *   text(`upZ: ${round(cam.upZ, 1)}`, 0, 45);
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * let cam;
   * let font;
   *
   * async function setup() {
   *   // Load a font and create a p5.Font object.
   *   font = await loadFont('assets/inconsolata.otf');
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Create a p5.Camera object.
   *   cam = createCamera();
   *
   *   // Set the camera
   *   setCamera(cam);
   *
   *   // Place the camera at the top-right: (100, -400, 800)
   *   // Point it at the origin: (0, 0, 0)
   *   // Set its "up" vector: (0, 1, 0).
   *   cam.camera(100, -400, 800, 0, 0, 0, 0, 1, 0);
   *
   *   describe(
   *     'A white cube on a gray background. The cube appears to rock back and forth. The text "upZ: Z" is written in black beneath it. Z oscillates between -1 and 1.'
   *   );
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Style the box.
   *   fill(255);
   *
   *   // Draw the box.
   *   box();
   *
   *   // Style the text.
   *   textAlign(CENTER);
   *   textSize(16);
   *   textFont(font);
   *   fill(0);
   *
   *   // Calculate the z-component.
   *   let z = sin(frameCount * 0.01);
   *
   *   // Update the camera's "up" vector.
   *   cam.camera(100, -400, 800, 0, 0, 0, 0, 1, z);
   *
   *   // Display the value of upZ, rounded to the nearest tenth.
   *   text(`upZ: ${round(cam.upZ, 1)}`, 0, 45);
   * }
   * </code>
   * </div>
   */

  ////////////////////////////////////////////////////////////////////////////////
  // Camera Projection Methods
  ////////////////////////////////////////////////////////////////////////////////

  /**
   * Sets a perspective projection for the camera.
   *
   * In a perspective projection, shapes that are further from the camera appear
   * smaller than shapes that are near the camera. This technique, called
   * foreshortening, creates realistic 3D scenes. Its applied by default in new
   * `p5.Camera` objects.
   *
   * `myCamera.perspective()` changes the cameras perspective by changing its
   * viewing frustum. The frustum is the volume of space thats visible to the
   * camera. The frustums shape is a pyramid with its top cut off. The camera
   * is placed where the top of the pyramid should be and points towards the
   * base of the pyramid. It views everything within the frustum.
   *
   * The first parameter, `fovy`, is the cameras vertical field of view. Its
   * an angle that describes how tall or narrow a view the camera has. For
   * example, calling `myCamera.perspective(0.5)` sets the cameras vertical
   * field of view to 0.5 radians. By default, `fovy` is calculated based on the
   * sketchs height and the cameras default z-coordinate, which is 800. The
   * formula for the default `fovy` is `2 * atan(height / 2 / 800)`.
   *
   * The second parameter, `aspect`, is the cameras aspect ratio. Its a number
   * that describes the ratio of the top planes width to its height. For
   * example, calling `myCamera.perspective(0.5, 1.5)` sets the cameras field
   * of view to 0.5 radians and aspect ratio to 1.5, which would make shapes
   * appear thinner on a square canvas. By default, `aspect` is set to
   * `width / height`.
   *
   * The third parameter, `near`, is the distance from the camera to the near
   * plane. For example, calling `myCamera.perspective(0.5, 1.5, 100)` sets the
   * cameras field of view to 0.5 radians, its aspect ratio to 1.5, and places
   * the near plane 100 pixels from the camera. Any shapes drawn less than 100
   * pixels from the camera wont be visible. By default, `near` is set to
   * `0.1 * 800`, which is 1/10th the default distance between the camera and
   * the origin.
   *
   * The fourth parameter, `far`, is the distance from the camera to the far
   * plane. For example, calling `myCamera.perspective(0.5, 1.5, 100, 10000)`
   * sets the cameras field of view to 0.5 radians, its aspect ratio to 1.5,
   * places the near plane 100 pixels from the camera, and places the far plane
   * 10,000 pixels from the camera. Any shapes drawn more than 10,000 pixels
   * from the camera wont be visible. By default, `far` is set to `10 * 800`,
   * which is 10 times the default distance between the camera and the origin.
   *
   * @for p5.Camera
   * @param  {Number} [fovy]   camera frustum vertical field of view. Defaults to
   *                           `2 * atan(height / 2 / 800)`.
   * @param  {Number} [aspect] camera frustum aspect ratio. Defaults to
   *                           `width / height`.
   * @param  {Number} [near]   distance from the camera to the near clipping plane.
   *                           Defaults to `0.1 * 800`.
   * @param  {Number} [far]    distance from the camera to the far clipping plane.
   *                           Defaults to `10 * 800`.
   *
   * @example
   * <div>
   * <code>
   * // Double-click to toggle between cameras.
   *
   * let cam1;
   * let cam2;
   * let isDefaultCamera = true;
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Create the first camera.
   *   // Keep its default settings.
   *   cam1 = createCamera();
   *
   *   // Create the second camera.
   *   cam2 = createCamera();
   *
   *   // Place it at the top-right.
   *   cam2.camera(400, -400, 800);
   *
   *   // Set its fovy to 0.2.
   *   // Set its aspect to 1.5.
   *   // Set its near to 600.
   *   // Set its far to 1200.
   *   cam2.perspective(0.2, 1.5, 600, 1200);
   *
   *   // Set the current camera to cam1.
   *   setCamera(cam1);
   *
   *   describe('A white cube on a gray background. The camera toggles between a frontal view and a skewed aerial view when the user double-clicks.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Draw the box.
   *   box();
   * }
   *
   * // Toggle the current camera when the user double-clicks.
   * function doubleClicked() {
   *   if (isDefaultCamera === true) {
   *     setCamera(cam2);
   *     isDefaultCamera = false;
   *   } else {
   *     setCamera(cam1);
   *     isDefaultCamera = true;
   *   }
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Double-click to toggle between cameras.
   *
   * let cam1;
   * let cam2;
   * let isDefaultCamera = true;
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Create the first camera.
   *   // Keep its default settings.
   *   cam1 = createCamera();
   *
   *   // Create the second camera.
   *   cam2 = createCamera();
   *
   *   // Place it at the top-right.
   *   cam2.camera(400, -400, 800);
   *
   *   // Set its fovy to 0.2.
   *   // Set its aspect to 1.5.
   *   // Set its near to 600.
   *   // Set its far to 1200.
   *   cam2.perspective(0.2, 1.5, 600, 1200);
   *
   *   // Set the current camera to cam1.
   *   setCamera(cam1);
   *
   *   describe('A white cube moves left and right on a gray background. The camera toggles between a frontal and a skewed aerial view when the user double-clicks.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Translate the origin left and right.
   *   let x = 100 * sin(frameCount * 0.01);
   *   translate(x, 0, 0);
   *
   *   // Draw the box.
   *   box();
   * }
   *
   * // Toggle the current camera when the user double-clicks.
   * function doubleClicked() {
   *   if (isDefaultCamera === true) {
   *     setCamera(cam2);
   *     isDefaultCamera = false;
   *   } else {
   *     setCamera(cam1);
   *     isDefaultCamera = true;
   *   }
   * }
   * </code>
   * </div>
   */
  perspective(fovy, aspect, near, far) {
    this.cameraType = arguments.length > 0 ? 'custom' : 'default';
    if (typeof fovy === 'undefined') {
      fovy = this.defaultCameraFOV;
      // this avoids issue where setting angleMode(DEGREES) before calling
      // perspective leads to a smaller than expected FOV (because
      // _computeCameraDefaultSettings computes in radians)
      this.cameraFOV = fovy;
    } else {
      this.cameraFOV = this._renderer._pInst._toRadians(fovy);
    }
    if (typeof aspect === 'undefined') {
      aspect = this.defaultAspectRatio;
    }
    if (typeof near === 'undefined') {
      near = this.defaultCameraNear;
    }
    if (typeof far === 'undefined') {
      far = this.defaultCameraFar;
    }

    if (near <= 0.0001) {
      near = 0.01;
      console.log(
        'Avoid perspective near plane values close to or below 0. ' +
        'Setting value to 0.01.'
      );
    }

    if (far < near) {
      console.log(
        'Perspective far plane value is less than near plane value. ' +
        'Nothing will be shown.'
      );
    }

    this.aspectRatio = aspect;
    this.cameraNear = near;
    this.cameraFar = far;

    this.projMatrix = new Matrix(4);

    const f = 1.0 / Math.tan(this.cameraFOV / 2);
    const nf = 1.0 / (this.cameraNear - this.cameraFar);

    /* eslint-disable indent */
    this.projMatrix.set(f / aspect, 0, 0, 0,
      0, -f * this.yScale, 0, 0,
      0, 0, (far + near) * nf, -1,
      0, 0, (2 * far * near) * nf, 0);
    /* eslint-enable indent */

    if (this._isActive()) {
      this._renderer.states.setValue('uPMatrix', this._renderer.states.uPMatrix.clone());
      this._renderer.states.uPMatrix.set(this.projMatrix);
    }
  }

  /**
   * Sets an orthographic projection for the camera.
   *
   * In an orthographic projection, shapes with the same size always appear the
   * same size, regardless of whether they are near or far from the camera.
   *
   * `myCamera.ortho()` changes the cameras perspective by changing its viewing
   * frustum from a truncated pyramid to a rectangular prism. The frustum is the
   * volume of space thats visible to the camera. The camera is placed in front
   * of the frustum and views everything within the frustum. `myCamera.ortho()`
   * has six optional parameters to define the viewing frustum.
   *
   * The first four parameters, `left`, `right`, `bottom`, and `top`, set the
   * coordinates of the frustums sides, bottom, and top. For example, calling
   * `myCamera.ortho(-100, 100, 200, -200)` creates a frustum thats 200 pixels
   * wide and 400 pixels tall. By default, these dimensions are set based on
   * the sketchs width and height, as in
   * `myCamera.ortho(-width / 2, width / 2, -height / 2, height / 2)`.
   *
   * The last two parameters, `near` and `far`, set the distance of the
   * frustums near and far plane from the camera. For example, calling
   * `myCamera.ortho(-100, 100, 200, -200, 50, 1000)` creates a frustum thats
   * 200 pixels wide, 400 pixels tall, starts 50 pixels from the camera, and
   * ends 1,000 pixels from the camera. By default, `near` and `far` are set to
   * 0 and `max(width, height) + 800`, respectively.
   *
   * @for p5.Camera
   * @param  {Number} [left]   x-coordinate of the frustums left plane. Defaults to `-width / 2`.
   * @param  {Number} [right]  x-coordinate of the frustums right plane. Defaults to `width / 2`.
   * @param  {Number} [bottom] y-coordinate of the frustums bottom plane. Defaults to `height / 2`.
   * @param  {Number} [top]    y-coordinate of the frustums top plane. Defaults to `-height / 2`.
   * @param  {Number} [near]   z-coordinate of the frustums near plane. Defaults to 0.
   * @param  {Number} [far]    z-coordinate of the frustums far plane. Defaults to `max(width, height) + 800`.
   *
   * @example
   * <div>
   * <code>
   * // Double-click to toggle between cameras.
   *
   * let cam1;
   * let cam2;
   * let isDefaultCamera = true;
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Create the first camera.
   *   // Keep its default settings.
   *   cam1 = createCamera();
   *
   *   // Create the second camera.
   *   cam2 = createCamera();
   *
   *   // Apply an orthographic projection.
   *   cam2.ortho();
   *
   *   // Set the current camera to cam1.
   *   setCamera(cam1);
   *
   *   describe('A row of white cubes against a gray background. The camera toggles between a perspective and an orthographic projection when the user double-clicks.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Translate the origin toward the camera.
   *   translate(-10, 10, 500);
   *
   *   // Rotate the coordinate system.
   *   rotateY(-0.1);
   *   rotateX(-0.1);
   *
   *   // Draw the row of boxes.
   *   for (let i = 0; i < 6; i += 1) {
   *     translate(0, 0, -40);
   *     box(10);
   *   }
   * }
   *
   * // Toggle the current camera when the user double-clicks.
   * function doubleClicked() {
   *   if (isDefaultCamera === true) {
   *     setCamera(cam2);
   *     isDefaultCamera = false;
   *   } else {
   *     setCamera(cam1);
   *     isDefaultCamera = true;
   *   }
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Double-click to toggle between cameras.
   *
   * let cam1;
   * let cam2;
   * let isDefaultCamera = true;
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Create the first camera.
   *   // Keep its default settings.
   *   cam1 = createCamera();
   *
   *   // Create the second camera.
   *   cam2 = createCamera();
   *
   *   // Apply an orthographic projection.
   *   cam2.ortho();
   *
   *   // Set the current camera to cam1.
   *   setCamera(cam1);
   *
   *   describe('A row of white cubes slither like a snake against a gray background. The camera toggles between a perspective and an orthographic projection when the user double-clicks.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Translate the origin toward the camera.
   *   translate(-10, 10, 500);
   *
   *   // Rotate the coordinate system.
   *   rotateY(-0.1);
   *   rotateX(-0.1);
   *
   *   // Draw the row of boxes.
   *   for (let i = 0; i < 6; i += 1) {
   *     push();
   *     // Calculate the box's coordinates.
   *     let x = 10 * sin(frameCount * 0.02 + i * 0.6);
   *     let z = -40 * i;
   *     // Translate the origin.
   *     translate(x, 0, z);
   *     // Draw the box.
   *     box(10);
   *     pop();
   *   }
   * }
   *
   * // Toggle the current camera when the user double-clicks.
   * function doubleClicked() {
   *   if (isDefaultCamera === true) {
   *     setCamera(cam2);
   *     isDefaultCamera = false;
   *   } else {
   *     setCamera(cam1);
   *     isDefaultCamera = true;
   *   }
   * }
   * </code>
   * </div>
   */
  ortho(left, right, bottom, top, near, far) {
    const source = this.fbo || this._renderer;
    if (left === undefined) left = -source.width / 2;
    if (right === undefined) right = +source.width / 2;
    if (bottom === undefined) bottom = -source.height / 2;
    if (top === undefined) top = +source.height / 2;
    if (near === undefined) near = 0;
    if (far === undefined) far = Math.max(source.width, source.height) + 800;
    this.cameraNear = near;
    this.cameraFar = far;
    const w = right - left;
    const h = top - bottom;
    const d = far - near;
    const x = 2 / w;
    const y = 2 / h * this.yScale;
    const z = -2 / d;
    const tx = -(right + left) / w;
    const ty = -(top + bottom) / h;
    const tz = -(far + near) / d;
    this.projMatrix = new Matrix(4);
    /* eslint-disable indent */
    this.projMatrix.set(x, 0, 0, 0,
      0, -y, 0, 0,
      0, 0, z, 0,
      tx, ty, tz, 1);
    /* eslint-enable indent */
    if (this._isActive()) {
      this._renderer.states.setValue('uPMatrix', this._renderer.states.uPMatrix.clone());
      this._renderer.states.uPMatrix.set(this.projMatrix);
    }
    this.cameraType = 'custom';
  }
  /**
   * Sets the camera's frustum.
   *
   * In a frustum projection, shapes that are further from the camera appear
   * smaller than shapes that are near the camera. This technique, called
   * foreshortening, creates realistic 3D scenes.
   *
   * `myCamera.frustum()` changes the cameras perspective by changing its
   * viewing frustum. The frustum is the volume of space thats visible to the
   * camera. The frustums shape is a pyramid with its top cut off. The camera
   * is placed where the top of the pyramid should be and points towards the
   * base of the pyramid. It views everything within the frustum.
   *
   * The first four parameters, `left`, `right`, `bottom`, and `top`, set the
   * coordinates of the frustums sides, bottom, and top. For example, calling
   * `myCamera.frustum(-100, 100, 200, -200)` creates a frustum thats 200
   * pixels wide and 400 pixels tall. By default, these coordinates are set
   * based on the sketchs width and height, as in
   * `myCamera.frustum(-width / 20, width / 20, height / 20, -height / 20)`.
   *
   * The last two parameters, `near` and `far`, set the distance of the
   * frustums near and far plane from the camera. For example, calling
   * `myCamera.frustum(-100, 100, 200, -200, 50, 1000)` creates a frustum thats
   * 200 pixels wide, 400 pixels tall, starts 50 pixels from the camera, and ends
   * 1,000 pixels from the camera. By default, near is set to `0.1 * 800`, which
   * is 1/10th the default distance between the camera and the origin. `far` is
   * set to `10 * 800`, which is 10 times the default distance between the
   * camera and the origin.
   *
   * @for p5.Camera
   * @param  {Number} [left]   x-coordinate of the frustums left plane. Defaults to `-width / 20`.
   * @param  {Number} [right]  x-coordinate of the frustums right plane. Defaults to `width / 20`.
   * @param  {Number} [bottom] y-coordinate of the frustums bottom plane. Defaults to `height / 20`.
   * @param  {Number} [top]    y-coordinate of the frustums top plane. Defaults to `-height / 20`.
   * @param  {Number} [near]   z-coordinate of the frustums near plane. Defaults to `0.1 * 800`.
   * @param  {Number} [far]    z-coordinate of the frustums far plane. Defaults to `10 * 800`.
   *
   * @example
   * <div>
   * <code>
   * // Double-click to toggle between cameras.
   *
   * let cam1;
   * let cam2;
   * let isDefaultCamera = true;
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Create the first camera.
   *   // Keep its default settings.
   *   cam1 = createCamera();
   *
   *   // Create the second camera.
   *   cam2 = createCamera();
   *
   *   // Adjust the frustum.
   *   // Center it.
   *   // Set its width and height to 20 pixels.
   *   // Place its near plane 300 pixels from the camera.
   *   // Place its far plane 350 pixels from the camera.
   *   cam2.frustum(-10, 10, -10, 10, 300, 350);
   *
   *   // Set the current camera to cam1.
   *   setCamera(cam1);
   *
   *   describe(
   *     'A row of white cubes against a gray background. The camera zooms in on one cube when the user double-clicks.'
   *   );
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Translate the origin toward the camera.
   *   translate(-10, 10, 600);
   *
   *   // Rotate the coordinate system.
   *   rotateY(-0.1);
   *   rotateX(-0.1);
   *
   *   // Draw the row of boxes.
   *   for (let i = 0; i < 6; i += 1) {
   *     translate(0, 0, -40);
   *     box(10);
   *   }
   * }
   *
   * // Toggle the current camera when the user double-clicks.
   * function doubleClicked() {
   *   if (isDefaultCamera === true) {
   *     setCamera(cam2);
   *     isDefaultCamera = false;
   *   } else {
   *     setCamera(cam1);
   *     isDefaultCamera = true;
   *   }
   * }
   * </code>
   * </div>
   */
  frustum(left, right, bottom, top, near, far) {
    if (left === undefined) left = -this._renderer.width * 0.05;
    if (right === undefined) right = +this._renderer.width * 0.05;
    if (bottom === undefined) bottom = +this._renderer.height * 0.05;
    if (top === undefined) top = -this._renderer.height * 0.05;
    if (near === undefined) near = this.defaultCameraNear;
    if (far === undefined) far = this.defaultCameraFar;

    this.cameraNear = near;
    this.cameraFar = far;

    const w = right - left;
    const h = top - bottom;
    const d = far - near;

    const x = +(2.0 * near) / w;
    const y = +(2.0 * near) / h * this.yScale;
    const z = -(2.0 * far * near) / d;

    const tx = (right + left) / w;
    const ty = (top + bottom) / h;
    const tz = -(far + near) / d;

    this.projMatrix = new Matrix(4);

    /* eslint-disable indent */
    this.projMatrix.set(x, 0, 0, 0,
      0, -y, 0, 0,
      tx, ty, tz, -1,
      0, 0, z, 0);
    /* eslint-enable indent */

    if (this._isActive()) {
      this._renderer.states.setValue('uPMatrix', this._renderer.states.uPMatrix.clone());
      this._renderer.states.uPMatrix.set(this.projMatrix);
    }

    this.cameraType = 'custom';
  }

  ////////////////////////////////////////////////////////////////////////////////
  // Camera Orientation Methods
  ////////////////////////////////////////////////////////////////////////////////

  /**
   * Rotate camera view about arbitrary axis defined by x,y,z
   * based on http://learnwebgl.brown37.net/07_cameras/camera_rotating_motion.html
   * @private
   */
  _rotateView(a, x, y, z) {
    let centerX = this.centerX;
    let centerY = this.centerY;
    let centerZ = this.centerZ;

    // move center by eye position such that rotation happens around eye position
    centerX -= this.eyeX;
    centerY -= this.eyeY;
    centerZ -= this.eyeZ;

    const rotation = new Matrix(4); // TODO Maybe pass p5
    rotation.rotate4x4(this._renderer._pInst._toRadians(a), x, y, z);

    /* eslint-disable max-len */
    const rotatedCenter = [
      centerX * rotation.mat4[0] + centerY * rotation.mat4[4] + centerZ * rotation.mat4[8],
      centerX * rotation.mat4[1] + centerY * rotation.mat4[5] + centerZ * rotation.mat4[9],
      centerX * rotation.mat4[2] + centerY * rotation.mat4[6] + centerZ * rotation.mat4[10]
    ];
    /* eslint-enable max-len */

    // add eye position back into center
    rotatedCenter[0] += this.eyeX;
    rotatedCenter[1] += this.eyeY;
    rotatedCenter[2] += this.eyeZ;

    this.camera(
      this.eyeX,
      this.eyeY,
      this.eyeZ,
      rotatedCenter[0],
      rotatedCenter[1],
      rotatedCenter[2],
      this.upX,
      this.upY,
      this.upZ
    );
  }

  /**
   * Rotates the camera in a clockwise/counter-clockwise direction.
   *
   * Rolling rotates the camera without changing its orientation. The rotation
   * happens in the cameras "local" space.
   *
   * The parameter, `angle`, is the angle the camera should rotate. Passing a
   * positive angle, as in `myCamera.roll(0.001)`, rotates the camera in counter-clockwise direction.
   * Passing a negative angle, as in `myCamera.roll(-0.001)`, rotates the
   * camera in clockwise direction.
   *
   * Note: Angles are interpreted based on the current
   * <a href="#/p5/angleMode">angleMode()</a>.
   *
   * @method roll
   * @param {Number} angle amount to rotate camera in current
   * <a href="#/p5/angleMode">angleMode</a> units.
   * @example
   * <div>
   * <code>
   * let cam;
   * let delta = 0.01;
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *   normalMaterial();
   *   // Create a p5.Camera object.
   *   cam = createCamera();
   *
   *   // Set the camera
   *   setCamera(cam);
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Roll camera according to angle 'delta'
   *   cam.roll(delta);
   *
   *   translate(0, 0, 0);
   *   box(20);
   *   translate(0, 25, 0);
   *   box(20);
   *   translate(0, 26, 0);
   *   box(20);
   *   translate(0, 27, 0);
   *   box(20);
   *   translate(0, 28, 0);
   *   box(20);
   *   translate(0,29, 0);
   *   box(20);
   *   translate(0, 30, 0);
   *   box(20);
   * }
   * </code>
   * </div>
   *
   * @alt
   * camera view rotates in counter clockwise direction with vertically stacked boxes in front of it.
   */
  roll(amount) {
    const local = this._getLocalAxes();
    const axisQuaternion = Quat.fromAxisAngle(
      this._renderer._pInst._toRadians(amount),
      local.z[0], local.z[1], local.z[2]);
    // const upQuat = new p5.Quat(0, this.upX, this.upY, this.upZ);
    const newUpVector = axisQuaternion.rotateVector(
      new Vector(this.upX, this.upY, this.upZ));
    this.camera(
      this.eyeX,
      this.eyeY,
      this.eyeZ,
      this.centerX,
      this.centerY,
      this.centerZ,
      newUpVector.x,
      newUpVector.y,
      newUpVector.z
    );
  }

  /**
   * Rotates the camera left and right.
   *
   * Panning rotates the camera without changing its position. The rotation
   * happens in the cameras "local" space.
   *
   * The parameter, `angle`, is the angle the camera should rotate. Passing a
   * positive angle, as in `myCamera.pan(0.001)`, rotates the camera to the
   * right. Passing a negative angle, as in `myCamera.pan(-0.001)`, rotates the
   * camera to the left.
   *
   * Note: Angles are interpreted based on the current
   * <a href="#/p5/angleMode">angleMode()</a>.
   *
   * @param {Number} angle amount to rotate in the current
   *                       <a href="#/p5/angleMode">angleMode()</a>.
   *
   * @example
   * <div>
   * <code>
   * let cam;
   * let delta = 0.001;
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Create a p5.Camera object.
   *   cam = createCamera();
   *
   *   // Set the camera
   *   setCamera(cam);
   *
   *   // Place the camera at the top-center.
   *   cam.setPosition(0, -400, 800);
   *
   *   // Point the camera at the origin.
   *   cam.lookAt(0, 0, 0);
   *
   *   describe(
   *     'A white cube on a gray background. The cube goes in and out of view as the camera pans left and right.'
   *   );
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Pan with the camera.
   *   cam.pan(delta);
   *
   *   // Switch directions every 120 frames.
   *   if (frameCount % 120 === 0) {
   *     delta *= -1;
   *   }
   *
   *   // Draw the box.
   *   box();
   * }
   * </code>
   * </div>
   */
  pan(amount) {
    const local = this._getLocalAxes();
    this._rotateView(amount, local.y[0], local.y[1], local.y[2]);
  }

  /**
   * Rotates the camera up and down.
   *
   * Tilting rotates the camera without changing its position. The rotation
   * happens in the cameras "local" space.
   *
   * The parameter, `angle`, is the angle the camera should rotate. Passing a
   * positive angle, as in `myCamera.tilt(0.001)`, rotates the camera down.
   * Passing a negative angle, as in `myCamera.tilt(-0.001)`, rotates the camera
   * up.
   *
   * Note: Angles are interpreted based on the current
   * <a href="#/p5/angleMode">angleMode()</a>.
   *
   * @param {Number} angle amount to rotate in the current
   *                       <a href="#/p5/angleMode">angleMode()</a>.
   *
   * @example
   * <div>
   * <code>
   * let cam;
   * let delta = 0.001;
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Create a p5.Camera object.
   *   cam = createCamera();
   *
   *   // Set the camera
   *   setCamera(cam);
   *
   *   // Place the camera at the top-center.
   *   cam.setPosition(0, -400, 800);
   *
   *   // Point the camera at the origin.
   *   cam.lookAt(0, 0, 0);
   *
   *   describe(
   *     'A white cube on a gray background. The cube goes in and out of view as the camera tilts up and down.'
   *   );
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Pan with the camera.
   *   cam.tilt(delta);
   *
   *   // Switch directions every 120 frames.
   *   if (frameCount % 120 === 0) {
   *     delta *= -1;
   *   }
   *
   *   // Draw the box.
   *   box();
   * }
   * </code>
   * </div>
   */
  tilt(amount) {
    const local = this._getLocalAxes();
    this._rotateView(amount, local.x[0], local.x[1], local.x[2]);
  }

  /**
   * Points the camera at a location.
   *
   * `myCamera.lookAt()` changes the cameras orientation without changing its
   * position.
   *
   * The parameters, `x`, `y`, and `z`, are the coordinates in "world" space
   * where the camera should point. For example, calling
   * `myCamera.lookAt(10, 20, 30)` points the camera at the coordinates
   * `(10, 20, 30)`.
   *
   * @for p5.Camera
   * @param {Number} x x-coordinate of the position where the camera should look in "world" space.
   * @param {Number} y y-coordinate of the position where the camera should look in "world" space.
   * @param {Number} z z-coordinate of the position where the camera should look in "world" space.
   *
   * @example
   * <div>
   * <code>
   * // Double-click to look at a different cube.
   *
   * let cam;
   * let isLookingLeft = true;
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Create a p5.Camera object.
   *   cam = createCamera();
   *
   *   // Set the camera
   *   setCamera(cam);
   *
   *   // Place the camera at the top-center.
   *   cam.setPosition(0, -400, 800);
   *
   *   // Point the camera at the origin.
   *   cam.lookAt(-30, 0, 0);
   *
   *   describe(
   *     'A red cube and a blue cube on a gray background. The camera switches focus between the cubes when the user double-clicks.'
   *   );
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Draw the box on the left.
   *   push();
   *   // Translate the origin to the left.
   *   translate(-30, 0, 0);
   *   // Style the box.
   *   fill(255, 0, 0);
   *   // Draw the box.
   *   box(20);
   *   pop();
   *
   *   // Draw the box on the right.
   *   push();
   *   // Translate the origin to the right.
   *   translate(30, 0, 0);
   *   // Style the box.
   *   fill(0, 0, 255);
   *   // Draw the box.
   *   box(20);
   *   pop();
   * }
   *
   * // Change the camera's focus when the user double-clicks.
   * function doubleClicked() {
   *   if (isLookingLeft === true) {
   *     cam.lookAt(30, 0, 0);
   *     isLookingLeft = false;
   *   } else {
   *     cam.lookAt(-30, 0, 0);
   *     isLookingLeft = true;
   *   }
   * }
   * </code>
   * </div>
   */
  lookAt(x, y, z) {
    this.camera(
      this.eyeX,
      this.eyeY,
      this.eyeZ,
      x,
      y,
      z,
      this.upX,
      this.upY,
      this.upZ
    );
  }

  ////////////////////////////////////////////////////////////////////////////////
  // Camera Position Methods
  ////////////////////////////////////////////////////////////////////////////////

  /**
   * Sets the position and orientation of the camera.
   *
   * `myCamera.camera()` allows objects to be viewed from different angles. It
   * has nine parameters that are all optional.
   *
   * The first three parameters, `x`, `y`, and `z`, are the coordinates of the
   * cameras position in "world" space. For example, calling
   * `myCamera.camera(0, 0, 0)` places the camera at the origin `(0, 0, 0)`. By
   * default, the camera is placed at `(0, 0, 800)`.
   *
   * The next three parameters, `centerX`, `centerY`, and `centerZ` are the
   * coordinates of the point where the camera faces in "world" space. For
   * example, calling `myCamera.camera(0, 0, 0, 10, 20, 30)` places the camera
   * at the origin `(0, 0, 0)` and points it at `(10, 20, 30)`. By default, the
   * camera points at the origin `(0, 0, 0)`.
   *
   * The last three parameters, `upX`, `upY`, and `upZ` are the components of
   * the "up" vector in "local" space. The "up" vector orients the cameras
   * y-axis. For example, calling
   * `myCamera.camera(0, 0, 0, 10, 20, 30, 0, -1, 0)` places the camera at the
   * origin `(0, 0, 0)`, points it at `(10, 20, 30)`, and sets the "up" vector
   * to `(0, -1, 0)` which is like holding it upside-down. By default, the "up"
   * vector is `(0, 1, 0)`.
   *
   * @for p5.Camera
   * @param  {Number} [x]        x-coordinate of the camera. Defaults to 0.
   * @param  {Number} [y]        y-coordinate of the camera. Defaults to 0.
   * @param  {Number} [z]        z-coordinate of the camera. Defaults to 800.
   * @param  {Number} [centerX]  x-coordinate of the point the camera faces. Defaults to 0.
   * @param  {Number} [centerY]  y-coordinate of the point the camera faces. Defaults to 0.
   * @param  {Number} [centerZ]  z-coordinate of the point the camera faces. Defaults to 0.
   * @param  {Number} [upX]      x-component of the cameras "up" vector. Defaults to 0.
   * @param  {Number} [upY]      x-component of the cameras "up" vector. Defaults to 1.
   * @param  {Number} [upZ]      z-component of the cameras "up" vector. Defaults to 0.
   *
   * @example
   * <div>
   * <code>
   * // Double-click to toggle between cameras.
   *
   * let cam1;
   * let cam2;
   * let isDefaultCamera = true;
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Create the first camera.
   *   // Keep its default settings.
   *   cam1 = createCamera();
   *
   *   // Create the second camera.
   *   cam2 = createCamera();
   *
   *   // Place it at the top-right: (1200, -600, 100)
   *   // Point it at the row of boxes: (-10, -10, 400)
   *   // Set its "up" vector to the default: (0, 1, 0)
   *   cam2.camera(1200, -600, 100, -10, -10, 400, 0, 1, 0);
   *
   *   // Set the current camera to cam1.
   *   setCamera(cam1);
   *
   *   describe(
   *     'A row of white cubes against a gray background. The camera toggles between a frontal and an aerial view when the user double-clicks.'
   *   );
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Translate the origin toward the camera.
   *   translate(-10, 10, 500);
   *
   *   // Rotate the coordinate system.
   *   rotateY(-0.1);
   *   rotateX(-0.1);
   *
   *   // Draw the row of boxes.
   *   for (let i = 0; i < 6; i += 1) {
   *     translate(0, 0, -30);
   *     box(10);
   *   }
   * }
   *
   * // Toggle the current camera when the user double-clicks.
   * function doubleClicked() {
   *   if (isDefaultCamera === true) {
   *     setCamera(cam2);
   *     isDefaultCamera = false;
   *   } else {
   *     setCamera(cam1);
   *     isDefaultCamera = true;
   *   }
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Double-click to toggle between cameras.
   *
   * let cam1;
   * let cam2;
   * let isDefaultCamera = true;
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Create the first camera.
   *   // Keep its default settings.
   *   cam1 = createCamera();
   *
   *   // Create the second camera.
   *   cam2 = createCamera();
   *
   *   // Place it at the right: (1200, 0, 100)
   *   // Point it at the row of boxes: (-10, -10, 400)
   *   // Set its "up" vector to the default: (0, 1, 0)
   *   cam2.camera(1200, 0, 100, -10, -10, 400, 0, 1, 0);
   *
   *   // Set the current camera to cam1.
   *   setCamera(cam1);
   *
   *   describe(
   *     'A row of white cubes against a gray background. The camera toggles between a static frontal view and an orbiting view when the user double-clicks.'
   *   );
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Update cam2's position.
   *   let x = 1200 * cos(frameCount * 0.01);
   *   let y = -600 * sin(frameCount * 0.01);
   *   cam2.camera(x, y, 100, -10, -10, 400, 0, 1, 0);
   *
   *   // Translate the origin toward the camera.
   *   translate(-10, 10, 500);
   *
   *   // Rotate the coordinate system.
   *   rotateY(-0.1);
   *   rotateX(-0.1);
   *
   *   // Draw the row of boxes.
   *   for (let i = 0; i < 6; i += 1) {
   *     translate(0, 0, -30);
   *     box(10);
   *   }
   * }
   *
   * // Toggle the current camera when the user double-clicks.
   * function doubleClicked() {
   *   if (isDefaultCamera === true) {
   *     setCamera(cam2);
   *     isDefaultCamera = false;
   *   } else {
   *     setCamera(cam1);
   *     isDefaultCamera = true;
   *   }
   * }
   * </code>
   * </div>
   */
  camera(
    eyeX,
    eyeY,
    eyeZ,
    centerX,
    centerY,
    centerZ,
    upX,
    upY,
    upZ
  ) {
    if (typeof eyeX === 'undefined') {
      eyeX = this.defaultEyeX;
      eyeY = this.defaultEyeY;
      eyeZ = this.defaultEyeZ;
      centerX = eyeX;
      centerY = eyeY;
      centerZ = 0;
      upX = 0;
      upY = 1;
      upZ = 0;
    }

    this.eyeX = eyeX;
    this.eyeY = eyeY;
    this.eyeZ = eyeZ;

    if (typeof centerX !== 'undefined') {
      this.centerX = centerX;
      this.centerY = centerY;
      this.centerZ = centerZ;
    }

    if (typeof upX !== 'undefined') {
      this.upX = upX;
      this.upY = upY;
      this.upZ = upZ;
    }

    const local = this._getLocalAxes();

    // the camera affects the model view matrix, insofar as it
    // inverse translates the world to the eye position of the camera
    // and rotates it.
    /* eslint-disable indent */
    this.cameraMatrix.set(local.x[0], local.y[0], local.z[0], 0,
      local.x[1], local.y[1], local.z[1], 0,
      local.x[2], local.y[2], local.z[2], 0,
      0, 0, 0, 1);
    /* eslint-enable indent */

    const tx = -eyeX;
    const ty = -eyeY;
    const tz = -eyeZ;

    this.cameraMatrix.translate([tx, ty, tz]);

    if (this._isActive()) {
      this._renderer.states.setValue('uViewMatrix', this._renderer.states.uViewMatrix.clone());
      this._renderer.states.uViewMatrix.set(this.cameraMatrix);
    }
    return this;
  }

  /**
   * Moves the camera along its "local" axes without changing its orientation.
   *
   * The parameters, `x`, `y`, and `z`, are the distances the camera should
   * move. For example, calling `myCamera.move(10, 20, 30)` moves the camera 10
   * pixels to the right, 20 pixels down, and 30 pixels backward in its "local"
   * space.
   *
   * @param {Number} x distance to move along the cameras "local" x-axis.
   * @param {Number} y distance to move along the cameras "local" y-axis.
   * @param {Number} z distance to move along the cameras "local" z-axis.
   * @example
   * <div>
   * <code>
   * // Click the canvas to begin detecting key presses.
   *
   * let cam;
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Create the first camera.
   *   // Keep its default settings.
   *   cam = createCamera();
   *
   *   // Place the camera at the top-right.
   *   cam.setPosition(400, -400, 800);
   *
   *   // Point it at the origin.
   *   cam.lookAt(0, 0, 0);
   *
   *   // Set the camera.
   *   setCamera(cam);
   *
   *   describe(
   *     'A white cube drawn against a gray background. The cube appears to move when the user presses certain keys.'
   *   );
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Move the camera along its "local" axes
   *   // when the user presses certain keys.
   *
   *   // Move horizontally.
   *   if (keyIsDown(LEFT_ARROW)) {
   *     cam.move(-1, 0, 0);
   *   }
   *   if (keyIsDown(RIGHT_ARROW)) {
   *     cam.move(1, 0, 0);
   *   }
   *
   *   // Move vertically.
   *   if (keyIsDown(UP_ARROW)) {
   *     cam.move(0, -1, 0);
   *   }
   *   if (keyIsDown(DOWN_ARROW)) {
   *     cam.move(0, 1, 0);
   *   }
   *
   *   // Move in/out of the screen.
   *   if (keyIsDown('i')) {
   *     cam.move(0, 0, -1);
   *   }
   *   if (keyIsDown('o')) {
   *     cam.move(0, 0, 1);
   *   }
   *
   *   // Draw the box.
   *   box();
   * }
   * </code>
   * </div>
   */
  move(x, y, z) {
    const local = this._getLocalAxes();

    // scale local axes by movement amounts
    // based on http://learnwebgl.brown37.net/07_cameras/camera_linear_motion.html
    const dx = [local.x[0] * x, local.x[1] * x, local.x[2] * x];
    const dy = [local.y[0] * y, local.y[1] * y, local.y[2] * y];
    const dz = [local.z[0] * z, local.z[1] * z, local.z[2] * z];

    this.camera(
      this.eyeX + dx[0] + dy[0] + dz[0],
      this.eyeY + dx[1] + dy[1] + dz[1],
      this.eyeZ + dx[2] + dy[2] + dz[2],
      this.centerX + dx[0] + dy[0] + dz[0],
      this.centerY + dx[1] + dy[1] + dz[1],
      this.centerZ + dx[2] + dy[2] + dz[2],
      this.upX,
      this.upY,
      this.upZ
    );
  }

  /**
   * Sets the cameras position in "world" space without changing its
   * orientation.
   *
   * The parameters, `x`, `y`, and `z`, are the coordinates where the camera
   * should be placed. For example, calling `myCamera.setPosition(10, 20, 30)`
   * places the camera at coordinates `(10, 20, 30)` in "world" space.
   *
   * @param {Number} x x-coordinate in "world" space.
   * @param {Number} y y-coordinate in "world" space.
   * @param {Number} z z-coordinate in "world" space.
   *
   * @example
   * <div>
   * <code>
   * // Double-click to toggle between cameras.
   *
   * let cam1;
   * let cam2;
   * let isDefaultCamera = true;
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Create the first camera.
   *   // Keep its default settings.
   *   cam1 = createCamera();
   *
   *   // Create the second camera.
   *   cam2 = createCamera();
   *
   *   // Place it closer to the origin.
   *   cam2.setPosition(0, 0, 600);
   *
   *   // Set the current camera to cam1.
   *   setCamera(cam1);
   *
   *   describe(
   *     'A row of white cubes against a gray background. The camera toggles the amount of zoom when the user double-clicks.'
   *   );
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Translate the origin toward the camera.
   *   translate(-10, 10, 500);
   *
   *   // Rotate the coordinate system.
   *   rotateY(-0.1);
   *   rotateX(-0.1);
   *
   *   // Draw the row of boxes.
   *   for (let i = 0; i < 6; i += 1) {
   *     translate(0, 0, -30);
   *     box(10);
   *   }
   * }
   *
   * // Toggle the current camera when the user double-clicks.
   * function doubleClicked() {
   *   if (isDefaultCamera === true) {
   *     setCamera(cam2);
   *     isDefaultCamera = false;
   *   } else {
   *     setCamera(cam1);
   *     isDefaultCamera = true;
   *   }
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Double-click to toggle between cameras.
   *
   * let cam1;
   * let cam2;
   * let isDefaultCamera = true;
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Create the first camera.
   *   // Keep its default settings.
   *   cam1 = createCamera();
   *
   *   // Create the second camera.
   *   cam2 = createCamera();
   *
   *   // Place it closer to the origin.
   *   cam2.setPosition(0, 0, 600);
   *
   *   // Set the current camera to cam1.
   *   setCamera(cam1);
   *
   *   describe(
   *     'A row of white cubes against a gray background. The camera toggles between a static view and a view that zooms in and out when the user double-clicks.'
   *   );
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Update cam2's z-coordinate.
   *   let z = 100 * sin(frameCount * 0.01) + 700;
   *   cam2.setPosition(0, 0, z);
   *
   *   // Translate the origin toward the camera.
   *   translate(-10, 10, 500);
   *
   *   // Rotate the coordinate system.
   *   rotateY(-0.1);
   *   rotateX(-0.1);
   *
   *   // Draw the row of boxes.
   *   for (let i = 0; i < 6; i += 1) {
   *     translate(0, 0, -30);
   *     box(10);
   *   }
   * }
   *
   * // Toggle the current camera when the user double-clicks.
   * function doubleClicked() {
   *   if (isDefaultCamera === true) {
   *     setCamera(cam2);
   *     isDefaultCamera = false;
   *   } else {
   *     setCamera(cam1);
   *     isDefaultCamera = true;
   *   }
   * }
   * </code>
   * </div>
   */
  setPosition(x, y, z) {
    const diffX = x - this.eyeX;
    const diffY = y - this.eyeY;
    const diffZ = z - this.eyeZ;

    this.camera(
      x,
      y,
      z,
      this.centerX + diffX,
      this.centerY + diffY,
      this.centerZ + diffZ,
      this.upX,
      this.upY,
      this.upZ
    );
  }

  /**
   * Sets the cameras position, orientation, and projection by copying another
   * camera.
   *
   * The parameter, `cam`, is the `p5.Camera` object to copy. For example, calling
   * `cam2.set(cam1)` will set `cam2` using `cam1`s configuration.
   *
   * @param {p5.Camera} cam camera to copy.
   *
   * @example
   * <div>
   * <code>
   * // Double-click to "reset" the camera zoom.
   *
   * let cam1;
   * let cam2;
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Create the first camera.
   *   cam1 = createCamera();
   *
   *   // Place the camera at the top-right.
   *   cam1.setPosition(400, -400, 800);
   *
   *   // Point it at the origin.
   *   cam1.lookAt(0, 0, 0);
   *
   *   // Create the second camera.
   *   cam2 = createCamera();
   *
   *   // Copy cam1's configuration.
   *   cam2.set(cam1);
   *
   *   // Set the camera.
   *   setCamera(cam2);
   *
   *   describe(
   *     'A white cube drawn against a gray background. The camera slowly moves forward. The camera resets when the user double-clicks.'
   *   );
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Update cam2's position.
   *   cam2.move(0, 0, -1);
   *
   *   // Draw the box.
   *   box();
   * }
   *
   * // "Reset" the camera when the user double-clicks.
   * function doubleClicked() {
   *   cam2.set(cam1);
   * }
   */
  set(cam) {
    const keyNamesOfThePropToCopy = [
      'eyeX', 'eyeY', 'eyeZ',
      'centerX', 'centerY', 'centerZ',
      'upX', 'upY', 'upZ',
      'cameraFOV', 'aspectRatio', 'cameraNear', 'cameraFar', 'cameraType',
      'yScale', 'useLinePerspective'
    ];
    for (const keyName of keyNamesOfThePropToCopy) {
      this[keyName] = cam[keyName];
    }

    this.cameraMatrix = cam.cameraMatrix.copy();
    this.projMatrix = cam.projMatrix.copy();

    if (this._isActive()) {
      this._renderer.states.setValue('uModelMatrix', this._renderer.states.uModelMatrix.clone());
      this._renderer.states.setValue('uViewMatrix', this._renderer.states.uViewMatrix.clone());
      this._renderer.states.setValue('uPMatrix', this._renderer.states.uPMatrix.clone());
      this._renderer.states.uModelMatrix.reset();
      this._renderer.states.uViewMatrix.set(this.cameraMatrix);
      this._renderer.states.uPMatrix.set(this.projMatrix);
    }
  }
  /**
   * Sets the cameras position and orientation to values that are in-between
   * those of two other cameras.
   *
   * `myCamera.slerp()` uses spherical linear interpolation to calculate a
   * position and orientation thats in-between two other cameras. Doing so is
   * helpful for transitioning smoothly between two perspectives.
   *
   * The first two parameters, `cam0` and `cam1`, are the `p5.Camera` objects
   * that should be used to set the current camera.
   *
   * The third parameter, `amt`, is the amount to interpolate between `cam0` and
   * `cam1`. 0.0 keeps the cameras position and orientation equal to `cam0`s,
   * 0.5 sets them halfway between `cam0`s and `cam1`s , and 1.0 sets the
   * position and orientation equal to `cam1`s.
   *
   * For example, calling `myCamera.slerp(cam0, cam1, 0.1)` sets cams position
   * and orientation very close to `cam0`s. Calling
   * `myCamera.slerp(cam0, cam1, 0.9)` sets cams position and orientation very
   * close to `cam1`s.
   *
   * Note: All of the cameras must use the same projection.
   *
   * @param {p5.Camera} cam0 first camera.
   * @param {p5.Camera} cam1 second camera.
   * @param {Number} amt amount of interpolation between 0.0 (`cam0`) and 1.0 (`cam1`).
   *
   * @example
   * <div>
   * <code>
   * let cam;
   * let cam0;
   * let cam1;
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Create the main camera.
   *   // Keep its default settings.
   *   cam = createCamera();
   *
   *   // Create the first camera.
   *   // Keep its default settings.
   *   cam0 = createCamera();
   *
   *   // Create the second camera.
   *   cam1 = createCamera();
   *
   *   // Place it at the top-right.
   *   cam1.setPosition(400, -400, 800);
   *
   *   // Point it at the origin.
   *   cam1.lookAt(0, 0, 0);
   *
   *   // Set the current camera to cam.
   *   setCamera(cam);
   *
   *   describe('A white cube drawn against a gray background. The camera slowly oscillates between a frontal view and an aerial view.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Calculate the amount to interpolate between cam0 and cam1.
   *   let amt = 0.5 * sin(frameCount * 0.01) + 0.5;
   *
   *   // Update the main camera's position and orientation.
   *   cam.slerp(cam0, cam1, amt);
   *
   *   box();
   * }
   * </code>
   * </div>
   */
  slerp(cam0, cam1, amt) {
    // If t is 0 or 1, do not interpolate and set the argument camera.
    if (amt === 0) {
      this.set(cam0);
      return;
    } else if (amt === 1) {
      this.set(cam1);
      return;
    }

    // For this cameras is ortho, assume that cam0 and cam1 are also ortho
    // and interpolate the elements of the projection matrix.
    // Use logarithmic interpolation for interpolation.
    if (this.projMatrix.mat4[15] !== 0) {
        this.projMatrix.setElement(
          0,
          cam0.projMatrix.mat4[0] *
            Math.pow(cam1.projMatrix.mat4[0] / cam0.projMatrix.mat4[0], amt)
        );
        this.projMatrix.setElement(
          5,
          cam0.projMatrix.mat4[5] *
            Math.pow(cam1.projMatrix.mat4[5] / cam0.projMatrix.mat4[5], amt)
        );
      // If the camera is active, make uPMatrix reflect changes in projMatrix.
      if (this._isActive()) {
        this._renderer.states.setValue('uPMatrix', this._renderer.states.uPMatrix.clone());
        this._renderer.states.uPMatrix.mat4 = this.projMatrix.mat4.slice();
      }
    }

    // prepare eye vector and center vector of argument cameras.
    const eye0 = new Vector(cam0.eyeX, cam0.eyeY, cam0.eyeZ);
    const eye1 = new Vector(cam1.eyeX, cam1.eyeY, cam1.eyeZ);
    const center0 = new Vector(cam0.centerX, cam0.centerY, cam0.centerZ);
    const center1 = new Vector(cam1.centerX, cam1.centerY, cam1.centerZ);

    // Calculate the distance between eye and center for each camera.
    // Logarithmically interpolate these with amt.
    const dist0 = Vector.dist(eye0, center0);
    const dist1 = Vector.dist(eye1, center1);
    const lerpedDist = dist0 * Math.pow(dist1 / dist0, amt);

    // Next, calculate the ratio to interpolate the eye and center by a constant
    // ratio for each camera. This ratio is the same for both. Also, with this ratio
    // of points, the distance is the minimum distance of the two points of
    // the same ratio.
    // With this method, if the viewpoint is fixed, linear interpolation is performed
    // at the viewpoint, and if the center is fixed, linear interpolation is performed
    // at the center, resulting in reasonable interpolation. If both move, the point
    // halfway between them is taken.
    const eyeDiff = Vector.sub(eye0, eye1);
    const diffDiff = eye0.copy().sub(eye1).sub(center0).add(center1);
    // Suppose there are two line segments. Consider the distance between the points
    // above them as if they were taken in the same ratio. This calculation figures out
    // a ratio that minimizes this.
    // Each line segment is, a line segment connecting the viewpoint and the center
    // for each camera.
    const divider = diffDiff.magSq();
    let ratio = 1; // default.
    if (divider > 0.000001) {
      ratio = Vector.dot(eyeDiff, diffDiff) / divider;
      ratio = Math.max(0, Math.min(ratio, 1));
    }

    // Take the appropriate proportions and work out the points
    // that are between the new viewpoint and the new center position.
    const lerpedMedium = Vector.lerp(
      Vector.lerp(eye0, center0, ratio),
      Vector.lerp(eye1, center1, ratio),
      amt
    );

    // Prepare each of rotation matrix from their camera matrix
    const rotMat0 = cam0.cameraMatrix.createSubMatrix3x3();
    const rotMat1 = cam1.cameraMatrix.createSubMatrix3x3();

    // get front and up vector from local-coordinate-system.
    const front0 = rotMat0.row(2);
    const front1 = rotMat1.row(2);
    const up0 = rotMat0.row(1);
    const up1 = rotMat1.row(1);

    // prepare new vectors.
    const newFront = new Vector();
    const newUp = new Vector();
    const newEye = new Vector();
    const newCenter = new Vector();

    // Create the inverse matrix of mat0 by transposing mat0,
    // and multiply it to mat1 from the right.
    // This matrix represents the difference between the two.
    // 'deltaRot' means 'difference of rotation matrices'.
    const deltaRot = rotMat1.mult(rotMat0.copy().transpose()); // mat1 is 3x3

    // Calculate the trace and from it the cos value of the angle.
    // An orthogonal matrix is just an orthonormal basis. If this is not the identity
    // matrix, it is a centered orthonormal basis plus some angle of rotation about
    // some axis. That's the angle. Letting this be theta, trace becomes 1+2cos(theta).
    // reference: https://en.wikipedia.org/wiki/Rotation_matrix#Determining_the_angle
    const diag = deltaRot.diagonal();
    let cosTheta = 0.5 * (diag[0] + diag[1] + diag[2] - 1);

    // If the angle is close to 0, the two matrices are very close,
    // so in that case we execute linearly interpolate.
    if (1 - cosTheta < 0.0000001) {
      // Obtain the front vector and up vector by linear interpolation
      // and normalize them.
      // calculate newEye, newCenter with newFront vector.
      newFront.set(Vector.lerp(front0, front1, amt)).normalize();

      newEye.set(newFront).mult(ratio * lerpedDist).add(lerpedMedium);
      newCenter.set(newFront).mult((ratio - 1) * lerpedDist).add(lerpedMedium);

      newUp.set(Vector.lerp(up0, up1, amt)).normalize();

      // set the camera
      this.camera(
        newEye.x, newEye.y, newEye.z,
        newCenter.x, newCenter.y, newCenter.z,
        newUp.x, newUp.y, newUp.z
      );
      return;
    }

    // Calculates the axis vector and the angle of the difference orthogonal matrix.
    // The axis vector is what I explained earlier in the comments.
    // similar calculation is here:
    // https://github.com/mrdoob/three.js/blob/883249620049d1632e8791732808fefd1a98c871/src/math/Quaternion.js#L294
    let a, b, c, sinTheta;
    let invOneMinusCosTheta = 1 / (1 - cosTheta);
    const maxDiag = Math.max(diag[0], diag[1], diag[2]);
    const offDiagSum13 = deltaRot.mat3[1] + deltaRot.mat3[3];
    const offDiagSum26 = deltaRot.mat3[2] + deltaRot.mat3[6];
    const offDiagSum57 = deltaRot.mat3[5] + deltaRot.mat3[7];

    if (maxDiag === diag[0]) {
      a = Math.sqrt((diag[0] - cosTheta) * invOneMinusCosTheta); // not zero.
      invOneMinusCosTheta /= a;
      b = 0.5 * offDiagSum13 * invOneMinusCosTheta;
      c = 0.5 * offDiagSum26 * invOneMinusCosTheta;
      sinTheta = 0.5 * (deltaRot.mat3[7] - deltaRot.mat3[5]) / a;

    } else if (maxDiag === diag[1]) {
      b = Math.sqrt((diag[1] - cosTheta) * invOneMinusCosTheta); // not zero.
      invOneMinusCosTheta /= b;
      c = 0.5 * offDiagSum57 * invOneMinusCosTheta;
      a = 0.5 * offDiagSum13 * invOneMinusCosTheta;
      sinTheta = 0.5 * (deltaRot.mat3[2] - deltaRot.mat3[6]) / b;

    } else {
      c = Math.sqrt((diag[2] - cosTheta) * invOneMinusCosTheta); // not zero.
      invOneMinusCosTheta /= c;
      a = 0.5 * offDiagSum26 * invOneMinusCosTheta;
      b = 0.5 * offDiagSum57 * invOneMinusCosTheta;
      sinTheta = 0.5 * (deltaRot.mat3[3] - deltaRot.mat3[1]) / c;
    }

    // Constructs a new matrix after interpolating the angles.
    // Multiplying mat0 by the first matrix yields mat1, but by creating a state
    // in the middle of that matrix, you can obtain a matrix that is
    // an intermediate state between mat0 and mat1.
    const angle = amt * Math.atan2(sinTheta, cosTheta);
    const cosAngle = Math.cos(angle);
    const sinAngle = Math.sin(angle);
    const oneMinusCosAngle = 1 - cosAngle;
    const ab = a * b;
    const bc = b * c;
    const ca = c * a;
    // 3x3
    const lerpedRotMat = new Matrix( [
      cosAngle + oneMinusCosAngle * a * a,
      oneMinusCosAngle * ab + sinAngle * c,
      oneMinusCosAngle * ca - sinAngle * b,
      oneMinusCosAngle * ab - sinAngle * c,
      cosAngle + oneMinusCosAngle * b * b,
      oneMinusCosAngle * bc + sinAngle * a,
      oneMinusCosAngle * ca + sinAngle * b,
      oneMinusCosAngle * bc - sinAngle * a,
      cosAngle + oneMinusCosAngle * c * c
    ]);

    // Multiply this to mat0 from left to get the interpolated front vector.
    // calculate newEye, newCenter with newFront vector.
    lerpedRotMat.multiplyVec(front0, newFront); // this is vec3

    newEye.set(newFront).mult(ratio * lerpedDist).add(lerpedMedium);
    newCenter.set(newFront).mult((ratio - 1) * lerpedDist).add(lerpedMedium);

    lerpedRotMat.multiplyVec(up0, newUp); // this is vec3

    // We also get the up vector in the same way and set the camera.
    // The eye position and center position are calculated based on the front vector.
    this.camera(
      newEye.x, newEye.y, newEye.z,
      newCenter.x, newCenter.y, newCenter.z,
      newUp.x, newUp.y, newUp.z
    );
  }

  ////////////////////////////////////////////////////////////////////////////////
  // Camera Helper Methods
  ////////////////////////////////////////////////////////////////////////////////

  // @TODO: combine this function with _setDefaultCamera to compute these values
  // as-needed
  _computeCameraDefaultSettings() {
    this.defaultAspectRatio = this._renderer.width / this._renderer.height;
    this.defaultEyeX = 0;
    this.defaultEyeY = 0;
    this.defaultEyeZ = 800;
    this.defaultCameraFOV =
      2 * Math.atan(this._renderer.height / 2 / this.defaultEyeZ);
    this.defaultCenterX = 0;
    this.defaultCenterY = 0;
    this.defaultCenterZ = 0;
    this.defaultCameraNear = this.defaultEyeZ * 0.1;
    this.defaultCameraFar = this.defaultEyeZ * 10;
  }

  //detect if user didn't set the camera
  //then call this function below
  _setDefaultCamera() {
    this.cameraFOV = this.defaultCameraFOV;
    this.aspectRatio = this.defaultAspectRatio;
    this.eyeX = this.defaultEyeX;
    this.eyeY = this.defaultEyeY;
    this.eyeZ = this.defaultEyeZ;
    this.centerX = this.defaultCenterX;
    this.centerY = this.defaultCenterY;
    this.centerZ = this.defaultCenterZ;
    this.upX = 0;
    this.upY = 1;
    this.upZ = 0;
    this.cameraNear = this.defaultCameraNear;
    this.cameraFar = this.defaultCameraFar;

    this.perspective();
    this.camera();

    this.cameraType = 'default';
  }

  _resize() {
    // If we're using the default camera, update the aspect ratio
    if (this.cameraType === 'default') {
      this._computeCameraDefaultSettings();
      this.cameraFOV = this.defaultCameraFOV;
      this.aspectRatio = this.defaultAspectRatio;
      this.perspective();
    }
  }

  /**
   * Returns a copy of a camera.
   * @private
   */
  copy() {
    const _cam = new Camera(this._renderer);
    _cam.cameraFOV = this.cameraFOV;
    _cam.aspectRatio = this.aspectRatio;
    _cam.eyeX = this.eyeX;
    _cam.eyeY = this.eyeY;
    _cam.eyeZ = this.eyeZ;
    _cam.centerX = this.centerX;
    _cam.centerY = this.centerY;
    _cam.centerZ = this.centerZ;
    _cam.upX = this.upX;
    _cam.upY = this.upY;
    _cam.upZ = this.upZ;
    _cam.cameraNear = this.cameraNear;
    _cam.cameraFar = this.cameraFar;

    _cam.cameraType = this.cameraType;
    _cam.useLinePerspective = this.useLinePerspective;

    _cam.cameraMatrix = this.cameraMatrix.copy();
    _cam.projMatrix = this.projMatrix.copy();
    _cam.yScale = this.yScale;

    return _cam;
  }

  clone() {
    return this.copy();
  }

  /**
   * Returns a camera's local axes: left-right, up-down, and forward-backward,
   * as defined by vectors in world-space.
   * @private
   */
  _getLocalAxes() {
    // calculate camera local Z vector
    let z0 = this.eyeX - this.centerX;
    let z1 = this.eyeY - this.centerY;
    let z2 = this.eyeZ - this.centerZ;

    // normalize camera local Z vector
    const eyeDist = Math.sqrt(z0 * z0 + z1 * z1 + z2 * z2);
    if (eyeDist !== 0) {
      z0 /= eyeDist;
      z1 /= eyeDist;
      z2 /= eyeDist;
    }

    // calculate camera Y vector
    let y0 = this.upX;
    let y1 = this.upY;
    let y2 = this.upZ;

    // compute camera local X vector as up vector (local Y) cross local Z
    let x0 = y1 * z2 - y2 * z1;
    let x1 = -y0 * z2 + y2 * z0;
    let x2 = y0 * z1 - y1 * z0;

    // recompute y = z cross x
    y0 = z1 * x2 - z2 * x1;
    y1 = -z0 * x2 + z2 * x0;
    y2 = z0 * x1 - z1 * x0;

    // cross product gives area of parallelogram, which is < 1.0 for
    // non-perpendicular unit-length vectors; so normalize x, y here:
    const xmag = Math.sqrt(x0 * x0 + x1 * x1 + x2 * x2);
    if (xmag !== 0) {
      x0 /= xmag;
      x1 /= xmag;
      x2 /= xmag;
    }

    const ymag = Math.sqrt(y0 * y0 + y1 * y1 + y2 * y2);
    if (ymag !== 0) {
      y0 /= ymag;
      y1 /= ymag;
      y2 /= ymag;
    }

    return {
      x: [x0, x1, x2],
      y: [y0, y1, y2],
      z: [z0, z1, z2]
    };
  }

  /**
   * Orbits the camera about center point. For use with orbitControl().
   * @private
   * @param {Number} dTheta change in spherical coordinate theta
   * @param {Number} dPhi change in spherical coordinate phi
   * @param {Number} dRadius change in radius
   */
  _orbit(dTheta, dPhi, dRadius) {
    // Calculate the vector and its magnitude from the center to the viewpoint
    const diffX = this.eyeX - this.centerX;
    const diffY = this.eyeY - this.centerY;
    const diffZ = this.eyeZ - this.centerZ;
    let camRadius = Math.hypot(diffX, diffY, diffZ);
    // front vector. unit vector from center to eye.
    const front = new Vector(diffX, diffY, diffZ).normalize();
    // up vector. normalized camera's up vector.
    const up = new Vector(this.upX, this.upY, this.upZ).normalize(); // y-axis
    // side vector. Right when viewed from the front
    const side = Vector.cross(up, front).normalize(); // x-axis
    // vertical vector. normalized vector of projection of front vector.
    const vertical = Vector.cross(side, up); // z-axis

    // update camRadius
    camRadius *= Math.pow(10, dRadius);
    // prevent zooming through the center:
    if (camRadius < this.cameraNear) {
      camRadius = this.cameraNear;
    }
    if (camRadius > this.cameraFar) {
      camRadius = this.cameraFar;
    }

    // calculate updated camera angle
    // Find the angle between the "up" and the "front", add dPhi to that.
    // angleBetween() may return negative value. Since this specification is subject to change
    // due to version updates, it cannot be adopted, so here we calculate using a method
    // that directly obtains the absolute value.
    const camPhi =
      Math.acos(Math.max(-1, Math.min(1, Vector.dot(front, up)))) + dPhi;
    // Rotate by dTheta in the shortest direction from "vertical" to "side"
    const camTheta = dTheta;

    // Invert camera's upX, upY, upZ if dPhi is below 0 or above PI
    if (camPhi <= 0 || camPhi >= Math.PI) {
      this.upX *= -1;
      this.upY *= -1;
      this.upZ *= -1;
    }

    // update eye vector by calculate new front vector
    up.mult(Math.cos(camPhi));
    vertical.mult(Math.cos(camTheta) * Math.sin(camPhi));
    side.mult(Math.sin(camTheta) * Math.sin(camPhi));

    front.set(up).add(vertical).add(side);

    this.eyeX = camRadius * front.x + this.centerX;
    this.eyeY = camRadius * front.y + this.centerY;
    this.eyeZ = camRadius * front.z + this.centerZ;

    // update camera
    this.camera(
      this.eyeX, this.eyeY, this.eyeZ,
      this.centerX, this.centerY, this.centerZ,
      this.upX, this.upY, this.upZ
    );
  }

  /**
   * Orbits the camera about center point. For use with orbitControl().
   * Unlike _orbit(), the direction of rotation always matches the direction of pointer movement.
   * @private
   * @param {Number} dx the x component of the rotation vector.
   * @param {Number} dy the y component of the rotation vector.
   * @param {Number} dRadius change in radius
   */
  _orbitFree(dx, dy, dRadius) {
    // Calculate the vector and its magnitude from the center to the viewpoint
    const diffX = this.eyeX - this.centerX;
    const diffY = this.eyeY - this.centerY;
    const diffZ = this.eyeZ - this.centerZ;
    let camRadius = Math.hypot(diffX, diffY, diffZ);
    // front vector. unit vector from center to eye.
    const front = new Vector(diffX, diffY, diffZ).normalize();
    // up vector. camera's up vector.
    const up = new Vector(this.upX, this.upY, this.upZ);
    // side vector. Right when viewed from the front. (like x-axis)
    const side = Vector.cross(up, front).normalize();
    // down vector. Bottom when viewed from the front. (like y-axis)
    const down = Vector.cross(front, side);

    // side vector and down vector are no longer used as-is.
    // Create a vector representing the direction of rotation
    // in the form cos(direction)*side + sin(direction)*down.
    // Make the current side vector into this.
    const directionAngle = Math.atan2(dy, dx);
    down.mult(Math.sin(directionAngle));
    side.mult(Math.cos(directionAngle)).add(down);
    // The amount of rotation is the size of the vector (dx, dy).
    const rotAngle = Math.sqrt(dx * dx + dy * dy);
    // The vector that is orthogonal to both the front vector and
    // the rotation direction vector is the rotation axis vector.
    const axis = Vector.cross(front, side);

    // update camRadius
    camRadius *= Math.pow(10, dRadius);
    // prevent zooming through the center:
    if (camRadius < this.cameraNear) {
      camRadius = this.cameraNear;
    }
    if (camRadius > this.cameraFar) {
      camRadius = this.cameraFar;
    }

    // If the axis vector is likened to the z-axis, the front vector is
    // the x-axis and the side vector is the y-axis. Rotate the up and front
    // vectors respectively by thinking of them as rotations around the z-axis.

    // Calculate the components by taking the dot product and
    // calculate a rotation based on that.
    const c = Math.cos(rotAngle);
    const s = Math.sin(rotAngle);
    const dotFront = up.dot(front);
    const dotSide = up.dot(side);
    const ux = dotFront * c + dotSide * s;
    const uy = -dotFront * s + dotSide * c;
    const uz = up.dot(axis);
    up.x = ux * front.x + uy * side.x + uz * axis.x;
    up.y = ux * front.y + uy * side.y + uz * axis.y;
    up.z = ux * front.z + uy * side.z + uz * axis.z;
    // We won't be using the side vector and the front vector anymore,
    // so let's make the front vector into the vector from the center to the new eye.
    side.mult(-s);
    front.mult(c).add(side).mult(camRadius);

    // it's complete. let's update camera.
    this.camera(
      front.x + this.centerX,
      front.y + this.centerY,
      front.z + this.centerZ,
      this.centerX, this.centerY, this.centerZ,
      up.x, up.y, up.z
    );
  }

  /**
   * Returns true if camera is currently attached to renderer.
   * @private
   */
  _isActive() {
    return this === this._renderer.states.curCamera;
  }
}
function camera(p5, fn){
  ////////////////////////////////////////////////////////////////////////////////
  // p5.Prototype Methods
  ////////////////////////////////////////////////////////////////////////////////

  /**
   * Sets the position and orientation of the current camera in a 3D sketch.
   *
   * `camera()` allows objects to be viewed from different angles. It has nine
   * parameters that are all optional.
   *
   * The first three parameters, `x`, `y`, and `z`, are the coordinates of the
   * cameras position. For example, calling `camera(0, 0, 0)` places the camera
   * at the origin `(0, 0, 0)`. By default, the camera is placed at
   * `(0, 0, 800)`.
   *
   * The next three parameters, `centerX`, `centerY`, and `centerZ` are the
   * coordinates of the point where the camera faces. For example, calling
   * `camera(0, 0, 0, 10, 20, 30)` places the camera at the origin `(0, 0, 0)`
   * and points it at `(10, 20, 30)`. By default, the camera points at the
   * origin `(0, 0, 0)`.
   *
   * The last three parameters, `upX`, `upY`, and `upZ` are the components of
   * the "up" vector. The "up" vector orients the cameras y-axis. For example,
   * calling `camera(0, 0, 0, 10, 20, 30, 0, -1, 0)` places the camera at the
   * origin `(0, 0, 0)`, points it at `(10, 20, 30)`, and sets the "up" vector
   * to `(0, -1, 0)` which is like holding it upside-down. By default, the "up"
   * vector is `(0, 1, 0)`.
   *
   * Note: `camera()` can only be used in WebGL mode.
   *
   * @method camera
   * @for p5
   * @param  {Number} [x]        x-coordinate of the camera. Defaults to 0.
   * @param  {Number} [y]        y-coordinate of the camera. Defaults to 0.
   * @param  {Number} [z]        z-coordinate of the camera. Defaults to 800.
   * @param  {Number} [centerX]  x-coordinate of the point the camera faces. Defaults to 0.
   * @param  {Number} [centerY]  y-coordinate of the point the camera faces. Defaults to 0.
   * @param  {Number} [centerZ]  z-coordinate of the point the camera faces. Defaults to 0.
   * @param  {Number} [upX]      x-component of the cameras "up" vector. Defaults to 0.
   * @param  {Number} [upY]      y-component of the cameras "up" vector. Defaults to 1.
   * @param  {Number} [upZ]      z-component of the cameras "up" vector. Defaults to 0.
   * @chainable
   *
   * @example
   * <div>
   * <code>
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A white cube on a gray background.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Move the camera to the top-right.
   *   camera(200, -400, 800);
   *
   *   // Draw the box.
   *   box();
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A white cube apperas to sway left and right on a gray background.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Calculate the camera's x-coordinate.
   *   let x = 400 * cos(frameCount * 0.01);
   *
   *   // Orbit the camera around the box.
   *   camera(x, -400, 800);
   *
   *   // Draw the box.
   *   box();
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Adjust the range sliders to change the camera's position.
   *
   * let xSlider;
   * let ySlider;
   * let zSlider;
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Create slider objects to set the camera's coordinates.
   *   xSlider = createSlider(-400, 400, 400);
   *   xSlider.position(0, 100);
   *   xSlider.size(100);
   *   ySlider = createSlider(-400, 400, -200);
   *   ySlider.position(0, 120);
   *   ySlider.size(100);
   *   zSlider = createSlider(0, 1600, 800);
   *   zSlider.position(0, 140);
   *   zSlider.size(100);
   *
   *   describe(
   *     'A white cube drawn against a gray background. Three range sliders appear beneath the image. The camera position changes when the user moves the sliders.'
   *   );
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Get the camera's coordinates from the sliders.
   *   let x = xSlider.value();
   *   let y = ySlider.value();
   *   let z = zSlider.value();
   *
   *   // Move the camera.
   *   camera(x, y, z);
   *
   *   // Draw the box.
   *   box();
   * }
   * </code>
   * </div>
   */
  fn.camera = function (...args) {
    this._assert3d('camera');
    // p5._validateParameters('camera', args);
    this._renderer.camera(...args);
    return this;
  };

  /**
   * Sets a perspective projection for the current camera in a 3D sketch.
   *
   * In a perspective projection, shapes that are further from the camera appear
   * smaller than shapes that are near the camera. This technique, called
   * foreshortening, creates realistic 3D scenes. Its applied by default in
   * WebGL mode.
   *
   * `perspective()` changes the cameras perspective by changing its viewing
   * frustum. The frustum is the volume of space thats visible to the camera.
   * Its shape is a pyramid with its top cut off. The camera is placed where
   * the top of the pyramid should be and views everything between the frustums
   * top (near) plane and its bottom (far) plane.
   *
   * The first parameter, `fovy`, is the cameras vertical field of view. Its
   * an angle that describes how tall or narrow a view the camera has. For
   * example, calling `perspective(0.5)` sets the cameras vertical field of
   * view to 0.5 radians. By default, `fovy` is calculated based on the sketchs
   * height and the cameras default z-coordinate, which is 800. The formula for
   * the default `fovy` is `2 * atan(height / 2 / 800)`.
   *
   * The second parameter, `aspect`, is the cameras aspect ratio. Its a number
   * that describes the ratio of the top planes width to its height. For
   * example, calling `perspective(0.5, 1.5)` sets the cameras field of view to
   * 0.5 radians and aspect ratio to 1.5, which would make shapes appear thinner
   * on a square canvas. By default, aspect is set to `width / height`.
   *
   * The third parameter, `near`, is the distance from the camera to the near
   * plane. For example, calling `perspective(0.5, 1.5, 100)` sets the cameras
   * field of view to 0.5 radians, its aspect ratio to 1.5, and places the near
   * plane 100 pixels from the camera. Any shapes drawn less than 100 pixels
   * from the camera wont be visible. By default, near is set to `0.1 * 800`,
   * which is 1/10th the default distance between the camera and the origin.
   *
   * The fourth parameter, `far`, is the distance from the camera to the far
   * plane. For example, calling `perspective(0.5, 1.5, 100, 10000)` sets the
   * cameras field of view to 0.5 radians, its aspect ratio to 1.5, places the
   * near plane 100 pixels from the camera, and places the far plane 10,000
   * pixels from the camera. Any shapes drawn more than 10,000 pixels from the
   * camera wont be visible. By default, far is set to `10 * 800`, which is 10
   * times the default distance between the camera and the origin.
   *
   * Note: `perspective()` can only be used in WebGL mode.
   *
   * @method  perspective
   * @for p5
   * @param  {Number} [fovy]   camera frustum vertical field of view. Defaults to
   *                           `2 * atan(height / 2 / 800)`.
   * @param  {Number} [aspect] camera frustum aspect ratio. Defaults to
   *                           `width / height`.
   * @param  {Number} [near]   distance from the camera to the near clipping plane.
   *                           Defaults to `0.1 * 800`.
   * @param  {Number} [far]    distance from the camera to the far clipping plane.
   *                           Defaults to `10 * 800`.
   * @chainable
   *
   * @example
   * <div>
   * <code>
   * // Double-click to squeeze the box.
   *
   * let isSqueezed = false;
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A white rectangular prism on a gray background. The box appears to become thinner when the user double-clicks.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Place the camera at the top-right.
   *   camera(400, -400, 800);
   *
   *   if (isSqueezed === true) {
   *     // Set fovy to 0.2.
   *     // Set aspect to 1.5.
   *     perspective(0.2, 1.5);
   *   }
   *
   *   // Draw the box.
   *   box();
   * }
   *
   * // Change the camera's perspective when the user double-clicks.
   * function doubleClicked() {
   *   isSqueezed = true;
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A white rectangular prism on a gray background. The prism moves away from the camera until it disappears.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Place the camera at the top-right.
   *   camera(400, -400, 800);
   *
   *   // Set fovy to 0.2.
   *   // Set aspect to 1.5.
   *   // Set near to 600.
   *   // Set far to 1200.
   *   perspective(0.2, 1.5, 600, 1200);
   *
   *   // Move the origin away from the camera.
   *   let x = -frameCount;
   *   let y = frameCount;
   *   let z = -2 * frameCount;
   *   translate(x, y, z);
   *
   *   // Draw the box.
   *   box();
   * }
   * </code>
   * </div>
   */
  fn.perspective = function (...args) {
    this._assert3d('perspective');
    // p5._validateParameters('perspective', args);
    this._renderer.perspective(...args);
    return this;
  };


  /**
   * Enables or disables perspective for lines in 3D sketches.
   *
   * In WebGL mode, lines can be drawn with a thinner stroke when theyre
   * further from the camera. Doing so gives them a more realistic appearance.
   *
   * By default, lines are drawn differently based on the type of perspective
   * being used:
   * - `perspective()` and `frustum()` simulate a realistic perspective. In
   * these modes, stroke weight is affected by the lines distance from the
   * camera. Doing so results in a more natural appearance. `perspective()` is
   * the default mode for 3D sketches.
   * - `ortho()` doesnt simulate a realistic perspective. In this mode, stroke
   * weights are consistent regardless of the lines distance from the camera.
   * Doing so results in a more predictable and consistent appearance.
   *
   * `linePerspective()` can override the default line drawing mode.
   *
   * The parameter, `enable`, is optional. Its a `Boolean` value that sets the
   * way lines are drawn. If `true` is passed, as in `linePerspective(true)`,
   * then lines will appear thinner when they are further from the camera. If
   * `false` is passed, as in `linePerspective(false)`, then lines will have
   * consistent stroke weights regardless of their distance from the camera. By
   * default, `linePerspective()` is enabled.
   *
   * Calling `linePerspective()` without passing an argument returns `true` if
   * it's enabled and `false` if not.
   *
   * Note: `linePerspective()` can only be used in WebGL mode.
   *
   * @method linePerspective
   * @for p5
   * @param {Boolean} enable whether to enable line perspective.
   *
   * @example
   * <div>
   * <code>
   * // Double-click the canvas to toggle the line perspective.
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe(
   *     'A white cube with black edges on a gray background. Its edges toggle between thick and thin when the user double-clicks.'
   *   );
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Translate the origin toward the camera.
   *   translate(-10, 10, 600);
   *
   *   // Rotate the coordinate system.
   *   rotateY(-0.1);
   *   rotateX(-0.1);
   *
   *   // Draw the row of boxes.
   *   for (let i = 0; i < 6; i += 1) {
   *     translate(0, 0, -40);
   *     box(10);
   *   }
   * }
   *
   * // Toggle the line perspective when the user double-clicks.
   * function doubleClicked() {
   *   let isEnabled = linePerspective();
   *   linePerspective(!isEnabled);
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Double-click the canvas to toggle the line perspective.
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe(
   *     'A row of cubes with black edges on a gray background. Their edges toggle between thick and thin when the user double-clicks.'
   *   );
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Use an orthographic projection.
   *   ortho();
   *
   *   // Translate the origin toward the camera.
   *   translate(-10, 10, 600);
   *
   *   // Rotate the coordinate system.
   *   rotateY(-0.1);
   *   rotateX(-0.1);
   *
   *   // Draw the row of boxes.
   *   for (let i = 0; i < 6; i += 1) {
   *     translate(0, 0, -40);
   *     box(10);
   *   }
   * }
   *
   * // Toggle the line perspective when the user double-clicks.
   * function doubleClicked() {
   *   let isEnabled = linePerspective();
   *   linePerspective(!isEnabled);
   * }
   * </code>
   * </div>
   */
  /**
   * @method linePerspective
   * @return {boolean} whether line perspective is enabled.
   */
  fn.linePerspective = function (enable) {
    // p5._validateParameters('linePerspective', arguments);
    if (!(this._renderer instanceof RendererGL)) {
      throw new Error('linePerspective() must be called in WebGL mode.');
    }
    return this._renderer.linePerspective(enable);
  };


  /**
   * Sets an orthographic projection for the current camera in a 3D sketch.
   *
   * In an orthographic projection, shapes with the same size always appear the
   * same size, regardless of whether they are near or far from the camera.
   *
   * `ortho()` changes the cameras perspective by changing its viewing frustum
   * from a truncated pyramid to a rectangular prism. The camera is placed in
   * front of the frustum and views everything between the frustums near plane
   * and its far plane. `ortho()` has six optional parameters to define the
   * frustum.
   *
   * The first four parameters, `left`, `right`, `bottom`, and `top`, set the
   * coordinates of the frustums sides, bottom, and top. For example, calling
   * `ortho(-100, 100, 200, -200)` creates a frustum thats 200 pixels wide and
   * 400 pixels tall. By default, these coordinates are set based on the
   * sketchs width and height, as in
   * `ortho(-width / 2, width / 2, -height / 2, height / 2)`.
   *
   * The last two parameters, `near` and `far`, set the distance of the
   * frustums near and far plane from the camera. For example, calling
   * `ortho(-100, 100, 200, 200, 50, 1000)` creates a frustum thats 200 pixels
   * wide, 400 pixels tall, starts 50 pixels from the camera, and ends 1,000
   * pixels from the camera. By default, `near` and `far` are set to 0 and
   * `max(width, height) + 800`, respectively.
   *
   * Note: `ortho()` can only be used in WebGL mode.
   *
   * @method  ortho
   * @for p5
   * @param  {Number} [left]   x-coordinate of the frustums left plane. Defaults to `-width / 2`.
   * @param  {Number} [right]  x-coordinate of the frustums right plane. Defaults to `width / 2`.
   * @param  {Number} [bottom] y-coordinate of the frustums bottom plane. Defaults to `height / 2`.
   * @param  {Number} [top]    y-coordinate of the frustums top plane. Defaults to `-height / 2`.
   * @param  {Number} [near]   z-coordinate of the frustums near plane. Defaults to 0.
   * @param  {Number} [far]    z-coordinate of the frustums far plane. Defaults to `max(width, height) + 800`.
   * @chainable
   *
   * @example
   * <div>
   * <code>
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A row of tiny, white cubes on a gray background. All the cubes appear the same size.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Apply an orthographic projection.
   *   ortho();
   *
   *   // Translate the origin toward the camera.
   *   translate(-10, 10, 600);
   *
   *   // Rotate the coordinate system.
   *   rotateY(-0.1);
   *   rotateX(-0.1);
   *
   *   // Draw the row of boxes.
   *   for (let i = 0; i < 6; i += 1) {
   *     translate(0, 0, -40);
   *     box(10);
   *   }
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A white cube on a gray background.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Apply an orthographic projection.
   *   // Center the frustum.
   *   // Set its width and height to 20.
   *   // Place its near plane 300 pixels from the camera.
   *   // Place its far plane 350 pixels from the camera.
   *   ortho(-10, 10, -10, 10, 300, 350);
   *
   *   // Translate the origin toward the camera.
   *   translate(-10, 10, 600);
   *
   *   // Rotate the coordinate system.
   *   rotateY(-0.1);
   *   rotateX(-0.1);
   *
   *   // Draw the row of boxes.
   *   for (let i = 0; i < 6; i += 1) {
   *     translate(0, 0, -40);
   *     box(10);
   *   }
   * }
   * </code>
   * </div>
   */
  fn.ortho = function (...args) {
    this._assert3d('ortho');
    // p5._validateParameters('ortho', args);
    this._renderer.ortho(...args);
    return this;
  };

  /**
   * Sets the frustum of the current camera in a 3D sketch.
   *
   * In a frustum projection, shapes that are further from the camera appear
   * smaller than shapes that are near the camera. This technique, called
   * foreshortening, creates realistic 3D scenes.
   *
   * `frustum()` changes the default cameras perspective by changing its
   * viewing frustum. The frustum is the volume of space thats visible to the
   * camera. The frustums shape is a pyramid with its top cut off. The camera
   * is placed where the top of the pyramid should be and points towards the
   * base of the pyramid. It views everything within the frustum.
   *
   * The first four parameters, `left`, `right`, `bottom`, and `top`, set the
   * coordinates of the frustums sides, bottom, and top. For example, calling
   * `frustum(-100, 100, 200, -200)` creates a frustum thats 200 pixels wide
   * and 400 pixels tall. By default, these coordinates are set based on the
   * sketchs width and height, as in
   * `ortho(-width / 20, width / 20, height / 20, -height / 20)`.
   *
   * The last two parameters, `near` and `far`, set the distance of the
   * frustums near and far plane from the camera. For example, calling
   * `ortho(-100, 100, 200, -200, 50, 1000)` creates a frustum thats 200 pixels
   * wide, 400 pixels tall, starts 50 pixels from the camera, and ends 1,000
   * pixels from the camera. By default, near is set to `0.1 * 800`, which is
   * 1/10th the default distance between the camera and the origin. `far` is set
   * to `10 * 800`, which is 10 times the default distance between the camera
   * and the origin.
   *
   * Note: `frustum()` can only be used in WebGL mode.
   *
   * @method frustum
   * @for p5
   * @param  {Number} [left]   x-coordinate of the frustums left plane. Defaults to `-width / 20`.
   * @param  {Number} [right]  x-coordinate of the frustums right plane. Defaults to `width / 20`.
   * @param  {Number} [bottom] y-coordinate of the frustums bottom plane. Defaults to `height / 20`.
   * @param  {Number} [top]    y-coordinate of the frustums top plane. Defaults to `-height / 20`.
   * @param  {Number} [near]   z-coordinate of the frustums near plane. Defaults to `0.1 * 800`.
   * @param  {Number} [far]    z-coordinate of the frustums far plane. Defaults to `10 * 800`.
   * @chainable
   *
   * @example
   * <div>
   * <code>
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A row of white cubes on a gray background.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Apply the default frustum projection.
   *   frustum();
   *
   *   // Translate the origin toward the camera.
   *   translate(-10, 10, 600);
   *
   *   // Rotate the coordinate system.
   *   rotateY(-0.1);
   *   rotateX(-0.1);
   *
   *   // Draw the row of boxes.
   *   for (let i = 0; i < 6; i += 1) {
   *     translate(0, 0, -40);
   *     box(10);
   *   }
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *   describe('A white cube on a gray background.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Adjust the frustum.
   *   // Center it.
   *   // Set its width and height to 20 pixels.
   *   // Place its near plane 300 pixels from the camera.
   *   // Place its far plane 350 pixels from the camera.
   *   frustum(-10, 10, -10, 10, 300, 350);
   *
   *   // Translate the origin toward the camera.
   *   translate(-10, 10, 600);
   *
   *   // Rotate the coordinate system.
   *   rotateY(-0.1);
   *   rotateX(-0.1);
   *
   *   // Draw the row of boxes.
   *   for (let i = 0; i < 6; i += 1) {
   *     translate(0, 0, -40);
   *     box(10);
   *   }
   * }
   * </code>
   * </div>
   */
  fn.frustum = function (...args) {
    this._assert3d('frustum');
    // p5._validateParameters('frustum', args);
    this._renderer.frustum(...args);
    return this;
  };

  /**
   * Creates a new <a href="#/p5.Camera">p5.Camera</a> object and sets it
   * as the current (active) camera.
   *
   * The new camera is initialized with a default position `(0, 0, 800)` and a
   * default perspective projection. Its properties can be controlled with
   * <a href="#/p5.Camera">p5.Camera</a> methods such as
   * `myCamera.lookAt(0, 0, 0)`.
   *
   * Note: Every 3D sketch starts with a default camera initialized.
   * This camera can be controlled with the functions
   * <a href="#/p5/camera">camera()</a>,
   * <a href="#/p5/perspective">perspective()</a>,
   * <a href="#/p5/ortho">ortho()</a>, and
   * <a href="#/p5/frustum">frustum()</a> if it's the only camera in the scene.
   *
   * Note: `createCamera()` can only be used in WebGL mode.
   *
   * @method createCamera
   * @return {p5.Camera} the new camera.
   * @for p5
   *
   * @example
   * <div>
   * <code>
   * // Double-click to toggle between cameras.
   *
   * let cam1;
   * let cam2;
   * let usingCam1 = true;
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Create the first camera.
   *   // Keep its default settings.
   *   cam1 = createCamera();
   *
   *   // Create the second camera.
   *   // Place it at the top-left.
   *   // Point it at the origin.
   *   cam2 = createCamera();
   *   cam2.setPosition(400, -400, 800);
   *   cam2.lookAt(0, 0, 0);
   *
   *   // Set the current camera to cam1.
   *   setCamera(cam1);
   *
   *   describe('A white cube on a gray background. The camera toggles between frontal and aerial views when the user double-clicks.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Draw the box.
   *   box();
   * }
   *
   * // Toggle the current camera when the user double-clicks.
   * function doubleClicked() {
   *   if (usingCam1 === true) {
   *     setCamera(cam2);
   *     usingCam1 = false;
   *   } else {
   *     setCamera(cam1);
   *     usingCam1 = true;
   *   }
   * }
   * </code>
   * </div>
   */
  fn.createCamera = function () {
    this._assert3d('createCamera');

    return this._renderer.createCamera();
  };

  /**
   * Sets the current (active) camera of a 3D sketch.
   *
   * `setCamera()` allows for switching between multiple cameras created with
   * <a href="#/p5/createCamera">createCamera()</a>.
   *
   * Note: `setCamera()` can only be used in WebGL mode.
   *
   * @method setCamera
   * @param  {p5.Camera} cam camera that should be made active.
   * @for p5
   *
   * @example
   * <div>
   * <code>
   * // Double-click to toggle between cameras.
   *
   * let cam1;
   * let cam2;
   * let usingCam1 = true;
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Create the first camera.
   *   // Keep its default settings.
   *   cam1 = createCamera();
   *
   *   // Create the second camera.
   *   // Place it at the top-left.
   *   // Point it at the origin.
   *   cam2 = createCamera();
   *   cam2.setPosition(400, -400, 800);
   *   cam2.lookAt(0, 0, 0);
   *
   *   // Set the current camera to cam1.
   *   setCamera(cam1);
   *
   *   describe('A white cube on a gray background. The camera toggles between frontal and aerial views when the user double-clicks.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Draw the box.
   *   box();
   * }
   *
   * // Toggle the current camera when the user double-clicks.
   * function doubleClicked() {
   *   if (usingCam1 === true) {
   *     setCamera(cam2);
   *     usingCam1 = false;
   *   } else {
   *     setCamera(cam1);
   *     usingCam1 = true;
   *   }
   * }
   * </code>
   * </div>
   */
  fn.setCamera = function (cam) {
    this._renderer.setCamera(cam);
  };

  /**
   * A class to describe a camera for viewing a 3D sketch.
   *
   * Each `p5.Camera` object represents a camera that views a section of 3D
   * space. It stores information about the cameras position, orientation, and
   * projection.
   *
   * In WebGL mode, the default camera is a `p5.Camera` object that can be
   * controlled with the <a href="#/p5/camera">camera()</a>,
   * <a href="#/p5/perspective">perspective()</a>,
   * <a href="#/p5/ortho">ortho()</a>, and
   * <a href="#/p5/frustum">frustum()</a> functions. Additional cameras can be
   * created with <a href="#/p5/createCamera">createCamera()</a> and activated
   * with <a href="#/p5/setCamera">setCamera()</a>.
   *
   * Note: `p5.Camera`s methods operate in two coordinate systems:
   * - The world coordinate system describes positions in terms of their
   * relationship to the origin along the x-, y-, and z-axes. For example,
   * calling `myCamera.setPosition()` places the camera in 3D space using
   * "world" coordinates.
   * - The "local" coordinate system describes positions from the camera's point
   * of view: left-right, up-down, and forward-backward. For example, calling
   * `myCamera.move()` moves the camera along its own axes.
   *
   * @class p5.Camera
   * @constructor
   * @param {rendererGL} rendererGL instance of WebGL renderer
   *
   * @example
   * <div>
   * <code>
   * let cam;
   * let delta = 0.001;
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Create a p5.Camera object.
   *   cam = createCamera();
   *
   *   // Set the camera
   *   setCamera(cam);
   *
   *   // Place the camera at the top-center.
   *   cam.setPosition(0, -400, 800);
   *
   *   // Point the camera at the origin.
   *   cam.lookAt(0, 0, 0);
   *
   *   describe(
   *     'A white cube on a gray background. The cube goes in and out of view as the camera pans left and right.'
   *   );
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Turn the camera left and right, called "panning".
   *   cam.pan(delta);
   *
   *   // Switch directions every 120 frames.
   *   if (frameCount % 120 === 0) {
   *     delta *= -1;
   *   }
   *
   *   // Draw the box.
   *   box();
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Double-click to toggle between cameras.
   *
   * let cam1;
   * let cam2;
   * let isDefaultCamera = true;
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Create the first camera.
   *   // Keep its default settings.
   *   cam1 = createCamera();
   *
   *   // Create the second camera.
   *   // Place it at the top-left.
   *   // Point it at the origin.
   *   cam2 = createCamera();
   *   cam2.setPosition(400, -400, 800);
   *   cam2.lookAt(0, 0, 0);
   *
   *   // Set the current camera to cam1.
   *   setCamera(cam1);
   *
   *   describe(
   *     'A white cube on a gray background. The camera toggles between frontal and aerial views when the user double-clicks.'
   *   );
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Draw the box.
   *   box();
   * }
   *
   * // Toggle the current camera when the user double-clicks.
   * function doubleClicked() {
   *   if (isDefaultCamera === true) {
   *     setCamera(cam2);
   *     isDefaultCamera = false;
   *   } else {
   *     setCamera(cam1);
   *     isDefaultCamera = true;
   *   }
   * }
   * </code>
   * </div>
   */
  p5.Camera = Camera;

  RendererGL.prototype.camera = function(...args) {
    this.states.curCamera.camera(...args);
  };

  RendererGL.prototype.perspective = function(...args) {
    this.states.curCamera.perspective(...args);
  };

  RendererGL.prototype.linePerspective = function(enable) {
    if (enable !== undefined) {
      // Set the line perspective if enable is provided
      this.states.curCamera.useLinePerspective = enable;
    } else {
      // If no argument is provided, return the current value
      return this.states.curCamera.useLinePerspective;
    }
  };

  RendererGL.prototype.ortho = function(...args) {
    this.states.curCamera.ortho(...args);
  };

  RendererGL.prototype.frustum = function(...args) {
    this.states.curCamera.frustum(...args);
  };

  RendererGL.prototype.createCamera = function() {
    // compute default camera settings, then set a default camera
    const _cam = new Camera(this);
    _cam._computeCameraDefaultSettings();
    _cam._setDefaultCamera();

    return _cam;
  };

  RendererGL.prototype.setCamera = function(cam) {
    this.states.setValue('curCamera', cam);

    // set the projection matrix (which is not normally updated each frame)
    this.states.setValue('uPMatrix', this.states.uPMatrix.clone());
    this.states.uPMatrix.set(cam.projMatrix);
    this.states.setValue('uViewMatrix', this.states.uViewMatrix.clone());
    this.states.uViewMatrix.set(cam.cameraMatrix);
  };
}

if(typeof p5 !== 'undefined'){
  camera(p5, p5.prototype);
}

/**
 * This module defines the p5.Shader class
 * @module 3D
 * @submodule Material
 * @for p5
 * @requires core
 */


class Shader {
  constructor(renderer, vertSrc, fragSrc, options = {}) {
    // TODO: adapt this to not take ids, but rather,
    // to take the source for a vertex and fragment shader
    // to enable custom shaders at some later date
    this._renderer = renderer;
    this._vertSrc = vertSrc;
    this._fragSrc = fragSrc;
    this._vertShader = -1;
    this._fragShader = -1;
    this._glProgram = 0;
    this._loadedAttributes = false;
    this.attributes = {};
    this._loadedUniforms = false;
    this.uniforms = {};
    this._bound = false;
    this.samplers = [];
    this.hooks = {
      // These should be passed in by `.modify()` instead of being manually
      // passed in.

      // Stores uniforms + default values.
      uniforms: options.uniforms || {},

      // Stores custom uniform + helper declarations as a string.
      declarations: options.declarations,

      // Stores helper functions to prepend to shaders.
      helpers: options.helpers || {},

      // Stores the hook implementations
      vertex: options.vertex || {},
      fragment: options.fragment || {},

      // Stores whether or not the hook implementation has been modified
      // from the default. This is supplied automatically by calling
      // yourShader.modify(...).
      modified: {
        vertex: (options.modified && options.modified.vertex) || {},
        fragment: (options.modified && options.modified.fragment) || {}
      }
    };
  }

  hookTypes(hookName) {
    let fullSrc = this._vertSrc;
    let body = this.hooks.vertex[hookName];
    if (!body) {
      body = this.hooks.fragment[hookName];
      fullSrc = this._fragSrc;
    }
    if (!body) {
      throw new Error(`Can't find hook ${hookName}!`);
    }
    const nameParts = hookName.split(/\s+/g);
    const functionName = nameParts.pop();
    const returnType = nameParts.pop();
    const returnQualifiers = [...nameParts];

    const parameterMatch = /\(([^\)]*)\)/.exec(body);
    if (!parameterMatch) {
      throw new Error(`Couldn't find function parameters in hook body:\n${body}`);
    }

    const structProperties = structName => {
      const structDefMatch = new RegExp(`struct\\s+${structName}\\s*\{([^\}]*)\}`).exec(fullSrc);
      if (!structDefMatch) return undefined;

      const properties = [];
      for (const defSrc of structDefMatch[1].split(';')) {
        // E.g. `int var1, var2;` or `MyStruct prop;`
        const parts = defSrc.trim().split(/\s+|,/g);
        const typeName = parts.shift();
        const names = [...parts];
        const typeProperties = structProperties(typeName);
        for (const name of names) {
          properties.push({
            name,
            type: {
              typeName,
              qualifiers: [],
              properties: typeProperties,
            },
          });
        }
      }
      return properties;
    };

    const parameters = parameterMatch[1].split(',').map(paramString => {
      // e.g. `int prop` or `in sampler2D prop` or `const float prop`
      const parts = paramString.trim().split(/\s+/g);
      const name = parts.pop();
      const typeName = parts.pop();
      const qualifiers = [...parts];
      const properties = structProperties(typeName);
      return {
        name,
        type: {
          typeName,
          qualifiers,
          properties,
        }
      }
    });

    return {
      name: functionName,
      returnType: {
        typeName: returnType,
        qualifiers: returnQualifiers,
        properties: structProperties(returnType)
      },
      parameters
    };
  }

  shaderSrc(src, shaderType) {
    const main = 'void main';
    let [preMain, postMain] = src.split(main);

    let hooks = '';
    let defines = '';
    for (const key in this.hooks.uniforms) {
      hooks += `uniform ${key};\n`;
    }
    if (this.hooks.declarations) {
      hooks += this.hooks.declarations + '\n';
    }
    if (this.hooks[shaderType].declarations) {
      hooks += this.hooks[shaderType].declarations + '\n';
    }
    for (const hookDef in this.hooks.helpers) {
      hooks += `${hookDef}${this.hooks.helpers[hookDef]}\n`;
    }
    for (const hookDef in this.hooks[shaderType]) {
      if (hookDef === 'declarations') continue;
      const [hookType, hookName] = hookDef.split(' ');

      // Add a #define so that if the shader wants to use preprocessor directives to
      // optimize away the extra function calls in main, it can do so
      if (this.hooks.modified[shaderType][hookDef]) {
        defines += '#define AUGMENTED_HOOK_' + hookName + '\n';
      }

      hooks +=
        hookType + ' HOOK_' + hookName + this.hooks[shaderType][hookDef] + '\n';
    }

    // Allow shaders to specify the location of hook #define statements. Normally these
    // go after function definitions, but one might want to have them defined earlier
    // in order to only conditionally make uniforms.
    if (preMain.indexOf('#define HOOK_DEFINES') !== -1) {
      preMain = preMain.replace('#define HOOK_DEFINES', '\n' + defines + '\n');
      defines = '';
    }

    return preMain + '\n' + defines + hooks + main + postMain;
  }

  /**
   * Shaders are written in <a href="https://developer.mozilla.org/en-US/docs/Games/Techniques/3D_on_the_web/GLSL_Shaders">GLSL</a>, but
   * there are different versions of GLSL that it might be written in.
   *
   * Calling this method on a `p5.Shader` will return the GLSL version it uses, either `100 es` or `300 es`.
   * WebGL 1 shaders will only use `100 es`, and WebGL 2 shaders may use either.
   *
   * @returns {String} The GLSL version used by the shader.
   */
  version() {
    const match = /#version (.+)$/.exec(this.vertSrc());
    if (match) {
      return match[1];
    } else {
      return '100 es';
    }
  }

  vertSrc() {
    return this.shaderSrc(this._vertSrc, 'vertex');
  }

  fragSrc() {
    return this.shaderSrc(this._fragSrc, 'fragment');
  }

  /**
   * Logs the hooks available in this shader, and their current implementation.
   *
   * Each shader may let you override bits of its behavior. Each bit is called
   * a *hook.* A hook is either for the *vertex* shader, if it affects the
   * position of vertices, or in the *fragment* shader, if it affects the pixel
   * color. This method logs those values to the console, letting you know what
   * you are able to use in a call to
   * <a href="#/p5.Shader/modify">`modify()`</a>.
   *
   * For example, this shader will produce the following output:
   *
   * ```js
   * myShader = baseMaterialShader().modify({
   *   declarations: 'uniform float time;',
   *   'vec3 getWorldPosition': `(vec3 pos) {
   *     pos.y += 20. * sin(time * 0.001 + pos.x * 0.05);
   *     return pos;
   *   }`
   * });
   * myShader.inspectHooks();
   * ```
   *
   * ```
   * ==== Vertex shader hooks: ====
   * void beforeVertex() {}
   * vec3 getLocalPosition(vec3 position) { return position; }
   * [MODIFIED] vec3 getWorldPosition(vec3 pos) {
   *       pos.y += 20. * sin(time * 0.001 + pos.x * 0.05);
   *       return pos;
   *     }
   * vec3 getLocalNormal(vec3 normal) { return normal; }
   * vec3 getWorldNormal(vec3 normal) { return normal; }
   * vec2 getUV(vec2 uv) { return uv; }
   * vec4 getVertexColor(vec4 color) { return color; }
   * void afterVertex() {}
   *
   * ==== Fragment shader hooks: ====
   * void beforeFragment() {}
   * Inputs getPixelInputs(Inputs inputs) { return inputs; }
   * vec4 combineColors(ColorComponents components) {
   *                 vec4 color = vec4(0.);
   *                 color.rgb += components.diffuse * components.baseColor;
   *                 color.rgb += components.ambient * components.ambientColor;
   *                 color.rgb += components.specular * components.specularColor;
   *                 color.rgb += components.emissive;
   *                 color.a = components.opacity;
   *                 return color;
   *               }
   * vec4 getFinalColor(vec4 color) { return color; }
   * void afterFragment() {}
   * ```
   *
   * @beta
   */
  inspectHooks() {
    console.log('==== Vertex shader hooks: ====');
    for (const key in this.hooks.vertex) {
      console.log(
        (this.hooks.modified.vertex[key] ? '[MODIFIED] ' : '') +
          key +
          this.hooks.vertex[key]
      );
    }
    console.log('');
    console.log('==== Fragment shader hooks: ====');
    for (const key in this.hooks.fragment) {
      console.log(
        (this.hooks.modified.fragment[key] ? '[MODIFIED] ' : '') +
          key +
          this.hooks.fragment[key]
      );
    }
    console.log('');
    console.log('==== Helper functions: ====');
    for (const key in this.hooks.helpers) {
      console.log(key + this.hooks.helpers[key]);
    }
  }

  /**
   * Returns a new shader, based on the original, but with custom snippets
   * of shader code replacing default behaviour.
   *
   * Each shader may let you override bits of its behavior. Each bit is called
   * a *hook.* For example, a hook can let you adjust positions of vertices, or
   * the color of a pixel. You can inspect the different hooks available by calling
   * <a href="#/p5.Shader/inspectHooks">`yourShader.inspectHooks()`</a>. You can
   * also read the reference for the default material, normal material, color, line, and point shaders to
   * see what hooks they have available.
   *
   * `modify()` can be passed a function as a parameter. Inside, you can override hooks
   * by calling them as functions. Each hook will take in a callback that takes in inputs
   * and is expected to return an output. For example, here is a function that changes the
   * material color to red:
   *
   * ```js example
   * let myShader;
   *
   * function setup() {
   *   createCanvas(200, 200, WEBGL);
   *   myShader = baseMaterialShader().modify(() => {
   *     getPixelInputs((inputs) => {
   *       inputs.color = [inputs.texCoord, 0, 1];
   *       return inputs;
   *     });
   *   });
   * }
   *
   * function draw() {
   *   background(255);
   *   noStroke();
   *   shader(myShader); // Apply the custom shader
   *   plane(width, height); // Draw a plane with the shader applied
   * }
   * ```
   *
   * In addition to calling hooks, you can create uniforms, which are special variables
   * used to pass data from p5.js into the shader. They can be created by calling `uniform` + the
   * type of the data, such as `uniformFloat` for a number of `uniformVector2` for a two-component vector.
   * They take in a function that returns the data for the variable. You can then reference these
   * variables in your hooks, and their values will update every time you apply
   * the shader with the result of your function.
   *
   * ```js example
   * let myShader;
   *
   * function setup() {
   *   createCanvas(200, 200, WEBGL);
   *   myShader = baseMaterialShader().modify(() => {
   *     // Get the current time from p5.js
   *     let t = uniformFloat(() => millis());
   *
   *     getPixelInputs((inputs) => {
   *       inputs.color = [
   *         inputs.texCoord,
   *         sin(t * 0.01) / 2 + 0.5,
   *         1,
   *       ];
   *       return inputs;
   *     });
   *   });
   * }
   *
   * function draw() {
   *   background(255);
   *   noStroke(255);
   *   shader(myShader); // Apply the custom shader
   *   plane(width, height); // Draw a plane with the shader applied
   * }
   * ```
   *
   * p5.strands functions are special, since they get turned into a shader instead of being
   * run like the rest of your code. They only have access to p5.js functions, and variables
   * you declare inside the `modify` callback. If you need access to local variables, you
   * can pass them into `modify` with an optional second parameter, `variables`. If you are
   * using instance mode, you will need to pass your sketch object in this way.
   *
   * ```js example
   * new p5((sketch) => {
   *   let myShader;
   *
   *   sketch.setup = function() {
   *     sketch.createCanvas(200, 200, sketch.WEBGL);
   *     myShader = sketch.baseMaterialShader().modify(() => {
   *       sketch.getPixelInputs((inputs) => {
   *         inputs.color = [inputs.texCoord, 0, 1];
   *         return inputs;
   *       });
   *     }, { sketch });
   *   }
   *
   *   sketch.draw = function() {
   *     sketch.background(255);
   *     sketch.noStroke();
   *     sketch.shader(myShader); // Apply the custom shader
   *     sketch.plane(sketch.width, sketch.height); // Draw a plane with the shader applied
   *   }
   * });
   * ```
   *
   * You can also write GLSL directly in `modify` if you need direct access. To do so,
   * `modify()` takes one parameter, `hooks`, an object with the hooks you want
   * to override. Each key of the `hooks` object is the name
   * of a hook, and the value is a string with the GLSL code for your hook.
   *
   * If you supply functions that aren't existing hooks, they will get added at the start of
   * the shader as helper functions so that you can use them in your hooks.
   *
   * To add new <a href="#/p5.Shader/setUniform">uniforms</a> to your shader, you can pass in a `uniforms` object containing
   * the type and name of the uniform as the key, and a default value or function returning
   * a default value as its value. These will be automatically set when the shader is set
   * with `shader(yourShader)`.
   *
   * ```js example
   * let myShader;
   *
   * function setup() {
   *   createCanvas(200, 200, WEBGL);
   *   myShader = baseMaterialShader().modify({
   *     uniforms: {
   *       'float time': () => millis() // Uniform for time
   *     },
   *     'Vertex getWorldInputs': `(Vertex inputs) {
   *       inputs.position.y +=
   *         20. * sin(time * 0.001 + inputs.position.x * 0.05);
   *       return inputs;
   *     }`
   *   });
   * }
   *
   * function draw() {
   *   background(255);
   *   shader(myShader); // Apply the custom shader
   *   lights();         // Enable lighting
   *   noStroke();       // Disable stroke
   *   fill('red');      // Set fill color to red
   *   sphere(50);       // Draw a sphere with the shader applied
   * }
   * ```
   *
   * You can also add a `declarations` key, where the value is a GLSL string declaring
   * custom uniform variables, globals, and functions shared
   * between hooks. To add declarations just in a vertex or fragment shader, add
   * `vertexDeclarations` and `fragmentDeclarations` keys.
   *
   * ```js example
   * let myShader;
   *
   * function setup() {
   *   createCanvas(200, 200, WEBGL);
   *   myShader = baseMaterialShader().modify({
   *     // Manually specifying a uniform
   *     declarations: 'uniform float time;',
   *     'Vertex getWorldInputs': `(Vertex inputs) {
   *       inputs.position.y +=
   *         20. * sin(time * 0.001 + inputs.position.x * 0.05);
   *       return inputs;
   *     }`
   *   });
   * }
   *
   * function draw() {
   *   background(255);
   *   shader(myShader);
   *   myShader.setUniform('time', millis());
   *   lights();
   *   noStroke();
   *   fill('red');
   *   sphere(50);
   * }
   * ```
   *
   * @beta
   * @param {Function} callback A function with p5.strands code to modify the shader.
   * @param {Object} [variables] An optional object with local variables p5.strands
   * should have access to.
   * @returns {p5.Shader}
   */
  /**
   * @param {Object} [hooks] The hooks in the shader to replace.
   * @returns {p5.Shader}
   */
  modify(hooks) {
    // p5._validateParameters('p5.Shader.modify', arguments);
    const newHooks = {
      vertex: {},
      fragment: {},
      helpers: {}
    };
    for (const key in hooks) {
      if (key === 'declarations') continue;
      if (key === 'uniforms') continue;
      if (key === 'vertexDeclarations') {
        newHooks.vertex.declarations =
          (newHooks.vertex.declarations || '') + '\n' + hooks[key];
      } else if (key === 'fragmentDeclarations') {
        newHooks.fragment.declarations =
          (newHooks.fragment.declarations || '') + '\n' + hooks[key];
      } else if (this.hooks.vertex[key]) {
        newHooks.vertex[key] = hooks[key];
      } else if (this.hooks.fragment[key]) {
        newHooks.fragment[key] = hooks[key];
      } else {
        newHooks.helpers[key] = hooks[key];
      }
    }
    const modifiedVertex = Object.assign({}, this.hooks.modified.vertex);
    const modifiedFragment = Object.assign({}, this.hooks.modified.fragment);
    for (const key in newHooks.vertex || {}) {
      if (key === 'declarations') continue;
      modifiedVertex[key] = true;
    }
    for (const key in newHooks.fragment || {}) {
      if (key === 'declarations') continue;
      modifiedFragment[key] = true;
    }

    return new Shader(this._renderer, this._vertSrc, this._fragSrc, {
      declarations:
        (this.hooks.declarations || '') + '\n' + (hooks.declarations || ''),
      uniforms: Object.assign({}, this.hooks.uniforms, hooks.uniforms || {}),
      fragment: Object.assign({}, this.hooks.fragment, newHooks.fragment || {}),
      vertex: Object.assign({}, this.hooks.vertex, newHooks.vertex || {}),
      helpers: Object.assign({}, this.hooks.helpers, newHooks.helpers || {}),
      modified: {
        vertex: modifiedVertex,
        fragment: modifiedFragment
      }
    });
  }

  /**
   * Creates, compiles, and links the shader based on its
   * sources for the vertex and fragment shaders (provided
   * to the constructor). Populates known attributes and
   * uniforms from the shader.
   * @chainable
   * @private
   */
  init() {
    if (this._glProgram === 0 /* or context is stale? */) {
      const gl = this._renderer.GL;

      // @todo: once custom shading is allowed,
      // friendly error messages should be used here to share
      // compiler and linker errors.

      //set up the shader by
      // 1. creating and getting a gl id for the shader program,
      // 2. compliling its vertex & fragment sources,
      // 3. linking the vertex and fragment shaders
      this._vertShader = gl.createShader(gl.VERTEX_SHADER);
      //load in our default vertex shader
      gl.shaderSource(this._vertShader, this.vertSrc());
      gl.compileShader(this._vertShader);
      // if our vertex shader failed compilation?
      if (!gl.getShaderParameter(this._vertShader, gl.COMPILE_STATUS)) {
        const glError = gl.getShaderInfoLog(this._vertShader);
        if (typeof IS_MINIFIED !== 'undefined') {
          console.error(glError);
        } else {
          throw glError;
        }
        return null;
      }

      this._fragShader = gl.createShader(gl.FRAGMENT_SHADER);
      //load in our material frag shader
      gl.shaderSource(this._fragShader, this.fragSrc());
      gl.compileShader(this._fragShader);
      // if our frag shader failed compilation?
      if (!gl.getShaderParameter(this._fragShader, gl.COMPILE_STATUS)) {
        const glError = gl.getShaderInfoLog(this._fragShader);
        if (typeof IS_MINIFIED !== 'undefined') {
          console.error(glError);
        } else {
          throw glError;
        }
        return null;
      }

      this._glProgram = gl.createProgram();
      gl.attachShader(this._glProgram, this._vertShader);
      gl.attachShader(this._glProgram, this._fragShader);
      gl.linkProgram(this._glProgram);
      if (!gl.getProgramParameter(this._glProgram, gl.LINK_STATUS)) {
        p5._friendlyError(
          `Snap! Error linking shader program: ${gl.getProgramInfoLog(
            this._glProgram
          )}`
        );
      }

      this._loadAttributes();
      this._loadUniforms();
    }
    return this;
  }

  /**
   * @private
   */
  setDefaultUniforms() {
    for (const key in this.hooks.uniforms) {
      const [, name] = key.split(' ');
      const initializer = this.hooks.uniforms[key];
      let value;
      if (initializer instanceof Function) {
        value = initializer();
      } else {
        value = initializer;
      }

      if (value !== undefined && value !== null) {
        this.setUniform(name, value);
      }
    }
  }

  /**
   * Copies the shader from one drawing context to another.
   *
   * Each `p5.Shader` object must be compiled by calling
   * <a href="#/p5/shader">shader()</a> before it can run. Compilation happens
   * in a drawing context which is usually the main canvas or an instance of
   * <a href="#/p5.Graphics">p5.Graphics</a>. A shader can only be used in the
   * context where it was compiled. The `copyToContext()` method compiles the
   * shader again and copies it to another drawing context where it can be
   * reused.
   *
   * The parameter, `context`, is the drawing context where the shader will be
   * used. The shader can be copied to an instance of
   * <a href="#/p5.Graphics">p5.Graphics</a>, as in
   * `myShader.copyToContext(pg)`. The shader can also be copied from a
   * <a href="#/p5.Graphics">p5.Graphics</a> object to the main canvas using
   * the `p5.instance` variable, as in `myShader.copyToContext(p5.instance)`.
   *
   * Note: A <a href="#/p5.Shader">p5.Shader</a> object created with
   * <a href="#/p5/createShader">createShader()</a>,
   * <a href="#/p5/createFilterShader">createFilterShader()</a>, or
   * <a href="#/p5/loadShader">loadShader()</a>
   * can be used directly with a <a href="#/p5.Framebuffer">p5.Framebuffer</a>
   * object created with
   * <a href="#/p5/createFramebuffer">createFramebuffer()</a>. Both objects
   * have the same context as the main canvas.
   *
   * @param {p5|p5.Graphics} context WebGL context for the copied shader.
   * @returns {p5.Shader} new shader compiled for the target context.
   *
   * @example
   * <div>
   * <code>
   * // Note: A "uniform" is a global variable within a shader program.
   *
   * // Create a string with the vertex shader program.
   * // The vertex shader is called for each vertex.
   * let vertSrc = `
   * precision highp float;
   * uniform mat4 uModelViewMatrix;
   * uniform mat4 uProjectionMatrix;
   *
   * attribute vec3 aPosition;
   * attribute vec2 aTexCoord;
   * varying vec2 vTexCoord;
   *
   * void main() {
   *   vTexCoord = aTexCoord;
   *   vec4 positionVec4 = vec4(aPosition, 1.0);
   *   gl_Position = uProjectionMatrix * uModelViewMatrix * positionVec4;
   * }
   * `;
   *
   * // Create a string with the fragment shader program.
   * // The fragment shader is called for each pixel.
   * let fragSrc = `
   * precision mediump float;
   * varying vec2 vTexCoord;
   *
   * void main() {
   *   vec2 uv = vTexCoord;
   *   vec3 color = vec3(uv.x, uv.y, min(uv.x + uv.y, 1.0));
   *   gl_FragColor = vec4(color, 1.0);\
   * }
   * `;
   *
   * let pg;
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   background(200);
   *
   *   // Create a p5.Shader object.
   *   let original = createShader(vertSrc, fragSrc);
   *
   *   // Compile the p5.Shader object.
   *   shader(original);
   *
   *   // Create a p5.Graphics object.
   *   pg = createGraphics(50, 50, WEBGL);
   *
   *   // Copy the original shader to the p5.Graphics object.
   *   let copied = original.copyToContext(pg);
   *
   *   // Apply the copied shader to the p5.Graphics object.
   *   pg.shader(copied);
   *
   *   // Style the display surface.
   *   pg.noStroke();
   *
   *   // Add a display surface for the shader.
   *   pg.plane(50, 50);
   *
   *   describe('A square with purple-blue gradient on its surface drawn against a gray background.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Draw the p5.Graphics object to the main canvas.
   *   image(pg, -25, -25);
   * }
   * </code>
   * </div>
   *
   * <div class='notest'>
   * <code>
   * // Note: A "uniform" is a global variable within a shader program.
   *
   * // Create a string with the vertex shader program.
   * // The vertex shader is called for each vertex.
   * let vertSrc = `
   * precision highp float;
   * uniform mat4 uModelViewMatrix;
   * uniform mat4 uProjectionMatrix;
   *
   * attribute vec3 aPosition;
   * attribute vec2 aTexCoord;
   * varying vec2 vTexCoord;
   *
   * void main() {
   *   vTexCoord = aTexCoord;
   *   vec4 positionVec4 = vec4(aPosition, 1.0);
   *   gl_Position = uProjectionMatrix * uModelViewMatrix * positionVec4;
   * }
   * `;
   *
   * // Create a string with the fragment shader program.
   * // The fragment shader is called for each pixel.
   * let fragSrc = `
   * precision mediump float;
   *
   * varying vec2 vTexCoord;
   *
   * void main() {
   *   vec2 uv = vTexCoord;
   *   vec3 color = vec3(uv.x, uv.y, min(uv.x + uv.y, 1.0));
   *   gl_FragColor = vec4(color, 1.0);
   * }
   * `;
   *
   * let copied;
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Create a p5.Graphics object.
   *   let pg = createGraphics(25, 25, WEBGL);
   *
   *   // Create a p5.Shader object.
   *   let original = pg.createShader(vertSrc, fragSrc);
   *
   *   // Compile the p5.Shader object.
   *   pg.shader(original);
   *
   *   // Copy the original shader to the main canvas.
   *   copied = original.copyToContext(p5.instance);
   *
   *   // Apply the copied shader to the main canvas.
   *   shader(copied);
   *
   *   describe('A rotating cube with a purple-blue gradient on its surface drawn against a gray background.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Rotate around the x-, y-, and z-axes.
   *   rotateX(frameCount * 0.01);
   *   rotateY(frameCount * 0.01);
   *   rotateZ(frameCount * 0.01);
   *
   *   // Draw the box.
   *   box(50);
   * }
   * </code>
   * </div>
   */
  copyToContext(context) {
    const shader = new Shader(
      context._renderer,
      this._vertSrc,
      this._fragSrc
    );
    shader.ensureCompiledOnContext(context._renderer);
    return shader;
  }

  /**
   * @private
   */
  ensureCompiledOnContext(context) {
    if (this._glProgram !== 0 && this._renderer !== context) {
      throw new Error(
        'The shader being run is attached to a different context. Do you need to copy it to this context first with .copyToContext()?'
      );
    } else if (this._glProgram === 0) {
      this._renderer = context?._renderer?.filterRenderer?._renderer || context;
      this.init();
    }
  }


  /**
   * Queries the active attributes for this shader and loads
   * their names and locations into the attributes array.
   * @private
   */
  _loadAttributes() {
    if (this._loadedAttributes) {
      return;
    }

    this.attributes = {};

    const gl = this._renderer.GL;

    const numAttributes = gl.getProgramParameter(
      this._glProgram,
      gl.ACTIVE_ATTRIBUTES
    );
    for (let i = 0; i < numAttributes; ++i) {
      const attributeInfo = gl.getActiveAttrib(this._glProgram, i);
      const name = attributeInfo.name;
      const location = gl.getAttribLocation(this._glProgram, name);
      const attribute = {};
      attribute.name = name;
      attribute.location = location;
      attribute.index = i;
      attribute.type = attributeInfo.type;
      attribute.size = attributeInfo.size;
      this.attributes[name] = attribute;
    }

    this._loadedAttributes = true;
  }

  /**
   * Queries the active uniforms for this shader and loads
   * their names and locations into the uniforms array.
   * @private
   */
  _loadUniforms() {
    if (this._loadedUniforms) {
      return;
    }

    const gl = this._renderer.GL;

    // Inspect shader and cache uniform info
    const numUniforms = gl.getProgramParameter(
      this._glProgram,
      gl.ACTIVE_UNIFORMS
    );

    let samplerIndex = 0;
    for (let i = 0; i < numUniforms; ++i) {
      const uniformInfo = gl.getActiveUniform(this._glProgram, i);
      const uniform = {};
      uniform.location = gl.getUniformLocation(
        this._glProgram,
        uniformInfo.name
      );
      uniform.size = uniformInfo.size;
      let uniformName = uniformInfo.name;
      //uniforms that are arrays have their name returned as
      //someUniform[0] which is a bit silly so we trim it
      //off here. The size property tells us that its an array
      //so we dont lose any information by doing this
      if (uniformInfo.size > 1) {
        uniformName = uniformName.substring(0, uniformName.indexOf('[0]'));
      }
      uniform.name = uniformName;
      uniform.type = uniformInfo.type;
      uniform._cachedData = undefined;
      if (uniform.type === gl.SAMPLER_2D) {
        uniform.samplerIndex = samplerIndex;
        samplerIndex++;
        this.samplers.push(uniform);
      }

      uniform.isArray =
        uniformInfo.size > 1 ||
        uniform.type === gl.FLOAT_MAT3 ||
        uniform.type === gl.FLOAT_MAT4 ||
        uniform.type === gl.FLOAT_VEC2 ||
        uniform.type === gl.FLOAT_VEC3 ||
        uniform.type === gl.FLOAT_VEC4 ||
        uniform.type === gl.INT_VEC2 ||
        uniform.type === gl.INT_VEC4 ||
        uniform.type === gl.INT_VEC3;

      this.uniforms[uniformName] = uniform;
    }
    this._loadedUniforms = true;
  }

  compile() {
    // TODO
  }

  /**
   * initializes (if needed) and binds the shader program.
   * @private
   */
  bindShader() {
    this.init();
    if (!this._bound) {
      this.useProgram();
      this._bound = true;
    }
  }

  /**
   * @chainable
   * @private
   */
  unbindShader() {
    if (this._bound) {
      this.unbindTextures();
      this._bound = false;
    }
    return this;
  }

  bindTextures() {
    const gl = this._renderer.GL;

    const empty = this._renderer._getEmptyTexture();

    for (const uniform of this.samplers) {
      let tex = uniform.texture;
      if (
        tex === undefined ||
        (
          false
        )
      ) {
        // user hasn't yet supplied a texture for this slot.
        // (or there may not be one--maybe just lighting),
        // so we supply a default texture instead.
        uniform.texture = tex = empty;
      }
      gl.activeTexture(gl.TEXTURE0 + uniform.samplerIndex);
      tex.bindTexture();
      tex.update();
      gl.uniform1i(uniform.location, uniform.samplerIndex);
    }
  }

  updateTextures() {
    for (const uniform of this.samplers) {
      const tex = uniform.texture;
      if (tex) {
        tex.update();
      }
    }
  }

  unbindTextures() {
    const gl = this._renderer.GL;
    const empty = this._renderer._getEmptyTexture();
    for (const uniform of this.samplers) {
      if (uniform.texture?.isFramebufferTexture) {
        gl.activeTexture(gl.TEXTURE0 + uniform.samplerIndex);
        empty.bindTexture();
        gl.uniform1i(uniform.location, uniform.samplerIndex);
      }
    }
  }

  /**
   * @chainable
   * @private
   */
  useProgram() {
    const gl = this._renderer.GL;
    if (this._renderer._curShader !== this) {
      gl.useProgram(this._glProgram);
      this._renderer._curShader = this;
    }
    return this;
  }

  /**
   * Sets the shaders uniform (global) variables.
   *
   * Shader programs run on the computers graphics processing unit (GPU).
   * They live in part of the computers memory thats completely separate
   * from the sketch that runs them. Uniforms are global variables within a
   * shader program. They provide a way to pass values from a sketch running
   * on the CPU to a shader program running on the GPU.
   *
   * The first parameter, `uniformName`, is a string with the uniforms name.
   * For the shader above, `uniformName` would be `'r'`.
   *
   * The second parameter, `data`, is the value that should be used to set the
   * uniform. For example, calling `myShader.setUniform('r', 0.5)` would set
   * the `r` uniform in the shader above to `0.5`. data should match the
   * uniforms type. Numbers, strings, booleans, arrays, and many types of
   * images can all be passed to a shader with `setUniform()`.
   *
   * @chainable
   * @param {String} uniformName name of the uniform. Must match the name
   *                             used in the vertex and fragment shaders.
   * @param {Boolean|Number|Number[]|p5.Image|p5.Graphics|p5.MediaElement|p5.Texture}
   * data value to assign to the uniform. Must match the uniforms data type.
   *
   * @example
   * <div>
   * <code>
   * // Note: A "uniform" is a global variable within a shader program.
   *
   * // Create a string with the vertex shader program.
   * // The vertex shader is called for each vertex.
   * let vertSrc = `
   * precision highp float;
   * uniform mat4 uModelViewMatrix;
   * uniform mat4 uProjectionMatrix;
   *
   * attribute vec3 aPosition;
   * attribute vec2 aTexCoord;
   * varying vec2 vTexCoord;
   *
   * void main() {
   *   vTexCoord = aTexCoord;
   *   vec4 positionVec4 = vec4(aPosition, 1.0);
   *   gl_Position = uProjectionMatrix * uModelViewMatrix * positionVec4;
   * }
   * `;
   *
   * // Create a string with the fragment shader program.
   * // The fragment shader is called for each pixel.
   * let fragSrc = `
   * precision mediump float;
   *
   * uniform float r;
   *
   * void main() {
   *   gl_FragColor = vec4(r, 1.0, 1.0, 1.0);
   * }
   * `;
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Create a p5.Shader object.
   *   let myShader = createShader(vertSrc, fragSrc);
   *
   *   // Apply the p5.Shader object.
   *   shader(myShader);
   *
   *   // Set the r uniform to 0.5.
   *   myShader.setUniform('r', 0.5);
   *
   *   // Style the drawing surface.
   *   noStroke();
   *
   *   // Add a plane as a drawing surface for the shader.
   *   plane(100, 100);
   *
   *   describe('A cyan square.');
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Note: A "uniform" is a global variable within a shader program.
   *
   * // Create a string with the vertex shader program.
   * // The vertex shader is called for each vertex.
   * let vertSrc = `
   * precision highp float;
   * uniform mat4 uModelViewMatrix;
   * uniform mat4 uProjectionMatrix;
   *
   * attribute vec3 aPosition;
   * attribute vec2 aTexCoord;
   * varying vec2 vTexCoord;
   *
   * void main() {
   *   vTexCoord = aTexCoord;
   *   vec4 positionVec4 = vec4(aPosition, 1.0);
   *   gl_Position = uProjectionMatrix * uModelViewMatrix * positionVec4;
   * }
   * `;
   *
   * // Create a string with the fragment shader program.
   * // The fragment shader is called for each pixel.
   * let fragSrc = `
   * precision mediump float;
   *
   * uniform float r;
   *
   * void main() {
   *   gl_FragColor = vec4(r, 1.0, 1.0, 1.0);
   * }
   * `;
   *
   * let myShader;
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Create a p5.Shader object.
   *   myShader = createShader(vertSrc, fragSrc);
   *
   *   // Compile and apply the p5.Shader object.
   *   shader(myShader);
   *
   *   describe('A square oscillates color between cyan and white.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Style the drawing surface.
   *   noStroke();
   *
   *   // Update the r uniform.
   *   let nextR = 0.5 * (sin(frameCount * 0.01) + 1);
   *   myShader.setUniform('r', nextR);
   *
   *   // Add a plane as a drawing surface.
   *   plane(100, 100);
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Note: A "uniform" is a global variable within a shader program.
   *
   * // Create a string with the vertex shader program.
   * // The vertex shader is called for each vertex.
   * let vertSrc = `
   * precision highp float;
   * uniform mat4 uModelViewMatrix;
   * uniform mat4 uProjectionMatrix;
   *
   * attribute vec3 aPosition;
   * attribute vec2 aTexCoord;
   * varying vec2 vTexCoord;
   *
   * void main() {
   *   vTexCoord = aTexCoord;
   *   vec4 positionVec4 = vec4(aPosition, 1.0);
   *   gl_Position = uProjectionMatrix * uModelViewMatrix * positionVec4;
   * }
   * `;
   *
   * // Create a string with the fragment shader program.
   * // The fragment shader is called for each pixel.
   * let fragSrc = `
   * precision highp float;
   * uniform vec2 p;
   * uniform float r;
   * const int numIterations = 500;
   * varying vec2 vTexCoord;
   *
   * void main() {
   *   vec2 c = p + gl_FragCoord.xy * r;
   *   vec2 z = c;
   *   float n = 0.0;
   *
   *   for (int i = numIterations; i > 0; i--) {
   *     if (z.x * z.x + z.y * z.y > 4.0) {
   *       n = float(i) / float(numIterations);
   *       break;
   *     }
   *
   *     z = vec2(z.x * z.x - z.y * z.y, 2.0 * z.x * z.y) + c;
   *   }
   *
   *   gl_FragColor = vec4(
   *     0.5 - cos(n * 17.0) / 2.0,
   *     0.5 - cos(n * 13.0) / 2.0,
   *     0.5 - cos(n * 23.0) / 2.0,
   *     1.0
   *   );
   * }
   * `;
   *
   * let mandelbrot;
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Create a p5.Shader object.
   *   mandelbrot = createShader(vertSrc, fragSrc);
   *
   *   // Compile and apply the p5.Shader object.
   *   shader(mandelbrot);
   *
   *   // Set the shader uniform p to an array.
   *   // p is the center point of the Mandelbrot image.
   *   mandelbrot.setUniform('p', [-0.74364388703, 0.13182590421]);
   *
   *   describe('A fractal image zooms in and out of focus.');
   * }
   *
   * function draw() {
   *   // Set the shader uniform r to a value that oscillates
   *   // between 0 and 0.005.
   *   // r is the size of the image in Mandelbrot-space.
   *   let radius = 0.005 * (sin(frameCount * 0.01) + 1);
   *   mandelbrot.setUniform('r', radius);
   *
   *   // Style the drawing surface.
   *   noStroke();
   *
   *   // Add a plane as a drawing surface.
   *   plane(100, 100);
   * }
   * </code>
   * </div>
   */
  setUniform(uniformName, data) {
    this.init();

    const uniform = this.uniforms[uniformName];
    if (!uniform) {
      return;
    }
    const gl = this._renderer.GL;

    if (uniform.isArray) {
      if (
        uniform._cachedData &&
        this._renderer._arraysEqual(uniform._cachedData, data)
      ) {
        return;
      } else {
        uniform._cachedData = data.slice(0);
      }
    } else if (uniform._cachedData && uniform._cachedData === data) {
      return;
    } else {
      if (Array.isArray(data)) {
        uniform._cachedData = data.slice(0);
      } else {
        uniform._cachedData = data;
      }
    }

    const location = uniform.location;

    this.useProgram();

    switch (uniform.type) {
      case gl.BOOL:
        if (data === true) {
          gl.uniform1i(location, 1);
        } else {
          gl.uniform1i(location, 0);
        }
        break;
      case gl.INT:
        if (uniform.size > 1) {
          data.length && gl.uniform1iv(location, data);
        } else {
          gl.uniform1i(location, data);
        }
        break;
      case gl.FLOAT:
        if (uniform.size > 1) {
          data.length && gl.uniform1fv(location, data);
        } else {
          gl.uniform1f(location, data);
        }
        break;
      case gl.FLOAT_MAT3:
        gl.uniformMatrix3fv(location, false, data);
        break;
      case gl.FLOAT_MAT4:
        gl.uniformMatrix4fv(location, false, data);
        break;
      case gl.FLOAT_VEC2:
        if (uniform.size > 1) {
          data.length && gl.uniform2fv(location, data);
        } else {
          gl.uniform2f(location, data[0], data[1]);
        }
        break;
      case gl.FLOAT_VEC3:
        if (uniform.size > 1) {
          data.length && gl.uniform3fv(location, data);
        } else {
          gl.uniform3f(location, data[0], data[1], data[2]);
        }
        break;
      case gl.FLOAT_VEC4:
        if (uniform.size > 1) {
          data.length && gl.uniform4fv(location, data);
        } else {
          gl.uniform4f(location, data[0], data[1], data[2], data[3]);
        }
        break;
      case gl.INT_VEC2:
        if (uniform.size > 1) {
          data.length && gl.uniform2iv(location, data);
        } else {
          gl.uniform2i(location, data[0], data[1]);
        }
        break;
      case gl.INT_VEC3:
        if (uniform.size > 1) {
          data.length && gl.uniform3iv(location, data);
        } else {
          gl.uniform3i(location, data[0], data[1], data[2]);
        }
        break;
      case gl.INT_VEC4:
        if (uniform.size > 1) {
          data.length && gl.uniform4iv(location, data);
        } else {
          gl.uniform4i(location, data[0], data[1], data[2], data[3]);
        }
        break;
      case gl.SAMPLER_2D:
        if (typeof data == 'number') {
          if (
            data < gl.TEXTURE0 ||
            data > gl.TEXTURE31 ||
            data !== Math.ceil(data)
          ) {
            console.log(
              ' p5.js says: ' +
                "You're trying to use a number as the data for a texture." +
                'Please use a texture.'
            );
            return this;
          }
          gl.activeTexture(data);
          gl.uniform1i(location, data);
        } else {
          gl.activeTexture(gl.TEXTURE0 + uniform.samplerIndex);
          uniform.texture =
            data instanceof Texture ? data : this._renderer.getTexture(data);
          gl.uniform1i(location, uniform.samplerIndex);
          if (uniform.texture.src.gifProperties) {
            uniform.texture.src._animateGif(this._renderer._pInst);
          }
        }
        break;
      case gl.SAMPLER_CUBE:
      case gl.SAMPLER_3D:
      case gl.SAMPLER_2D_SHADOW:
      case gl.SAMPLER_2D_ARRAY:
      case gl.SAMPLER_2D_ARRAY_SHADOW:
      case gl.SAMPLER_CUBE_SHADOW:
      case gl.INT_SAMPLER_2D:
      case gl.INT_SAMPLER_3D:
      case gl.INT_SAMPLER_CUBE:
      case gl.INT_SAMPLER_2D_ARRAY:
      case gl.UNSIGNED_INT_SAMPLER_2D:
      case gl.UNSIGNED_INT_SAMPLER_3D:
      case gl.UNSIGNED_INT_SAMPLER_CUBE:
      case gl.UNSIGNED_INT_SAMPLER_2D_ARRAY:
        if (typeof data !== 'number') {
          break;
        }
        if (
          data < gl.TEXTURE0 ||
          data > gl.TEXTURE31 ||
          data !== Math.ceil(data)
        ) {
          console.log(
            ' p5.js says: ' +
              "You're trying to use a number as the data for a texture." +
              'Please use a texture.'
          );
          break;
        }
        gl.activeTexture(data);
        gl.uniform1i(location, data);
        break;
      //@todo complete all types
    }
    return this;
  }

  /**
   * @chainable
   * @private
   */
  enableAttrib(attr, size, type, normalized, stride, offset) {
    if (attr) {
      if (
        typeof IS_MINIFIED === 'undefined' &&
        this.attributes[attr.name] !== attr
      ) {
        console.warn(
          `The attribute "${attr.name}"passed to enableAttrib does not belong to this shader.`
        );
      }
      const loc = attr.location;
      if (loc !== -1) {
        const gl = this._renderer.GL;
        // Enable register even if it is disabled
        if (!this._renderer.registerEnabled.has(loc)) {
          gl.enableVertexAttribArray(loc);
          // Record register availability
          this._renderer.registerEnabled.add(loc);
        }
        this._renderer.GL.vertexAttribPointer(
          loc,
          size,
          type || gl.FLOAT,
          normalized || false,
          stride || 0,
          offset || 0
        );
      }
    }
    return this;
  }

  /**
   * Once all buffers have been bound, this checks to see if there are any
   * remaining active attributes, likely left over from previous renders,
   * and disables them so that they don't affect rendering.
   * @private
   */
  disableRemainingAttributes() {
    for (const location of this._renderer.registerEnabled.values()) {
      if (
        !Object.keys(this.attributes).some(
          key => this.attributes[key].location === location
        )
      ) {
        this._renderer.GL.disableVertexAttribArray(location);
        this._renderer.registerEnabled.delete(location);
      }
    }
  }
}
function shader(p5, fn){
  /**
   * A class to describe a shader program.
   *
   * Each `p5.Shader` object contains a shader program that runs on the graphics
   * processing unit (GPU). Shaders can process many pixels or vertices at the
   * same time, making them fast for many graphics tasks. Theyre written in a
   * language called
   * <a href="https://developer.mozilla.org/en-US/docs/Games/Techniques/3D_on_the_web/GLSL_Shaders" target="_blank">GLSL</a>
   * and run along with the rest of the code in a sketch.
   *
   * A shader program consists of two files, a vertex shader and a fragment
   * shader. The vertex shader affects where 3D geometry is drawn on the screen
   * and the fragment shader affects color. Once the `p5.Shader` object is
   * created, it can be used with the <a href="#/p5/shader">shader()</a>
   * function, as in `shader(myShader)`.
   *
   * A shader can optionally describe *hooks,* which are functions in GLSL that
   * users may choose to provide to customize the behavior of the shader. For the
   * vertex or the fragment shader, users can pass in an object where each key is
   * the type and name of a hook function, and each value is a string with the
   * parameter list and default implementation of the hook. For example, to let users
   * optionally run code at the start of the vertex shader, the options object could
   * include:
   *
   * ```js
   * {
   *   vertex: {
   *     'void beforeVertex': '() {}'
   *   }
   * }
   * ```
   *
   * Then, in your vertex shader source, you can run a hook by calling a function
   * with the same name prefixed by `HOOK_`:
   *
   * ```glsl
   * void main() {
   *   HOOK_beforeVertex();
   *   // Add the rest ofy our shader code here!
   * }
   * ```
   *
   * Note: <a href="#/p5/createShader">createShader()</a>,
   * <a href="#/p5/createFilterShader">createFilterShader()</a>, and
   * <a href="#/p5/loadShader">loadShader()</a> are the recommended ways to
   * create an instance of this class.
   *
   * @class p5.Shader
   * @constructor
   * @param {p5.RendererGL} renderer WebGL context for this shader.
   * @param {String} vertSrc source code for the vertex shader program.
   * @param {String} fragSrc source code for the fragment shader program.
   * @param {Object} [options] An optional object describing how this shader can
   * be augmented with hooks. It can include:
   *  - `vertex`: An object describing the available vertex shader hooks.
   *  - `fragment`: An object describing the available frament shader hooks.
   *
   * @example
   * <div>
   * <code>
   * // Note: A "uniform" is a global variable within a shader program.
   *
   * // Create a string with the vertex shader program.
   * // The vertex shader is called for each vertex.
   * let vertSrc = `
   * precision highp float;
   * uniform mat4 uModelViewMatrix;
   * uniform mat4 uProjectionMatrix;
   *
   * attribute vec3 aPosition;
   * attribute vec2 aTexCoord;
   * varying vec2 vTexCoord;
   *
   * void main() {
   *   vTexCoord = aTexCoord;
   *   vec4 positionVec4 = vec4(aPosition, 1.0);
   *   gl_Position = uProjectionMatrix * uModelViewMatrix * positionVec4;
   * }
   * `;
   *
   * // Create a string with the fragment shader program.
   * // The fragment shader is called for each pixel.
   * let fragSrc = `
   * precision highp float;
   *
   * void main() {
   *   // Set each pixel's RGBA value to yellow.
   *   gl_FragColor = vec4(1.0, 1.0, 0.0, 1.0);
   * }
   * `;
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Create a p5.Shader object.
   *   let myShader = createShader(vertSrc, fragSrc);
   *
   *   // Apply the p5.Shader object.
   *   shader(myShader);
   *
   *   // Style the drawing surface.
   *   noStroke();
   *
   *   // Add a plane as a drawing surface.
   *   plane(100, 100);
   *
   *   describe('A yellow square.');
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Note: A "uniform" is a global variable within a shader program.
   *
   * let mandelbrot;
   *
   * async function setup() {
   *   mandelbrot = await loadShader('assets/shader.vert', 'assets/shader.frag');
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Use the p5.Shader object.
   *   shader(mandelbrot);
   *
   *   // Set the shader uniform p to an array.
   *   mandelbrot.setUniform('p', [-0.74364388703, 0.13182590421]);
   *
   *   describe('A fractal image zooms in and out of focus.');
   * }
   *
   * function draw() {
   *   // Set the shader uniform r to a value that oscillates between 0 and 2.
   *   mandelbrot.setUniform('r', sin(frameCount * 0.01) + 1);
   *
   *   // Add a quad as a display surface for the shader.
   *   quad(-1, -1, 1, -1, 1, 1, -1, 1);
   * }
   * </code>
   * </div>
   */
  p5.Shader = Shader;
}

if(typeof p5 !== 'undefined'){
  shader(p5, p5.prototype);
}

var filterBaseVert = "precision highp int;\n\nuniform mat4 uModelViewMatrix;\nuniform mat4 uProjectionMatrix;\n\nIN vec3 aPosition;\nIN vec2 aTexCoord;\nOUT vec2 vTexCoord;\n\nvoid main() {\n  // transferring texcoords for the frag shader\n  vTexCoord = aTexCoord;\n\n  // copy position with a fourth coordinate for projection (1.0 is normal)\n  vec4 positionVec4 = vec4(aPosition, 1.0);\n\n  // project to 3D space\n  gl_Position = uProjectionMatrix * uModelViewMatrix * positionVec4;\n}\n";

var lightingShader = "#define PI 3.141592\n\nprecision highp float;\nprecision highp int;\n\nuniform mat4 uViewMatrix;\n\nuniform bool uUseLighting;\n\nuniform int uAmbientLightCount;\nuniform vec3 uAmbientColor[5];\nuniform mat3 uCameraRotation;\nuniform int uDirectionalLightCount;\nuniform vec3 uLightingDirection[5];\nuniform vec3 uDirectionalDiffuseColors[5];\nuniform vec3 uDirectionalSpecularColors[5];\n\nuniform int uPointLightCount;\nuniform vec3 uPointLightLocation[5];\nuniform vec3 uPointLightDiffuseColors[5];\t\nuniform vec3 uPointLightSpecularColors[5];\n\nuniform int uSpotLightCount;\nuniform float uSpotLightAngle[5];\nuniform float uSpotLightConc[5];\nuniform vec3 uSpotLightDiffuseColors[5];\nuniform vec3 uSpotLightSpecularColors[5];\nuniform vec3 uSpotLightLocation[5];\nuniform vec3 uSpotLightDirection[5];\n\nuniform bool uSpecular;\nuniform float uShininess;\nuniform float uMetallic;\n\nuniform float uConstantAttenuation;\nuniform float uLinearAttenuation;\nuniform float uQuadraticAttenuation;\n\n// setting from  _setImageLightUniforms()\n// boolean to initiate the calculateImageDiffuse and calculateImageSpecular\nuniform bool uUseImageLight;\n// texture for use in calculateImageDiffuse\nuniform sampler2D environmentMapDiffused;\n// texture for use in calculateImageSpecular\nuniform sampler2D environmentMapSpecular;\n\nconst float specularFactor = 2.0;\nconst float diffuseFactor = 0.73;\n\nstruct LightResult {\n  float specular;\n  float diffuse;\n};\n\nfloat _phongSpecular(\n  vec3 lightDirection,\n  vec3 viewDirection,\n  vec3 surfaceNormal,\n  float shininess) {\n\n  vec3 R = reflect(lightDirection, surfaceNormal);\n  return pow(max(0.0, dot(R, viewDirection)), shininess);\n}\n\nfloat _lambertDiffuse(vec3 lightDirection, vec3 surfaceNormal) {\n  return max(0.0, dot(-lightDirection, surfaceNormal));\n}\n\nLightResult _light(vec3 viewDirection, vec3 normal, vec3 lightVector, float shininess, float metallic) {\n\n  vec3 lightDir = normalize(lightVector);\n\n  //compute our diffuse & specular terms\n  LightResult lr;\n  float specularIntensity = mix(1.0, 0.4, metallic);\n  float diffuseIntensity = mix(1.0, 0.1, metallic);\n  if (uSpecular)\n    lr.specular = (_phongSpecular(lightDir, viewDirection, normal, shininess)) * specularIntensity;\n    lr.diffuse = _lambertDiffuse(lightDir, normal) * diffuseIntensity;\n  return lr;\n}\n\n// converts the range of \"value\" from [min1 to max1] to [min2 to max2]\nfloat map(float value, float min1, float max1, float min2, float max2) {\n  return min2 + (value - min1) * (max2 - min2) / (max1 - min1);\n}\n\nvec2 mapTextureToNormal( vec3 v ){\n  // x = r sin(phi) cos(theta)   \n  // y = r cos(phi)  \n  // z = r sin(phi) sin(theta)\n  float phi = acos( v.y );\n  // if phi is 0, then there are no x, z components\n  float theta = 0.0;\n  // else \n  theta = acos(v.x / sin(phi));\n  float sinTheta = v.z / sin(phi);\n  if (sinTheta < 0.0) {\n    // Turn it into -theta, but in the 0-2PI range\n    theta = 2.0 * PI - theta;\n  }\n  theta = theta / (2.0 * 3.14159);\n  phi = phi / 3.14159 ;\n  \n  vec2 angles = vec2( fract(theta + 0.25), 1.0 - phi );\n  return angles;\n}\n\n\nvec3 calculateImageDiffuse(vec3 vNormal, vec3 vViewPosition, float metallic){\n  // make 2 seperate builds \n  vec3 worldCameraPosition =  vec3(0.0, 0.0, 0.0);  // hardcoded world camera position\n  vec3 worldNormal = normalize(vNormal * uCameraRotation);\n  vec2 newTexCoor = mapTextureToNormal( worldNormal );\n  vec4 texture = TEXTURE( environmentMapDiffused, newTexCoor );\n  // this is to make the darker sections more dark\n  // png and jpg usually flatten the brightness so it is to reverse that\n  return mix(smoothstep(vec3(0.0), vec3(1.0), texture.xyz), vec3(0.0), metallic);\n}\n\nvec3 calculateImageSpecular(vec3 vNormal, vec3 vViewPosition, float shininess, float metallic){\n  vec3 worldCameraPosition =  vec3(0.0, 0.0, 0.0);\n  vec3 worldNormal = normalize(vNormal);\n  vec3 lightDirection = normalize( vViewPosition - worldCameraPosition );\n  vec3 R = reflect(lightDirection, worldNormal) * uCameraRotation;\n  vec2 newTexCoor = mapTextureToNormal( R );\n#ifdef WEBGL2\n  // In p5js the range of shininess is >= 1,\n  // Therefore roughness range will be ([0,1]*8)*20 or [0, 160]\n  // The factor of 8 is because currently the getSpecularTexture\n  // only calculated 8 different levels of roughness\n  // The factor of 20 is just to spread up this range so that,\n  // [1, max] of shininess is converted to [0,160] of roughness\n  float roughness = 20. / shininess;\n  vec4 outColor = textureLod(environmentMapSpecular, newTexCoor, roughness * 8.);\n#else\n  vec4 outColor = TEXTURE(environmentMapSpecular, newTexCoor);\n#endif\n  // this is to make the darker sections more dark\n  // png and jpg usually flatten the brightness so it is to reverse that\n  return mix(\n    pow(outColor.xyz, vec3(10)),\n    pow(outColor.xyz, vec3(1.2)),\n    metallic \n  );\n}\n\nvoid totalLight(\n  vec3 modelPosition,\n  vec3 normal,\n  float shininess,\n  float metallic,\n  out vec3 totalDiffuse,\n  out vec3 totalSpecular\n) {\n\n  totalSpecular = vec3(0.0);\n\n  if (!uUseLighting) {\n    totalDiffuse = vec3(1.0);\n    return;\n  }\n\n  totalDiffuse = vec3(0.0);\n\n  vec3 viewDirection = normalize(-modelPosition);\n\n  for (int j = 0; j < 5; j++) {\n    if (j < uDirectionalLightCount) {\n      vec3 lightVector = (uViewMatrix * vec4(uLightingDirection[j], 0.0)).xyz;\n      vec3 lightColor = uDirectionalDiffuseColors[j];\n      vec3 specularColor = uDirectionalSpecularColors[j];\n      LightResult result = _light(viewDirection, normal, lightVector, shininess, metallic);\n      totalDiffuse += result.diffuse * lightColor;\n      totalSpecular += result.specular * lightColor * specularColor;\n    }\n\n    if (j < uPointLightCount) {\n      vec3 lightPosition = (uViewMatrix * vec4(uPointLightLocation[j], 1.0)).xyz;\n      vec3 lightVector = modelPosition - lightPosition;\n      //calculate attenuation\n      float lightDistance = length(lightVector);\n      float lightFalloff = 1.0 / (uConstantAttenuation + lightDistance * uLinearAttenuation + (lightDistance * lightDistance) * uQuadraticAttenuation);\n      vec3 lightColor = lightFalloff * uPointLightDiffuseColors[j];\n      vec3 specularColor = lightFalloff * uPointLightSpecularColors[j];\n\n      LightResult result = _light(viewDirection, normal, lightVector, shininess, metallic);\n      totalDiffuse += result.diffuse * lightColor;\n      totalSpecular += result.specular * lightColor * specularColor;\n    }\n\n    if(j < uSpotLightCount) {\n      vec3 lightPosition = (uViewMatrix * vec4(uSpotLightLocation[j], 1.0)).xyz;\n      vec3 lightVector = modelPosition - lightPosition;\n    \n      float lightDistance = length(lightVector);\n      float lightFalloff = 1.0 / (uConstantAttenuation + lightDistance * uLinearAttenuation + (lightDistance * lightDistance) * uQuadraticAttenuation);\n\n      vec3 lightDirection = (uViewMatrix * vec4(uSpotLightDirection[j], 0.0)).xyz;\n      float spotDot = dot(normalize(lightVector), normalize(lightDirection));\n      float spotFalloff;\n      if(spotDot < uSpotLightAngle[j]) {\n        spotFalloff = 0.0;\n      }\n      else {\n        spotFalloff = pow(spotDot, uSpotLightConc[j]);\n      }\n      lightFalloff *= spotFalloff;\n\n      vec3 lightColor = uSpotLightDiffuseColors[j];\n      vec3 specularColor = uSpotLightSpecularColors[j];\n     \n      LightResult result = _light(viewDirection, normal, lightVector, shininess, metallic);\n      \n      totalDiffuse += result.diffuse * lightColor * lightFalloff;\n      totalSpecular += result.specular * lightColor * specularColor * lightFalloff;\n    }\n  }\n\n  if( uUseImageLight ){\n    totalDiffuse += calculateImageDiffuse(normal, modelPosition, metallic);\n    totalSpecular += calculateImageSpecular(normal, modelPosition, shininess, metallic);\n  }\n\n  totalDiffuse *= diffuseFactor;\n  totalSpecular *= specularFactor;\n}\n";

var webgl2CompatibilityShader = "#ifdef WEBGL2\n\n#define IN in\n#define OUT out\n\n#ifdef FRAGMENT_SHADER\nout vec4 outColor;\n#define OUT_COLOR outColor\n#endif\n#define TEXTURE texture\n\n#else\n\n#ifdef FRAGMENT_SHADER\n#define IN varying\n#else\n#define IN attribute\n#endif\n#define OUT varying\n#define TEXTURE texture2D\n\n#ifdef FRAGMENT_SHADER\n#define OUT_COLOR gl_FragColor\n#endif\n\n#endif\n\n#ifdef FRAGMENT_SHADER\nvec4 getTexture(in sampler2D content, vec2 coord) {\n  vec4 color = TEXTURE(content, coord);\n  color.rgb /= color.a;\n  return color;\n}\n#endif\n";

var normalVert = "IN vec3 aPosition;\nIN vec3 aNormal;\nIN vec2 aTexCoord;\nIN vec4 aVertexColor;\n\n#define HOOK_DEFINES\n\n#ifdef AUGMENTED_HOOK_getWorldInputs\nuniform mat4 uModelMatrix;\nuniform mat4 uViewMatrix;\nuniform mat3 uModelNormalMatrix;\nuniform mat3 uCameraNormalMatrix;\n#else\nuniform mat4 uModelViewMatrix;\nuniform mat3 uNormalMatrix;\n#endif\nuniform mat4 uProjectionMatrix;\n\nuniform vec4 uMaterialColor;\nuniform bool uUseVertexColor;\n\nOUT vec3 vVertexNormal;\nOUT highp vec2 vVertTexCoord;\nOUT vec4 vColor;\n\nstruct Vertex {\n  vec3 position;\n  vec3 normal;\n  vec2 texCoord;\n  vec4 color;\n};\n\nvoid main(void) {\n  HOOK_beforeVertex();\n\n  Vertex inputs;\n  inputs.position = aPosition;\n  inputs.normal = aNormal;\n  inputs.texCoord = aTexCoord;\n  inputs.color = (uUseVertexColor && aVertexColor.x >= 0.0) ? aVertexColor : uMaterialColor;\n#ifdef AUGMENTED_HOOK_getObjectInputs\n  inputs = HOOK_getObjectInputs(inputs);\n#endif\n\n#ifdef AUGMENTED_HOOK_getWorldInputs\n  inputs.position = (uModelMatrix * vec4(inputs.position, 1.)).xyz;\n  inputs.normal = uModelNormalMatrix * inputs.normal;\n  inputs = HOOK_getWorldInputs(inputs);\n#endif\n\n#ifdef AUGMENTED_HOOK_getWorldInputs\n  // Already multiplied by the model matrix, just apply view\n  inputs.position = (uViewMatrix * vec4(inputs.position, 1.)).xyz;\n  inputs.normal = uCameraNormalMatrix * inputs.normal;\n#else\n  // Apply both at once\n  inputs.position = (uModelViewMatrix * vec4(inputs.position, 1.)).xyz;\n  inputs.normal = uNormalMatrix * inputs.normal;\n#endif\n#ifdef AUGMENTED_HOOK_getCameraInputs\n  inputs = HOOK_getCameraInputs(inputs);\n#endif\n\n  // Pass varyings to fragment shader\n  vVertTexCoord = inputs.texCoord;\n  vVertexNormal = normalize(inputs.normal);\n  vColor = inputs.color;\n\n  gl_Position = uProjectionMatrix * vec4(inputs.position, 1.);\n\n  HOOK_afterVertex();\n}\n";

var normalFrag = "IN vec3 vVertexNormal;\nvoid main(void) {\n  HOOK_beforeFragment();\n  OUT_COLOR = HOOK_getFinalColor(vec4(vVertexNormal, 1.0));\n  HOOK_afterFragment();\n}\n";

var basicFrag = "IN vec4 vColor;\nvoid main(void) {\n  HOOK_beforeFragment();\n  OUT_COLOR = HOOK_getFinalColor(vec4(vColor.rgb, 1.) * vColor.a);\n  HOOK_afterFragment();\n}\n";

var sphereMappingFrag = "#define PI 3.141592\n\nprecision highp float;\n  \nuniform sampler2D uEnvMap;\nuniform mat3 uNewNormalMatrix;\nuniform float uFovY;\nuniform float uAspect;\n\nvarying vec2 vTexCoord;\n  \nvoid main() {\n    float uFovX = uFovY * uAspect; \n    float angleY = mix(uFovY/2.0,  -uFovY/2.0, vTexCoord.y);\n    float angleX = mix(uFovX/2.0, -uFovX/2.0, vTexCoord.x);\n    vec3 rotatedNormal = vec3( angleX, angleY, 1.0 );\n    rotatedNormal = uNewNormalMatrix * normalize(rotatedNormal);\n    float temp = rotatedNormal.z;\n    rotatedNormal.z = rotatedNormal.x;\n    rotatedNormal.x = -temp;\n    vec2 suv;\n    suv.y = 0.5 + 0.5 * (-rotatedNormal.y);\n    suv.x = atan(rotatedNormal.z, rotatedNormal.x) / (2.0 * PI) + 0.5;\n    vec4 newTexColor = texture2D(uEnvMap, suv.xy);\n    gl_FragColor = newTexColor;\n}\n";

var lightVert = "// include lighting.glgl\n\nIN vec3 aPosition;\nIN vec3 aNormal;\nIN vec2 aTexCoord;\nIN vec4 aVertexColor;\n\nuniform mat4 uModelViewMatrix;\nuniform mat4 uProjectionMatrix;\nuniform mat3 uNormalMatrix;\n\nuniform bool uUseVertexColor;\nuniform vec4 uMaterialColor;\n\nOUT highp vec2 vVertTexCoord;\nOUT vec3 vDiffuseColor;\nOUT vec3 vSpecularColor;\nOUT vec4 vColor;\n\nvoid main(void) {\n\n  vec4 viewModelPosition = uModelViewMatrix * vec4(aPosition, 1.0);\n  gl_Position = uProjectionMatrix * viewModelPosition;\n\n  vec3 vertexNormal = normalize(uNormalMatrix * aNormal);\n  vVertTexCoord = aTexCoord;\n\n  totalLight(viewModelPosition.xyz, vertexNormal, vDiffuseColor, vSpecularColor);\n\n  for (int i = 0; i < 8; i++) {\n    if (i < uAmbientLightCount) {\n      vDiffuseColor += uAmbientColor[i];\n    }\n  }\n  \n  vColor = ((uUseVertexColor && aVertexColor.x >= 0.0) ? aVertexColor : uMaterialColor);\n}\n";

var lightTextureFrag = "uniform vec4 uTint;\nuniform sampler2D uSampler;\nuniform bool isTexture;\nuniform bool uEmissive;\n\nIN highp vec2 vVertTexCoord;\nIN vec3 vDiffuseColor;\nIN vec3 vSpecularColor;\nIN vec4 vColor;\n\nvoid main(void) {\n  if(uEmissive && !isTexture) {\n    OUT_COLOR = vColor;\n  }\n  else {\n    vec4 baseColor = isTexture\n      // Textures come in with premultiplied alpha. To apply tint and still have\n      // premultiplied alpha output, we need to multiply the RGB channels by the\n      // tint RGB, and all channels by the tint alpha.\n      ? TEXTURE(uSampler, vVertTexCoord) * vec4(uTint.rgb/255., 1.) * (uTint.a/255.)\n      // Colors come in with unmultiplied alpha, so we need to multiply the RGB\n      // channels by alpha to convert it to premultiplied alpha.\n      : vec4(vColor.rgb * vColor.a, vColor.a);\n    OUT_COLOR = vec4(baseColor.rgb * vDiffuseColor + vSpecularColor, baseColor.a);\n  }\n}\n";

var phongVert = "precision highp int;\n\n#define HOOK_DEFINES\n\nIN vec3 aPosition;\nIN vec3 aNormal;\nIN vec2 aTexCoord;\nIN vec4 aVertexColor;\n\nuniform vec3 uAmbientColor[5];\n\n#ifdef AUGMENTED_HOOK_getWorldInputs\nuniform mat4 uModelMatrix;\nuniform mat4 uViewMatrix;\nuniform mat3 uModelNormalMatrix;\nuniform mat3 uCameraNormalMatrix;\n#else\nuniform mat4 uModelViewMatrix;\nuniform mat3 uNormalMatrix;\n#endif\nuniform mat4 uProjectionMatrix;\nuniform int uAmbientLightCount;\n\nuniform bool uUseVertexColor;\nuniform vec4 uMaterialColor;\n\nOUT vec3 vNormal;\nOUT vec2 vTexCoord;\nOUT vec3 vViewPosition;\nOUT vec3 vAmbientColor;\nOUT vec4 vColor;\n\nstruct Vertex {\n  vec3 position;\n  vec3 normal;\n  vec2 texCoord;\n  vec4 color;\n};\n\nvoid main(void) {\n  HOOK_beforeVertex();\n\n  Vertex inputs;\n  inputs.position = aPosition;\n  inputs.normal = aNormal;\n  inputs.texCoord = aTexCoord;\n  inputs.color = (uUseVertexColor && aVertexColor.x >= 0.0) ? aVertexColor : uMaterialColor;\n#ifdef AUGMENTED_HOOK_getObjectInputs\n  inputs = HOOK_getObjectInputs(inputs);\n#endif\n\n#ifdef AUGMENTED_HOOK_getWorldInputs\n  inputs.position = (uModelMatrix * vec4(inputs.position, 1.)).xyz;\n  inputs.normal = uModelNormalMatrix * inputs.normal;\n  inputs = HOOK_getWorldInputs(inputs);\n#endif\n\n#ifdef AUGMENTED_HOOK_getWorldInputs\n  // Already multiplied by the model matrix, just apply view\n  inputs.position = (uViewMatrix * vec4(inputs.position, 1.)).xyz;\n  inputs.normal = uCameraNormalMatrix * inputs.normal;\n#else\n  // Apply both at once\n  inputs.position = (uModelViewMatrix * vec4(inputs.position, 1.)).xyz;\n  inputs.normal = uNormalMatrix * inputs.normal;\n#endif\n#ifdef AUGMENTED_HOOK_getCameraInputs\n  inputs = HOOK_getCameraInputs(inputs);\n#endif\n\n  // Pass varyings to fragment shader\n  vViewPosition = inputs.position;\n  vTexCoord = inputs.texCoord;\n  vNormal = inputs.normal;\n  vColor = inputs.color;\n\n  // TODO: this should be a uniform\n  vAmbientColor = vec3(0.0);\n  for (int i = 0; i < 5; i++) {\n    if (i < uAmbientLightCount) {\n      vAmbientColor += uAmbientColor[i];\n    }\n  }\n\n  gl_Position = uProjectionMatrix * vec4(inputs.position, 1.);\n  HOOK_afterVertex();\n}\n";

var phongFrag = "// include lighting.glsl\nprecision highp int;\n\nuniform bool uHasSetAmbient;\nuniform vec4 uSpecularMatColor;\nuniform vec4 uAmbientMatColor;\nuniform vec4 uEmissiveMatColor;\n\nuniform vec4 uTint;\nuniform sampler2D uSampler;\nuniform bool isTexture;\n\nIN vec3 vNormal;\nIN vec2 vTexCoord;\nIN vec3 vViewPosition;\nIN vec3 vAmbientColor;\nIN vec4 vColor;\n\nstruct ColorComponents {\n  vec3 baseColor;\n  float opacity;\n  vec3 ambientColor;\n  vec3 specularColor;\n  vec3 diffuse;\n  vec3 ambient;\n  vec3 specular;\n  vec3 emissive;\n};\n\nstruct Inputs {\n  vec3 normal;\n  vec2 texCoord;\n  vec3 ambientLight;\n  vec3 ambientMaterial;\n  vec3 specularMaterial;\n  vec3 emissiveMaterial;\n  vec4 color;\n  float shininess;\n  float metalness;\n};\n\nvoid main(void) {\n  HOOK_beforeFragment();\n\n  Inputs inputs;\n  inputs.normal = normalize(vNormal);\n  inputs.texCoord = vTexCoord;\n  inputs.ambientLight = vAmbientColor;\n  inputs.color = isTexture\n      ? TEXTURE(uSampler, vTexCoord) * (vec4(uTint.rgb/255., 1.) * uTint.a/255.)\n      : vColor;\n  if (isTexture && inputs.color.a > 0.0) {\n    // Textures come in with premultiplied alpha. Temporarily unpremultiply it\n    // so hooks users don't have to think about premultiplied alpha.\n    inputs.color.rgb /= inputs.color.a;\n  }\n  inputs.shininess = uShininess;\n  inputs.metalness = uMetallic;\n  inputs.ambientMaterial = uHasSetAmbient ? uAmbientMatColor.rgb : inputs.color.rgb;\n  inputs.specularMaterial = uSpecularMatColor.rgb;\n  inputs.emissiveMaterial = uEmissiveMatColor.rgb;\n  inputs = HOOK_getPixelInputs(inputs);\n\n  vec3 diffuse;\n  vec3 specular;\n  totalLight(vViewPosition, inputs.normal, inputs.shininess, inputs.metalness, diffuse, specular);\n\n  // Calculating final color as result of all lights (plus emissive term).\n\n  vec2 texCoord = inputs.texCoord;\n  vec4 baseColor = inputs.color;\n  ColorComponents c;\n  c.opacity = baseColor.a;\n  c.baseColor = baseColor.rgb;\n  c.ambientColor = inputs.ambientMaterial;\n  c.specularColor = inputs.specularMaterial;\n  c.diffuse = diffuse;\n  c.ambient = inputs.ambientLight;\n  c.specular = specular;\n  c.emissive = inputs.emissiveMaterial;\n  OUT_COLOR = HOOK_getFinalColor(HOOK_combineColors(c));\n  OUT_COLOR.rgb *= OUT_COLOR.a; // Premultiply alpha before rendering\n  HOOK_afterFragment();\n}\n";

var fontVert = "IN vec3 aPosition;\nIN vec2 aTexCoord;\nuniform mat4 uModelViewMatrix;\nuniform mat4 uProjectionMatrix;\n\nuniform vec4 uGlyphRect;\nuniform float uGlyphOffset;\n\nOUT vec2 vTexCoord;\nOUT float w;\n\nvoid main() {\n  vec4 positionVec4 = vec4(aPosition, 1.0);\n\n  // scale by the size of the glyph's rectangle\n  positionVec4.xy *= uGlyphRect.zw - uGlyphRect.xy;\n\n  // Expand glyph bounding boxes by 1px on each side to give a bit of room\n  // for antialiasing\n  vec3 newOrigin = (uModelViewMatrix * vec4(0., 0., 0., 1.)).xyz;\n  vec3 newDX = (uModelViewMatrix * vec4(1., 0., 0., 1.)).xyz;\n  vec3 newDY = (uModelViewMatrix * vec4(0., 1., 0., 1.)).xyz;\n  vec2 pixelScale = vec2(\n    1. / length(newOrigin - newDX),\n    1. / length(newOrigin - newDY)\n  );\n  vec2 offset = pixelScale * normalize(aTexCoord - vec2(0.5, 0.5));\n  vec2 textureOffset = offset * (1. / vec2(\n    uGlyphRect.z - uGlyphRect.x,\n    uGlyphRect.w - uGlyphRect.y\n  ));\n\n  // move to the corner of the glyph\n  positionVec4.xy += uGlyphRect.xy;\n\n  // move to the letter's line offset\n  positionVec4.x += uGlyphOffset;\n\n  positionVec4.xy += offset;\n  \n  gl_Position = uProjectionMatrix * uModelViewMatrix * positionVec4;\n  vTexCoord = aTexCoord + textureOffset;\n  w = gl_Position.w;\n}\n";

var fontFrag = "#ifndef WEBGL2\n#extension GL_OES_standard_derivatives : enable\n#endif\n\n#if 0\n  // simulate integer math using floats\n\t#define int float\n\t#define ivec2 vec2\n\t#define INT(x) float(x)\n\n\tint ifloor(float v) { return floor(v); }\n\tivec2 ifloor(vec2 v) { return floor(v); }\n\n#else\n  // use native integer math\n\tprecision highp int;\n\t#define INT(x) x\n\n\tint ifloor(float v) { return int(v); }\n\tint ifloor(int v) { return v; }\n\tivec2 ifloor(vec2 v) { return ivec2(v); }\n\n#endif\n\nuniform sampler2D uSamplerStrokes;\nuniform sampler2D uSamplerRowStrokes;\nuniform sampler2D uSamplerRows;\nuniform sampler2D uSamplerColStrokes;\nuniform sampler2D uSamplerCols;\n\nuniform ivec2 uStrokeImageSize;\nuniform ivec2 uCellsImageSize;\nuniform ivec2 uGridImageSize;\n\nuniform ivec2 uGridOffset;\nuniform ivec2 uGridSize;\nuniform vec4 uMaterialColor;\n\nIN vec2 vTexCoord;\n\n// some helper functions\nint ROUND(float v) { return ifloor(v + 0.5); }\nivec2 ROUND(vec2 v) { return ifloor(v + 0.5); }\nfloat saturate(float v) { return clamp(v, 0.0, 1.0); }\nvec2 saturate(vec2 v) { return clamp(v, 0.0, 1.0); }\n\nint mul(float v1, int v2) {\n  return ifloor(v1 * float(v2));\n}\n\nivec2 mul(vec2 v1, ivec2 v2) {\n  return ifloor(v1 * vec2(v2) + 0.5);\n}\n\n// unpack a 16-bit integer from a float vec2\nint getInt16(vec2 v) {\n  ivec2 iv = ROUND(v * 255.0);\n  return iv.x * INT(128) + iv.y;\n}\n\nvec2 pixelScale;\nvec2 coverage = vec2(0.0);\nvec2 weight = vec2(0.5);\nconst float minDistance = 1.0/8192.0;\nconst float hardness = 1.05; // amount of antialias\n\n// the maximum number of curves in a glyph\nconst int N = INT(250);\n\n// retrieves an indexed pixel from a sampler\nvec4 getTexel(sampler2D sampler, int pos, ivec2 size) {\n  int width = size.x;\n  int y = ifloor(pos / width);\n  int x = pos - y * width;  // pos % width\n\n  return TEXTURE(sampler, (vec2(x, y) + 0.5) / vec2(size));\n}\n\nvoid calulateCrossings(vec2 p0, vec2 p1, vec2 p2, out vec2 C1, out vec2 C2) {\n\n  // get the coefficients of the quadratic in t\n  vec2 a = p0 - p1 * 2.0 + p2;\n  vec2 b = p0 - p1;\n  vec2 c = p0 - vTexCoord;\n\n  // found out which values of 't' it crosses the axes\n  vec2 surd = sqrt(max(vec2(0.0), b * b - a * c));\n  vec2 t1 = ((b - surd) / a).yx;\n  vec2 t2 = ((b + surd) / a).yx;\n\n  // approximate straight lines to avoid rounding errors\n  if (abs(a.y) < 0.001)\n    t1.x = t2.x = c.y / (2.0 * b.y);\n\n  if (abs(a.x) < 0.001)\n    t1.y = t2.y = c.x / (2.0 * b.x);\n\n  // plug into quadratic formula to find the corrdinates of the crossings\n  C1 = ((a * t1 - b * 2.0) * t1 + c) * pixelScale;\n  C2 = ((a * t2 - b * 2.0) * t2 + c) * pixelScale;\n}\n\nvoid coverageX(vec2 p0, vec2 p1, vec2 p2) {\n\n  vec2 C1, C2;\n  calulateCrossings(p0, p1, p2, C1, C2);\n\n  // determine on which side of the x-axis the points lie\n  bool y0 = p0.y > vTexCoord.y;\n  bool y1 = p1.y > vTexCoord.y;\n  bool y2 = p2.y > vTexCoord.y;\n\n  // could web be under the curve (after t1)?\n  if (y1 ? !y2 : y0) {\n    // add the coverage for t1\n    coverage.x += saturate(C1.x + 0.5);\n    // calculate the anti-aliasing for t1\n    weight.x = min(weight.x, abs(C1.x));\n  }\n\n  // are we outside the curve (after t2)?\n  if (y1 ? !y0 : y2) {\n    // subtract the coverage for t2\n    coverage.x -= saturate(C2.x + 0.5);\n    // calculate the anti-aliasing for t2\n    weight.x = min(weight.x, abs(C2.x));\n  }\n}\n\n// this is essentially the same as coverageX, but with the axes swapped\nvoid coverageY(vec2 p0, vec2 p1, vec2 p2) {\n\n  vec2 C1, C2;\n  calulateCrossings(p0, p1, p2, C1, C2);\n\n  bool x0 = p0.x > vTexCoord.x;\n  bool x1 = p1.x > vTexCoord.x;\n  bool x2 = p2.x > vTexCoord.x;\n\n  if (x1 ? !x2 : x0) {\n    coverage.y -= saturate(C1.y + 0.5);\n    weight.y = min(weight.y, abs(C1.y));\n  }\n\n  if (x1 ? !x0 : x2) {\n    coverage.y += saturate(C2.y + 0.5);\n    weight.y = min(weight.y, abs(C2.y));\n  }\n}\n\nvoid main() {\n\n  // calculate the pixel scale based on screen-coordinates\n  pixelScale = hardness / fwidth(vTexCoord);\n\n  // which grid cell is this pixel in?\n  ivec2 gridCoord = ifloor(vTexCoord * vec2(uGridSize));\n\n  // intersect curves in this row\n  {\n    // the index into the row info bitmap\n    int rowIndex = gridCoord.y + uGridOffset.y;\n    // fetch the info texel\n    vec4 rowInfo = getTexel(uSamplerRows, rowIndex, uGridImageSize);\n    // unpack the rowInfo\n    int rowStrokeIndex = getInt16(rowInfo.xy);\n    int rowStrokeCount = getInt16(rowInfo.zw);\n\n    for (int iRowStroke = INT(0); iRowStroke < N; iRowStroke++) {\n      if (iRowStroke >= rowStrokeCount)\n        break;\n\n      // each stroke is made up of 3 points: the start and control point\n      // and the start of the next curve.\n      // fetch the indices of this pair of strokes:\n      vec4 strokeIndices = getTexel(uSamplerRowStrokes, rowStrokeIndex++, uCellsImageSize);\n\n      // unpack the stroke index\n      int strokePos = getInt16(strokeIndices.xy);\n\n      // fetch the two strokes\n      vec4 stroke0 = getTexel(uSamplerStrokes, strokePos + INT(0), uStrokeImageSize);\n      vec4 stroke1 = getTexel(uSamplerStrokes, strokePos + INT(1), uStrokeImageSize);\n\n      // calculate the coverage\n      coverageX(stroke0.xy, stroke0.zw, stroke1.xy);\n    }\n  }\n\n  // intersect curves in this column\n  {\n    int colIndex = gridCoord.x + uGridOffset.x;\n    vec4 colInfo = getTexel(uSamplerCols, colIndex, uGridImageSize);\n    int colStrokeIndex = getInt16(colInfo.xy);\n    int colStrokeCount = getInt16(colInfo.zw);\n    \n    for (int iColStroke = INT(0); iColStroke < N; iColStroke++) {\n      if (iColStroke >= colStrokeCount)\n        break;\n\n      vec4 strokeIndices = getTexel(uSamplerColStrokes, colStrokeIndex++, uCellsImageSize);\n\n      int strokePos = getInt16(strokeIndices.xy);\n      vec4 stroke0 = getTexel(uSamplerStrokes, strokePos + INT(0), uStrokeImageSize);\n      vec4 stroke1 = getTexel(uSamplerStrokes, strokePos + INT(1), uStrokeImageSize);\n      coverageY(stroke0.xy, stroke0.zw, stroke1.xy);\n    }\n  }\n\n  weight = saturate(1.0 - weight * 2.0);\n  float distance = max(weight.x + weight.y, minDistance); // manhattan approx.\n  float antialias = abs(dot(coverage, weight) / distance);\n  float cover = min(abs(coverage.x), abs(coverage.y));\n  OUT_COLOR = vec4(uMaterialColor.rgb, 1.) * uMaterialColor.a;\n  OUT_COLOR *= saturate(max(antialias, cover));\n}\n";

var lineVert = "/*\n  Part of the Processing project - http://processing.org\n  Copyright (c) 2012-15 The Processing Foundation\n  Copyright (c) 2004-12 Ben Fry and Casey Reas\n  Copyright (c) 2001-04 Massachusetts Institute of Technology\n  This library is free software; you can redistribute it and/or\n  modify it under the terms of the GNU Lesser General Public\n  License as published by the Free Software Foundation, version 2.1.\n  This library is distributed in the hope that it will be useful,\n  but WITHOUT ANY WARRANTY; without even the implied warranty of\n  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n  Lesser General Public License for more details.\n  You should have received a copy of the GNU Lesser General\n  Public License along with this library; if not, write to the\n  Free Software Foundation, Inc., 59 Temple Place, Suite 330,\n  Boston, MA  02111-1307  USA\n*/\n\n#define PROCESSING_LINE_SHADER\n\n#define HOOK_DEFINES\n\nprecision highp int;\nprecision highp float;\n\n#ifdef AUGMENTED_HOOK_getWorldInputs\nuniform mat4 uModelMatrix;\nuniform mat4 uViewMatrix;\n#else\nuniform mat4 uModelViewMatrix;\n#endif\n\nuniform mat4 uProjectionMatrix;\nuniform float uStrokeWeight;\n\nuniform bool uUseLineColor;\nuniform bool uSimpleLines;\nuniform vec4 uMaterialColor;\n\nuniform vec4 uViewport;\nuniform int uPerspective;\nuniform int uStrokeJoin;\n\nIN vec3 aPosition;\nIN vec3 aTangentIn;\nIN vec3 aTangentOut;\nIN float aSide;\nIN vec4 aVertexColor;\n\nOUT vec4 vColor;\nOUT vec2 vTangent;\nOUT vec2 vCenter;\nOUT vec2 vPosition;\nOUT float vMaxDist;\nOUT float vCap;\nOUT float vJoin;\nOUT float vStrokeWeight;\n\nvec2 lineIntersection(vec2 aPoint, vec2 aDir, vec2 bPoint, vec2 bDir) {\n  // Rotate and translate so a starts at the origin and goes out to the right\n  bPoint -= aPoint;\n  vec2 rotatedBFrom = vec2(\n    bPoint.x*aDir.x + bPoint.y*aDir.y,\n    bPoint.y*aDir.x - bPoint.x*aDir.y\n  );\n  vec2 bTo = bPoint + bDir;\n  vec2 rotatedBTo = vec2(\n    bTo.x*aDir.x + bTo.y*aDir.y,\n    bTo.y*aDir.x - bTo.x*aDir.y\n  );\n  float intersectionDistance =\n    rotatedBTo.x + (rotatedBFrom.x - rotatedBTo.x) * rotatedBTo.y /\n    (rotatedBTo.y - rotatedBFrom.y);\n  return aPoint + aDir * intersectionDistance;\n}\n\nstruct StrokeVertex {\n  vec3 position;\n  vec3 tangentIn;\n  vec3 tangentOut;\n  vec4 color;\n  float weight;\n};\n\nvoid main() {\n  HOOK_beforeVertex();\n\n  if (!uSimpleLines) {\n      // Caps have one of either the in or out tangent set to 0\n      vCap = (aTangentIn == vec3(0.)) != (aTangentOut == vec3(0.)) ? 1. : 0.;\n\n      // Joins have two unique, defined tangents\n      vJoin = (\n          aTangentIn != vec3(0.) &&\n          aTangentOut != vec3(0.) &&\n          aTangentIn != aTangentOut\n      ) ? 1. : 0.;\n  }\n\n  StrokeVertex inputs;\n  inputs.position = aPosition.xyz;\n  inputs.color = uUseLineColor ? aVertexColor : uMaterialColor;\n  inputs.weight = uStrokeWeight;\n  inputs.tangentIn = aTangentIn;\n  inputs.tangentOut = aTangentOut;\n\n#ifdef AUGMENTED_HOOK_getObjectInputs\n  inputs = HOOK_getObjectInputs(inputs);\n#endif\n\n#ifdef AUGMENTED_HOOK_getWorldInputs\n  inputs.position = (uModelMatrix * vec4(inputs.position, 1.)).xyz;\n  inputs.tangentIn = (uModelMatrix * vec4(aTangentIn, 0.)).xyz;\n  inputs.tangentOut = (uModelMatrix * vec4(aTangentOut, 0.)).xyz;\n  inputs = HOOK_getWorldInputs(inputs);\n#endif\n\n#ifdef AUGMENTED_HOOK_getWorldInputs\n  // Already multiplied by the model matrix, just apply view\n  inputs.position = (uViewMatrix * vec4(inputs.position, 1.)).xyz;\n  inputs.tangentIn = (uViewMatrix * vec4(aTangentIn, 0.)).xyz;\n  inputs.tangentOut = (uViewMatrix * vec4(aTangentOut, 0.)).xyz;\n#else\n  // Apply both at once\n  inputs.position = (uModelViewMatrix * vec4(inputs.position, 1.)).xyz;\n  inputs.tangentIn = (uModelViewMatrix * vec4(aTangentIn, 0.)).xyz;\n  inputs.tangentOut = (uModelViewMatrix * vec4(aTangentOut, 0.)).xyz;\n#endif\n#ifdef AUGMENTED_HOOK_getCameraInputs\n  inputs = hook_getCameraInputs(inputs);\n#endif\n\n  vec4 posp = vec4(inputs.position, 1.);\n  vec4 posqIn = vec4(inputs.position + inputs.tangentIn, 1.);\n  vec4 posqOut = vec4(inputs.position + inputs.tangentOut, 1.);\n  vStrokeWeight = inputs.weight;\n\n  float facingCamera = pow(\n    // The word space tangent's z value is 0 if it's facing the camera\n    abs(normalize(posqIn-posp).z),\n\n    // Using pow() here to ramp `facingCamera` up from 0 to 1 really quickly\n    // so most lines get scaled and don't get clipped\n    0.25\n  );\n\n  // Moving vertices slightly toward the camera\n  // to avoid depth-fighting with the fill triangles.\n  // A mix of scaling and offsetting is used based on distance\n  // Discussion here:\n  // https://github.com/processing/p5.js/issues/7200 \n\n  // using a scale <1 moves the lines towards nearby camera\n  // in order to prevent popping effects due to half of\n  // the line disappearing behind the geometry faces.\n  float zDistance = -posp.z; \n  float distanceFactor = smoothstep(0.0, 800.0, zDistance); \n  \n  // Discussed here:\n  // http://www.opengl.org/discussion_boards/ubbthreads.php?ubb=showflat&Number=252848  \n  float scale = mix(1., 0.995, facingCamera);\n  float dynamicScale = mix(scale, 1.0, distanceFactor); // Closer = more scale, farther = less\n\n  posp.xyz = posp.xyz * dynamicScale;\n  posqIn.xyz = posqIn.xyz * dynamicScale;\n  posqOut.xyz = posqOut.xyz * dynamicScale;\n\n  // Moving vertices slightly toward camera when far away \n  // https://github.com/processing/p5.js/issues/6956 \n  float zOffset = mix(0., -1., facingCamera);\n  float dynamicZAdjustment = mix(0.0, zOffset, distanceFactor); // Closer = less zAdjustment, farther = more\n\n  posp.z -= dynamicZAdjustment;\n  posqIn.z -= dynamicZAdjustment;\n  posqOut.z -= dynamicZAdjustment;\n  \n  vec4 p = uProjectionMatrix * posp;\n  vec4 qIn = uProjectionMatrix * posqIn;\n  vec4 qOut = uProjectionMatrix * posqOut;\n\n  // formula to convert from clip space (range -1..1) to screen space (range 0..[width or height])\n  // screen_p = (p.xy/p.w + <1,1>) * 0.5 * uViewport.zw\n\n  // prevent division by W by transforming the tangent formula (div by 0 causes\n  // the line to disappear, see https://github.com/processing/processing/issues/5183)\n  // t = screen_q - screen_p\n  //\n  // tangent is normalized and we don't care which aDirection it points to (+-)\n  // t = +- normalize( screen_q - screen_p )\n  // t = +- normalize( (q.xy/q.w+<1,1>)*0.5*uViewport.zw - (p.xy/p.w+<1,1>)*0.5*uViewport.zw )\n  //\n  // extract common factor, <1,1> - <1,1> cancels out\n  // t = +- normalize( (q.xy/q.w - p.xy/p.w) * 0.5 * uViewport.zw )\n  //\n  // convert to common divisor\n  // t = +- normalize( ((q.xy*p.w - p.xy*q.w) / (p.w*q.w)) * 0.5 * uViewport.zw )\n  //\n  // remove the common scalar divisor/factor, not needed due to normalize and +-\n  // (keep uViewport - can't remove because it has different components for x and y\n  //  and corrects for aspect ratio, see https://github.com/processing/processing/issues/5181)\n  // t = +- normalize( (q.xy*p.w - p.xy*q.w) * uViewport.zw )\n\n  vec2 tangentIn = normalize((qIn.xy*p.w - p.xy*qIn.w) * uViewport.zw);\n  vec2 tangentOut = normalize((qOut.xy*p.w - p.xy*qOut.w) * uViewport.zw);\n\n  vec2 curPerspScale;\n  if(uPerspective == 1) {\n    // Perspective ---\n    // convert from world to clip by multiplying with projection scaling factor\n    // to get the right thickness (see https://github.com/processing/processing/issues/5182)\n\n    // The y value of the projection matrix may be flipped if rendering to a Framebuffer.\n    // Multiplying again by its sign here negates the flip to get just the scale.\n    curPerspScale = (uProjectionMatrix * vec4(1, sign(uProjectionMatrix[1][1]), 0, 0)).xy;\n  } else {\n    // No Perspective ---\n    // multiply by W (to cancel out division by W later in the pipeline) and\n    // convert from screen to clip (derived from clip to screen above)\n    curPerspScale = p.w / (0.5 * uViewport.zw);\n  }\n\n  vec2 offset;\n  if (vJoin == 1. && !uSimpleLines) {\n    vTangent = normalize(tangentIn + tangentOut);\n    vec2 normalIn = vec2(-tangentIn.y, tangentIn.x);\n    vec2 normalOut = vec2(-tangentOut.y, tangentOut.x);\n    float side = sign(aSide);\n    float sideEnum = abs(aSide);\n\n    // We generate vertices for joins on either side of the centerline, but\n    // the \"elbow\" side is the only one needing a join. By not setting the\n    // offset for the other side, all its vertices will end up in the same\n    // spot and not render, effectively discarding it.\n    if (sign(dot(tangentOut, vec2(-tangentIn.y, tangentIn.x))) != side) {\n      // Side enums:\n      //   1: the side going into the join\n      //   2: the middle of the join\n      //   3: the side going out of the join\n      if (sideEnum == 2.) {\n        // Calculate the position + tangent on either side of the join, and\n        // find where the lines intersect to find the elbow of the join\n        vec2 c = (posp.xy/posp.w + vec2(1.,1.)) * 0.5 * uViewport.zw;\n        vec2 intersection = lineIntersection(\n          c + (side * normalIn * inputs.weight / 2.),\n          tangentIn,\n          c + (side * normalOut * inputs.weight / 2.),\n          tangentOut\n        );\n        offset = (intersection - c);\n\n        // When lines are thick and the angle of the join approaches 180, the\n        // elbow might be really far from the center. We'll apply a limit to\n        // the magnitude to avoid lines going across the whole screen when this\n        // happens.\n        float mag = length(offset);\n        float maxMag = 3. * inputs.weight;\n        if (mag > maxMag) {\n          offset *= maxMag / mag;\n        }\n      } else if (sideEnum == 1.) {\n        offset = side * normalIn * inputs.weight / 2.;\n      } else if (sideEnum == 3.) {\n        offset = side * normalOut * inputs.weight / 2.;\n      }\n    }\n    if (uStrokeJoin == STROKE_JOIN_BEVEL) {\n      vec2 avgNormal = vec2(-vTangent.y, vTangent.x);\n      vMaxDist = abs(dot(avgNormal, normalIn * inputs.weight / 2.));\n    } else {\n      vMaxDist = inputs.weight / 2.;\n    }\n  } else {\n    vec2 tangent = aTangentIn == vec3(0.) ? tangentOut : tangentIn;\n    vTangent = tangent;\n    vec2 normal = vec2(-tangent.y, tangent.x);\n\n    float normalOffset = sign(aSide);\n    // Caps will have side values of -2 or 2 on the edge of the cap that\n    // extends out from the line\n    float tangentOffset = abs(aSide) - 1.;\n    offset = (normal * normalOffset + tangent * tangentOffset) *\n      inputs.weight * 0.5;\n    vMaxDist = inputs.weight / 2.;\n  }\n\n  vCenter = p.xy;\n  vPosition = vCenter + offset;\n  vColor = inputs.color;\n\n  gl_Position.xy = p.xy + offset.xy * curPerspScale;\n  gl_Position.zw = p.zw;\n  \n  HOOK_afterVertex();\n}\n";

var lineFrag = "precision highp int;\nprecision highp float;\n\nuniform vec4 uMaterialColor;\nuniform int uStrokeCap;\nuniform int uStrokeJoin;\n\nIN vec4 vColor;\nIN vec2 vTangent;\nIN vec2 vCenter;\nIN vec2 vPosition;\nIN float vStrokeWeight;\nIN float vMaxDist;\nIN float vCap;\nIN float vJoin;\n\nfloat distSquared(vec2 a, vec2 b) {\n  vec2 aToB = b - a;\n  return dot(aToB, aToB);\n}\n\nstruct Inputs {\n  vec4 color;\n  vec2 tangent;\n  vec2 center;\n  vec2 position;\n  float strokeWeight;\n};\n\nvoid main() {\n  HOOK_beforeFragment();\n\n  Inputs inputs;\n  inputs.color = vColor;\n  inputs.tangent = vTangent;\n  inputs.center = vCenter;\n  inputs.position = vPosition;\n  inputs.strokeWeight = vStrokeWeight;\n  inputs = HOOK_getPixelInputs(inputs);\n\n  if (vCap > 0.) {\n    if (\n      uStrokeCap == STROKE_CAP_ROUND &&\n      HOOK_shouldDiscard(distSquared(inputs.position, inputs.center) > inputs.strokeWeight * inputs.strokeWeight * 0.25)\n    ) {\n      discard;\n    } else if (\n      uStrokeCap == STROKE_CAP_SQUARE &&\n      HOOK_shouldDiscard(dot(inputs.position - inputs.center, inputs.tangent) > 0.)\n    ) {\n      discard;\n    // Use full area for PROJECT\n    } else if (HOOK_shouldDiscard(false)) {\n      discard;\n    }\n  } else if (vJoin > 0.) {\n    if (\n      uStrokeJoin == STROKE_JOIN_ROUND &&\n      HOOK_shouldDiscard(distSquared(inputs.position, inputs.center) > inputs.strokeWeight * inputs.strokeWeight * 0.25)\n    ) {\n      discard;\n    } else if (uStrokeJoin == STROKE_JOIN_BEVEL) {\n      vec2 normal = vec2(-inputs.tangent.y, inputs.tangent.x);\n      if (HOOK_shouldDiscard(abs(dot(inputs.position - inputs.center, normal)) > vMaxDist)) {\n        discard;\n      }\n    // Use full area for MITER\n    } else if (HOOK_shouldDiscard(false)) {\n      discard;\n    }\n  }\n  OUT_COLOR = HOOK_getFinalColor(vec4(inputs.color.rgb, 1.) * inputs.color.a);\n  HOOK_afterFragment();\n}\n";

var pointVert = "IN vec3 aPosition;\nuniform float uPointSize;\nOUT float vStrokeWeight;\nuniform mat4 uModelViewMatrix;\nuniform mat4 uProjectionMatrix;\n\nvoid main() {\n  HOOK_beforeVertex();\n  vec4 viewModelPosition = vec4(HOOK_getWorldPosition(\n    (uModelViewMatrix * vec4(HOOK_getLocalPosition(aPosition), 1.0)).xyz\n  ), 1.);\n  gl_Position = uProjectionMatrix * viewModelPosition;  \n\n  float pointSize = HOOK_getPointSize(uPointSize);\n\n\tgl_PointSize = pointSize;\n\tvStrokeWeight = pointSize;\n  HOOK_afterVertex();\n}\n";

var pointFrag = "precision mediump int;\nuniform vec4 uMaterialColor;\nIN float vStrokeWeight;\n\nvoid main(){\n  HOOK_beforeFragment();\n  float mask = 0.0;\n\n  // make a circular mask using the gl_PointCoord (goes from 0 - 1 on a point)\n  // might be able to get a nicer edge on big strokeweights with smoothstep but slightly less performant\n\n  mask = step(0.98, length(gl_PointCoord * 2.0 - 1.0));\n\n  // if strokeWeight is 1 or less lets just draw a square\n  // this prevents weird artifacting from carving circles when our points are really small\n  // if strokeWeight is larger than 1, we just use it as is\n\n  mask = mix(0.0, mask, clamp(floor(vStrokeWeight - 0.5),0.0,1.0));\n\n  // throw away the borders of the mask\n  // otherwise we get weird alpha blending issues\n\n  if(HOOK_shouldDiscard(mask > 0.98)){\n    discard;\n  }\n\n  OUT_COLOR = HOOK_getFinalColor(vec4(uMaterialColor.rgb, 1.) * uMaterialColor.a);\n  HOOK_afterFragment();\n}\n";

var imageLightVert = "precision highp float;\nattribute vec3 aPosition;\nattribute vec3 aNormal;\nattribute vec2 aTexCoord;\n\nvarying vec3 localPos;\nvarying vec3 vWorldNormal;\nvarying vec3 vWorldPosition;\nvarying vec2 vTexCoord;\n\nuniform mat4 uModelViewMatrix;\nuniform mat4 uProjectionMatrix;\nuniform mat3 uNormalMatrix;\n\nvoid main() {\n  // Multiply the position by the matrix.\n  vec4 viewModelPosition = uModelViewMatrix * vec4(aPosition, 1.0);\n  gl_Position = uProjectionMatrix * viewModelPosition;  \n  \n  // orient the normals and pass to the fragment shader\n  vWorldNormal = uNormalMatrix * aNormal;\n  \n  // send the view position to the fragment shader\n  vWorldPosition = (uModelViewMatrix * vec4(aPosition, 1.0)).xyz;\n  \n  localPos = vWorldPosition;\n  vTexCoord = aTexCoord;\n}\n\n\n/*\nin the vertex shader we'll compute the world position and world oriented normal of the vertices and pass those to the fragment shader as varyings.\n*/\n";

var imageLightDiffusedFrag = "precision highp float;\nvarying vec3 localPos;\n\n// the HDR cubemap converted (can be from an equirectangular environment map.)\nuniform sampler2D environmentMap;\nvarying vec2 vTexCoord;\n\nconst float PI = 3.14159265359;\n\nvec2 nTOE( vec3 v ){\n  // x = r sin(phi) cos(theta)   \n  // y = r cos(phi)  \n  // z = r sin(phi) sin(theta)\n  float phi = acos( v.y );\n  // if phi is 0, then there are no x, z components\n  float theta = 0.0;\n  // else \n  theta = acos(v.x / sin(phi));\n  float sinTheta = v.z / sin(phi);\n  if (sinTheta < 0.0) {\n    // Turn it into -theta, but in the 0-2PI range\n    theta = 2.0 * PI - theta;\n  }\n  theta = theta / (2.0 * 3.14159);\n  phi = phi / 3.14159 ;\n  \n  vec2 angles = vec2( phi, theta );\n  return angles;\n}\n\nfloat random(vec2 p) {\n  vec3 p3  = fract(vec3(p.xyx) * .1031);\n  p3 += dot(p3, p3.yzx + 33.33);\n  return fract((p3.x + p3.y) * p3.z);\n}\n\nvoid main()\n{   \t \n\t// the sample direction equals the hemisphere's orientation\n  float phi = vTexCoord.x * 2.0 * PI;\n  float theta = vTexCoord.y * PI;\n  float x = sin(theta) * cos(phi);\n  float y = sin(theta) * sin(phi);\n  float z = cos(theta);\n  vec3 normal = vec3( x, y, z);\n\n\t// Discretely sampling the hemisphere given the integral's\n  // spherical coordinates translates to the following fragment code:\n\tvec3 irradiance = vec3(0.0);  \n\tvec3 up\t= vec3(0.0, 1.0, 0.0);\n\tvec3 right = normalize(cross(up, normal));\n\tup = normalize(cross(normal, right));\n\n\t//  We specify a fixed sampleDelta delta value to traverse\n  // the hemisphere; decreasing or increasing the sample delta\n  // will increase or decrease the accuracy respectively.\n\tconst float sampleDelta = 0.100;\n\tfloat nrSamples = 0.0;\n  float randomOffset = random(gl_FragCoord.xy) * sampleDelta;\n\tfor(float rawPhi = 0.0; rawPhi < 2.0 * PI; rawPhi += sampleDelta)\n\t{\n    float phi = rawPhi + randomOffset;\n    for(float rawTheta = 0.0; rawTheta < ( 0.5 ) * PI; rawTheta += sampleDelta)\n    {\n      float theta = rawTheta + randomOffset;\n      // spherical to cartesian (in tangent space) // tangent space to world // add each sample result to irradiance\n      float x = sin(theta) * cos(phi);\n      float y = sin(theta) * sin(phi);\n      float z = cos(theta);\n      vec3 tangentSample = vec3( x, y, z);\n      \n      vec3 sampleVec = tangentSample.x * right + tangentSample.y * up + tangentSample.z * normal;\n        irradiance += (texture2D(environmentMap, nTOE(sampleVec)).xyz) * cos(theta) * sin(theta);\n      nrSamples++;\n    }\n\t}\n\t// divide by the total number of samples taken, giving us the average sampled irradiance.\n\tirradiance = PI * irradiance * (1.0 / float(nrSamples )) ;\n  \n \n\tgl_FragColor = vec4(irradiance, 1.0);\n}";

var imageLightSpecularFrag = "precision highp float;\r\nvarying vec3 localPos;\r\nvarying vec2 vTexCoord;\r\n\r\n// our texture\r\nuniform sampler2D environmentMap;\r\nuniform float roughness;\r\n\r\nconst float PI = 3.14159265359;\r\n\r\nfloat VanDerCorput(int bits);\r\nvec2 HammersleyNoBitOps(int i, int N);\r\nvec3 ImportanceSampleGGX(vec2 Xi, vec3 N, float roughness);\r\n\r\n\r\nvec2 nTOE( vec3 v ){\r\n  // x = r sin(phi) cos(theta)   \r\n  // y = r cos(phi)  \r\n  // z = r sin(phi) sin(theta)\r\n  float phi = acos( v.y );\r\n  // if phi is 0, then there are no x, z components\r\n  float theta = 0.0;\r\n  // else \r\n  theta = acos(v.x / sin(phi));\r\n  float sinTheta = v.z / sin(phi);\r\n  if (sinTheta < 0.0) {\r\n    // Turn it into -theta, but in the 0-2PI range\r\n    theta = 2.0 * PI - theta;\r\n  }\r\n  theta = theta / (2.0 * 3.14159);\r\n  phi = phi / 3.14159 ;\r\n  \r\n  vec2 angles = vec2( phi, theta );\r\n  return angles;\r\n}\r\n\r\n\r\nvoid main(){\r\n  const int SAMPLE_COUNT = 400; // 4096\r\n  int lowRoughnessLimit = int(pow(2.0,(roughness+0.1)*20.0));\r\n  float totalWeight = 0.0;\r\n  vec3 prefilteredColor = vec3(0.0);\r\n  float phi = vTexCoord.x * 2.0 * PI;\r\n  float theta = vTexCoord.y * PI;\r\n  float x = sin(theta) * cos(phi);\r\n  float y = sin(theta) * sin(phi);\r\n  float z = cos(theta);\r\n  vec3 N = vec3(x,y,z);\r\n  vec3 V = N;\r\n  for (int i = 0; i < SAMPLE_COUNT; ++i)\r\n  {\r\n    // break at smaller sample numbers for low roughness levels\r\n    if(i == lowRoughnessLimit)\r\n    {\r\n      break;\r\n    }\r\n    vec2 Xi = HammersleyNoBitOps(i, SAMPLE_COUNT);\r\n    vec3 H = ImportanceSampleGGX(Xi, N, roughness);\r\n    vec3 L = normalize(2.0 * dot(V, H) * H - V);\r\n\r\n    float NdotL = max(dot(N, L), 0.0);\r\n    if (NdotL > 0.0)\r\n    {\r\n      prefilteredColor += texture2D(environmentMap, nTOE(L)).xyz * NdotL;\r\n      totalWeight += NdotL;\r\n    }\r\n  }\r\n  prefilteredColor = prefilteredColor / totalWeight;\r\n\r\n  gl_FragColor = vec4(prefilteredColor, 1.0);\r\n}\r\n\r\nvec3 ImportanceSampleGGX(vec2 Xi, vec3 N, float roughness){\r\n  float a = roughness * roughness;\r\n\r\n  float phi = 2.0 * PI * Xi.x;\r\n  float cosTheta = sqrt((1.0 - Xi.y) / (1.0 + (a * a - 1.0) * Xi.y));\r\n  float sinTheta = sqrt(1.0 - cosTheta * cosTheta);\r\n  // from spherical coordinates to cartesian coordinates\r\n  vec3 H;\r\n  H.x = cos(phi) * sinTheta;\r\n  H.y = sin(phi) * sinTheta;\r\n  H.z = cosTheta;\r\n\r\n  // from tangent-space vector to world-space sample vector\r\n  vec3 up = abs(N.z) < 0.999 ? vec3(0.0, 0.0, 1.0) : vec3(1.0, 0.0, 0.0);\r\n  vec3 tangent = normalize(cross(up, N));\r\n  vec3 bitangent = cross(N, tangent);\r\n\r\n  vec3 sampleVec = tangent * H.x + bitangent * H.y + N * H.z;\r\n  return normalize(sampleVec);\r\n}\r\n\r\n\r\nfloat VanDerCorput(int n, int base)\r\n{\r\n#ifdef WEBGL2\r\n\r\n    uint bits = uint(n);\r\n    bits = (bits << 16u) | (bits >> 16u);\r\n    bits = ((bits & 0x55555555u) << 1u) | ((bits & 0xAAAAAAAAu) >> 1u);\r\n    bits = ((bits & 0x33333333u) << 2u) | ((bits & 0xCCCCCCCCu) >> 2u);\r\n    bits = ((bits & 0x0F0F0F0Fu) << 4u) | ((bits & 0xF0F0F0F0u) >> 4u);\r\n    bits = ((bits & 0x00FF00FFu) << 8u) | ((bits & 0xFF00FF00u) >> 8u);\r\n    return float(bits) * 2.3283064365386963e-10; // / 0x100000000\r\n\r\n#else\r\n\r\n  float invBase = 1.0 / float(base);\r\n  float denom = 1.0;\r\n  float result = 0.0;\r\n\r\n\r\n  for (int i = 0; i < 32; ++i)\r\n  {\r\n        if (n > 0)\r\n        {\r\n        denom = mod(float(n), 2.0);\r\n        result += denom * invBase;\r\n        invBase = invBase / 2.0;\r\n        n = int(float(n) / 2.0);\r\n        }\r\n  }\r\n\r\n\r\n  return result;\r\n\r\n#endif\r\n}\r\n\r\nvec2 HammersleyNoBitOps(int i, int N)\r\n{\r\n  return vec2(float(i) / float(N), VanDerCorput(i, 2));\r\n}\r\n";

var filterBaseFrag = "precision highp float;\n\nuniform sampler2D tex0;\nuniform vec2 canvasSize;\nuniform vec2 texelSize;\n\nIN vec2 vTexCoord;\n\nstruct FilterInputs {\n  vec2 texCoord;\n  vec2 canvasSize;\n  vec2 texelSize;\n};\n\nvoid main(void) {\n  FilterInputs inputs;\n  inputs.texCoord = vTexCoord;\n  inputs.canvasSize = canvasSize;\n  inputs.texelSize = texelSize;\n  OUT_COLOR = HOOK_getColor(inputs, tex0);\n  OUT_COLOR.rgb *= outColor.a;\n}\n";

var filterGrayFrag = "precision highp float;\n\nvarying vec2 vTexCoord;\n\nuniform sampler2D tex0;\n\nfloat luma(vec3 color) {\n  // weighted grayscale with luminance values\n  return dot(color, vec3(0.2126, 0.7152, 0.0722));\n}\n\nvoid main() {\n  vec4 tex = texture2D(tex0, vTexCoord);\n  float gray = luma(tex.rgb);\n  gl_FragColor = vec4(gray, gray, gray, tex.a);\n}\n";

var filterErodeFrag = "// Reduces the bright areas in an image\n\nprecision highp float;\n\nvarying vec2 vTexCoord;\n\nuniform sampler2D tex0;\nuniform vec2 texelSize;\n\nfloat luma(vec3 color) {\n  // weighted grayscale with luminance values\n  // weights 77, 151, 28 taken from src/image/filters.js\n  return dot(color, vec3(0.300781, 0.589844, 0.109375));\n}\n\nvoid main() {\n  vec4 color = texture2D(tex0, vTexCoord);\n  float lum = luma(color.rgb);\n\n  // set current color as the darkest neighbor color\n\n  vec4 neighbors[4];\n  neighbors[0] = texture2D(tex0, vTexCoord + vec2( texelSize.x, 0.0));\n  neighbors[1] = texture2D(tex0, vTexCoord + vec2(-texelSize.x, 0.0));\n  neighbors[2] = texture2D(tex0, vTexCoord + vec2(0.0,  texelSize.y));\n  neighbors[3] = texture2D(tex0, vTexCoord + vec2(0.0, -texelSize.y));\n\n  for (int i = 0; i < 4; i++) {\n    vec4 neighborColor = neighbors[i];\n    float neighborLum = luma(neighborColor.rgb);\n\n    if (neighborLum < lum) {\n      color = neighborColor;\n      lum = neighborLum;\n    }\n  }\n\n  gl_FragColor = color;\n}\n";

var filterDilateFrag = "// Increase the bright areas in an image\n\nprecision highp float;\n\nvarying vec2 vTexCoord;\n\nuniform sampler2D tex0;\nuniform vec2 texelSize;\n\nfloat luma(vec3 color) {\n  // weighted grayscale with luminance values\n  // weights 77, 151, 28 taken from src/image/filters.js\n  return dot(color, vec3(0.300781, 0.589844, 0.109375));\n}\n\nvoid main() {\n  vec4 color = texture2D(tex0, vTexCoord);\n  float lum = luma(color.rgb);\n\n  // set current color as the brightest neighbor color\n\n  vec4 neighbors[4];\n  neighbors[0] = texture2D(tex0, vTexCoord + vec2( texelSize.x, 0.0));\n  neighbors[1] = texture2D(tex0, vTexCoord + vec2(-texelSize.x, 0.0));\n  neighbors[2] = texture2D(tex0, vTexCoord + vec2(0.0,  texelSize.y));\n  neighbors[3] = texture2D(tex0, vTexCoord + vec2(0.0, -texelSize.y));\n\n  for (int i = 0; i < 4; i++) {\n    vec4 neighborColor = neighbors[i];\n    float neighborLum = luma(neighborColor.rgb);\n\n    if (neighborLum > lum) {\n      color = neighborColor;\n      lum = neighborLum;\n    }\n  }\n\n  gl_FragColor = color;\n}\n";

var filterBlurFrag = "precision highp float;\n\n// Two-pass blur filter, unweighted kernel.\n// See also a similar blur at Adam Ferriss' repo of shader examples:\n// https://github.com/aferriss/p5jsShaderExamples/blob/gh-pages/4_image-effects/4-9_single-pass-blur/effect.frag\n\n\nuniform sampler2D tex0;\nvarying vec2 vTexCoord;\nuniform vec2 direction;\nuniform vec2 canvasSize;\nuniform float radius;\n\nfloat random(vec2 p) {\n  vec3 p3  = fract(vec3(p.xyx) * .1031);\n  p3 += dot(p3, p3.yzx + 33.33);\n  return fract((p3.x + p3.y) * p3.z);\n}\n\n// This isn't a real Gaussian weight, it's a quadratic weight. It's what the\n// CPU mode's blur uses though, so we also use it here to match.\nfloat quadWeight(float x, float e) {\n  return pow(e-abs(x), 2.);\n}\n\nvoid main(){\n  vec2 uv = vTexCoord;\n\n  // A reasonable maximum number of samples\n  const float maxSamples = 64.0;\n\n  float numSamples = floor(7. * radius);\n  if (fract(numSamples / 2.) == 0.) {\n    numSamples++;\n  }\n  vec4 avg = vec4(0.0);\n  float total = 0.0;\n\n  // Calculate the spacing to avoid skewing if numSamples > maxSamples\n  float spacing = 1.0;\n  if (numSamples > maxSamples) {\n    spacing = numSamples / maxSamples;\n    numSamples = maxSamples;\n  }\n\n  float randomOffset = (spacing - 1.0) * mix(-0.5, 0.5, random(gl_FragCoord.xy));\n  for (float i = 0.0; i < maxSamples; i++) {\n    if (i >= numSamples) break;\n\n    float sample = i * spacing - (numSamples - 1.0) * 0.5 * spacing + randomOffset;\n    vec2 sampleCoord = uv + vec2(sample, sample) / canvasSize * direction;\n    float weight = quadWeight(sample, (numSamples - 1.0) * 0.5 * spacing);\n\n    avg += weight * texture2D(tex0, sampleCoord);\n    total += weight;\n  }\n\n  avg /= total;\n  gl_FragColor = avg;\n}\n";

var filterPosterizeFrag = "// Limit color space for a stylized cartoon / poster effect\n\nprecision highp float;\n\nvarying vec2 vTexCoord;\n\nuniform sampler2D tex0;\nuniform float filterParameter;\n\nvec3 quantize(vec3 color, float n) {\n  // restrict values to N options/bins\n  // and floor each channel to nearest value\n  //\n  // eg. when N = 5, values = 0.0, 0.25, 0.50, 0.75, 1.0\n  // then quantize (0.1, 0.7, 0.9) -> (0.0, 0.5, 1.0)\n\n  color = color * n;\n  color = floor(color);\n  color = color / (n - 1.0);\n  return color;\n}\n\nvoid main() {\n  vec4 color = texture2D(tex0, vTexCoord);\n\n  vec3 restrictedColor = quantize(color.rgb / color.a, filterParameter);\n\n  gl_FragColor = vec4(restrictedColor.rgb * color.a, color.a);\n}\n";

var filterOpaqueFrag = "// Set alpha channel to entirely opaque\n\nprecision highp float;\n\nvarying vec2 vTexCoord;\n\nuniform sampler2D tex0;\n\nvoid main() {\n  vec4 color = texture2D(tex0, vTexCoord);\n  gl_FragColor = vec4(color.rgb / color.a, 1.0);\n}\n";

var filterInvertFrag = "// Set each pixel to inverse value\n// Note that original INVERT does not change the opacity, so this follows suit\n\nprecision highp float;\n\nvarying vec2 vTexCoord;\n\nuniform sampler2D tex0;\n\nvoid main() {\nvec4 color = texture2D(tex0, vTexCoord);\nvec3 origColor = color.rgb / color.a;\nvec3 invertedColor = vec3(1.0) - origColor;\ngl_FragColor = vec4(invertedColor * color.a, color.a);\n}\n";

var filterThresholdFrag = "// Convert pixels to either white or black, \n// depending on if their luma is above or below filterParameter\n\nprecision highp float;\n\nvarying vec2 vTexCoord;\n\nuniform sampler2D tex0;\nuniform float filterParameter;\n\nfloat luma(vec3 color) {\n  // weighted grayscale with luminance values\n  return dot(color, vec3(0.2126, 0.7152, 0.0722));\n}\n\nvoid main() {\n  vec4 color = texture2D(tex0, vTexCoord);\n  float gray = luma(color.rgb / color.a);\n  // floor() used to match src/image/filters.js\n  float threshold = floor(filterParameter * 255.0) / 255.0;\n  float blackOrWhite = step(threshold, gray);\n  gl_FragColor = vec4(vec3(blackOrWhite) * color.a, color.a);\n}\n";

var filterShaderVert = "uniform mat4 uModelViewMatrix;\nuniform mat4 uProjectionMatrix;\n\nattribute vec3 aPosition;\n// texcoords only come from p5 to vertex shader\n// so pass texcoords on to the fragment shader in a varying variable\nattribute vec2 aTexCoord;\nvarying vec2 vTexCoord;\n\nvoid main() {\n  // transferring texcoords for the frag shader\n  vTexCoord = aTexCoord;\n\n  // copy position with a fourth coordinate for projection (1.0 is normal)\n  vec4 positionVec4 = vec4(aPosition, 1.0);\n\n  gl_Position = uProjectionMatrix * uModelViewMatrix * positionVec4;\n}\n";

const STROKE_CAP_ENUM = {};
const STROKE_JOIN_ENUM = {};
let lineDefs = "";
const defineStrokeCapEnum = function (key, val) {
  lineDefs += `#define STROKE_CAP_${key} ${val}\n`;
  STROKE_CAP_ENUM[constants[key]] = val;
};
const defineStrokeJoinEnum = function (key, val) {
  lineDefs += `#define STROKE_JOIN_${key} ${val}\n`;
  STROKE_JOIN_ENUM[constants[key]] = val;
};

// Define constants in line shaders for each type of cap/join, and also record
// the values in JS objects
defineStrokeCapEnum("ROUND", 0);
defineStrokeCapEnum("PROJECT", 1);
defineStrokeCapEnum("SQUARE", 2);
defineStrokeJoinEnum("ROUND", 0);
defineStrokeJoinEnum("MITER", 1);
defineStrokeJoinEnum("BEVEL", 2);

const defaultShaders = {
  normalVert,
  normalFrag,
  basicFrag,
  sphereMappingFrag,
  lightVert: lightingShader + lightVert,
  lightTextureFrag,
  phongVert,
  phongFrag: lightingShader + phongFrag,
  fontVert,
  fontFrag,
  lineVert: lineDefs + lineVert,
  lineFrag: lineDefs + lineFrag,
  pointVert,
  pointFrag,
  imageLightVert,
  imageLightDiffusedFrag,
  imageLightSpecularFrag,
  filterBaseVert,
  filterBaseFrag,
};
let sphereMapping = defaultShaders.sphereMappingFrag;
for (const key in defaultShaders) {
  defaultShaders[key] = webgl2CompatibilityShader + defaultShaders[key];
}

const filterShaderFrags = {
  [GRAY]: filterGrayFrag,
  [ERODE]: filterErodeFrag,
  [DILATE]: filterDilateFrag,
  [BLUR]: filterBlurFrag,
  [POSTERIZE]: filterPosterizeFrag,
  [OPAQUE]: filterOpaqueFrag,
  [INVERT]: filterInvertFrag,
  [THRESHOLD]: filterThresholdFrag,
};

/**
 * 3D graphics class
 * @private
 * @class p5.RendererGL
 * @extends p5.Renderer
 * @todo extend class to include public method for offscreen
 * rendering (FBO).
 */
class RendererGL extends Renderer {
  constructor(pInst, w, h, isMainCanvas, elt, attr) {
    super(pInst, w, h, isMainCanvas);

    // Create new canvas
    this.canvas = this.elt = elt || document.createElement("canvas");
    this._setAttributeDefaults(pInst);
    this._initContext();
    // This redundant property is useful in reminding you that you are
    // interacting with WebGLRenderingContext, still worth considering future removal
    this.GL = this.drawingContext;

    if (this._isMainCanvas) {
      // for pixel method sharing with pimage
      this._pInst._curElement = this;
      this._pInst.canvas = this.canvas;
    } else {
      // hide if offscreen buffer by default
      this.canvas.style.display = "none";
    }
    this.elt.id = "defaultCanvas0";
    this.elt.classList.add("p5Canvas");

    // Set and return p5.Element
    this.wrappedElt = new Element(this.elt, this._pInst);

    // Extend renderer with methods of p5.Element with getters
    for (const p of Object.getOwnPropertyNames(Element.prototype)) {
      if (p !== 'constructor' && p[0] !== '_') {
        Object.defineProperty(this, p, {
          get() {
            return this.wrappedElt[p];
          }
        });
      }
    }

    const dimensions = this._adjustDimensions(w, h);
    w = dimensions.adjustedWidth;
    h = dimensions.adjustedHeight;

    this.width = w;
    this.height = h;

    // Set canvas size
    this.elt.width = w * this._pixelDensity;
    this.elt.height = h * this._pixelDensity;
    this.elt.style.width = `${w}px`;
    this.elt.style.height = `${h}px`;
    this._origViewport = {
      width: this.GL.drawingBufferWidth,
      height: this.GL.drawingBufferHeight,
    };
    this.viewport(this._origViewport.width, this._origViewport.height);

    // Attach canvas element to DOM
    if (this._pInst._userNode) {
      // user input node case
      this._pInst._userNode.appendChild(this.elt);
    } else {
      //create main element
      if (document.getElementsByTagName("main").length === 0) {
        let m = document.createElement("main");
        document.body.appendChild(m);
      }
      //append canvas to main
      document.getElementsByTagName("main")[0].appendChild(this.elt);
    }

    this.isP3D = true; //lets us know we're in 3d mode

    // When constructing a new Geometry, this will represent the builder
    this.geometryBuilder = undefined;

    // Push/pop state
    this.states.uModelMatrix = new Matrix(4);
    this.states.uViewMatrix = new Matrix(4);
    this.states.uPMatrix = new Matrix(4);

    this.states.curCamera = new Camera(this);
    this.states.uPMatrix.set(this.states.curCamera.projMatrix);
    this.states.uViewMatrix.set(this.states.curCamera.cameraMatrix);

    this.states.enableLighting = false;
    this.states.ambientLightColors = [];
    this.states.specularColors = [1, 1, 1];
    this.states.directionalLightDirections = [];
    this.states.directionalLightDiffuseColors = [];
    this.states.directionalLightSpecularColors = [];
    this.states.pointLightPositions = [];
    this.states.pointLightDiffuseColors = [];
    this.states.pointLightSpecularColors = [];
    this.states.spotLightPositions = [];
    this.states.spotLightDirections = [];
    this.states.spotLightDiffuseColors = [];
    this.states.spotLightSpecularColors = [];
    this.states.spotLightAngle = [];
    this.states.spotLightConc = [];
    this.states.activeImageLight = null;

    this.states.curFillColor = [1, 1, 1, 1];
    this.states.curAmbientColor = [1, 1, 1, 1];
    this.states.curSpecularColor = [0, 0, 0, 0];
    this.states.curEmissiveColor = [0, 0, 0, 0];
    this.states.curStrokeColor = [0, 0, 0, 1];

    this.states.curBlendMode = BLEND;

    this.states._hasSetAmbient = false;
    this.states._useSpecularMaterial = false;
    this.states._useEmissiveMaterial = false;
    this.states._useNormalMaterial = false;
    this.states._useShininess = 1;
    this.states._useMetalness = 0;

    this.states.tint = [255, 255, 255, 255];

    this.states.constantAttenuation = 1;
    this.states.linearAttenuation = 0;
    this.states.quadraticAttenuation = 0;

    this.states._currentNormal = new Vector(0, 0, 1);

    this.states.drawMode = FILL;

    this.states._tex = null;
    this.states.textureMode = IMAGE;
    this.states.textureWrapX = CLAMP;
    this.states.textureWrapY = CLAMP;

    // erasing
    this._isErasing = false;

    // simple lines
    this._simpleLines = false;

    // clipping
    this._clipDepths = [];
    this._isClipApplied = false;
    this._stencilTestOn = false;

    this.mixedAmbientLight = [];
    this.mixedSpecularColor = [];

    // p5.framebuffer for this are calculated in getDiffusedTexture function
    this.diffusedTextures = new Map();
    // p5.framebuffer for this are calculated in getSpecularTexture function
    this.specularTextures = new Map();

    this.preEraseBlend = undefined;
    this._cachedBlendMode = undefined;
    this._cachedFillStyle = [1, 1, 1, 1];
    this._cachedStrokeStyle = [0, 0, 0, 1];
    if (this.webglVersion === WEBGL2) {
      this.blendExt = this.GL;
    } else {
      this.blendExt = this.GL.getExtension("EXT_blend_minmax");
    }
    this._isBlending = false;

    this._useLineColor = false;
    this._useVertexColor = false;

    this.registerEnabled = new Set();

    // Camera
    this.states.curCamera._computeCameraDefaultSettings();
    this.states.curCamera._setDefaultCamera();

    // FilterCamera
    this.filterCamera = new Camera(this);
    this.filterCamera._computeCameraDefaultSettings();
    this.filterCamera._setDefaultCamera();
    // Information about the previous frame's touch object
    // for executing orbitControl()
    this.prevTouches = [];
    // Velocity variable for use with orbitControl()
    this.zoomVelocity = 0;
    this.rotateVelocity = new Vector(0, 0);
    this.moveVelocity = new Vector(0, 0);
    // Flags for recording the state of zooming, rotation and moving
    this.executeZoom = false;
    this.executeRotateAndMove = false;

    this._drawingFilter = false;
    this._drawingImage = false;

    this.specularShader = undefined;
    this.sphereMapping = undefined;
    this.diffusedShader = undefined;
    this._baseFilterShader = undefined;
    this._defaultLightShader = undefined;
    this._defaultImmediateModeShader = undefined;
    this._defaultNormalShader = undefined;
    this._defaultColorShader = undefined;
    this._defaultPointShader = undefined;

    this.states.userFillShader = undefined;
    this.states.userStrokeShader = undefined;
    this.states.userPointShader = undefined;
    this.states.userImageShader = undefined;

    this.states.curveDetail = 1 / 4;

    // Used by beginShape/endShape functions to construct a p5.Geometry
    this.shapeBuilder = new ShapeBuilder(this);

    this.buffers = {
      fill: [
        new RenderBuffer(
          3,
          "vertices",
          "vertexBuffer",
          "aPosition",
          this,
          this._vToNArray
        ),
        new RenderBuffer(
          3,
          "vertexNormals",
          "normalBuffer",
          "aNormal",
          this,
          this._vToNArray
        ),
        new RenderBuffer(
          4,
          "vertexColors",
          "colorBuffer",
          "aVertexColor",
          this
        ),
        new RenderBuffer(
          3,
          "vertexAmbients",
          "ambientBuffer",
          "aAmbientColor",
          this
        ),
        new RenderBuffer(2, "uvs", "uvBuffer", "aTexCoord", this, (arr) =>
          arr.flat()
        ),
      ],
      stroke: [
        new RenderBuffer(
          4,
          "lineVertexColors",
          "lineColorBuffer",
          "aVertexColor",
          this
        ),
        new RenderBuffer(
          3,
          "lineVertices",
          "lineVerticesBuffer",
          "aPosition",
          this
        ),
        new RenderBuffer(
          3,
          "lineTangentsIn",
          "lineTangentsInBuffer",
          "aTangentIn",
          this
        ),
        new RenderBuffer(
          3,
          "lineTangentsOut",
          "lineTangentsOutBuffer",
          "aTangentOut",
          this
        ),
        new RenderBuffer(1, "lineSides", "lineSidesBuffer", "aSide", this),
      ],
      text: [
        new RenderBuffer(
          3,
          "vertices",
          "vertexBuffer",
          "aPosition",
          this,
          this._vToNArray
        ),
        new RenderBuffer(2, "uvs", "uvBuffer", "aTexCoord", this, (arr) =>
          arr.flat()
        ),
      ],
      point: this.GL.createBuffer(),
      user: [],
    };

    this.geometryBufferCache = new GeometryBufferCache(this);

    this.curStrokeCap = ROUND;
    this.curStrokeJoin = ROUND;

    // map of texture sources to textures created in this gl context via this.getTexture(src)
    this.textures = new Map();

    // set of framebuffers in use
    this.framebuffers = new Set();
    // stack of active framebuffers
    this.activeFramebuffers = [];

    // for post processing step
    this.states.filterShader = undefined;
    this.filterLayer = undefined;
    this.filterLayerTemp = undefined;
    this.defaultFilterShaders = {};

    this.fontInfos = {};

    this._curShader = undefined;
    this.drawShapeCount = 1;

    this.scratchMat3 = new Matrix(3);

    this._userEnabledStencil = false;
    // Store original methods for internal use
    this._internalEnable = this.drawingContext.enable;
    this._internalDisable = this.drawingContext.disable;

    // Override WebGL enable function
    this.drawingContext.enable = (key) => {
      if (key === this.drawingContext.STENCIL_TEST) {
        if (!this._clipping) {
          this._userEnabledStencil = true;
        }
      }
      return this._internalEnable.call(this.drawingContext, key);
    };

    // Override WebGL disable function
    this.drawingContext.disable = (key) => {
      if (key === this.drawingContext.STENCIL_TEST) {
          this._userEnabledStencil = false;
      }
      return this._internalDisable.call(this.drawingContext, key);
    };

    // Whether or not to remove degenerate faces from geometry. This is usually
    // set to false for performance.
    this._validateFaces = false;
  }

  remove() {
    this.wrappedElt.remove();
    this.wrappedElt = null;
    this.canvas = null;
    this.elt = null;
  }

  //////////////////////////////////////////////
  // Geometry Building
  //////////////////////////////////////////////

  /**
   * Starts creating a new p5.Geometry. Subsequent shapes drawn will be added
   * to the geometry and then returned when
   * <a href="#/p5/endGeometry">endGeometry()</a> is called. One can also use
   * <a href="#/p5/buildGeometry">buildGeometry()</a> to pass a function that
   * draws shapes.
   *
   * If you need to draw complex shapes every frame which don't change over time,
   * combining them upfront with `beginGeometry()` and `endGeometry()` and then
   * drawing that will run faster than repeatedly drawing the individual pieces.
   * @private
   */
  beginGeometry() {
    if (this.geometryBuilder) {
      throw new Error(
        "It looks like `beginGeometry()` is being called while another p5.Geometry is already being build."
      );
    }
    this.geometryBuilder = new GeometryBuilder(this);
    this.geometryBuilder.prevFillColor = this.states.fillColor;
    this.fill(new Color([-1, -1, -1, -1]));
  }

  /**
   * Finishes creating a new <a href="#/p5.Geometry">p5.Geometry</a> that was
   * started using <a href="#/p5/beginGeometry">beginGeometry()</a>. One can also
   * use <a href="#/p5/buildGeometry">buildGeometry()</a> to pass a function that
   * draws shapes.
   * @private
   *
   * @returns {p5.Geometry} The model that was built.
   */
  endGeometry() {
    if (!this.geometryBuilder) {
      throw new Error(
        "Make sure you call beginGeometry() before endGeometry()!"
      );
    }
    const geometry = this.geometryBuilder.finish();
    this.fill(this.geometryBuilder.prevFillColor);
    this.geometryBuilder = undefined;
    return geometry;
  }

  /**
   * Creates a new <a href="#/p5.Geometry">p5.Geometry</a> that contains all
   * the shapes drawn in a provided callback function. The returned combined shape
   * can then be drawn all at once using <a href="#/p5/model">model()</a>.
   *
   * If you need to draw complex shapes every frame which don't change over time,
   * combining them with `buildGeometry()` once and then drawing that will run
   * faster than repeatedly drawing the individual pieces.
   *
   * One can also draw shapes directly between
   * <a href="#/p5/beginGeometry">beginGeometry()</a> and
   * <a href="#/p5/endGeometry">endGeometry()</a> instead of using a callback
   * function.
   * @param {Function} callback A function that draws shapes.
   * @returns {p5.Geometry} The model that was built from the callback function.
   */
  buildGeometry(callback) {
    this.beginGeometry();
    callback();
    return this.endGeometry();
  }

  //////////////////////////////////////////////
  // Shape drawing
  //////////////////////////////////////////////

  beginShape(...args) {
    super.beginShape(...args);
    // TODO remove when shape refactor is complete
    // this.shapeBuilder.beginShape(...args);
  }

  curveDetail(d) {
    if (d === undefined) {
      return this.states.curveDetail;
    } else {
      this.states.setValue("curveDetail", d);
    }
  }

  drawShape(shape) {
    const visitor = new PrimitiveToVerticesConverter({
      curveDetail: this.states.curveDetail,
    });
    shape.accept(visitor);
    this.shapeBuilder.constructFromContours(shape, visitor.contours);

    if (this.geometryBuilder) {
      this.geometryBuilder.addImmediate(
        this.shapeBuilder.geometry,
        this.shapeBuilder.shapeMode,
        { validateFaces: this._validateFaces }
      );
    } else if (this.states.fillColor || this.states.strokeColor) {
      if (this.shapeBuilder.shapeMode === POINTS) {
        this._drawPoints(
          this.shapeBuilder.geometry.vertices,
          this.buffers.point
        );
      } else {
        this._drawGeometry(this.shapeBuilder.geometry, {
          mode: this.shapeBuilder.shapeMode,
          count: this.drawShapeCount,
        });
      }
    }
    this.drawShapeCount = 1;
  }

  endShape(mode, count) {
    this.drawShapeCount = count;
    super.endShape(mode, count);
  }

  vertexProperty(...args) {
    this.currentShape.vertexProperty(...args);
  }

  normal(xorv, y, z) {
    if (xorv instanceof Vector) {
      this.states.setValue("_currentNormal", xorv);
    } else {
      this.states.setValue("_currentNormal", new Vector(xorv, y, z));
    }
    this.updateShapeVertexProperties();
  }

  model(model, count = 1) {
    if (model.vertices.length > 0) {
      if (this.geometryBuilder) {
        this.geometryBuilder.addRetained(model);
      } else {
        if (!this.geometryInHash(model.gid)) {
          model._edgesToVertices();
          this._getOrMakeCachedBuffers(model);
        }

        this._drawGeometry(model, { count });
      }
    }
  }

  //////////////////////////////////////////////
  // Rendering
  //////////////////////////////////////////////

  _drawGeometry(geometry, { mode = TRIANGLES, count = 1 } = {}) {
    for (const propName in geometry.userVertexProperties) {
      const prop = geometry.userVertexProperties[propName];
      this.buffers.user.push(
        new RenderBuffer(
          prop.getDataSize(),
          prop.getSrcName(),
          prop.getDstName(),
          prop.getName(),
          this
        )
      );
    }

    if (
      this.states.fillColor &&
      geometry.vertices.length >= 3 &&
      ![LINES, POINTS].includes(mode)
    ) {
      this._drawFills(geometry, { mode, count });
    }

    if (this.states.strokeColor && geometry.lineVertices.length >= 1) {
      this._drawStrokes(geometry, { count });
    }

    this.buffers.user = [];
  }

  _drawGeometryScaled(model, scaleX, scaleY, scaleZ) {
    let originalModelMatrix = this.states.uModelMatrix;
    this.states.setValue("uModelMatrix", this.states.uModelMatrix.clone());
    try {
      this.states.uModelMatrix.scale(scaleX, scaleY, scaleZ);

      if (this.geometryBuilder) {
        this.geometryBuilder.addRetained(model);
      } else {
        this._drawGeometry(model);
      }
    } finally {
      this.states.setValue("uModelMatrix", originalModelMatrix);
    }
  }

  _drawFills(geometry, { count, mode } = {}) {
    this._useVertexColor = geometry.vertexColors.length > 0;

    const shader =
      !this._drawingFilter && this.states.userFillShader
        ? this.states.userFillShader
        : this._getFillShader();
    shader.bindShader();
    this._setGlobalUniforms(shader);
    this._setFillUniforms(shader);
    shader.bindTextures();

    for (const buff of this.buffers.fill) {
      buff._prepareBuffer(geometry, shader);
    }
    this._prepareUserAttributes(geometry, shader);
    shader.disableRemainingAttributes();

    this._applyColorBlend(
      this.states.curFillColor,
      geometry.hasFillTransparency()
    );

    this._drawBuffers(geometry, { mode, count });

    shader.unbindShader();
  }

  _drawStrokes(geometry, { count } = {}) {
    const gl = this.GL;

    this._useLineColor = geometry.vertexStrokeColors.length > 0;

    const shader = this._getStrokeShader();
    shader.bindShader();
    this._setGlobalUniforms(shader);
    this._setStrokeUniforms(shader);
    shader.bindTextures();

    for (const buff of this.buffers.stroke) {
      buff._prepareBuffer(geometry, shader);
    }
    this._prepareUserAttributes(geometry, shader);
    shader.disableRemainingAttributes();

    this._applyColorBlend(
      this.states.curStrokeColor,
      geometry.hasStrokeTransparency()
    );

    if (count === 1) {
      gl.drawArrays(gl.TRIANGLES, 0, geometry.lineVertices.length / 3);
    } else {
      try {
        gl.drawArraysInstanced(
          gl.TRIANGLES,
          0,
          geometry.lineVertices.length / 3,
          count
        );
      } catch (e) {
        console.log(
          " p5.js says: Instancing is only supported in WebGL2 mode"
        );
      }
    }

    shader.unbindShader();
  }

  _drawPoints(vertices, vertexBuffer) {
    const gl = this.GL;
    const pointShader = this._getPointShader();
    pointShader.bindShader();
    this._setGlobalUniforms(pointShader);
    this._setPointUniforms(pointShader);
    pointShader.bindTextures();

    this._bindBuffer(
      vertexBuffer,
      gl.ARRAY_BUFFER,
      this._vToNArray(vertices),
      Float32Array,
      gl.STATIC_DRAW
    );

    pointShader.enableAttrib(pointShader.attributes.aPosition, 3);

    this._applyColorBlend(this.states.curStrokeColor);

    gl.drawArrays(gl.Points, 0, vertices.length);

    pointShader.unbindShader();
  }

  _prepareUserAttributes(geometry, shader) {
    for (const buff of this.buffers.user) {
      if (!this._pInst.constructor.disableFriendlyErrors) {
        // Check for the right data size
        const prop = geometry.userVertexProperties[buff.attr];
        if (prop) {
          const adjustedLength = prop.getSrcArray().length / prop.getDataSize();
          if (adjustedLength > geometry.vertices.length) {
            this._pInst.constructor._friendlyError(
              `One of the geometries has a custom vertex property '${prop.getName()}' with more values than vertices. This is probably caused by directly using the Geometry.vertexProperty() method.`,
              "vertexProperty()"
            );
          } else if (adjustedLength < geometry.vertices.length) {
            this._pInst.constructor._friendlyError(
              `One of the geometries has a custom vertex property '${prop.getName()}' with fewer values than vertices. This is probably caused by directly using the Geometry.vertexProperty() method.`,
              "vertexProperty()"
            );
          }
        }
      }
      buff._prepareBuffer(geometry, shader);
    }
  }

  _drawBuffers(geometry, { mode = this.GL.TRIANGLES, count }) {
    const gl = this.GL;
    const glBuffers = this.geometryBufferCache.getCached(geometry);

    if (!glBuffers) return;

    if (glBuffers.indexBuffer) {
      this._bindBuffer(glBuffers.indexBuffer, gl.ELEMENT_ARRAY_BUFFER);

      // If this model is using a Uint32Array we need to ensure the
      // OES_element_index_uint WebGL extension is enabled.
      if (
        this._pInst.webglVersion !== WEBGL2 &&
        glBuffers.indexBufferType === gl.UNSIGNED_INT
      ) {
        if (!gl.getExtension("OES_element_index_uint")) {
          throw new Error(
            "Unable to render a 3d model with > 65535 triangles. Your web browser does not support the WebGL Extension OES_element_index_uint."
          );
        }
      }

      if (count === 1) {
        gl.drawElements(
          gl.TRIANGLES,
          geometry.faces.length * 3,
          glBuffers.indexBufferType,
          0
        );
      } else {
        try {
          gl.drawElementsInstanced(
            gl.TRIANGLES,
            geometry.faces.length * 3,
            glBuffers.indexBufferType,
            0,
            count
          );
        } catch (e) {
          console.log(
            " p5.js says: Instancing is only supported in WebGL2 mode"
          );
        }
      }
    } else {
      if (count === 1) {
        gl.drawArrays(mode, 0, geometry.vertices.length);
      } else {
        try {
          gl.drawArraysInstanced(mode, 0, geometry.vertices.length, count);
        } catch (e) {
          console.log(
            " p5.js says: Instancing is only supported in WebGL2 mode"
          );
        }
      }
    }
  }

  _getOrMakeCachedBuffers(geometry) {
    return this.geometryBufferCache.ensureCached(geometry);
  }

  //////////////////////////////////////////////
  // Setting
  //////////////////////////////////////////////

  _setAttributeDefaults(pInst) {
    // See issue #3850, safer to enable AA in Safari
    const applyAA = navigator.userAgent.toLowerCase().includes("safari");
    const defaults = {
      alpha: true,
      depth: true,
      stencil: true,
      antialias: applyAA,
      premultipliedAlpha: true,
      preserveDrawingBuffer: true,
      perPixelLighting: true,
      version: 2,
    };
    if (pInst._glAttributes === null) {
      pInst._glAttributes = defaults;
    } else {
      pInst._glAttributes = Object.assign(defaults, pInst._glAttributes);
    }
    return;
  }

  _initContext() {
    if (this._pInst._glAttributes?.version !== 1) {
      // Unless WebGL1 is explicitly asked for, try to create a WebGL2 context
      this.drawingContext = this.canvas.getContext(
        "webgl2",
        this._pInst._glAttributes
      );
    }
    this.webglVersion = this.drawingContext
      ? WEBGL2
      : WEBGL;
    // If this is the main canvas, make sure the global `webglVersion` is set
    this._pInst.webglVersion = this.webglVersion;
    if (!this.drawingContext) {
      // If we were unable to create a WebGL2 context (either because it was
      // disabled via `setAttributes({ version: 1 })` or because the device
      // doesn't support it), fall back to a WebGL1 context
      this.drawingContext =
        this.canvas.getContext("webgl", this._pInst._glAttributes) ||
        this.canvas.getContext("experimental-webgl", this._pInst._glAttributes);
    }
    if (this.drawingContext === null) {
      throw new Error("Error creating webgl context");
    } else {
      const gl = this.drawingContext;
      gl.enable(gl.DEPTH_TEST);
      gl.depthFunc(gl.LEQUAL);
      gl.viewport(0, 0, gl.drawingBufferWidth, gl.drawingBufferHeight);
      // Make sure all images are loaded into the canvas premultiplied so that
      // they match the way we render colors. This will make framebuffer textures
      // be encoded the same way as textures from everything else.
      gl.pixelStorei(gl.UNPACK_PREMULTIPLY_ALPHA_WEBGL, true);
      this._viewport = this.drawingContext.getParameter(
        this.drawingContext.VIEWPORT
      );
    }
  }

  _getMaxTextureSize() {
    const gl = this.drawingContext;
    return gl.getParameter(gl.MAX_TEXTURE_SIZE);
  }

  _adjustDimensions(width, height) {
    if (!this._maxTextureSize) {
      this._maxTextureSize = this._getMaxTextureSize();
    }
    let maxTextureSize = this._maxTextureSize;

    let maxAllowedPixelDimensions = Math.floor(
      maxTextureSize / this._pixelDensity
    );
    let adjustedWidth = Math.min(width, maxAllowedPixelDimensions);
    let adjustedHeight = Math.min(height, maxAllowedPixelDimensions);

    if (adjustedWidth !== width || adjustedHeight !== height) {
      console.warn(
        "Warning: The requested width/height exceeds hardware limits. " +
          `Adjusting dimensions to width: ${adjustedWidth}, height: ${adjustedHeight}.`
      );
    }

    return { adjustedWidth, adjustedHeight };
  }

  //This is helper function to reset the context anytime the attributes
  //are changed with setAttributes()

  _resetContext(options, callback) {
    const w = this.width;
    const h = this.height;
    const defaultId = this.canvas.id;
    const isPGraphics = this._pInst instanceof Graphics;

    // Preserve existing position and styles before recreation
    const prevStyle = {
      position: this.canvas.style.position,
      top: this.canvas.style.top,
      left: this.canvas.style.left,
    };

    if (isPGraphics) {
      // Handle PGraphics: remove and recreate the canvas
      const pg = this._pInst;
      pg.canvas.parentNode.removeChild(pg.canvas);
      pg.canvas = document.createElement("canvas");
      const node = pg._pInst._userNode || document.body;
      node.appendChild(pg.canvas);
      Element.call(pg, pg.canvas, pg._pInst);
      // Restore previous width and height
      pg.width = w;
      pg.height = h;
    } else {
      // Handle main canvas: remove and recreate it
      let c = this.canvas;
      if (c) {
        c.parentNode.removeChild(c);
      }
      c = document.createElement("canvas");
      c.id = defaultId;
      // Attach the new canvas to the correct parent node
      if (this._pInst._userNode) {
        this._pInst._userNode.appendChild(c);
      } else {
        document.body.appendChild(c);
      }
      this._pInst.canvas = c;
      this.canvas = c;

      // Restore the saved position
      this.canvas.style.position = prevStyle.position;
      this.canvas.style.top = prevStyle.top;
      this.canvas.style.left = prevStyle.left;
    }

    const renderer = new RendererGL(
      this._pInst,
      w,
      h,
      !isPGraphics,
      this._pInst.canvas
    );
    this._pInst._renderer = renderer;

    renderer._applyDefaults();

    if (typeof callback === "function") {
      //setTimeout with 0 forces the task to the back of the queue, this ensures that
      //we finish switching out the renderer
      setTimeout(() => {
        callback.apply(window._renderer, options);
      }, 0);
    }
  }

  _update() {
    // reset model view and apply initial camera transform
    // (containing only look at info; no projection).
    this.states.setValue("uModelMatrix", this.states.uModelMatrix.clone());
    this.states.uModelMatrix.reset();
    this.states.setValue("uViewMatrix", this.states.uViewMatrix.clone());
    this.states.uViewMatrix.set(this.states.curCamera.cameraMatrix);

    // reset light data for new frame.

    this.states.setValue("ambientLightColors", []);
    this.states.setValue("specularColors", [1, 1, 1]);

    this.states.setValue("directionalLightDirections", []);
    this.states.setValue("directionalLightDiffuseColors", []);
    this.states.setValue("directionalLightSpecularColors", []);

    this.states.setValue("pointLightPositions", []);
    this.states.setValue("pointLightDiffuseColors", []);
    this.states.setValue("pointLightSpecularColors", []);

    this.states.setValue("spotLightPositions", []);
    this.states.setValue("spotLightDirections", []);
    this.states.setValue("spotLightDiffuseColors", []);
    this.states.setValue("spotLightSpecularColors", []);
    this.states.setValue("spotLightAngle", []);
    this.states.setValue("spotLightConc", []);

    this.states.setValue("enableLighting", false);

    //reset tint value for new frame
    this.states.setValue("tint", [255, 255, 255, 255]);

    //Clear depth every frame
    this.GL.clearStencil(0);
    this.GL.clear(this.GL.DEPTH_BUFFER_BIT | this.GL.STENCIL_BUFFER_BIT);
    if (!this._userEnabledStencil) {
      this._internalDisable.call(this.GL, this.GL.STENCIL_TEST);
    }

  }

  /**
   * [background description]
   */
  background(...args) {
    const _col = this._pInst.color(...args);
    this.clear(..._col._getRGBA());
  }

  //////////////////////////////////////////////
  // Positioning
  //////////////////////////////////////////////

  get uModelMatrix() {
    return this.states.uModelMatrix;
  }

  get uViewMatrix() {
    return this.states.uViewMatrix;
  }

  get uPMatrix() {
    return this.states.uPMatrix;
  }

  get uMVMatrix() {
    const m = this.uModelMatrix.copy();
    m.mult(this.uViewMatrix);
    return m;
  }

  /**
   * Get a matrix from world-space to screen-space
   */
  getWorldToScreenMatrix() {
    const modelMatrix = this.states.uModelMatrix;
    const viewMatrix = this.states.uViewMatrix;
    const projectionMatrix = this.states.uPMatrix;
    const projectedToScreenMatrix = new Matrix(4);
    projectedToScreenMatrix.scale(this.width, this.height, 1);
    projectedToScreenMatrix.translate([0.5, 0.5, 0.5]);
    projectedToScreenMatrix.scale(0.5, -0.5, 0.5);

    const modelViewMatrix = modelMatrix.copy().mult(viewMatrix);
    const modelViewProjectionMatrix = modelViewMatrix.mult(projectionMatrix);
    const worldToScreenMatrix = modelViewProjectionMatrix.mult(projectedToScreenMatrix);
    return worldToScreenMatrix;
  }

  //////////////////////////////////////////////
  // COLOR
  //////////////////////////////////////////////
  /**
   * Basic fill material for geometry with a given color
   * @param  {Number|Number[]|String|p5.Color} v1  gray value,
   * red or hue value (depending on the current color mode),
   * or color Array, or CSS color string
   * @param  {Number}            [v2] green or saturation value
   * @param  {Number}            [v3] blue or brightness value
   * @param  {Number}            [a]  opacity
   * @chainable
   * @example
   * <div>
   * <code>
   * function setup() {
   *   createCanvas(200, 200, WEBGL);
   * }
   *
   * function draw() {
   *   background(0);
   *   noStroke();
   *   fill(100, 100, 240);
   *   rotateX(frameCount * 0.01);
   *   rotateY(frameCount * 0.01);
   *   box(75, 75, 75);
   * }
   * </code>
   * </div>
   *
   * @alt
   * black canvas with purple cube spinning
   */
  fill(...args) {
    super.fill(...args);
    //see material.js for more info on color blending in webgl
    // const color = fn.color.apply(this._pInst, arguments);
    const color = this.states.fillColor;
    this.states.setValue("curFillColor", color._array);
    this.states.setValue("drawMode", FILL);
    this.states.setValue("_useNormalMaterial", false);
    this.states.setValue("_tex", null);
  }

  /**
   * Basic stroke material for geometry with a given color
   * @param  {Number|Number[]|String|p5.Color} v1  gray value,
   * red or hue value (depending on the current color mode),
   * or color Array, or CSS color string
   * @param  {Number}            [v2] green or saturation value
   * @param  {Number}            [v3] blue or brightness value
   * @param  {Number}            [a]  opacity
   * @example
   * <div>
   * <code>
   * function setup() {
   *   createCanvas(200, 200, WEBGL);
   * }
   *
   * function draw() {
   *   background(0);
   *   stroke(240, 150, 150);
   *   fill(100, 100, 240);
   *   rotateX(frameCount * 0.01);
   *   rotateY(frameCount * 0.01);
   *   box(75, 75, 75);
   * }
   * </code>
   * </div>
   *
   * @alt
   * black canvas with purple cube with pink outline spinning
   */
  stroke(...args) {
    super.stroke(...args);
    // const color = fn.color.apply(this._pInst, arguments);
    this.states.setValue("curStrokeColor", this.states.strokeColor._array);
  }

  getCommonVertexProperties() {
    return {
      ...super.getCommonVertexProperties(),
      stroke: this.states.strokeColor,
      fill: this.states.fillColor,
      normal: this.states._currentNormal,
    };
  }

  getSupportedIndividualVertexProperties() {
    return {
      textureCoordinates: true,
    };
  }

  strokeCap(cap) {
    this.curStrokeCap = cap;
  }

  strokeJoin(join) {
    this.curStrokeJoin = join;
  }
  getFilterLayer() {
    if (!this.filterLayer) {
      this.filterLayer = new Framebuffer(this);
    }
    return this.filterLayer;
  }
  getFilterLayerTemp() {
    if (!this.filterLayerTemp) {
      this.filterLayerTemp = new Framebuffer(this);
    }
    return this.filterLayerTemp;
  }
  matchSize(fboToMatch, target) {
    if (
      fboToMatch.width !== target.width ||
      fboToMatch.height !== target.height
    ) {
      fboToMatch.resize(target.width, target.height);
    }

    if (fboToMatch.pixelDensity() !== target.pixelDensity()) {
      fboToMatch.pixelDensity(target.pixelDensity());
    }
  }
  filter(...args) {
    let fbo = this.getFilterLayer();

    // use internal shader for filter constants BLUR, INVERT, etc
    let filterParameter = undefined;
    let operation = undefined;
    if (typeof args[0] === "string") {
      operation = args[0];
      let useDefaultParam =
        operation in filterParamDefaults && args[1] === undefined;
      filterParameter = useDefaultParam
        ? filterParamDefaults[operation]
        : args[1];

      // Create and store shader for constants once on initial filter call.
      // Need to store multiple in case user calls different filters,
      // eg. filter(BLUR) then filter(GRAY)
      if (!(operation in this.defaultFilterShaders)) {
        this.defaultFilterShaders[operation] = new Shader(
          fbo.renderer,
          filterShaderVert,
          filterShaderFrags[operation]
        );
      }
      this.states.setValue(
        "filterShader",
        this.defaultFilterShaders[operation]
      );
    }
    // use custom user-supplied shader
    else {
      this.states.setValue("filterShader", args[0]);
    }

    // Setting the target to the framebuffer when applying a filter to a framebuffer.

    const target = this.activeFramebuffer() || this;

    // Resize the framebuffer 'fbo' and adjust its pixel density if it doesn't match the target.
    this.matchSize(fbo, target);

    fbo.draw(() => this.clear()); // prevent undesirable feedback effects accumulating secretly.

    let texelSize = [
      1 / (target.width * target.pixelDensity()),
      1 / (target.height * target.pixelDensity()),
    ];

    // apply blur shader with multiple passes.
    if (operation === BLUR) {
      // Treating 'tmp' as a framebuffer.
      const tmp = this.getFilterLayerTemp();
      // Resize the framebuffer 'tmp' and adjust its pixel density if it doesn't match the target.
      this.matchSize(tmp, target);
      // setup
      this.push();
      this.states.setValue("strokeColor", null);
      this.blendMode(BLEND);

      // draw main to temp buffer
      this.shader(this.states.filterShader);
      this.states.filterShader.setUniform("texelSize", texelSize);
      this.states.filterShader.setUniform("canvasSize", [
        target.width,
        target.height,
      ]);
      this.states.filterShader.setUniform(
        "radius",
        Math.max(1, filterParameter)
      );

      // Horiz pass: draw `target` to `tmp`
      tmp.draw(() => {
        this.states.filterShader.setUniform("direction", [1, 0]);
        this.states.filterShader.setUniform("tex0", target);
        this.clear();
        this.shader(this.states.filterShader);
        this.noLights();
        this.plane(target.width, target.height);
      });

      // Vert pass: draw `tmp` to `fbo`
      fbo.draw(() => {
        this.states.filterShader.setUniform("direction", [0, 1]);
        this.states.filterShader.setUniform("tex0", tmp);
        this.clear();
        this.shader(this.states.filterShader);
        this.noLights();
        this.plane(target.width, target.height);
      });

      this.pop();
    }
    // every other non-blur shader uses single pass
    else {
      fbo.draw(() => {
        this.states.setValue("strokeColor", null);
        this.blendMode(BLEND);
        this.shader(this.states.filterShader);
        this.states.filterShader.setUniform("tex0", target);
        this.states.filterShader.setUniform("texelSize", texelSize);
        this.states.filterShader.setUniform("canvasSize", [
          target.width,
          target.height,
        ]);
        // filterParameter uniform only used for POSTERIZE, and THRESHOLD
        // but shouldn't hurt to always set
        this.states.filterShader.setUniform("filterParameter", filterParameter);
        this.noLights();
        this.plane(target.width, target.height);
      });
    }
    // draw fbo contents onto main renderer.
    this.push();
    this.states.setValue("strokeColor", null);
    this.clear();
    this.push();
    this.states.setValue("imageMode", CORNER);
    this.blendMode(BLEND);
    target.filterCamera._resize();
    this.setCamera(target.filterCamera);
    this.resetMatrix();
    this._drawingFilter = true;
    this.image(
      fbo,
      0,
      0,
      this.width,
      this.height,
      -target.width / 2,
      -target.height / 2,
      target.width,
      target.height
    );
    this._drawingFilter = false;
    this.clearDepth();
    this.pop();
    this.pop();
  }

  // Pass this off to the host instance so that we can treat a renderer and a
  // framebuffer the same in filter()

  pixelDensity(newDensity) {
    if (newDensity) {
      return this._pInst.pixelDensity(newDensity);
    }
    return this._pInst.pixelDensity();
  }

  blendMode(mode) {
    if (
      mode === DARKEST ||
      mode === LIGHTEST ||
      mode === ADD ||
      mode === BLEND ||
      mode === SUBTRACT ||
      mode === SCREEN ||
      mode === EXCLUSION ||
      mode === REPLACE ||
      mode === MULTIPLY ||
      mode === REMOVE
    )
      this.states.setValue("curBlendMode", mode);
    else if (
      mode === BURN ||
      mode === OVERLAY ||
      mode === HARD_LIGHT ||
      mode === SOFT_LIGHT ||
      mode === DODGE
    ) {
      console.warn(
        "BURN, OVERLAY, HARD_LIGHT, SOFT_LIGHT, and DODGE only work for blendMode in 2D mode."
      );
    }
  }

  erase(opacityFill, opacityStroke) {
    if (!this._isErasing) {
      this.preEraseBlend = this.states.curBlendMode;
      this._isErasing = true;
      this.blendMode(REMOVE);
      this._cachedFillStyle = this.states.curFillColor.slice();
      this.states.setValue("curFillColor", [1, 1, 1, opacityFill / 255]);
      this._cachedStrokeStyle = this.states.curStrokeColor.slice();
      this.states.setValue("curStrokeColor", [1, 1, 1, opacityStroke / 255]);
    }
  }

  noErase() {
    if (this._isErasing) {
      // Restore colors
      this.states.setValue("curFillColor", this._cachedFillStyle.slice());
      this.states.setValue("curStrokeColor", this._cachedStrokeStyle.slice());
      // Restore blend mode
      this.states.setValue("curBlendMode", this.preEraseBlend);
      this.blendMode(this.preEraseBlend);
      // Ensure that _applyBlendMode() sets preEraseBlend back to the original blend mode
      this._isErasing = false;
      this._applyBlendMode();
    }
  }

  drawTarget() {
    return this.activeFramebuffers[this.activeFramebuffers.length - 1] || this;
  }

  beginClip(options = {}) {
    super.beginClip(options);

    this.drawTarget()._isClipApplied = true;

    const gl = this.GL;
    gl.clearStencil(0);
    gl.clear(gl.STENCIL_BUFFER_BIT);
    this._internalEnable.call(gl, gl.STENCIL_TEST);
    this._stencilTestOn = true;
    gl.stencilFunc(
      gl.ALWAYS, // the test
      1, // reference value
      0xff // mask
    );
    gl.stencilOp(
      gl.KEEP, // what to do if the stencil test fails
      gl.KEEP, // what to do if the depth test fails
      gl.REPLACE // what to do if both tests pass
    );
    gl.disable(gl.DEPTH_TEST);

    this.push();
    this.resetShader();
    if (this.states.fillColor) this.fill(0, 0);
    if (this.states.strokeColor) this.stroke(0, 0);
  }

  endClip() {
    this.pop();

    const gl = this.GL;
    gl.stencilOp(
      gl.KEEP, // what to do if the stencil test fails
      gl.KEEP, // what to do if the depth test fails
      gl.KEEP // what to do if both tests pass
    );
    gl.stencilFunc(
      this._clipInvert ? gl.EQUAL : gl.NOTEQUAL, // the test
      0, // reference value
      0xff // mask
    );
    gl.enable(gl.DEPTH_TEST);

    // Mark the depth at which the clip has been applied so that we can clear it
    // when we pop past this depth
    this._clipDepths.push(this._pushPopDepth);

    super.endClip();
  }

  _clearClip() {
    this.GL.clearStencil(1);
    this.GL.clear(this.GL.STENCIL_BUFFER_BIT);
    if (this._clipDepths.length > 0) {
      this._clipDepths.pop();
    }
    this.drawTarget()._isClipApplied = false;
  }

  // x,y are canvas-relative (pre-scaled by _pixelDensity)
  _getPixel(x, y) {
    const gl = this.GL;
    return readPixelWebGL(
      gl,
      null,
      x,
      y,
      gl.RGBA,
      gl.UNSIGNED_BYTE,
      this._pInst.height * this._pInst.pixelDensity()
    );
  }

  /**
   * Loads the pixels data for this canvas into the pixels[] attribute.
   * Note that updatePixels() and set() do not work.
   * Any pixel manipulation must be done directly to the pixels[] array.
   *
   * @private
   */
  loadPixels() {
    //@todo_FES
    if (this._pInst._glAttributes.preserveDrawingBuffer !== true) {
      console.log(
        "loadPixels only works in WebGL when preserveDrawingBuffer " +
          "is true."
      );
      return;
    }

    const pd = this._pixelDensity;
    const gl = this.GL;

    this.pixels = readPixelsWebGL(
      this.pixels,
      gl,
      null,
      0,
      0,
      this.width * pd,
      this.height * pd,
      gl.RGBA,
      gl.UNSIGNED_BYTE,
      this.height * pd
    );
  }

  updatePixels() {
    const fbo = this._getTempFramebuffer();
    fbo.pixels = this.pixels;
    fbo.updatePixels();
    this.push();
    this.resetMatrix();
    this.clear();
    this.states.setValue("imageMode", CORNER);
    this.image(
      fbo,
      0,
      0,
      fbo.width,
      fbo.height,
      -fbo.width / 2,
      -fbo.height / 2,
      fbo.width,
      fbo.height
    );
    this.pop();
    this.GL.clearDepth(1);
    this.GL.clear(this.GL.DEPTH_BUFFER_BIT);
  }

  /**
   * @private
   * @returns {p5.Framebuffer} A p5.Framebuffer set to match the size and settings
   * of the renderer's canvas. It will be created if it does not yet exist, and
   * reused if it does.
   */
  _getTempFramebuffer() {
    if (!this._tempFramebuffer) {
      this._tempFramebuffer = new Framebuffer(this, {
        format: UNSIGNED_BYTE,
        useDepth: this._pInst._glAttributes.depth,
        depthFormat: UNSIGNED_INT,
        antialias: this._pInst._glAttributes.antialias,
      });
    }
    return this._tempFramebuffer;
  }

  //////////////////////////////////////////////
  // HASH | for geometry
  //////////////////////////////////////////////

  geometryInHash(gid) {
    return this.geometryBufferCache.isCached(gid);
  }

  viewport(w, h) {
    this._viewport = [0, 0, w, h];
    this.GL.viewport(0, 0, w, h);
  }

  /**
   * [resize description]
   * @private
   * @param  {Number} w [description]
   * @param  {Number} h [description]
   */
  resize(w, h) {
    super.resize(w, h);

    // save canvas properties
    const props = {};
    for (const key in this.drawingContext) {
      const val = this.drawingContext[key];
      if (typeof val !== "object" && typeof val !== "function") {
        props[key] = val;
      }
    }

    const dimensions = this._adjustDimensions(w, h);
    w = dimensions.adjustedWidth;
    h = dimensions.adjustedHeight;

    this.width = w;
    this.height = h;

    this.canvas.width = w * this._pixelDensity;
    this.canvas.height = h * this._pixelDensity;
    this.canvas.style.width = `${w}px`;
    this.canvas.style.height = `${h}px`;
    this._origViewport = {
      width: this.GL.drawingBufferWidth,
      height: this.GL.drawingBufferHeight,
    };
    this.viewport(this._origViewport.width, this._origViewport.height);

    this.states.curCamera._resize();

    //resize pixels buffer
    if (typeof this.pixels !== "undefined") {
      this.pixels = new Uint8Array(
        this.GL.drawingBufferWidth * this.GL.drawingBufferHeight * 4
      );
    }

    for (const framebuffer of this.framebuffers) {
      // Notify framebuffers of the resize so that any auto-sized framebuffers
      // can also update their size
      framebuffer._canvasSizeChanged();
    }

    // reset canvas properties
    for (const savedKey in props) {
      try {
        this.drawingContext[savedKey] = props[savedKey];
      } catch (err) {
        // ignore read-only property errors
      }
    }
  }

  /**
   * clears color and depth buffers
   * with r,g,b,a
   * @private
   * @param {Number} r normalized red val.
   * @param {Number} g normalized green val.
   * @param {Number} b normalized blue val.
   * @param {Number} a normalized alpha val.
   */
  clear(...args) {
    const _r = args[0] || 0;
    const _g = args[1] || 0;
    const _b = args[2] || 0;
    let _a = args[3] || 0;

    const activeFramebuffer = this.activeFramebuffer();
    if (
      activeFramebuffer &&
      activeFramebuffer.format === UNSIGNED_BYTE &&
      !activeFramebuffer.antialias &&
      _a === 0
    ) {
      // Drivers on Intel Macs check for 0,0,0,0 exactly when drawing to a
      // framebuffer and ignore the command if it's the only drawing command to
      // the framebuffer. To work around it, we can set the alpha to a value so
      // low that it still rounds down to 0, but that circumvents the buggy
      // check in the driver.
      _a = 1e-10;
    }

    this.GL.clearColor(_r * _a, _g * _a, _b * _a, _a);
    this.GL.clearDepth(1);
    this.GL.clear(this.GL.COLOR_BUFFER_BIT | this.GL.DEPTH_BUFFER_BIT);
  }

  /**
   * Resets all depth information so that nothing previously drawn will
   * occlude anything subsequently drawn.
   */
  clearDepth(depth = 1) {
    this.GL.clearDepth(depth);
    this.GL.clear(this.GL.DEPTH_BUFFER_BIT);
  }

  applyMatrix(a, b, c, d, e, f) {
    this.states.setValue("uModelMatrix", this.states.uModelMatrix.clone());
    if (arguments.length === 16) {
      // this.states.uModelMatrix.apply(arguments);
      Matrix.prototype.apply.apply(this.states.uModelMatrix, arguments);
    } else {
      this.states.uModelMatrix.apply([
        a,
        b,
        0,
        0,
        c,
        d,
        0,
        0,
        0,
        0,
        1,
        0,
        e,
        f,
        0,
        1,
      ]);
    }
  }

  /**
   * [translate description]
   * @private
   * @param  {Number} x [description]
   * @param  {Number} y [description]
   * @param  {Number} z [description]
   * @chainable
   * @todo implement handle for components or vector as args
   */
  translate(x, y, z) {
    if (x instanceof Vector) {
      z = x.z;
      y = x.y;
      x = x.x;
    }
    this.states.setValue("uModelMatrix", this.states.uModelMatrix.clone());
    this.states.uModelMatrix.translate([x, y, z]);
    return this;
  }

  /**
   * Scales the Model View Matrix by a vector
   * @private
   * @param  {Number | p5.Vector | Array} x [description]
   * @param  {Number} [y] y-axis scalar
   * @param  {Number} [z] z-axis scalar
   * @chainable
   */
  scale(x, y, z) {
    this.states.setValue("uModelMatrix", this.states.uModelMatrix.clone());
    this.states.uModelMatrix.scale(x, y, z);
    return this;
  }

  rotate(rad, axis) {
    if (typeof axis === "undefined") {
      return this.rotateZ(rad);
    }
    this.states.setValue("uModelMatrix", this.states.uModelMatrix.clone());
    Matrix.prototype.rotate4x4.apply(this.states.uModelMatrix, arguments);
    return this;
  }

  rotateX(rad) {
    this.rotate(rad, 1, 0, 0);
    return this;
  }

  rotateY(rad) {
    this.rotate(rad, 0, 1, 0);
    return this;
  }

  rotateZ(rad) {
    this.rotate(rad, 0, 0, 1);
    return this;
  }

  pop(...args) {
    if (
      this._clipDepths.length > 0 &&
      this._pushPopDepth === this._clipDepths[this._clipDepths.length - 1]
    ) {
      this._clearClip();
      if (!this._userEnabledStencil) {
        this._internalDisable.call(this.GL, this.GL.STENCIL_TEST);
      }

    // Reset saved state
    // this._userEnabledStencil = this._savedStencilTestState;
    }
    super.pop(...args);
    this._applyStencilTestIfClipping();
  }
  _applyStencilTestIfClipping() {
    const drawTarget = this.drawTarget();
    if (drawTarget._isClipApplied !== this._stencilTestOn) {
      if (drawTarget._isClipApplied) {
        this._internalEnable.call(this.GL, this.GL.STENCIL_TEST);
        this._stencilTestOn = true;
      } else {
        if (!this._userEnabledStencil) {
          this._internalDisable.call(this.GL, this.GL.STENCIL_TEST);
        }
        this._stencilTestOn = false;
      }
    }
  }
  resetMatrix() {
    this.states.setValue("uModelMatrix", this.states.uModelMatrix.clone());
    this.states.uModelMatrix.reset();
    this.states.setValue("uViewMatrix", this.states.uViewMatrix.clone());
    this.states.uViewMatrix.set(this.states.curCamera.cameraMatrix);
    return this;
  }

  //////////////////////////////////////////////
  // SHADER
  //////////////////////////////////////////////

  /*
   * shaders are created and cached on a per-renderer basis,
   * on the grounds that each renderer will have its own gl context
   * and the shader must be valid in that context.
   */

  _getStrokeShader() {
    // select the stroke shader to use
    const stroke = this.states.userStrokeShader;
    if (stroke) {
      return stroke;
    }
    return this._getLineShader();
  }

  _getSphereMapping(img) {
    if (!this.sphereMapping) {
      this.sphereMapping = this._pInst.createFilterShader(sphereMapping);
    }
    this.scratchMat3.inverseTranspose4x4(this.states.uViewMatrix);
    this.scratchMat3.invert(this.scratchMat3); // uNMMatrix is 3x3
    this.sphereMapping.setUniform("uFovY", this.states.curCamera.cameraFOV);
    this.sphereMapping.setUniform("uAspect", this.states.curCamera.aspectRatio);
    this.sphereMapping.setUniform("uNewNormalMatrix", this.scratchMat3.mat3);
    this.sphereMapping.setUniform("uEnvMap", img);
    return this.sphereMapping;
  }

  /*
   * This method will handle both image shaders and
   * fill shaders, returning the appropriate shader
   * depending on the current context (image or shape).
   */
  _getFillShader() {
    // If drawing an image, check for user-defined image shader and filters
    if (this._drawingImage) {
      // Use user-defined image shader if available and no filter is applied
      if (this.states.userImageShader && !this._drawingFilter) {
        return this.states.userImageShader;
      } else {
        return this._getLightShader(); // Fallback to light shader
      }
    }
    // If user has defined a fill shader, return that
    else if (this.states.userFillShader) {
      return this.states.userFillShader;
    }
    // Use normal shader if normal material is active
    else if (this.states._useNormalMaterial) {
      return this._getNormalShader();
    }
    // Use light shader if lighting or textures are enabled
    else if (this.states.enableLighting || this.states._tex) {
      return this._getLightShader();
    }
    // Default to color shader if no other conditions are met
    return this._getColorShader();
  }

  _getPointShader() {
    // select the point shader to use
    const point = this.states.userPointShader;
    if (!point || !point.isPointShader()) {
      return this._getPointShader();
    }
    return point;
  }

  baseMaterialShader() {
    if (!this._pInst._glAttributes.perPixelLighting) {
      throw new Error(
        "The material shader does not support hooks without perPixelLighting. Try turning it back on."
      );
    }
    return this._getLightShader();
  }

  _getLightShader() {
    if (!this._defaultLightShader) {
      if (this._pInst._glAttributes.perPixelLighting) {
        this._defaultLightShader = new Shader(
          this,
          this._webGL2CompatibilityPrefix("vert", "highp") +
            defaultShaders.phongVert,
          this._webGL2CompatibilityPrefix("frag", "highp") +
            defaultShaders.phongFrag,
          {
            vertex: {
              "void beforeVertex": "() {}",
              "Vertex getObjectInputs": "(Vertex inputs) { return inputs; }",
              "Vertex getWorldInputs": "(Vertex inputs) { return inputs; }",
              "Vertex getCameraInputs": "(Vertex inputs) { return inputs; }",
              "void afterVertex": "() {}",
            },
            fragment: {
              "void beforeFragment": "() {}",
              "Inputs getPixelInputs": "(Inputs inputs) { return inputs; }",
              "vec4 combineColors": `(ColorComponents components) {
                vec4 color = vec4(0.);
                color.rgb += components.diffuse * components.baseColor;
                color.rgb += components.ambient * components.ambientColor;
                color.rgb += components.specular * components.specularColor;
                color.rgb += components.emissive;
                color.a = components.opacity;
                return color;
              }`,
              "vec4 getFinalColor": "(vec4 color) { return color; }",
              "void afterFragment": "() {}",
            },
          }
        );
      } else {
        this._defaultLightShader = new Shader(
          this,
          this._webGL2CompatibilityPrefix("vert", "highp") +
            defaultShaders.lightVert,
          this._webGL2CompatibilityPrefix("frag", "highp") +
            defaultShaders.lightTextureFrag
        );
      }
    }

    return this._defaultLightShader;
  }

  baseNormalShader() {
    return this._getNormalShader();
  }

  _getNormalShader() {
    if (!this._defaultNormalShader) {
      this._defaultNormalShader = new Shader(
        this,
        this._webGL2CompatibilityPrefix("vert", "mediump") +
          defaultShaders.normalVert,
        this._webGL2CompatibilityPrefix("frag", "mediump") +
          defaultShaders.normalFrag,
        {
          vertex: {
            "void beforeVertex": "() {}",
            "Vertex getObjectInputs": "(Vertex inputs) { return inputs; }",
            "Vertex getWorldInputs": "(Vertex inputs) { return inputs; }",
            "Vertex getCameraInputs": "(Vertex inputs) { return inputs; }",
            "void afterVertex": "() {}",
          },
          fragment: {
            "void beforeFragment": "() {}",
            "vec4 getFinalColor": "(vec4 color) { return color; }",
            "void afterFragment": "() {}",
          },
        }
      );
    }

    return this._defaultNormalShader;
  }

  baseColorShader() {
    return this._getColorShader();
  }

  _getColorShader() {
    if (!this._defaultColorShader) {
      this._defaultColorShader = new Shader(
        this,
        this._webGL2CompatibilityPrefix("vert", "mediump") +
          defaultShaders.normalVert,
        this._webGL2CompatibilityPrefix("frag", "mediump") +
          defaultShaders.basicFrag,
        {
          vertex: {
            "void beforeVertex": "() {}",
            "Vertex getObjectInputs": "(Vertex inputs) { return inputs; }",
            "Vertex getWorldInputs": "(Vertex inputs) { return inputs; }",
            "Vertex getCameraInputs": "(Vertex inputs) { return inputs; }",
            "void afterVertex": "() {}",
          },
          fragment: {
            "void beforeFragment": "() {}",
            "vec4 getFinalColor": "(vec4 color) { return color; }",
            "void afterFragment": "() {}",
          },
        }
      );
    }

    return this._defaultColorShader;
  }

  /**
   * TODO(dave): un-private this when there is a way to actually override the
   * shader used for points
   *
   * Get the shader used when drawing points with <a href="#/p5/point">`point()`</a>.
   *
   * You can call <a href="#/p5.Shader/modify">`pointShader().modify()`</a>
   * and change any of the following hooks:
   * - `void beforeVertex`: Called at the start of the vertex shader.
   * - `vec3 getLocalPosition`: Update the position of vertices before transforms are applied. It takes in `vec3 position` and must return a modified version.
   * - `vec3 getWorldPosition`: Update the position of vertices after transforms are applied. It takes in `vec3 position` and pust return a modified version.
   * - `float getPointSize`: Update the size of the point. It takes in `float size` and must return a modified version.
   * - `void afterVertex`: Called at the end of the vertex shader.
   * - `void beforeFragment`: Called at the start of the fragment shader.
   * - `bool shouldDiscard`: Points are drawn inside a square, with the corners discarded in the fragment shader to create a circle. Use this to change this logic. It takes in a `bool willDiscard` and must return a modified version.
   * - `vec4 getFinalColor`: Update the final color after mixing. It takes in a `vec4 color` and must return a modified version.
   * - `void afterFragment`: Called at the end of the fragment shader.
   *
   * Call `pointShader().inspectHooks()` to see all the possible hooks and
   * their default implementations.
   *
   * @returns {p5.Shader} The `point()` shader
   * @private()
   */
  pointShader() {
    return this._getPointShader();
  }

  _getPointShader() {
    if (!this._defaultPointShader) {
      this._defaultPointShader = new Shader(
        this,
        this._webGL2CompatibilityPrefix("vert", "mediump") +
          defaultShaders.pointVert,
        this._webGL2CompatibilityPrefix("frag", "mediump") +
          defaultShaders.pointFrag,
        {
          vertex: {
            "void beforeVertex": "() {}",
            "vec3 getLocalPosition": "(vec3 position) { return position; }",
            "vec3 getWorldPosition": "(vec3 position) { return position; }",
            "float getPointSize": "(float size) { return size; }",
            "void afterVertex": "() {}",
          },
          fragment: {
            "void beforeFragment": "() {}",
            "vec4 getFinalColor": "(vec4 color) { return color; }",
            "bool shouldDiscard": "(bool outside) { return outside; }",
            "void afterFragment": "() {}",
          },
        }
      );
    }
    return this._defaultPointShader;
  }

  baseStrokeShader() {
    return this._getLineShader();
  }

  _getLineShader() {
    if (!this._defaultLineShader) {
      this._defaultLineShader = new Shader(
        this,
        this._webGL2CompatibilityPrefix("vert", "mediump") +
          defaultShaders.lineVert,
        this._webGL2CompatibilityPrefix("frag", "mediump") +
          defaultShaders.lineFrag,
        {
          vertex: {
            "void beforeVertex": "() {}",
            "StrokeVertex getObjectInputs":
              "(StrokeVertex inputs) { return inputs; }",
            "StrokeVertex getWorldInputs":
              "(StrokeVertex inputs) { return inputs; }",
            "StrokeVertex getCameraInputs":
              "(StrokeVertex inputs) { return inputs; }",
            "void afterVertex": "() {}",
          },
          fragment: {
            "void beforeFragment": "() {}",
            "Inputs getPixelInputs": "(Inputs inputs) { return inputs; }",
            "vec4 getFinalColor": "(vec4 color) { return color; }",
            "bool shouldDiscard": "(bool outside) { return outside; }",
            "void afterFragment": "() {}",
          },
        }
      );
    }

    return this._defaultLineShader;
  }

  _getFontShader() {
    if (!this._defaultFontShader) {
      if (this.webglVersion === WEBGL) {
        this.GL.getExtension("OES_standard_derivatives");
      }
      this._defaultFontShader = new Shader(
        this,
        this._webGL2CompatibilityPrefix("vert", "highp") +
          defaultShaders.fontVert,
        this._webGL2CompatibilityPrefix("frag", "highp") +
          defaultShaders.fontFrag
      );
    }
    return this._defaultFontShader;
  }

  baseFilterShader() {
    if (!this._baseFilterShader) {
      this._baseFilterShader = new Shader(
        this,
        this._webGL2CompatibilityPrefix("vert", "highp") +
          defaultShaders.filterBaseVert,
        this._webGL2CompatibilityPrefix("frag", "highp") +
          defaultShaders.filterBaseFrag,
        {
            vertex: {},
            fragment: {
              "vec4 getColor": `(FilterInputs inputs, in sampler2D canvasContent) {
                return getTexture(canvasContent, inputs.texCoord);
              }`,
            },
          }
      );
    }
    return this._baseFilterShader;
  }

  _webGL2CompatibilityPrefix(shaderType, floatPrecision) {
    let code = "";
    if (this.webglVersion === WEBGL2) {
      code += "#version 300 es\n#define WEBGL2\n";
    }
    if (shaderType === "vert") {
      code += "#define VERTEX_SHADER\n";
    } else if (shaderType === "frag") {
      code += "#define FRAGMENT_SHADER\n";
    }
    if (floatPrecision) {
      code += `precision ${floatPrecision} float;\n`;
    }
    return code;
  }

  /**
   * @private
   * Note: DO NOT CALL THIS while in the middle of binding another texture,
   * since it will change the texture binding in order to allocate the empty
   * texture! Grab its value beforehand!
   */
  _getEmptyTexture() {
    if (!this._emptyTexture) {
      // a plain white texture RGBA, full alpha, single pixel.
      const im = new Image(1, 1);
      im.set(0, 0, 255);
      this._emptyTexture = new Texture(this, im);
    }
    return this._emptyTexture;
  }

  getTexture(input) {
    let src = input;
    if (src instanceof Framebuffer) {
      src = src.color;
    }

    const texture = this.textures.get(src);
    if (texture) {
      return texture;
    }

    const tex = new Texture(this, src);
    this.textures.set(src, tex);
    return tex;
  }
  /*
   *  used in imageLight,
   *  To create a blurry image from the input non blurry img, if it doesn't already exist
   *  Add it to the diffusedTexture map,
   *  Returns the blurry image
   *  maps a Image used by imageLight() to a p5.Framebuffer
   */
  getDiffusedTexture(input) {
    // if one already exists for a given input image
    if (this.diffusedTextures.get(input) != null) {
      return this.diffusedTextures.get(input);
    }
    // if not, only then create one
    let newFramebuffer;
    // hardcoded to 200px, because it's going to be blurry and smooth
    let smallWidth = 200;
    let width = smallWidth;
    let height = Math.floor(smallWidth * (input.height / input.width));
    newFramebuffer = new Framebuffer(this, {
      width,
      height,
      density: 1,
    });
    // create framebuffer is like making a new sketch, all functions on main
    // sketch it would be available on framebuffer
    if (!this.diffusedShader) {
      this.diffusedShader = this._pInst.createShader(
        defaultShaders.imageLightVert,
        defaultShaders.imageLightDiffusedFrag
      );
    }
    newFramebuffer.draw(() => {
      this.shader(this.diffusedShader);
      this.diffusedShader.setUniform("environmentMap", input);
      this.states.setValue("strokeColor", null);
      this.noLights();
      this.plane(width, height);
    });
    this.diffusedTextures.set(input, newFramebuffer);
    return newFramebuffer;
  }

  /*
   *  used in imageLight,
   *  To create a texture from the input non blurry image, if it doesn't already exist
   *  Creating 8 different levels of textures according to different
   *  sizes and atoring them in `levels` array
   *  Creating a new Mipmap texture with that `levels` array
   *  Storing the texture for input image in map called `specularTextures`
   *  maps the input Image to a p5.MipmapTexture
   */
  getSpecularTexture(input) {
    // check if already exits (there are tex of diff resolution so which one to check)
    // currently doing the whole array
    if (this.specularTextures.get(input) != null) {
      return this.specularTextures.get(input);
    }
    // Hardcoded size
    const size = 512;
    let tex;
    const levels = [];
    const framebuffer = new Framebuffer(this, {
      width: size,
      height: size,
      density: 1,
    });
    let count = Math.log(size) / Math.log(2);
    if (!this.specularShader) {
      this.specularShader = this._pInst.createShader(
        defaultShaders.imageLightVert,
        defaultShaders.imageLightSpecularFrag
      );
    }
    // currently only 8 levels
    // This loop calculates 8 framebuffers of varying size of canvas
    // and corresponding different roughness levels.
    // Roughness increases with the decrease in canvas size,
    // because rougher surfaces have less detailed/more blurry reflections.
    for (let w = size; w >= 1; w /= 2) {
      framebuffer.resize(w, w);
      let currCount = Math.log(w) / Math.log(2);
      let roughness = 1 - currCount / count;
      framebuffer.draw(() => {
        this.shader(this.specularShader);
        this.clear();
        this.specularShader.setUniform("environmentMap", input);
        this.specularShader.setUniform("roughness", roughness);
        this.states.setValue("strokeColor", null);
        this.noLights();
        this.plane(w, w);
      });
      levels.push(framebuffer.get().drawingContext.getImageData(0, 0, w, w));
    }
    // Free the Framebuffer
    framebuffer.remove();
    tex = new MipmapTexture(this, levels, {});
    this.specularTextures.set(input, tex);
    return tex;
  }

  /**
   * @private
   * @returns {p5.Framebuffer|null} The currently active framebuffer, or null if
   * the main canvas is the current draw target.
   */
  activeFramebuffer() {
    return this.activeFramebuffers[this.activeFramebuffers.length - 1] || null;
  }

  createFramebuffer(options) {
    return new Framebuffer(this, options);
  }

  _setGlobalUniforms(shader) {
    const modelMatrix = this.states.uModelMatrix;
    const viewMatrix = this.states.uViewMatrix;
    const projectionMatrix = this.states.uPMatrix;
    const modelViewMatrix = modelMatrix.copy().mult(viewMatrix);

    shader.setUniform(
      "uPerspective",
      this.states.curCamera.useLinePerspective ? 1 : 0
    );
    shader.setUniform("uViewMatrix", viewMatrix.mat4);
    shader.setUniform("uProjectionMatrix", projectionMatrix.mat4);
    shader.setUniform("uModelMatrix", modelMatrix.mat4);
    shader.setUniform("uModelViewMatrix", modelViewMatrix.mat4);
    if (shader.uniforms.uModelViewProjectionMatrix) {
      const modelViewProjectionMatrix = modelViewMatrix.copy();
      modelViewProjectionMatrix.mult(projectionMatrix);
      shader.setUniform(
        "uModelViewProjectionMatrix",
        modelViewProjectionMatrix.mat4
      );
    }
    if (shader.uniforms.uNormalMatrix) {
      this.scratchMat3.inverseTranspose4x4(modelViewMatrix);
      shader.setUniform("uNormalMatrix", this.scratchMat3.mat3);
    }
    if (shader.uniforms.uModelNormalMatrix) {
      this.scratchMat3.inverseTranspose4x4(this.states.uModelMatrix);
      shader.setUniform("uModelNormalMatrix", this.scratchMat3.mat3);
    }
    if (shader.uniforms.uCameraNormalMatrix) {
      this.scratchMat3.inverseTranspose4x4(this.states.uViewMatrix);
      shader.setUniform("uCameraNormalMatrix", this.scratchMat3.mat3);
    }
    if (shader.uniforms.uCameraRotation) {
      this.scratchMat3.inverseTranspose4x4(this.states.uViewMatrix);
      shader.setUniform("uCameraRotation", this.scratchMat3.mat3);
    }
    shader.setUniform("uViewport", this._viewport);
  }

  _setStrokeUniforms(strokeShader) {
    // set the uniform values
    strokeShader.setUniform("uSimpleLines", this._simpleLines);
    strokeShader.setUniform("uUseLineColor", this._useLineColor);
    strokeShader.setUniform("uMaterialColor", this.states.curStrokeColor);
    strokeShader.setUniform("uStrokeWeight", this.states.strokeWeight);
    strokeShader.setUniform("uStrokeCap", STROKE_CAP_ENUM[this.curStrokeCap]);
    strokeShader.setUniform(
      "uStrokeJoin",
      STROKE_JOIN_ENUM[this.curStrokeJoin]
    );
  }

  _setFillUniforms(fillShader) {
    this.mixedSpecularColor = [...this.states.curSpecularColor];
    const empty = this._getEmptyTexture();

    if (this.states._useMetalness > 0) {
      this.mixedSpecularColor = this.mixedSpecularColor.map(
        (mixedSpecularColor, index) =>
          this.states.curFillColor[index] * this.states._useMetalness +
          mixedSpecularColor * (1 - this.states._useMetalness)
      );
    }

    // TODO: optimize
    fillShader.setUniform("uUseVertexColor", this._useVertexColor);
    fillShader.setUniform("uMaterialColor", this.states.curFillColor);
    fillShader.setUniform("isTexture", !!this.states._tex);
    // We need to explicitly set uSampler back to an empty texture here.
    // In general, we record the last set texture so we can re-apply it
    // the next time a shader is used. However, the texture() function
    // works differently and is global p5 state. If the p5 state has
    // been cleared, we also need to clear the value in uSampler to match.
    fillShader.setUniform("uSampler", this.states._tex || empty);
    fillShader.setUniform("uTint", this.states.tint);

    fillShader.setUniform("uHasSetAmbient", this.states._hasSetAmbient);
    fillShader.setUniform("uAmbientMatColor", this.states.curAmbientColor);
    fillShader.setUniform("uSpecularMatColor", this.mixedSpecularColor);
    fillShader.setUniform("uEmissiveMatColor", this.states.curEmissiveColor);
    fillShader.setUniform("uSpecular", this.states._useSpecularMaterial);
    fillShader.setUniform("uEmissive", this.states._useEmissiveMaterial);
    fillShader.setUniform("uShininess", this.states._useShininess);
    fillShader.setUniform("uMetallic", this.states._useMetalness);

    this._setImageLightUniforms(fillShader);

    fillShader.setUniform("uUseLighting", this.states.enableLighting);

    const pointLightCount = this.states.pointLightDiffuseColors.length / 3;
    fillShader.setUniform("uPointLightCount", pointLightCount);
    fillShader.setUniform(
      "uPointLightLocation",
      this.states.pointLightPositions
    );
    fillShader.setUniform(
      "uPointLightDiffuseColors",
      this.states.pointLightDiffuseColors
    );
    fillShader.setUniform(
      "uPointLightSpecularColors",
      this.states.pointLightSpecularColors
    );

    const directionalLightCount =
      this.states.directionalLightDiffuseColors.length / 3;
    fillShader.setUniform("uDirectionalLightCount", directionalLightCount);
    fillShader.setUniform(
      "uLightingDirection",
      this.states.directionalLightDirections
    );
    fillShader.setUniform(
      "uDirectionalDiffuseColors",
      this.states.directionalLightDiffuseColors
    );
    fillShader.setUniform(
      "uDirectionalSpecularColors",
      this.states.directionalLightSpecularColors
    );

    // TODO: sum these here...
    const ambientLightCount = this.states.ambientLightColors.length / 3;
    this.mixedAmbientLight = [...this.states.ambientLightColors];

    if (this.states._useMetalness > 0) {
      this.mixedAmbientLight = this.mixedAmbientLight.map((ambientColors) => {
        let mixing = ambientColors - this.states._useMetalness;
        return Math.max(0, mixing);
      });
    }
    fillShader.setUniform("uAmbientLightCount", ambientLightCount);
    fillShader.setUniform("uAmbientColor", this.mixedAmbientLight);

    const spotLightCount = this.states.spotLightDiffuseColors.length / 3;
    fillShader.setUniform("uSpotLightCount", spotLightCount);
    fillShader.setUniform("uSpotLightAngle", this.states.spotLightAngle);
    fillShader.setUniform("uSpotLightConc", this.states.spotLightConc);
    fillShader.setUniform(
      "uSpotLightDiffuseColors",
      this.states.spotLightDiffuseColors
    );
    fillShader.setUniform(
      "uSpotLightSpecularColors",
      this.states.spotLightSpecularColors
    );
    fillShader.setUniform("uSpotLightLocation", this.states.spotLightPositions);
    fillShader.setUniform(
      "uSpotLightDirection",
      this.states.spotLightDirections
    );

    fillShader.setUniform(
      "uConstantAttenuation",
      this.states.constantAttenuation
    );
    fillShader.setUniform("uLinearAttenuation", this.states.linearAttenuation);
    fillShader.setUniform(
      "uQuadraticAttenuation",
      this.states.quadraticAttenuation
    );
  }

  // getting called from _setFillUniforms
  _setImageLightUniforms(shader) {
    //set uniform values
    shader.setUniform("uUseImageLight", this.states.activeImageLight != null);
    // true
    if (this.states.activeImageLight) {
      // this.states.activeImageLight has image as a key
      // look up the texture from the diffusedTexture map
      let diffusedLight = this.getDiffusedTexture(this.states.activeImageLight);
      shader.setUniform("environmentMapDiffused", diffusedLight);
      let specularLight = this.getSpecularTexture(this.states.activeImageLight);

      shader.setUniform("environmentMapSpecular", specularLight);
    }
  }

  _setPointUniforms(pointShader) {
    // set the uniform values
    pointShader.setUniform("uMaterialColor", this.states.curStrokeColor);
    // @todo is there an instance where this isn't stroke weight?
    // should be they be same var?
    pointShader.setUniform(
      "uPointSize",
      this.states.strokeWeight * this._pixelDensity
    );
  }

  /* Binds a buffer to the drawing context
   * when passed more than two arguments it also updates or initializes
   * the data associated with the buffer
   */
  _bindBuffer(buffer, target, values, type, usage) {
    if (!target) target = this.GL.ARRAY_BUFFER;
    this.GL.bindBuffer(target, buffer);
    if (values !== undefined) {
      let data = values;
      if (values instanceof DataArray) {
        data = values.dataArray();
      } else if (!(data instanceof (type || Float32Array))) {
        data = new (type || Float32Array)(data);
      }
      this.GL.bufferData(target, data, usage || this.GL.STATIC_DRAW);
    }
  }

  ///////////////////////////////
  //// UTILITY FUNCTIONS
  //////////////////////////////
  _arraysEqual(a, b) {
    const aLength = a.length;
    if (aLength !== b.length) return false;
    return a.every((ai, i) => ai === b[i]);
  }

  _isTypedArray(arr) {
    return [
      Float32Array,
      Float64Array,
      Int16Array,
      Uint16Array,
      Uint32Array,
    ].some((x) => arr instanceof x);
  }

  /**
   * turn a p5.Vector Array into a one dimensional number array
   * @private
   * @param  {p5.Vector[]} arr  an array of p5.Vector
   * @return {Number[]}     a one dimensional array of numbers
   * [p5.Vector(1, 2, 3), p5.Vector(4, 5, 6)] ->
   * [1, 2, 3, 4, 5, 6]
   */
  _vToNArray(arr) {
    return arr.flatMap((item) => [item.x, item.y, item.z]);
  }
}

function rendererGL(p5, fn) {
  p5.RendererGL = RendererGL;

  /**
   * @module Rendering
   * @submodule Rendering
   * @for p5
   */
  /**
   * Set attributes for the WebGL Drawing context.
   * This is a way of adjusting how the WebGL
   * renderer works to fine-tune the display and performance.
   *
   * Note that this will reinitialize the drawing context
   * if called after the WebGL canvas is made.
   *
   * If an object is passed as the parameter, all attributes
   * not declared in the object will be set to defaults.
   *
   * The available attributes are:
   * <br>
   * alpha - indicates if the canvas contains an alpha buffer
   * default is true
   *
   * depth - indicates whether the drawing buffer has a depth buffer
   * of at least 16 bits - default is true
   *
   * stencil - indicates whether the drawing buffer has a stencil buffer
   * of at least 8 bits
   *
   * antialias - indicates whether or not to perform anti-aliasing
   * default is false (true in Safari)
   *
   * premultipliedAlpha - indicates that the page compositor will assume
   * the drawing buffer contains colors with pre-multiplied alpha
   * default is true
   *
   * preserveDrawingBuffer - if true the buffers will not be cleared and
   * and will preserve their values until cleared or overwritten by author
   * (note that p5 clears automatically on draw loop)
   * default is true
   *
   * perPixelLighting - if true, per-pixel lighting will be used in the
   * lighting shader otherwise per-vertex lighting is used.
   * default is true.
   *
   * version - either 1 or 2, to specify which WebGL version to ask for. By
   * default, WebGL 2 will be requested. If WebGL2 is not available, it will
   * fall back to WebGL 1. You can check what version is used with by looking at
   * the global `webglVersion` property.
   *
   * @method setAttributes
   * @for p5
   * @param  {String}  key Name of attribute
   * @param  {Boolean}        value New value of named attribute
   * @example
   * <div>
   * <code>
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   * }
   *
   * function draw() {
   *   background(255);
   *   push();
   *   rotateZ(frameCount * 0.02);
   *   rotateX(frameCount * 0.02);
   *   rotateY(frameCount * 0.02);
   *   fill(0, 0, 0);
   *   box(50);
   *   pop();
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   *  // Now with the antialias attribute set to true.
   * function setup() {
   *   setAttributes('antialias', true);
   *   createCanvas(100, 100, WEBGL);
   * }
   *
   * function draw() {
   *   background(255);
   *   push();
   *   rotateZ(frameCount * 0.02);
   *   rotateX(frameCount * 0.02);
   *   rotateY(frameCount * 0.02);
   *   fill(0, 0, 0);
   *   box(50);
   *   pop();
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // press the mouse button to disable perPixelLighting
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *   noStroke();
   *   fill(255);
   * }
   *
   * let lights = [
   *   { c: '#f00', t: 1.12, p: 1.91, r: 0.2 },
   *   { c: '#0f0', t: 1.21, p: 1.31, r: 0.2 },
   *   { c: '#00f', t: 1.37, p: 1.57, r: 0.2 },
   *   { c: '#ff0', t: 1.12, p: 1.91, r: 0.7 },
   *   { c: '#0ff', t: 1.21, p: 1.31, r: 0.7 },
   *   { c: '#f0f', t: 1.37, p: 1.57, r: 0.7 }
   * ];
   *
   * function draw() {
   *   let t = millis() / 1000 + 1000;
   *   background(0);
   *   directionalLight(color('#222'), 1, 1, 1);
   *
   *   for (let i = 0; i < lights.length; i++) {
   *     let light = lights[i];
   *     pointLight(
   *       color(light.c),
   *       p5.Vector.fromAngles(t * light.t, t * light.p, width * light.r)
   *     );
   *   }
   *
   *   specularMaterial(255);
   *   sphere(width * 0.1);
   *
   *   rotateX(t * 0.77);
   *   rotateY(t * 0.83);
   *   rotateZ(t * 0.91);
   *   torus(width * 0.3, width * 0.07, 24, 10);
   * }
   *
   * function mousePressed() {
   *   setAttributes('perPixelLighting', false);
   *   noStroke();
   *   fill(255);
   * }
   * function mouseReleased() {
   *   setAttributes('perPixelLighting', true);
   *   noStroke();
   *   fill(255);
   * }
   * </code>
   * </div>
   *
   * @alt a rotating cube with smoother edges
   */
  /**
   * @method setAttributes
   * @for p5
   * @param  {Object}  obj object with key-value pairs
   */
  fn.setAttributes = function (key, value) {
    if (typeof this._glAttributes === "undefined") {
      console.log(
        "You are trying to use setAttributes on a p5.Graphics object " +
          "that does not use a WEBGL renderer."
      );
      return;
    }
    let unchanged = true;
    if (typeof value !== "undefined") {
      //first time modifying the attributes
      if (this._glAttributes === null) {
        this._glAttributes = {};
      }
      if (this._glAttributes[key] !== value) {
        //changing value of previously altered attribute
        this._glAttributes[key] = value;
        unchanged = false;
      }
      //setting all attributes with some change
    } else if (key instanceof Object) {
      if (this._glAttributes !== key) {
        this._glAttributes = key;
        unchanged = false;
      }
    }
    //@todo_FES
    if (!this._renderer.isP3D || unchanged) {
      return;
    }

    if (!this._setupDone) {
      if (this._renderer.geometryBufferCache.numCached() > 0) {
        p5._friendlyError(
          "Sorry, Could not set the attributes, you need to call setAttributes() " +
            "before calling the other drawing methods in setup()"
        );
        return;
      }
    }

    this._renderer._resetContext();

    if (this._renderer.states.curCamera) {
      this._renderer.states.curCamera._renderer = this._renderer;
    }
  };

  /**
   * ensures that p5 is using a 3d renderer. throws an error if not.
   */
  fn._assert3d = function (name) {
    if (!this._renderer.isP3D)
      throw new Error(
        `${name}() is only supported in WEBGL mode. If you'd like to use 3D graphics and WebGL, see  https://p5js.org/examples/form-3d-primitives.html for more information.`
      );
  };

  p5.renderers[WEBGL] = p5.RendererGL;
  p5.renderers[WEBGL2] = p5.RendererGL;
}

/**
 * @private
 * @param {Uint8Array|Float32Array|undefined} pixels An existing pixels array to reuse if the size is the same
 * @param {WebGLRenderingContext} gl The WebGL context
 * @param {WebGLFramebuffer|null} framebuffer The Framebuffer to read
 * @param {Number} x The x coordiante to read, premultiplied by pixel density
 * @param {Number} y The y coordiante to read, premultiplied by pixel density
 * @param {Number} width The width in pixels to be read (factoring in pixel density)
 * @param {Number} height The height in pixels to be read (factoring in pixel density)
 * @param {GLEnum} format Either RGB or RGBA depending on how many channels to read
 * @param {GLEnum} type The datatype of each channel, e.g. UNSIGNED_BYTE or FLOAT
 * @param {Number|undefined} flipY If provided, the total height with which to flip the y axis about
 * @returns {Uint8Array|Float32Array} pixels A pixels array with the current state of the
 * WebGL context read into it
 */
function readPixelsWebGL(
  pixels,
  gl,
  framebuffer,
  x,
  y,
  width,
  height,
  format,
  type,
  flipY
) {
  // Record the currently bound framebuffer so we can go back to it after, and
  // bind the framebuffer we want to read from
  const prevFramebuffer = gl.getParameter(gl.FRAMEBUFFER_BINDING);
  gl.bindFramebuffer(gl.FRAMEBUFFER, framebuffer);

  const channels = format === gl.RGBA ? 4 : 3;

  // Make a pixels buffer if it doesn't already exist
  const len = width * height * channels;
  const TypedArrayClass = type === gl.UNSIGNED_BYTE ? Uint8Array : Float32Array;
  if (!(pixels instanceof TypedArrayClass) || pixels.length !== len) {
    pixels = new TypedArrayClass(len);
  }

  gl.readPixels(
    x,
    flipY ? flipY - y - height : y,
    width,
    height,
    format,
    type,
    pixels
  );

  // Re-bind whatever was previously bound
  gl.bindFramebuffer(gl.FRAMEBUFFER, prevFramebuffer);

  if (flipY) {
    // WebGL pixels are inverted compared to 2D pixels, so we have to flip
    // the resulting rows. Adapted from https://stackoverflow.com/a/41973289
    const halfHeight = Math.floor(height / 2);
    const tmpRow = new TypedArrayClass(width * channels);
    for (let y = 0; y < halfHeight; y++) {
      const topOffset = y * width * 4;
      const bottomOffset = (height - y - 1) * width * 4;
      tmpRow.set(pixels.subarray(topOffset, topOffset + width * 4));
      pixels.copyWithin(topOffset, bottomOffset, bottomOffset + width * 4);
      pixels.set(tmpRow, bottomOffset);
    }
  }

  return pixels;
}

/**
 * @private
 * @param {WebGLRenderingContext} gl The WebGL context
 * @param {WebGLFramebuffer|null} framebuffer The Framebuffer to read
 * @param {Number} x The x coordinate to read, premultiplied by pixel density
 * @param {Number} y The y coordinate to read, premultiplied by pixel density
 * @param {GLEnum} format Either RGB or RGBA depending on how many channels to read
 * @param {GLEnum} type The datatype of each channel, e.g. UNSIGNED_BYTE or FLOAT
 * @param {Number|undefined} flipY If provided, the total height with which to flip the y axis about
 * @returns {Number[]} pixels The channel data for the pixel at that location
 */
function readPixelWebGL(gl, framebuffer, x, y, format, type, flipY) {
  // Record the currently bound framebuffer so we can go back to it after, and
  // bind the framebuffer we want to read from
  const prevFramebuffer = gl.getParameter(gl.FRAMEBUFFER_BINDING);
  gl.bindFramebuffer(gl.FRAMEBUFFER, framebuffer);

  const channels = format === gl.RGBA ? 4 : 3;
  const TypedArrayClass = type === gl.UNSIGNED_BYTE ? Uint8Array : Float32Array;
  const pixels = new TypedArrayClass(channels);

  gl.readPixels(x, flipY ? flipY - y - 1 : y, 1, 1, format, type, pixels);

  // Re-bind whatever was previously bound
  gl.bindFramebuffer(gl.FRAMEBUFFER, prevFramebuffer);

  return Array.from(pixels);
}

if (typeof p5 !== "undefined") {
  rendererGL(p5, p5.prototype);
}

/**
 * @module Shape
 * @submodule 3D Primitives
 * @for p5
 * @requires core
 * @requires p5.Geometry
 */


function primitives3D(p5, fn){
/**
 * Sets the stroke rendering mode to balance performance and visual features when drawing lines.
 *
 * `strokeMode()` offers two modes:
 *
 * - `SIMPLE`: Optimizes for speed by disabling caps, joins, and stroke color features.
 *   Use this mode for faster line rendering when these visual details are unnecessary.
 * - `FULL`: Enables caps, joins, and stroke color for lines.
 *   This mode provides enhanced visuals but may reduce performance due to additional processing.
 *
 * Choose the mode that best suits your application's needs to either improve rendering speed or enhance visual quality.
 *
 * @method strokeMode
 * @param {String} mode - The stroke mode to set. Possible values are:
 *   - `'SIMPLE'`: Fast rendering without caps, joins, or stroke color.
 *   - `'FULL'`: Detailed rendering with caps, joins, and stroke color.
 *
 * @example
 * <div>
 * <code>
 * function setup() {
 *   createCanvas(300, 300, WEBGL);
 *   describe('A sphere with red stroke and a red, wavy line on a gray background. The wavy line have caps, joins and colors.');
 * }
 *
 * function draw() {
 *   background(128);
 *   strokeMode(FULL); // Enables detailed rendering with caps, joins, and stroke color.
 *   push();
 *   strokeWeight(1);
 *   translate(0, -50, 0);
 *   sphere(50);
 *   pop();
 *   orbitControl();
 *
 *   noFill();
 *   strokeWeight(15);
 *   stroke('red');
 *   beginShape();
 *   bezierOrder(2); // Sets the order of the Bezier curve.
 *   bezierVertex(80, 80);
 *   bezierVertex(50, -40);
 *   bezierVertex(-80, 80);
 *   endShape();
 * }
 * </code>
 * </div>
 *
 * <div>
 * <code>
 * function setup() {
 *   createCanvas(300, 300, WEBGL);
 *   describe('A sphere with red stroke and a  wavy line without full curve decorations without caps and color on a gray background.');
 * }
 *
 * function draw() {
 *   background(128);
 *   strokeMode(SIMPLE); // Simplifies stroke rendering for better performance.
 *   
 *   // Draw sphere
 *   push();
 *   strokeWeight(1);
 *   translate(0, -50, 0);
 *   sphere(50);
 *   pop();
 *   orbitControl();
 *
 *   // Draw modified wavy red line
 *   noFill();
 *   strokeWeight(15);
 *   stroke('red');
 *   beginShape();
 *   bezierOrder(2); // Sets the order of the Bezier curve.
 *   bezierVertex(80, 80);
 *   bezierVertex(50, -40);
 *   bezierVertex(-80, 80);
 *   endShape();
 * }
 * </code>
 * </div>
 */

  fn.strokeMode = function (mode) {
    if (mode === undefined) {
      return this._renderer._simpleLines ? SIMPLE : FULL;
    } else if (mode === SIMPLE) {
      this._renderer._simpleLines = true;
    } else if (mode === FULL) {
      this._renderer._simpleLines = false;
    } else {
      throw Error('no such parameter');
    }
  };
  /**
   * Creates a custom <a href="#/p5.Geometry">p5.Geometry</a> object from
   * simpler 3D shapes.
   *
   * `buildGeometry()` helps with creating complex 3D shapes from simpler ones
   * such as <a href="#/p5/sphere">sphere()</a>. It can help to make sketches
   * more performant. For example, if a complex 3D shape doesnt change while a
   * sketch runs, then it can be created with `buildGeometry()`. Creating a
   * <a href="#/p5.Geometry">p5.Geometry</a> object once and then drawing it
   * will run faster than repeatedly drawing the individual pieces.
   *
   * The parameter, `callback`, is a function with the drawing instructions for
   * the new <a href="#/p5.Geometry">p5.Geometry</a> object. It will be called
   * once to create the new 3D shape.
   *
   * See <a href="#/p5/beginGeometry">beginGeometry()</a> and
   * <a href="#/p5/endGeometry">endGeometry()</a> for another way to build 3D
   * shapes.
   *
   * Note: `buildGeometry()` can only be used in WebGL mode.
   *
   * @method buildGeometry
   * @param {Function} callback function that draws the shape.
   * @returns {p5.Geometry} new 3D shape.
   *
   * @example
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   *
   * let shape;
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Create the p5.Geometry object.
   *   shape = buildGeometry(createShape);
   *
   *   describe('A white cone drawn on a gray background.');
   * }
   *
   * function draw() {
   *   background(50);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Turn on the lights.
   *   lights();
   *
   *   // Style the p5.Geometry object.
   *   noStroke();
   *
   *   // Draw the p5.Geometry object.
   *   model(shape);
   * }
   *
   * // Create p5.Geometry object from a single cone.
   * function createShape() {
   *   cone();
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   *
   * let shape;
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Create the arrow.
   *   shape = buildGeometry(createArrow);
   *
   *   describe('A white arrow drawn on a gray background.');
   * }
   *
   * function draw() {
   *   background(50);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Turn on the lights.
   *   lights();
   *
   *   // Style the arrow.
   *   noStroke();
   *
   *   // Draw the arrow.
   *   model(shape);
   * }
   *
   * function createArrow() {
   *   // Add shapes to the p5.Geometry object.
   *   push();
   *   rotateX(PI);
   *   cone(10);
   *   translate(0, -10, 0);
   *   cylinder(3, 20);
   *   pop();
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   *
   * let shape;
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Create the p5.Geometry object.
   *   shape = buildGeometry(createArrow);
   *
   *   describe('Two white arrows drawn on a gray background. The arrow on the right rotates slowly.');
   * }
   *
   * function draw() {
   *   background(50);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Turn on the lights.
   *   lights();
   *
   *   // Style the arrows.
   *   noStroke();
   *
   *   // Draw the p5.Geometry object.
   *   model(shape);
   *
   *   // Translate and rotate the coordinate system.
   *   translate(30, 0, 0);
   *   rotateZ(frameCount * 0.01);
   *
   *   // Draw the p5.Geometry object again.
   *   model(shape);
   * }
   *
   * function createArrow() {
   *   // Add shapes to the p5.Geometry object.
   *   push();
   *   rotateX(PI);
   *   cone(10);
   *   translate(0, -10, 0);
   *   cylinder(3, 20);
   *   pop();
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   *
   * let button;
   * let particles;
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Create a button to reset the particle system.
   *   button = createButton('Reset');
   *
   *   // Call resetModel() when the user presses the button.
   *   button.mousePressed(resetModel);
   *
   *   // Add the original set of particles.
   *   resetModel();
   *
   *   describe('A set of white spheres on a gray background. The spheres are positioned randomly. Their positions reset when the user presses the Reset button.');
   * }
   *
   * function draw() {
   *   background(50);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Turn on the lights.
   *   lights();
   *
   *   // Style the particles.
   *   noStroke();
   *
   *   // Draw the particles.
   *   model(particles);
   * }
   *
   * function resetModel() {
   *   // If the p5.Geometry object has already been created,
   *   // free those resources.
   *   if (particles) {
   *     freeGeometry(particles);
   *   }
   *
   *   // Create a new p5.Geometry object with random spheres.
   *   particles = buildGeometry(createParticles);
   * }
   *
   * function createParticles() {
   *   for (let i = 0; i < 60; i += 1) {
   *     // Calculate random coordinates.
   *     let x = randomGaussian(0, 20);
   *     let y = randomGaussian(0, 20);
   *     let z = randomGaussian(0, 20);
   *
   *     push();
   *     // Translate to the particle's coordinates.
   *     translate(x, y, z);
   *     // Draw the particle.
   *     sphere(5);
   *     pop();
   *   }
   * }
   * </code>
   * </div>
   */
  fn.buildGeometry = function(callback) {
    return this._renderer.buildGeometry(callback);
  };

  /**
   * Clears a <a href="#/p5.Geometry">p5.Geometry</a> object from the graphics
   * processing unit (GPU) memory.
   *
   * <a href="#/p5.Geometry">p5.Geometry</a> objects can contain lots of data
   * about their vertices, surface normals, colors, and so on. Complex 3D shapes
   * can use lots of memory which is a limited resource in many GPUs. Calling
   * `freeGeometry()` can improve performance by freeing a
   * <a href="#/p5.Geometry">p5.Geometry</a> objects resources from GPU memory.
   * `freeGeometry()` works with <a href="#/p5.Geometry">p5.Geometry</a> objects
   * created with <a href="#/p5/beginGeometry">beginGeometry()</a> and
   * <a href="#/p5/endGeometry">endGeometry()</a>,
   * <a href="#/p5/buildGeometry">buildGeometry()</a>, and
   * <a href="#/p5/loadModel">loadModel()</a>.
   *
   * The parameter, `geometry`, is the <a href="#/p5.Geometry">p5.Geometry</a>
   * object to be freed.
   *
   * Note: A <a href="#/p5.Geometry">p5.Geometry</a> object can still be drawn
   * after its resources are cleared from GPU memory. It may take longer to draw
   * the first time its redrawn.
   *
   * Note: `freeGeometry()` can only be used in WebGL mode.
   *
   * @method freeGeometry
   * @param {p5.Geometry} geometry 3D shape whose resources should be freed.
   *
   * @example
   * <div>
   * <code>
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   background(200);
   *
   *   // Create a p5.Geometry object.
   *   beginGeometry();
   *   cone();
   *   let shape = endGeometry();
   *
   *   // Draw the shape.
   *   model(shape);
   *
   *   // Free the shape's resources.
   *   freeGeometry(shape);
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   *
   * let button;
   * let particles;
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Create a button to reset the particle system.
   *   button = createButton('Reset');
   *
   *   // Call resetModel() when the user presses the button.
   *   button.mousePressed(resetModel);
   *
   *   // Add the original set of particles.
   *   resetModel();
   * }
   *
   * function draw() {
   *   background(50);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Turn on the lights.
   *   lights();
   *
   *   // Style the particles.
   *   noStroke();
   *
   *   // Draw the particles.
   *   model(particles);
   * }
   *
   * function resetModel() {
   *   // If the p5.Geometry object has already been created,
   *   // free those resources.
   *   if (particles) {
   *     freeGeometry(particles);
   *   }
   *
   *   // Create a new p5.Geometry object with random spheres.
   *   particles = buildGeometry(createParticles);
   * }
   *
   * function createParticles() {
   *   for (let i = 0; i < 60; i += 1) {
   *     // Calculate random coordinates.
   *     let x = randomGaussian(0, 20);
   *     let y = randomGaussian(0, 20);
   *     let z = randomGaussian(0, 20);
   *
   *     push();
   *     // Translate to the particle's coordinates.
   *     translate(x, y, z);
   *     // Draw the particle.
   *     sphere(5);
   *     pop();
   *   }
   * }
   * </code>
   * </div>
   */
  fn.freeGeometry = function(geometry) {
    this._renderer.geometryBufferCache.freeBuffers(geometry.gid);
  };

  /**
   * Draws a plane.
   *
   * A plane is a four-sided, flat shape with every angle measuring 90. Its
   * similar to a rectangle and offers advanced drawing features in WebGL mode.
   *
   * The first parameter, `width`, is optional. If a `Number` is passed, as in
   * `plane(20)`, it sets the planes width and height. By default, `width` is
   * 50.
   *
   * The second parameter, `height`, is also optional. If a `Number` is passed,
   * as in `plane(20, 30)`, it sets the planes height. By default, `height` is
   * set to the planes `width`.
   *
   * The third parameter, `detailX`, is also optional. If a `Number` is passed,
   * as in `plane(20, 30, 5)` it sets the number of triangle subdivisions to use
   * along the x-axis. All 3D shapes are made by connecting triangles to form
   * their surfaces. By default, `detailX` is 1.
   *
   * The fourth parameter, `detailY`, is also optional. If a `Number` is passed,
   * as in `plane(20, 30, 5, 7)` it sets the number of triangle subdivisions to
   * use along the y-axis. All 3D shapes are made by connecting triangles to
   * form their surfaces. By default, `detailY` is 1.
   *
   * Note: `plane()` can only be used in WebGL mode.
   *
   * @method plane
   * @param  {Number} [width]    width of the plane.
   * @param  {Number} [height]   height of the plane.
   * @param  {Integer} [detailX] number of triangle subdivisions along the x-axis.
   * @param {Integer} [detailY]  number of triangle subdivisions along the y-axis.
   * @chainable
   *
   * @example
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A white plane on a gray background.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Draw the plane.
   *   plane();
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A white plane on a gray background.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Draw the plane.
   *   // Set its width and height to 30.
   *   plane(30);
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A white plane on a gray background.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Draw the plane.
   *   // Set its width to 30 and height to 50.
   *   plane(30, 50);
   * }
   * </code>
   * </div>
   */
  fn.plane = function(
    width = 50,
    height = width,
    detailX = 1,
    detailY = 1
  ) {
    this._assert3d('plane');
    // p5._validateParameters('plane', arguments);

    this._renderer.plane(width, height, detailX, detailY);
    return this;
  };

  /**
   * Draws a box (rectangular prism).
   *
   * A box is a 3D shape with six faces. Each face makes a 90 with four
   * neighboring faces.
   *
   * The first parameter, `width`, is optional. If a `Number` is passed, as in
   * `box(20)`, it sets the boxs width and height. By default, `width` is 50.
   *
   * The second parameter, `height`, is also optional. If a `Number` is passed,
   * as in `box(20, 30)`, it sets the boxs height. By default, `height` is set
   * to the boxs `width`.
   *
   * The third parameter, `depth`, is also optional. If a `Number` is passed, as
   * in `box(20, 30, 40)`, it sets the boxs depth. By default, `depth` is set
   * to the boxs `height`.
   *
   * The fourth parameter, `detailX`, is also optional. If a `Number` is passed,
   * as in `box(20, 30, 40, 5)`, it sets the number of triangle subdivisions to
   * use along the x-axis. All 3D shapes are made by connecting triangles to
   * form their surfaces. By default, `detailX` is 1.
   *
   * The fifth parameter, `detailY`, is also optional. If a number is passed, as
   * in `box(20, 30, 40, 5, 7)`, it sets the number of triangle subdivisions to
   * use along the y-axis. All 3D shapes are made by connecting triangles to
   * form their surfaces. By default, `detailY` is 1.
   *
   * Note: `box()` can only be used in WebGL mode.
   *
   * @method  box
   * @param  {Number} [width]     width of the box.
   * @param  {Number} [height]    height of the box.
   * @param  {Number} [depth]     depth of the box.
   * @param {Integer} [detailX]   number of triangle subdivisions along the x-axis.
   * @param {Integer} [detailY]   number of triangle subdivisions along the y-axis.
   * @chainable
   *
   * @example
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A white box on a gray background.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Draw the box.
   *   box();
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A white box on a gray background.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Draw the box.
   *   // Set its width and height to 30.
   *   box(30);
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A white box on a gray background.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Draw the box.
   *   // Set its width to 30 and height to 50.
   *   box(30, 50);
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A white box on a gray background.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Draw the box.
   *   // Set its width to 30, height to 50, and depth to 10.
   *   box(30, 50, 10);
   * }
   * </code>
   * </div>
   */
  fn.box = function(width, height, depth, detailX, detailY) {
    this._assert3d('box');
    // p5._validateParameters('box', arguments);

    this._renderer.box(width, height, depth, detailX, detailY);

    return this;
  };

  /**
   * Draws a sphere.
   *
   * A sphere is a 3D shape with triangular faces that connect to form a round
   * surface. Spheres with few faces look like crystals. Spheres with many faces
   * have smooth surfaces and look like balls.
   *
   * The first parameter, `radius`, is optional. If a `Number` is passed, as in
   * `sphere(20)`, it sets the radius of the sphere. By default, `radius` is 50.
   *
   * The second parameter, `detailX`, is also optional. If a `Number` is passed,
   * as in `sphere(20, 5)`, it sets the number of triangle subdivisions to use
   * along the x-axis. All 3D shapes are made by connecting triangles to form
   * their surfaces. By default, `detailX` is 24.
   *
   * The third parameter, `detailY`, is also optional. If a `Number` is passed,
   * as in `sphere(20, 5, 2)`, it sets the number of triangle subdivisions to
   * use along the y-axis. All 3D shapes are made by connecting triangles to
   * form their surfaces. By default, `detailY` is 16.
   *
   * Note: `sphere()` can only be used in WebGL mode.
   *
   * @method sphere
   * @param  {Number} [radius]   radius of the sphere. Defaults to 50.
   * @param  {Integer} [detailX] number of triangle subdivisions along the x-axis. Defaults to 24.
   * @param  {Integer} [detailY] number of triangle subdivisions along the y-axis. Defaults to 16.
   *
   * @chainable
   * @example
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A white sphere on a gray background.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Draw the sphere.
   *   sphere();
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A white sphere on a gray background.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Draw the sphere.
   *   // Set its radius to 30.
   *   sphere(30);
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A white sphere on a gray background.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Draw the sphere.
   *   // Set its radius to 30.
   *   // Set its detailX to 6.
   *   sphere(30, 6);
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A white sphere on a gray background.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Draw the sphere.
   *   // Set its radius to 30.
   *   // Set its detailX to 24.
   *   // Set its detailY to 4.
   *   sphere(30, 24, 4);
   * }
   * </code>
   * </div>
   */
  fn.sphere = function(radius = 50, detailX = 24, detailY = 16) {
    this._assert3d('sphere');
    // p5._validateParameters('sphere', arguments);

    this._renderer.sphere(radius, detailX, detailY);

    return this;
  };

  /**
   * Draws a cylinder.
   *
   * A cylinder is a 3D shape with triangular faces that connect a flat bottom
   * to a flat top. Cylinders with few faces look like boxes. Cylinders with
   * many faces have smooth surfaces.
   *
   * The first parameter, `radius`, is optional. If a `Number` is passed, as in
   * `cylinder(20)`, it sets the radius of the cylinders base. By default,
   * `radius` is 50.
   *
   * The second parameter, `height`, is also optional. If a `Number` is passed,
   * as in `cylinder(20, 30)`, it sets the cylinders height. By default,
   * `height` is set to the cylinders `radius`.
   *
   * The third parameter, `detailX`, is also optional. If a `Number` is passed,
   * as in `cylinder(20, 30, 5)`, it sets the number of edges used to form the
   * cylinder's top and bottom. Using more edges makes the top and bottom look
   * more like circles. By default, `detailX` is 24.
   *
   * The fourth parameter, `detailY`, is also optional. If a `Number` is passed,
   * as in `cylinder(20, 30, 5, 2)`, it sets the number of triangle subdivisions
   * to use along the y-axis, between cylinder's the top and bottom. All 3D
   * shapes are made by connecting triangles to form their surfaces. By default,
   * `detailY` is 1.
   *
   * The fifth parameter, `bottomCap`, is also optional. If a `false` is passed,
   * as in `cylinder(20, 30, 5, 2, false)` the cylinders bottom wont be drawn.
   * By default, `bottomCap` is `true`.
   *
   * The sixth parameter, `topCap`, is also optional. If a `false` is passed, as
   * in `cylinder(20, 30, 5, 2, false, false)` the cylinders top wont be
   * drawn. By default, `topCap` is `true`.
   *
   * Note: `cylinder()` can only be used in WebGL mode.
   *
   * @method cylinder
   * @param  {Number}  [radius]    radius of the cylinder. Defaults to 50.
   * @param  {Number}  [height]    height of the cylinder. Defaults to the value of `radius`.
   * @param  {Integer} [detailX]   number of edges along the top and bottom. Defaults to 24.
   * @param  {Integer} [detailY]   number of triangle subdivisions along the y-axis. Defaults to 1.
   * @param  {Boolean} [bottomCap] whether to draw the cylinder's bottom. Defaults to `true`.
   * @param  {Boolean} [topCap]    whether to draw the cylinder's top. Defaults to `true`.
   * @chainable
   *
   * @example
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A white cylinder on a gray background.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Draw the cylinder.
   *   cylinder();
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A white cylinder on a gray background.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Draw the cylinder.
   *   // Set its radius and height to 30.
   *   cylinder(30);
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A white cylinder on a gray background.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Draw the cylinder.
   *   // Set its radius to 30 and height to 50.
   *   cylinder(30, 50);
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A white box on a gray background.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Draw the cylinder.
   *   // Set its radius to 30 and height to 50.
   *   // Set its detailX to 5.
   *   cylinder(30, 50, 5);
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A white cylinder on a gray background.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Draw the cylinder.
   *   // Set its radius to 30 and height to 50.
   *   // Set its detailX to 24 and detailY to 2.
   *   cylinder(30, 50, 24, 2);
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A white cylinder on a gray background. Its top is missing.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Draw the cylinder.
   *   // Set its radius to 30 and height to 50.
   *   // Set its detailX to 24 and detailY to 1.
   *   // Don't draw its bottom.
   *   cylinder(30, 50, 24, 1, false);
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A white cylinder on a gray background. Its top and bottom are missing.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Draw the cylinder.
   *   // Set its radius to 30 and height to 50.
   *   // Set its detailX to 24 and detailY to 1.
   *   // Don't draw its bottom or top.
   *   cylinder(30, 50, 24, 1, false, false);
   * }
   * </code>
   * </div>
   */
  fn.cylinder = function(
    radius = 50,
    height = radius,
    detailX = 24,
    detailY = 1,
    bottomCap = true,
    topCap = true
  ) {
    this._assert3d('cylinder');
    // p5._validateParameters('cylinder', arguments);

    this._renderer.cylinder(radius, height, detailX, detailY, bottomCap, topCap);

    return this;
  };

  /**
   * Draws a cone.
   *
   * A cone is a 3D shape with triangular faces that connect a flat bottom to a
   * single point. Cones with few faces look like pyramids. Cones with many
   * faces have smooth surfaces.
   *
   * The first parameter, `radius`, is optional. If a `Number` is passed, as in
   * `cone(20)`, it sets the radius of the cones base. By default, `radius` is
   * 50.
   *
   * The second parameter, `height`, is also optional. If a `Number` is passed,
   * as in `cone(20, 30)`, it sets the cones height. By default, `height` is
   * set to the cones `radius`.
   *
   * The third parameter, `detailX`, is also optional. If a `Number` is passed,
   * as in `cone(20, 30, 5)`, it sets the number of edges used to form the
   * cone's base. Using more edges makes the base look more like a circle. By
   * default, `detailX` is 24.
   *
   * The fourth parameter, `detailY`, is also optional. If a `Number` is passed,
   * as in `cone(20, 30, 5, 7)`, it sets the number of triangle subdivisions to
   * use along the y-axis connecting the base to the tip. All 3D shapes are made
   * by connecting triangles to form their surfaces. By default, `detailY` is 1.
   *
   * The fifth parameter, `cap`, is also optional. If a `false` is passed, as
   * in `cone(20, 30, 5, 7, false)` the cones base wont be drawn. By default,
   * `cap` is `true`.
   *
   * Note: `cone()` can only be used in WebGL mode.
   *
   * @method cone
   * @param  {Number}  [radius]  radius of the cone's base. Defaults to 50.
   * @param  {Number}  [height]  height of the cone. Defaults to the value of `radius`.
   * @param  {Integer} [detailX] number of edges used to draw the base. Defaults to 24.
   * @param  {Integer} [detailY] number of triangle subdivisions along the y-axis. Defaults to 1.
   * @param  {Boolean} [cap]     whether to draw the cone's base.  Defaults to `true`.
   * @chainable
   *
   * @example
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A white cone on a gray background.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Draw the cone.
   *   cone();
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A white cone on a gray background.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Draw the cone.
   *   // Set its radius and height to 30.
   *   cone(30);
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A white cone on a gray background.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Draw the cone.
   *   // Set its radius to 30 and height to 50.
   *   cone(30, 50);
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A white cone on a gray background.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Draw the cone.
   *   // Set its radius to 30 and height to 50.
   *   // Set its detailX to 5.
   *   cone(30, 50, 5);
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A white pyramid on a gray background.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Draw the cone.
   *   // Set its radius to 30 and height to 50.
   *   // Set its detailX to 5.
   *   cone(30, 50, 5);
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A white cone on a gray background.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Draw the cone.
   *   // Set its radius to 30 and height to 50.
   *   // Set its detailX to 24 and detailY to 2.
   *   cone(30, 50, 24, 2);
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A white cone on a gray background. Its base is missing.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Draw the cone.
   *   // Set its radius to 30 and height to 50.
   *   // Set its detailX to 24 and detailY to 1.
   *   // Don't draw its base.
   *   cone(30, 50, 24, 1, false);
   * }
   * </code>
   * </div>
   */
  fn.cone = function(
    radius = 50,
    height = radius,
    detailX = 24,
    detailY = 1,
    cap = true
  ) {
    this._assert3d('cone');
    // p5._validateParameters('cone', arguments);

    this._renderer.cone(radius, height, detailX, detailY, cap);

    return this;
  };

  /**
   * Draws an ellipsoid.
   *
   * An ellipsoid is a 3D shape with triangular faces that connect to form a
   * round surface. Ellipsoids with few faces look like crystals. Ellipsoids
   * with many faces have smooth surfaces and look like eggs. `ellipsoid()`
   * defines a shape by its radii. This is different from
   * <a href="#/p5/ellipse">ellipse()</a> which uses diameters
   * (width and height).
   *
   * The first parameter, `radiusX`, is optional. If a `Number` is passed, as in
   * `ellipsoid(20)`, it sets the radius of the ellipsoid along the x-axis. By
   * default, `radiusX` is 50.
   *
   * The second parameter, `radiusY`, is also optional. If a `Number` is passed,
   * as in `ellipsoid(20, 30)`, it sets the ellipsoids radius along the y-axis.
   * By default, `radiusY` is set to the ellipsoids `radiusX`.
   *
   * The third parameter, `radiusZ`, is also optional. If a `Number` is passed,
   * as in `ellipsoid(20, 30, 40)`, it sets the ellipsoids radius along the
   * z-axis. By default, `radiusZ` is set to the ellipsoids `radiusY`.
   *
   * The fourth parameter, `detailX`, is also optional. If a `Number` is passed,
   * as in `ellipsoid(20, 30, 40, 5)`, it sets the number of triangle
   * subdivisions to use along the x-axis. All 3D shapes are made by connecting
   * triangles to form their surfaces. By default, `detailX` is 24.
   *
   * The fifth parameter, `detailY`, is also optional. If a `Number` is passed,
   * as in `ellipsoid(20, 30, 40, 5, 7)`, it sets the number of triangle
   * subdivisions to use along the y-axis. All 3D shapes are made by connecting
   * triangles to form their surfaces. By default, `detailY` is 16.
   *
   * Note: `ellipsoid()` can only be used in WebGL mode.
   *
   * @method ellipsoid
   * @param  {Number} [radiusX]  radius of the ellipsoid along the x-axis. Defaults to 50.
   * @param  {Number} [radiusY]  radius of the ellipsoid along the y-axis. Defaults to `radiusX`.
   * @param  {Number} [radiusZ]  radius of the ellipsoid along the z-axis. Defaults to `radiusY`.
   * @param  {Integer} [detailX] number of triangle subdivisions along the x-axis. Defaults to 24.
   * @param  {Integer} [detailY] number of triangle subdivisions along the y-axis. Defaults to 16.
   * @chainable
   *
   * @example
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A white sphere on a gray background.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Draw the ellipsoid.
   *   // Set its radiusX to 30.
   *   ellipsoid(30);
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A white ellipsoid on a gray background.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Draw the ellipsoid.
   *   // Set its radiusX to 30.
   *   // Set its radiusY to 40.
   *   ellipsoid(30, 40);
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A white ellipsoid on a gray background.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Draw the ellipsoid.
   *   // Set its radiusX to 30.
   *   // Set its radiusY to 40.
   *   // Set its radiusZ to 50.
   *   ellipsoid(30, 40, 50);
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A white ellipsoid on a gray background.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Draw the ellipsoid.
   *   // Set its radiusX to 30.
   *   // Set its radiusY to 40.
   *   // Set its radiusZ to 50.
   *   // Set its detailX to 4.
   *   ellipsoid(30, 40, 50, 4);
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A white ellipsoid on a gray background.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Draw the ellipsoid.
   *   // Set its radiusX to 30.
   *   // Set its radiusY to 40.
   *   // Set its radiusZ to 50.
   *   // Set its detailX to 4.
   *   // Set its detailY to 3.
   *   ellipsoid(30, 40, 50, 4, 3);
   * }
   * </code>
   * </div>
   */
  fn.ellipsoid = function(
    radiusX = 50,
    radiusY = radiusX,
    radiusZ = radiusX,
    detailX = 24,
    detailY = 16
  ) {
    this._assert3d('ellipsoid');
    // p5._validateParameters('ellipsoid', arguments);

    this._renderer.ellipsoid(radiusX, radiusY, radiusZ, detailX, detailY);

    return this;
  };

  /**
   * Draws a torus.
   *
   * A torus is a 3D shape with triangular faces that connect to form a ring.
   * Toruses with few faces look flattened. Toruses with many faces have smooth
   * surfaces.
   *
   * The first parameter, `radius`, is optional. If a `Number` is passed, as in
   * `torus(30)`, it sets the radius of the ring. By default, `radius` is 50.
   *
   * The second parameter, `tubeRadius`, is also optional. If a `Number` is
   * passed, as in `torus(30, 15)`, it sets the radius of the tube. By default,
   * `tubeRadius` is 10.
   *
   * The third parameter, `detailX`, is also optional. If a `Number` is passed,
   * as in `torus(30, 15, 5)`, it sets the number of edges used to draw the hole
   * of the torus. Using more edges makes the hole look more like a circle. By
   * default, `detailX` is 24.
   *
   * The fourth parameter, `detailY`, is also optional. If a `Number` is passed,
   * as in `torus(30, 15, 5, 7)`, it sets the number of triangle subdivisions to
   * use while filling in the torus height. By default, `detailY` is 16.
   *
   * Note: `torus()` can only be used in WebGL mode.
   *
   * @method torus
   * @param  {Number} [radius]      radius of the torus. Defaults to 50.
   * @param  {Number} [tubeRadius]  radius of the tube. Defaults to 10.
   * @param  {Integer} [detailX]    number of edges that form the hole. Defaults to 24.
   * @param  {Integer} [detailY]    number of triangle subdivisions along the y-axis. Defaults to 16.
   * @chainable
   *
   * @example
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A white torus on a gray background.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Draw the torus.
   *   torus();
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A white torus on a gray background.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Draw the torus.
   *   // Set its radius to 30.
   *   torus(30);
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A white torus on a gray background.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Draw the torus.
   *   // Set its radius to 30 and tubeRadius to 15.
   *   torus(30, 15);
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A white torus on a gray background.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Draw the torus.
   *   // Set its radius to 30 and tubeRadius to 15.
   *   // Set its detailX to 5.
   *   torus(30, 15, 5);
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A white torus on a gray background.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Draw the torus.
   *   // Set its radius to 30 and tubeRadius to 15.
   *   // Set its detailX to 5.
   *   // Set its detailY to 3.
   *   torus(30, 15, 5, 3);
   * }
   * </code>
   * </div>
   */
  fn.torus = function(radius, tubeRadius, detailX, detailY) {
    this._assert3d('torus');
    // p5._validateParameters('torus', arguments);

    this._renderer.torus(radius, tubeRadius, detailX, detailY);

    return this;
  };

  ///////////////////////
  ///  2D primitives  ///
  ///////////////////////
  //
  // Note: Documentation is not generated on the p5.js website for functions on
  // the p5.RendererGL prototype.

  /**
   * Draws a point, a coordinate in space at the dimension of one pixel,
   * given x, y and z coordinates. The color of the point is determined
   * by the current stroke, while the point size is determined by current
   * stroke weight.
   * @private
   * @param {Number} x x-coordinate of point
   * @param {Number} y y-coordinate of point
   * @param {Number} z z-coordinate of point
   * @chainable
   * @example
   * <div>
   * <code>
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   * }
   *
   * function draw() {
   *   background(50);
   *   stroke(255);
   *   strokeWeight(4);
   *   point(25, 0);
   *   strokeWeight(3);
   *   point(-25, 0);
   *   strokeWeight(2);
   *   point(0, 25);
   *   strokeWeight(1);
   *   point(0, -25);
   * }
   * </code>
   * </div>
   */
  RendererGL.prototype.point = function(x, y, z = 0) {

    const _vertex = [];
    _vertex.push(new Vector(x, y, z));
    this._drawPoints(_vertex, this.buffers.point);

    return this;
  };

  RendererGL.prototype.triangle = function(args) {
    const x1 = args[0],
      y1 = args[1];
    const x2 = args[2],
      y2 = args[3];
    const x3 = args[4],
      y3 = args[5];

    const gid = 'tri';
    if (!this.geometryInHash(gid)) {
      const _triangle = function() {
        const vertices = [];
        vertices.push(new Vector(0, 0, 0));
        vertices.push(new Vector(1, 0, 0));
        vertices.push(new Vector(0, 1, 0));
        this.edges = [[0, 1], [1, 2], [2, 0]];
        this.vertices = vertices;
        this.faces = [[0, 1, 2]];
        this.uvs = [0, 0, 1, 0, 1, 1];
      };
      const triGeom = new Geometry(1, 1, _triangle, this);
      triGeom._edgesToVertices();
      triGeom.computeNormals();
      triGeom.gid = gid;
      this.geometryBufferCache.ensureCached(triGeom);
    }

    // only one triangle is cached, one point is at the origin, and the
    // two adjacent sides are tne unit vectors along the X & Y axes.
    //
    // this matrix multiplication transforms those two unit vectors
    // onto the required vector prior to rendering, and moves the
    // origin appropriately.
    const uModelMatrix = this.states.uModelMatrix.copy();
    try {
      // triangle orientation.
      const orientation = Math.sign(x1*y2-x2*y1 + x2*y3-x3*y2 + x3*y1-x1*y3);
      const mult = new Matrix([
        x2 - x1, y2 - y1, 0, 0, // the resulting unit X-axis
        x3 - x1, y3 - y1, 0, 0, // the resulting unit Y-axis
        0, 0, orientation, 0,   // the resulting unit Z-axis (Reflect the specified order of vertices)
        x1, y1, 0, 1            // the resulting origin
      ]).mult(this.states.uModelMatrix);

      this.states.setValue('uModelMatrix', mult);

      this._drawGeometry(this.geometryBufferCache.getGeometryByID(gid));
    } finally {
      this.states.setValue('uModelMatrix', uModelMatrix);
    }

    return this;
  };

  RendererGL.prototype.ellipse = function(args) {
    this.arc(
      args[0],
      args[1],
      args[2],
      args[3],
      0,
      TWO_PI,
      OPEN,
      args[4]
    );
  };

  RendererGL.prototype.arc = function(...args) {
    const x = args[0];
    const y = args[1];
    const width = args[2];
    const height = args[3];
    const start = args[4];
    const stop = args[5];
    const mode = args[6];
    const detail = args[7] || 25;

    let shape;
    let gid;

    // check if it is an ellipse or an arc
    if (Math.abs(stop - start) >= TWO_PI) {
      shape = 'ellipse';
      gid = `${shape}|${detail}|`;
    } else {
      shape = 'arc';
      gid = `${shape}|${start}|${stop}|${mode}|${detail}|`;
    }

    if (!this.geometryInHash(gid)) {
      const _arc = function() {

        // if the start and stop angles are not the same, push vertices to the array
        if (start.toFixed(10) !== stop.toFixed(10)) {
          // if the mode specified is PIE or null, push the mid point of the arc in vertices
          if (mode === PIE || typeof mode === 'undefined') {
            this.vertices.push(new Vector(0.5, 0.5, 0));
            this.uvs.push([0.5, 0.5]);
          }

          // vertices for the perimeter of the circle
          for (let i = 0; i <= detail; i++) {
            const u = i / detail;
            const theta = (stop - start) * u + start;

            const _x = 0.5 + Math.cos(theta) / 2;
            const _y = 0.5 + Math.sin(theta) / 2;

            this.vertices.push(new Vector(_x, _y, 0));
            this.uvs.push([_x, _y]);

            if (i < detail - 1) {
              this.faces.push([0, i + 1, i + 2]);
              this.edges.push([i + 1, i + 2]);
            }
          }

          // check the mode specified in order to push vertices and faces, different for each mode
          switch (mode) {
            case PIE:
              this.faces.push([
                0,
                this.vertices.length - 2,
                this.vertices.length - 1
              ]);
              this.edges.push([0, 1]);
              this.edges.push([
                this.vertices.length - 2,
                this.vertices.length - 1
              ]);
              this.edges.push([0, this.vertices.length - 1]);
              break;

            case CHORD:
              this.edges.push([0, 1]);
              this.edges.push([0, this.vertices.length - 1]);
              break;

            case OPEN:
              this.edges.push([0, 1]);
              break;

            default:
              this.faces.push([
                0,
                this.vertices.length - 2,
                this.vertices.length - 1
              ]);
              this.edges.push([
                this.vertices.length - 2,
                this.vertices.length - 1
              ]);
          }
        }
      };

      const arcGeom = new Geometry(detail, 1, _arc, this);
      arcGeom.computeNormals();

      if (detail <= 50) {
        arcGeom._edgesToVertices(arcGeom);
      } else if (this.states.strokeColor) {
        console.log(
          `Cannot apply a stroke to an ${shape} with more than 50 detail`
        );
      }

      arcGeom.gid = gid;
      this.geometryBufferCache.ensureCached(arcGeom);
    }

    const uModelMatrix = this.states.uModelMatrix;
    this.states.setValue('uModelMatrix', this.states.uModelMatrix.clone());

    try {
      this.states.uModelMatrix.translate([x, y, 0]);
      this.states.uModelMatrix.scale(width, height, 1);

      this._drawGeometry(this.geometryBufferCache.getGeometryByID(gid));
    } finally {
      this.states.setValue('uModelMatrix', uModelMatrix);
    }

    return this;
  };

  RendererGL.prototype.rect = function(args) {
    const x = args[0];
    const y = args[1];
    const width = args[2];
    const height = args[3];

    if (typeof args[4] === 'undefined') {
      // Use the retained mode for drawing rectangle,
      // if args for rounding rectangle is not provided by user.
      const perPixelLighting = this._pInst._glAttributes.perPixelLighting;
      const detailX = args[4] || (perPixelLighting ? 1 : 24);
      const detailY = args[5] || (perPixelLighting ? 1 : 16);
      const gid = `rect|${detailX}|${detailY}`;
      if (!this.geometryInHash(gid)) {
        const _rect = function() {
          for (let i = 0; i <= this.detailY; i++) {
            const v = i / this.detailY;
            for (let j = 0; j <= this.detailX; j++) {
              const u = j / this.detailX;
              const p = new Vector(u, v, 0);
              this.vertices.push(p);
              this.uvs.push(u, v);
            }
          }
          // using stroke indices to avoid stroke over face(s) of rectangle
          if (detailX > 0 && detailY > 0) {
            this.edges = [
              [0, detailX],
              [detailX, (detailX + 1) * (detailY + 1) - 1],
              [(detailX + 1) * (detailY + 1) - 1, (detailX + 1) * detailY],
              [(detailX + 1) * detailY, 0]
            ];
          }
        };
        const rectGeom = new Geometry(detailX, detailY, _rect, this);
        rectGeom
          .computeFaces()
          .computeNormals()
          ._edgesToVertices();
        rectGeom.gid = gid;
        this.geometryBufferCache.ensureCached(rectGeom);
      }

      // only a single rectangle (of a given detail) is cached: a square with
      // opposite corners at (0,0) & (1,1).
      //
      // before rendering, this square is scaled & moved to the required location.
      const uModelMatrix = this.states.uModelMatrix;
      this.states.setValue('uModelMatrix', this.states.uModelMatrix.copy());
      try {
        this.states.uModelMatrix.translate([x, y, 0]);
        this.states.uModelMatrix.scale(width, height, 1);

        this._drawGeometry(this.geometryBufferCache.getGeometryByID(gid));
      } finally {
        this.states.setValue('uModelMatrix', uModelMatrix);
      }
    } else {
      // Use Immediate mode to round the rectangle corner,
      // if args for rounding corners is provided by user
      let tl = args[4];
      let tr = typeof args[5] === 'undefined' ? tl : args[5];
      let br = typeof args[6] === 'undefined' ? tr : args[6];
      let bl = typeof args[7] === 'undefined' ? br : args[7];

      let a = x;
      let b = y;
      let c = width;
      let d = height;

      c += a;
      d += b;

      if (a > c) {
        const temp = a;
        a = c;
        c = temp;
      }

      if (b > d) {
        const temp = b;
        b = d;
        d = temp;
      }

      const maxRounding = Math.min((c - a) / 2, (d - b) / 2);
      if (tl > maxRounding) tl = maxRounding;
      if (tr > maxRounding) tr = maxRounding;
      if (br > maxRounding) br = maxRounding;
      if (bl > maxRounding) bl = maxRounding;

      let x1 = a;
      let y1 = b;
      let x2 = c;
      let y2 = d;

      const prevMode = this.states.textureMode;
      this.states.setValue('textureMode', NORMAL);
      const prevOrder = this.bezierOrder();
      this.bezierOrder(2);
      this.beginShape();
      const addUVs = (x, y) => [x, y, (x - x1)/width, (y - y1)/height];
      if (tr !== 0) {
        this.vertex(...addUVs(x2 - tr, y1));
        this.bezierVertex(...addUVs(x2, y1));
        this.bezierVertex(...addUVs(x2, y1 + tr));
      } else {
        this.vertex(...addUVs(x2, y1));
      }
      if (br !== 0) {
        this.vertex(...addUVs(x2, y2 - br));
        this.bezierVertex(...addUVs(x2, y2));
        this.bezierVertex(...addUVs(x2 - br, y2));
      } else {
        this.vertex(...addUVs(x2, y2));
      }
      if (bl !== 0) {
        this.vertex(...addUVs(x1 + bl, y2));
        this.bezierVertex(...addUVs(x1, y2));
        this.bezierVertex(...addUVs(x1, y2 - bl));
      } else {
        this.vertex(...addUVs(x1, y2));
      }
      if (tl !== 0) {
        this.vertex(...addUVs(x1, y1 + tl));
        this.bezierVertex(...addUVs(x1, y1));
        this.bezierVertex(...addUVs(x1 + tl, y1));
      } else {
        this.vertex(...addUVs(x1, y1));
      }

      this.endShape(CLOSE);
      this.states.setValue('textureMode', prevMode);
      this.bezierOrder(prevOrder);
    }
    return this;
  };

  /* eslint-disable max-len */
  RendererGL.prototype.quad = function(x1, y1, z1, x2, y2, z2, x3, y3, z3, x4, y4, z4, detailX=2, detailY=2) {
    /* eslint-enable max-len */

    const gid =
      `quad|${x1}|${y1}|${z1}|${x2}|${y2}|${z2}|${x3}|${y3}|${z3}|${x4}|${y4}|${z4}|${detailX}|${detailY}`;

    if (!this.geometryInHash(gid)) {
      const quadGeom = new Geometry(detailX, detailY, function() {
        //algorithm adapted from c++ to js
        //https://stackoverflow.com/questions/16989181/whats-the-correct-way-to-draw-a-distorted-plane-in-opengl/16993202#16993202
        let xRes = 1.0 / (this.detailX - 1);
        let yRes = 1.0 / (this.detailY - 1);
        for (let y = 0; y < this.detailY; y++) {
          for (let x = 0; x < this.detailX; x++) {
            let pctx = x * xRes;
            let pcty = y * yRes;

            let linePt0x = (1 - pcty) * x1 + pcty * x4;
            let linePt0y = (1 - pcty) * y1 + pcty * y4;
            let linePt0z = (1 - pcty) * z1 + pcty * z4;
            let linePt1x = (1 - pcty) * x2 + pcty * x3;
            let linePt1y = (1 - pcty) * y2 + pcty * y3;
            let linePt1z = (1 - pcty) * z2 + pcty * z3;

            let ptx = (1 - pctx) * linePt0x + pctx * linePt1x;
            let pty = (1 - pctx) * linePt0y + pctx * linePt1y;
            let ptz = (1 - pctx) * linePt0z + pctx * linePt1z;

            this.vertices.push(new Vector(ptx, pty, ptz));
            this.uvs.push([pctx, pcty]);
          }
        }
      }, this);

      quadGeom.faces = [];
      for(let y = 0; y < detailY-1; y++){
        for(let x = 0; x < detailX-1; x++){
          let pt0 = x + y * detailX;
          let pt1 = (x + 1) + y * detailX;
          let pt2 = (x + 1) + (y + 1) * detailX;
          let pt3 = x + (y + 1) * detailX;
          quadGeom.faces.push([pt0, pt1, pt2]);
          quadGeom.faces.push([pt0, pt2, pt3]);
        }
      }
      quadGeom.computeNormals();
      quadGeom.edges.length = 0;
      const vertexOrder = [0, 2, 3, 1];
      for (let i = 0; i < vertexOrder.length; i++) {
        const startVertex = vertexOrder[i];
        const endVertex = vertexOrder[(i + 1) % vertexOrder.length];
        quadGeom.edges.push([startVertex, endVertex]);
      }
      quadGeom._edgesToVertices();
      quadGeom.gid = gid;
      this.geometryBufferCache.ensureCached(quadGeom);
    }
    this._drawGeometry(this.geometryBufferCache.getGeometryByID(gid));
    return this;
  };

  //this implementation of bezier curve
  //is based on Bernstein polynomial
  // pretier-ignore
  RendererGL.prototype.bezier = function(
    x1,
    y1,
    z1, // x2
    x2, // y2
    y2, // x3
    z2, // y3
    x3, // x4
    y3, // y4
    z3,
    x4,
    y4,
    z4
  ) {
    if (arguments.length === 8) {
      y4 = y3;
      x4 = x3;
      y3 = z2;
      x3 = y2;
      y2 = x2;
      x2 = z1;
      z1 = z2 = z3 = z4 = 0;
    }
    // TODO: handle quadratic?
    this.bezierOrder();
    this.bezierOrder(3);
    this.beginShape();
    this.vertex(x1, y1, z1);
    this.bezierVertex(x2, y2, z2);
    this.bezierVertex(x3, y3, z3);
    this.bezierVertex(x4, y4, z4);
    this.endShape();
  };

  // pretier-ignore
  RendererGL.prototype.curve = function(
    x1,
    y1,
    z1, // x2
    x2, // y2
    y2, // x3
    z2, // y3
    x3, // x4
    y3, // y4
    z3,
    x4,
    y4,
    z4
  ) {
    if (arguments.length === 8) {
      x4 = x3;
      y4 = y3;
      x3 = y2;
      y3 = x2;
      x2 = z1;
      y2 = x2;
      z1 = z2 = z3 = z4 = 0;
    }
    this.beginShape();
    this.splineVertex(x1, y1, z1);
    this.splineVertex(x2, y2, z2);
    this.splineVertex(x3, y3, z3);
    this.splineVertex(x4, y4, z4);
    this.endShape();
  };

  /**
   * Draw a line given two points
   * @private
   * @param {Number} x0 x-coordinate of first vertex
   * @param {Number} y0 y-coordinate of first vertex
   * @param {Number} z0 z-coordinate of first vertex
   * @param {Number} x1 x-coordinate of second vertex
   * @param {Number} y1 y-coordinate of second vertex
   * @param {Number} z1 z-coordinate of second vertex
   * @chainable
   * @example
   * <div>
   * <code>
   * //draw a line
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   * }
   *
   * function draw() {
   *   background(200);
   *   rotateX(frameCount * 0.01);
   *   rotateY(frameCount * 0.01);
   *   // Use fill instead of stroke to change the color of shape.
   *   fill(255, 0, 0);
   *   line(10, 10, 0, 60, 60, 20);
   * }
   * </code>
   * </div>
   */
  RendererGL.prototype.line = function(...args) {
    if (args.length === 6) {
      // TODO shapes refactor
      this.beginShape(LINES);
      this.vertex(args[0], args[1], args[2]);
      this.vertex(args[3], args[4], args[5]);
      this.endShape();
    } else if (args.length === 4) {
      this.beginShape(LINES);
      this.vertex(args[0], args[1], 0);
      this.vertex(args[2], args[3], 0);
      this.endShape();
    }
    return this;
  };

  RendererGL.prototype.image = function(
    img,
    sx,
    sy,
    sWidth,
    sHeight,
    dx,
    dy,
    dWidth,
    dHeight
  ) {
    // console.log(arguments);
    if (this._isErasing) {
      this.blendMode(this._cachedBlendMode);
    }

    this.push();
    this.noLights();
    this.states.setValue('strokeColor', null);

    this.texture(img);
    this.states.setValue('textureMode', NORMAL);

    let u0 = 0;
    if (sx <= img.width) {
      u0 = sx / img.width;
    }

    let u1 = 1;
    if (sx + sWidth <= img.width) {
      u1 = (sx + sWidth) / img.width;
    }

    let v0 = 0;
    if (sy <= img.height) {
      v0 = sy / img.height;
    }

    let v1 = 1;
    if (sy + sHeight <= img.height) {
      v1 = (sy + sHeight) / img.height;
    }

    this._drawingImage = true;
    this.beginShape();
    this.vertex(dx, dy, 0, u0, v0);
    this.vertex(dx + dWidth, dy, 0, u1, v0);
    this.vertex(dx + dWidth, dy + dHeight, 0, u1, v1);
    this.vertex(dx, dy + dHeight, 0, u0, v1);
    this.endShape(CLOSE);
    this._drawingImage = false;

    this.pop();

    if (this._isErasing) {
      this.blendMode(REMOVE);
    }
  };

  ///////////////////////
  ///  3D primitives  ///
  ///////////////////////
  /**
   * @private
   * Helper function for creating both cones and cylinders
   * Will only generate well-defined geometry when bottomRadius, height > 0
   * and topRadius >= 0
   * If topRadius == 0, topCap should be false
   */
  const _truncatedCone = function(
    bottomRadius,
    topRadius,
    height,
    detailX,
    detailY,
    bottomCap,
    topCap
  ) {
    bottomRadius = bottomRadius <= 0 ? 1 : bottomRadius;
    topRadius = topRadius < 0 ? 0 : topRadius;
    height = height <= 0 ? bottomRadius : height;
    detailX = detailX < 3 ? 3 : detailX;
    detailY = detailY < 1 ? 1 : detailY;
    bottomCap = bottomCap === undefined ? true : bottomCap;
    topCap = topCap === undefined ? topRadius !== 0 : topCap;
    const start = bottomCap ? -2 : 0;
    const end = detailY + (topCap ? 2 : 0);
    //ensure constant slant for interior vertex normals
    const slant = Math.atan2(bottomRadius - topRadius, height);
    const sinSlant = Math.sin(slant);
    const cosSlant = Math.cos(slant);
    let yy, ii, jj;
    for (yy = start; yy <= end; ++yy) {
      let v = yy / detailY;
      let y = height * v;
      let ringRadius;
      if (yy < 0) {
        //for the bottomCap edge
        y = 0;
        v = 0;
        ringRadius = bottomRadius;
      } else if (yy > detailY) {
        //for the topCap edge
        y = height;
        v = 1;
        ringRadius = topRadius;
      } else {
        //for the middle
        ringRadius = bottomRadius + (topRadius - bottomRadius) * v;
      }
      if (yy === -2 || yy === detailY + 2) {
        //center of bottom or top caps
        ringRadius = 0;
      }

      y -= height / 2; //shift coordiate origin to the center of object
      for (ii = 0; ii < detailX; ++ii) {
        const u = ii / (detailX - 1);
        const ur = 2 * Math.PI * u;
        const sur = Math.sin(ur);
        const cur = Math.cos(ur);

        //VERTICES
        this.vertices.push(new Vector(sur * ringRadius, y, cur * ringRadius));

        //VERTEX NORMALS
        let vertexNormal;
        if (yy < 0) {
          vertexNormal = new Vector(0, -1, 0);
        } else if (yy > detailY && topRadius) {
          vertexNormal = new Vector(0, 1, 0);
        } else {
          vertexNormal = new Vector(sur * cosSlant, sinSlant, cur * cosSlant);
        }
        this.vertexNormals.push(vertexNormal);
        //UVs
        this.uvs.push(u, v);
      }
    }

    let startIndex = 0;
    if (bottomCap) {
      for (jj = 0; jj < detailX; ++jj) {
        const nextjj = (jj + 1) % detailX;
        this.faces.push([
          startIndex + jj,
          startIndex + detailX + nextjj,
          startIndex + detailX + jj
        ]);
      }
      startIndex += detailX * 2;
    }
    for (yy = 0; yy < detailY; ++yy) {
      for (ii = 0; ii < detailX; ++ii) {
        const nextii = (ii + 1) % detailX;
        this.faces.push([
          startIndex + ii,
          startIndex + nextii,
          startIndex + detailX + nextii
        ]);
        this.faces.push([
          startIndex + ii,
          startIndex + detailX + nextii,
          startIndex + detailX + ii
        ]);
      }
      startIndex += detailX;
    }
    if (topCap) {
      startIndex += detailX;
      for (ii = 0; ii < detailX; ++ii) {
        this.faces.push([
          startIndex + ii,
          startIndex + (ii + 1) % detailX,
          startIndex + detailX
        ]);
      }
    }
  };

  RendererGL.prototype.plane = function(
    width = 50,
    height = width,
    detailX = 1,
    detailY = 1
  ) {
    const gid = `plane|${detailX}|${detailY}`;

    if (!this.geometryInHash(gid)) {
      const _plane = function() {
        let u, v, p;
        for (let i = 0; i <= this.detailY; i++) {
          v = i / this.detailY;
          for (let j = 0; j <= this.detailX; j++) {
            u = j / this.detailX;
            p = new Vector(u - 0.5, v - 0.5, 0);
            this.vertices.push(p);
            this.uvs.push(u, v);
          }
        }
      };
      const planeGeom = new Geometry(detailX, detailY, _plane, this);
      planeGeom.computeFaces().computeNormals();
      if (detailX <= 1 && detailY <= 1) {
        planeGeom._makeTriangleEdges()._edgesToVertices();
      } else if (this.states.strokeColor) {
        console.log(
          'Cannot draw stroke on plane objects with more' +
          ' than 1 detailX or 1 detailY'
        );
      }
      planeGeom.gid = gid;
      this.geometryBufferCache.ensureCached(planeGeom);
    }

    this._drawGeometryScaled(this.geometryBufferCache.getGeometryByID(gid), width, height, 1);
  };

  RendererGL.prototype.box = function(
    width = 50,
    height = width,
    depth = height,
    detailX,
    detailY
  ){
    const perPixelLighting =
      this.attributes && this.attributes.perPixelLighting;
    if (typeof detailX === 'undefined') {
      detailX = perPixelLighting ? 1 : 4;
    }
    if (typeof detailY === 'undefined') {
      detailY = perPixelLighting ? 1 : 4;
    }

    const gid = `box|${detailX}|${detailY}`;
    if (!this.geometryInHash(gid)) {
      const _box = function() {
        const cubeIndices = [
          [0, 4, 2, 6], // -1, 0, 0],// -x
          [1, 3, 5, 7], // +1, 0, 0],// +x
          [0, 1, 4, 5], // 0, -1, 0],// -y
          [2, 6, 3, 7], // 0, +1, 0],// +y
          [0, 2, 1, 3], // 0, 0, -1],// -z
          [4, 5, 6, 7] // 0, 0, +1] // +z
        ];
        //using custom edges
        //to avoid diagonal stroke lines across face of box
        this.edges = [
          [0, 1],
          [1, 3],
          [3, 2],
          [6, 7],
          [8, 9],
          [9, 11],
          [14, 15],
          [16, 17],
          [17, 19],
          [18, 19],
          [20, 21],
          [22, 23]
        ];

        cubeIndices.forEach((cubeIndex, i) => {
          const v = i * 4;
          for (let j = 0; j < 4; j++) {
            const d = cubeIndex[j];
            //inspired by lightgl:
            //https://github.com/evanw/lightgl.js
            //octants:https://en.wikipedia.org/wiki/Octant_(solid_geometry)
            const octant = new Vector(
              ((d & 1) * 2 - 1) / 2,
              ((d & 2) - 1) / 2,
              ((d & 4) / 2 - 1) / 2
            );
            this.vertices.push(octant);
            this.uvs.push(j & 1, (j & 2) / 2);
          }
          this.faces.push([v, v + 1, v + 2]);
          this.faces.push([v + 2, v + 1, v + 3]);
        });
      };
      const boxGeom = new Geometry(detailX, detailY, _box, this);
      boxGeom.computeNormals();
      if (detailX <= 4 && detailY <= 4) {
        boxGeom._edgesToVertices();
      } else if (this.states.strokeColor) {
        console.log(
          'Cannot draw stroke on box objects with more' +
          ' than 4 detailX or 4 detailY'
        );
      }
      //initialize our geometry buffer with
      //the key val pair:
      //geometry Id, Geom object
      boxGeom.gid = gid;
      this.geometryBufferCache.ensureCached(boxGeom);
    }
    this._drawGeometryScaled(this.geometryBufferCache.getGeometryByID(gid), width, height, depth);
  };

  RendererGL.prototype.sphere = function(
    radius = 50,
    detailX = 24,
    detailY = 16
  ) {
    this.ellipsoid(radius, radius, radius, detailX, detailY);
  };

  RendererGL.prototype.ellipsoid = function(
    radiusX = 50,
    radiusY = radiusX,
    radiusZ = radiusX,
    detailX = 24,
    detailY = 16
  ) {
    const gid = `ellipsoid|${detailX}|${detailY}`;

    if (!this.geometryInHash(gid)) {
      const _ellipsoid = function() {
        for (let i = 0; i <= this.detailY; i++) {
          const v = i / this.detailY;
          const phi = Math.PI * v - Math.PI / 2;
          const cosPhi = Math.cos(phi);
          const sinPhi = Math.sin(phi);

          for (let j = 0; j <= this.detailX; j++) {
            const u = j / this.detailX;
            const theta = 2 * Math.PI * u;
            const cosTheta = Math.cos(theta);
            const sinTheta = Math.sin(theta);
            const p = new p5.Vector(cosPhi * sinTheta, sinPhi, cosPhi * cosTheta);
            this.vertices.push(p);
            this.vertexNormals.push(p);
            this.uvs.push(u, v);
          }
        }
      };
      const ellipsoidGeom = new Geometry(detailX, detailY, _ellipsoid, this);
      ellipsoidGeom.computeFaces();
      if (detailX <= 24 && detailY <= 24) {
        ellipsoidGeom._makeTriangleEdges()._edgesToVertices();
      } else if (this.states.strokeColor) {
        console.log(
          'Cannot draw stroke on ellipsoids with more' +
          ' than 24 detailX or 24 detailY'
        );
      }
      ellipsoidGeom.gid = gid;
      this.geometryBufferCache.ensureCached(ellipsoidGeom);
    }

    this._drawGeometryScaled(this.geometryBufferCache.getGeometryByID(gid), radiusX, radiusY, radiusZ);
  };

  RendererGL.prototype.cylinder = function(
    radius = 50,
    height = radius,
    detailX = 24,
    detailY = 1,
    bottomCap = true,
    topCap = true
  ) {
    const gid = `cylinder|${detailX}|${detailY}|${bottomCap}|${topCap}`;
    if (!this.geometryInHash(gid)) {
      const cylinderGeom = new p5.Geometry(detailX, detailY, function() {
        _truncatedCone.call(
          this,
          1,
          1,
          1,
          detailX,
          detailY,
          bottomCap,
          topCap
        );
      }, this);
      // normals are computed in call to _truncatedCone
      if (detailX <= 24 && detailY <= 16) {
        cylinderGeom._makeTriangleEdges()._edgesToVertices();
      } else if (this.states.strokeColor) {
        console.log(
          'Cannot draw stroke on cylinder objects with more' +
          ' than 24 detailX or 16 detailY'
        );
      }
      cylinderGeom.gid = gid;
      this.geometryBufferCache.ensureCached(cylinderGeom);
    }

    this._drawGeometryScaled(this.geometryBufferCache.getGeometryByID(gid), radius, height, radius);
  };

  RendererGL.prototype.cone = function(
    radius = 50,
    height = radius,
    detailX = 24,
    detailY = 1,
    cap = true
  ) {
    const gid = `cone|${detailX}|${detailY}|${cap}`;
    if (!this.geometryInHash(gid)) {
      const coneGeom = new Geometry(detailX, detailY, function() {
        _truncatedCone.call(
          this,
          1,
          0,
          1,
          detailX,
          detailY,
          cap,
          false
        );
      }, this);
      if (detailX <= 24 && detailY <= 16) {
        coneGeom._makeTriangleEdges()._edgesToVertices();
      } else if (this.states.strokeColor) {
        console.log(
          'Cannot draw stroke on cone objects with more' +
          ' than 24 detailX or 16 detailY'
        );
      }
      coneGeom.gid = gid;
      this.geometryBufferCache.ensureCached(coneGeom);
    }

    this._drawGeometryScaled(this.geometryBufferCache.getGeometryByID(gid), radius, height, radius);
  };

  RendererGL.prototype.torus = function(
    radius = 50,
    tubeRadius = 10,
    detailX = 24,
    detailY = 16
  ) {
    if (radius === 0) {
      return; // nothing to draw
    }

    if (tubeRadius === 0) {
      return; // nothing to draw
    }

    const tubeRatio = (tubeRadius / radius).toPrecision(4);
    const gid = `torus|${tubeRatio}|${detailX}|${detailY}`;

    if (!this.geometryInHash(gid)) {
      const _torus = function() {
        for (let i = 0; i <= this.detailY; i++) {
          const v = i / this.detailY;
          const phi = 2 * Math.PI * v;
          const cosPhi = Math.cos(phi);
          const sinPhi = Math.sin(phi);
          const r = 1 + tubeRatio * cosPhi;

          for (let j = 0; j <= this.detailX; j++) {
            const u = j / this.detailX;
            const theta = 2 * Math.PI * u;
            const cosTheta = Math.cos(theta);
            const sinTheta = Math.sin(theta);

            const p = new Vector(
              r * cosTheta,
              r * sinTheta,
              tubeRatio * sinPhi
            );

            const n = new Vector(cosPhi * cosTheta, cosPhi * sinTheta, sinPhi);

            this.vertices.push(p);
            this.vertexNormals.push(n);
            this.uvs.push(u, v);
          }
        }
      };
      const torusGeom = new Geometry(detailX, detailY, _torus, this);
      torusGeom.computeFaces();
      if (detailX <= 24 && detailY <= 16) {
        torusGeom._makeTriangleEdges()._edgesToVertices();
      } else if (this.states.strokeColor) {
        console.log(
          'Cannot draw strokes on torus object with more' +
          ' than 24 detailX or 16 detailY'
        );
      }
      torusGeom.gid = gid;
      this.geometryBufferCache.ensureCached(torusGeom);
    }
    this._drawGeometryScaled(this.geometryBufferCache.getGeometryByID(gid), radius, radius, radius);
  };

  /**
   * Sets the number of segments used to draw spline curves in WebGL mode.
   *
   * In WebGL mode, smooth shapes are drawn using many flat segments. Adding
   * more flat segments makes shapes appear smoother.
   *
   * The parameter, `detail`, is the density of segments to use while drawing a
   * spline curve.
   *
   * Note: `curveDetail()` has no effect in 2D mode.
   *
   * @method curveDetail
   * @param {Number} resolution number of segments to use. Default is 1/4
   * @chainable
   *
   * @example
   *
   * <div>
   * <code>
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   background(200);
   *
   *   // Set the curveDetail() to 0.5
   *   curveDetail(0.5);
   * 
   *   // Do not show all the vertices
   *   splineProperty('ends', EXCLUDE)
   *
   *   // Draw a black spline curve.
   *   noFill();
   *   strokeWeight(1);
   *   stroke(0);
   *   spline(-45, -24, 0, 23, -26, 0, 23, 11, 0, -35, 15, 0);
   *
   *   // Draw red spline curves from the anchor points to the control points.
   *   spline(255, 0, 0);
   *   spline(-45, -24, 0, -45, -24, 0, 23, -26, 0, 23, 11, 0);
   *   spline(23, -26, 0, 23, 11, 0, -35, 15, 0, -35, 15, 0);
   *
   *   // Draw the anchor points in black.
   *   strokeWeight(5);
   *   stroke(0);
   *   point(23, -26);
   *   point(23, 11);
   *
   *   // Draw the control points in red.
   *   stroke(255, 0, 0);
   *   point(-45, -24);
   *   point(-35, 15);
   *
   *   describe(
   *     'A gray square with a jagged curve drawn in three segments. The curve is a sideways U shape with red segments on top and bottom, and a black segment on the right. The endpoints of all the segments are marked with dots.'
   *   );
   * }
   * </code>
   * </div>
   */
  fn.curveDetail = function(d) {
    if (!(this._renderer instanceof RendererGL)) {
      throw new Error(
        'curveDetail() only works in WebGL mode. Did you mean to call createCanvas(width, height, WEBGL)?'
      );
    }
    return this._renderer.curveDetail(d);
  };
}

if(typeof p5 !== 'undefined'){
  primitives3D(p5, p5.prototype);
}

/**
 * @module 3D
 * @submodule Lights
 * @for p5
 * @requires core
 */


function light(p5, fn){
  /**
   * Creates a light that shines from all directions.
   *
   * Ambient light does not come from one direction. Instead, 3D shapes are
   * lit evenly from all sides. Ambient lights are almost always used in
   * combination with other types of lights.
   *
   * There are three ways to call `ambientLight()` with optional parameters to
   * set the lights color.
   *
   * The first way to call `ambientLight()` has two parameters, `gray` and
   * `alpha`. `alpha` is optional. Grayscale and alpha values between 0 and 255
   * can be passed to set the ambient lights color, as in `ambientLight(50)` or
   * `ambientLight(50, 30)`.
   *
   * The second way to call `ambientLight()` has one parameter, color. A
   * <a href="#/p5.Color">p5.Color</a> object, an array of color values, or a
   * CSS color string, as in `ambientLight('magenta')`, can be passed to set the
   * ambient lights color.
   *
   * The third way to call `ambientLight()` has four parameters, `v1`, `v2`,
   * `v3`, and `alpha`. `alpha` is optional. RGBA, HSBA, or HSLA values can be
   * passed to set the ambient lights colors, as in `ambientLight(255, 0, 0)`
   * or `ambientLight(255, 0, 0, 30)`. Color values will be interpreted using
   * the current <a href="#/p5/colorMode">colorMode()</a>.
   *
   * @method ambientLight
   * @param  {Number}        v1 red or hue value in the current
   *                            <a href="#/p5/colorMode">colorMode()</a>.
   * @param  {Number}        v2 green or saturation value in the current
   *                            <a href="#/p5/colorMode">colorMode()</a>.
   * @param  {Number}        v3 blue, brightness, or lightness value in the current
   *                            <a href="#/p5/colorMode">colorMode()</a>.
   * @param  {Number}        [alpha] alpha (transparency) value in the current
   *                                 <a href="#/p5/colorMode">colorMode()</a>.
   * @chainable
   *
   * @example
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   * // Double-click the canvas to turn on the light.
   *
   * let isLit = false;
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A sphere drawn against a gray background. The sphere appears to change color when the user double-clicks.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Control the light.
   *   if (isLit === true) {
   *     // Use a grayscale value of 80.
   *     ambientLight(80);
   *   }
   *
   *   // Draw the sphere.
   *   sphere(30);
   * }
   *
   * // Turn on the ambient light when the user double-clicks.
   * function doubleClicked() {
   *   isLit = true;
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A faded magenta sphere drawn against a gray background.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Turn on the lights.
   *   // Use a p5.Color object.
   *   let c = color('orchid');
   *   ambientLight(c);
   *
   *   // Draw the sphere.
   *   sphere();
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A faded magenta sphere drawn against a gray background.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Turn on the lights.
   *   // Use a CSS color string.
   *   ambientLight('#DA70D6');
   *
   *   // Draw the sphere.
   *   sphere(30);
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A faded magenta sphere drawn against a gray background.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Turn on the lights.
   *   // Use RGB values
   *   ambientLight(218, 112, 214);
   *
   *   // Draw the sphere.
   *   sphere(30);
   * }
   * </code>
   * </div>
   */

  /**
   * @method ambientLight
   * @param  {Number}        gray  grayscale value between 0 and 255.
   * @param  {Number}        [alpha]
   * @chainable
   */

  /**
   * @method ambientLight
   * @param  {String}        value color as a CSS string.
   * @chainable
   */

  /**
   * @method ambientLight
   * @param  {Number[]}      values color as an array of RGBA, HSBA, or HSLA
   *                                 values.
   * @chainable
   */

  /**
   * @method ambientLight
   * @param  {p5.Color}      color color as a <a href="#/p5.Color">p5.Color</a> object.
   * @chainable
   */
  fn.ambientLight = function (v1, v2, v3, a) {
    this._assert3d('ambientLight');
    // p5._validateParameters('ambientLight', arguments);

    this._renderer.ambientLight(...arguments);

    return this;
  };

  /**
   * Sets the specular color for lights.
   *
   * `specularColor()` affects lights that bounce off a surface in a preferred
   * direction. These lights include
   * <a href="#/p5/directionalLight">directionalLight()</a>,
   * <a href="#/p5/pointLight">pointLight()</a>, and
   * <a href="#/p5/spotLight">spotLight()</a>. The function helps to create
   * highlights on <a href="#/p5.Geometry">p5.Geometry</a> objects that are
   * styled with <a href="#/p5/specularMaterial">specularMaterial()</a>. If a
   * geometry does not use
   * <a href="#/p5/specularMaterial">specularMaterial()</a>, then
   * `specularColor()` will have no effect.
   *
   * Note: `specularColor()` doesnt affect lights that bounce in all
   * directions, including <a href="#/p5/ambientLight">ambientLight()</a> and
   * <a href="#/p5/imageLight">imageLight()</a>.
   *
   * There are three ways to call `specularColor()` with optional parameters to
   * set the specular highlight color.
   *
   * The first way to call `specularColor()` has two optional parameters, `gray`
   * and `alpha`. Grayscale and alpha values between 0 and 255, as in
   * `specularColor(50)` or `specularColor(50, 80)`, can be passed to set the
   * specular highlight color.
   *
   * The second way to call `specularColor()` has one optional parameter,
   * `color`. A <a href="#/p5.Color">p5.Color</a> object, an array of color
   * values, or a CSS color string can be passed to set the specular highlight
   * color.
   *
   * The third way to call `specularColor()` has four optional parameters, `v1`,
   * `v2`, `v3`, and `alpha`. RGBA, HSBA, or HSLA values, as in
   * `specularColor(255, 0, 0, 80)`, can be passed to set the specular highlight
   * color. Color values will be interpreted using the current
   * <a href="#/p5/colorMode">colorMode()</a>.
   *
   * @method specularColor
   * @param  {Number}        v1 red or hue value in the current
   *                            <a href="#/p5/colorMode">colorMode()</a>.
   * @param  {Number}        v2 green or saturation value in the current
   *                            <a href="#/p5/colorMode">colorMode()</a>.
   * @param  {Number}        v3 blue, brightness, or lightness value in the current
   *                            <a href="#/p5/colorMode">colorMode()</a>.
   * @chainable
   *
   * @example
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A white sphere drawn on a gray background.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // No specular color.
   *   // Draw the sphere.
   *   sphere(30);
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   * // Double-click the canvas to add a point light.
   *
   * let isLit = false;
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A sphere drawn on a gray background. A spotlight starts shining when the user double-clicks.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Style the sphere.
   *   noStroke();
   *   specularColor(100);
   *   specularMaterial(255, 255, 255);
   *
   *   // Control the light.
   *   if (isLit === true) {
   *     // Add a white point light from the top-right.
   *     pointLight(255, 255, 255, 30, -20, 40);
   *   }
   *
   *   // Draw the sphere.
   *   sphere(30);
   * }
   *
   * // Turn on the point light when the user double-clicks.
   * function doubleClicked() {
   *   isLit = true;
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A black sphere drawn on a gray background. An area on the surface of the sphere is highlighted in blue.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Add a specular highlight.
   *   // Use a p5.Color object.
   *   let c = color('dodgerblue');
   *   specularColor(c);
   *
   *   // Add a white point light from the top-right.
   *   pointLight(255, 255, 255, 30, -20, 40);
   *
   *   // Style the sphere.
   *   noStroke();
   *
   *   // Add a white specular material.
   *   specularMaterial(255, 255, 255);
   *
   *   // Draw the sphere.
   *   sphere(30);
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A black sphere drawn on a gray background. An area on the surface of the sphere is highlighted in blue.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Add a specular highlight.
   *   // Use a CSS color string.
   *   specularColor('#1E90FF');
   *
   *   // Add a white point light from the top-right.
   *   pointLight(255, 255, 255, 30, -20, 40);
   *
   *   // Style the sphere.
   *   noStroke();
   *
   *   // Add a white specular material.
   *   specularMaterial(255, 255, 255);
   *
   *   // Draw the sphere.
   *   sphere(30);
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A black sphere drawn on a gray background. An area on the surface of the sphere is highlighted in blue.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Add a specular highlight.
   *   // Use RGB values.
   *   specularColor(30, 144, 255);
   *
   *   // Add a white point light from the top-right.
   *   pointLight(255, 255, 255, 30, -20, 40);
   *
   *   // Style the sphere.
   *   noStroke();
   *
   *   // Add a white specular material.
   *   specularMaterial(255, 255, 255);
   *
   *   // Draw the sphere.
   *   sphere(30);
   * }
   * </code>
   * </div>
   */

  /**
   * @method specularColor
   * @param  {Number}        gray grayscale value between 0 and 255.
   * @chainable
   */

  /**
   * @method specularColor
   * @param  {String}        value color as a CSS string.
   * @chainable
   */

  /**
   * @method specularColor
   * @param  {Number[]}      values color as an array of RGBA, HSBA, or HSLA
   *                                 values.
   * @chainable
   */

  /**
   * @method specularColor
   * @param  {p5.Color}      color color as a <a href="#/p5.Color">p5.Color</a> object.
   * @chainable
   */
  fn.specularColor = function (v1, v2, v3) {
    this._assert3d('specularColor');
    // p5._validateParameters('specularColor', arguments);

    this._renderer.specularColor(...arguments);

    return this;
  };

  /**
   * Creates a light that shines in one direction.
   *
   * Directional lights dont shine from a specific point. Theyre like a sun
   * that shines from somewhere offscreen. The lights direction is set using
   * three `(x, y, z)` values between -1 and 1. For example, setting a lights
   * direction as `(1, 0, 0)` will light <a href="#/p5.Geometry">p5.Geometry</a>
   * objects from the left since the light faces directly to the right. A
   * maximum of 5 directional lights can be active at once.
   *
   * There are four ways to call `directionalLight()` with parameters to set the
   * lights color and direction.
   *
   * The first way to call `directionalLight()` has six parameters. The first
   * three parameters, `v1`, `v2`, and `v3`, set the lights color using the
   * current <a href="#/p5/colorMode">colorMode()</a>. The last three
   * parameters, `x`, `y`, and `z`, set the lights direction. For example,
   * `directionalLight(255, 0, 0, 1, 0, 0)` creates a red `(255, 0, 0)` light
   * that shines to the right `(1, 0, 0)`.
   *
   * The second way to call `directionalLight()` has four parameters. The first
   * three parameters, `v1`, `v2`, and `v3`, set the lights color using the
   * current <a href="#/p5/colorMode">colorMode()</a>. The last parameter,
   * `direction` sets the lights direction using a
   * <a href="#/p5.Vector">p5.Vector</a> object. For example,
   * `directionalLight(255, 0, 0, lightDir)` creates a red `(255, 0, 0)` light
   * that shines in the direction the `lightDir` vector points.
   *
   * The third way to call `directionalLight()` has four parameters. The first
   * parameter, `color`, sets the lights color using a
   * <a href="#/p5.Color">p5.Color</a> object or an array of color values. The
   * last three parameters, `x`, `y`, and `z`, set the lights direction. For
   * example, `directionalLight(myColor, 1, 0, 0)` creates a light that shines
   * to the right `(1, 0, 0)` with the color value of `myColor`.
   *
   * The fourth way to call `directionalLight()` has two parameters. The first
   * parameter, `color`, sets the lights color using a
   * <a href="#/p5.Color">p5.Color</a> object or an array of color values. The
   * second parameter, `direction`, sets the lights direction using a
   * <a href="#/p5.Vector">p5.Vector</a> object. For example,
   * `directionalLight(myColor, lightDir)` creates a light that shines in the
   * direction the `lightDir` vector points with the color value of `myColor`.
   *
   * @method directionalLight
   * @param  {Number}    v1 red or hue value in the current
   *                        <a href="#/p5/colorMode">colorMode()</a>.
   * @param  {Number}    v2 green or saturation value in the current
   *                        <a href="#/p5/colorMode">colorMode()</a>.
   * @param  {Number}    v3 blue, brightness, or lightness value in the current
   *                        <a href="#/p5/colorMode">colorMode()</a>.
   * @param  {Number}    x  x-component of the light's direction between -1 and 1.
   * @param  {Number}    y  y-component of the light's direction between -1 and 1.
   * @param  {Number}    z  z-component of the light's direction between -1 and 1.
   * @chainable
   *
   * @example
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   * // Double-click to turn on the directional light.
   *
   * let isLit = false;
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A sphere drawn on a gray background. A red light starts shining from above when the user double-clicks.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Control the light.
   *   if (isLit === true) {
   *     // Add a red directional light from above.
   *     // Use RGB values and XYZ directions.
   *     directionalLight(255, 0, 0, 0, 1, 0);
   *   }
   *
   *   // Style the sphere.
   *   noStroke();
   *
   *   // Draw the sphere.
   *   sphere(30);
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A sphere drawn on a gray background. The top of the sphere appears bright red. The color gets darker toward the bottom.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Add a red directional light from above.
   *   // Use a p5.Color object and XYZ directions.
   *   let c = color(255, 0, 0);
   *   directionalLight(c, 0, 1, 0);
   *
   *   // Style the sphere.
   *   noStroke();
   *
   *   // Draw the sphere.
   *   sphere(30);
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A sphere drawn on a gray background. The top of the sphere appears bright red. The color gets darker toward the bottom.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Add a red directional light from above.
   *   // Use a p5.Color object and a p5.Vector object.
   *   let c = color(255, 0, 0);
   *   let lightDir = createVector(0, 1, 0);
   *   directionalLight(c, lightDir);
   *
   *   // Style the sphere.
   *   noStroke();
   *
   *   // Draw the sphere.
   *   sphere(30);
   * }
   * </code>
   * </div>
   */

  /**
   * @method directionalLight
   * @param  {Number}    v1
   * @param  {Number}    v2
   * @param  {Number}    v3
   * @param  {p5.Vector} direction direction of the light as a
   *                               <a href="#/p5.Vector">p5.Vector</a> object.
   * @chainable
   */

  /**
   * @method directionalLight
   * @param  {p5.Color|Number[]|String} color color as a <a href="#/p5.Color">p5.Color</a> object,
   *                                           an array of color values, or as a CSS string.
   * @param  {Number}                   x
   * @param  {Number}                   y
   * @param  {Number}                   z
   * @chainable
   */

  /**
   * @method directionalLight
   * @param  {p5.Color|Number[]|String} color
   * @param  {p5.Vector}                direction
   * @chainable
   */
  fn.directionalLight = function (v1, v2, v3, x, y, z) {
    this._assert3d('directionalLight');
    // p5._validateParameters('directionalLight', arguments);

    //@TODO: check parameters number
    this._renderer.directionalLight(...arguments);

    return this;
  };

  /**
   * Creates a light that shines from a point in all directions.
   *
   * Point lights are like light bulbs that shine in all directions. They can be
   * placed at different positions to achieve different lighting effects. A
   * maximum of 5 point lights can be active at once.
   *
   * There are four ways to call `pointLight()` with parameters to set the
   * lights color and position.
   *
   * The first way to call `pointLight()` has six parameters. The first three
   * parameters, `v1`, `v2`, and `v3`, set the lights color using the current
   * <a href="#/p5/colorMode">colorMode()</a>. The last three parameters, `x`,
   * `y`, and `z`, set the lights position. For example,
   * `pointLight(255, 0, 0, 50, 0, 0)` creates a red `(255, 0, 0)` light that
   * shines from the coordinates `(50, 0, 0)`.
   *
   * The second way to call `pointLight()` has four parameters. The first three
   * parameters, `v1`, `v2`, and `v3`, set the lights color using the current
   * <a href="#/p5/colorMode">colorMode()</a>. The last parameter, position sets
   * the lights position using a <a href="#/p5.Vector">p5.Vector</a> object.
   * For example, `pointLight(255, 0, 0, lightPos)` creates a red `(255, 0, 0)`
   * light that shines from the position set by the `lightPos` vector.
   *
   * The third way to call `pointLight()` has four parameters. The first
   * parameter, `color`, sets the lights color using a
   * <a href="#/p5.Color">p5.Color</a> object or an array of color values. The
   * last three parameters, `x`, `y`, and `z`, set the lights position. For
   * example, `directionalLight(myColor, 50, 0, 0)` creates a light that shines
   * from the coordinates `(50, 0, 0)` with the color value of `myColor`.
   *
   * The fourth way to call `pointLight()` has two parameters. The first
   * parameter, `color`, sets the lights color using a
   * <a href="#/p5.Color">p5.Color</a> object or an array of color values. The
   * second parameter, `position`, sets the lights position using a
   * <a href="#/p5.Vector">p5.Vector</a> object. For example,
   * `directionalLight(myColor, lightPos)` creates a light that shines from the
   * position set by the `lightPos` vector with the color value of `myColor`.
   *
   * @method pointLight
   * @param  {Number}    v1 red or hue value in the current
   *                        <a href="#/p5/colorMode">colorMode()</a>.
   * @param  {Number}    v2 green or saturation value in the current
   *                        <a href="#/p5/colorMode">colorMode()</a>.
   * @param  {Number}    v3 blue, brightness, or lightness value in the current
   *                        <a href="#/p5/colorMode">colorMode()</a>.
   * @param  {Number}    x  x-coordinate of the light.
   * @param  {Number}    y  y-coordinate of the light.
   * @param  {Number}    z  z-coordinate of the light.
   * @chainable
   *
   * @example
   *
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   * // Double-click to turn on the point light.
   *
   * let isLit = false;
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A sphere drawn on a gray background. A red light starts shining from above when the user double-clicks.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Control the light.
   *   if (isLit === true) {
   *     // Add a red point light from above.
   *     // Use RGB values and XYZ coordinates.
   *     pointLight(255, 0, 0, 0, -150, 0);
   *   }
   *
   *   // Style the sphere.
   *   noStroke();
   *
   *   // Draw the sphere.
   *   sphere(30);
   * }
   *
   * // Turn on the point light when the user double-clicks.
   * function doubleClicked() {
   *   isLit = true;
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A sphere drawn on a gray background. The top of the sphere appears bright red. The color gets darker toward the bottom.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Add a red point light from above.
   *   // Use a p5.Color object and XYZ directions.
   *   let c = color(255, 0, 0);
   *   pointLight(c, 0, -150, 0);
   *
   *   // Style the sphere.
   *   noStroke();
   *
   *   // Draw the sphere.
   *   sphere(30);
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A sphere drawn on a gray background. The top of the sphere appears bright red. The color gets darker toward the bottom.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Add a red point light from above.
   *   // Use a p5.Color object and a p5.Vector object.
   *   let c = color(255, 0, 0);
   *   let lightPos = createVector(0, -150, 0);
   *   pointLight(c, lightPos);
   *
   *   // Style the sphere.
   *   noStroke();
   *
   *   // Draw the sphere.
   *   sphere(30);
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('Four spheres arranged in a square and drawn on a gray background. The spheres appear bright red toward the center of the square. The color gets darker toward the corners of the square.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Add a red point light that points to the center of the scene.
   *   // Use a p5.Color object and a p5.Vector object.
   *   let c = color(255, 0, 0);
   *   let lightPos = createVector(0, 0, 65);
   *   pointLight(c, lightPos);
   *
   *   // Style the spheres.
   *   noStroke();
   *
   *   // Draw a sphere up and to the left.
   *   push();
   *   translate(-25, -25, 25);
   *   sphere(10);
   *   pop();
   *
   *   // Draw a box up and to the right.
   *   push();
   *   translate(25, -25, 25);
   *   sphere(10);
   *   pop();
   *
   *   // Draw a sphere down and to the left.
   *   push();
   *   translate(-25, 25, 25);
   *   sphere(10);
   *   pop();
   *
   *   // Draw a box down and to the right.
   *   push();
   *   translate(25, 25, 25);
   *   sphere(10);
   *   pop();
   * }
   * </code>
   * </div>
   */

  /**
   * @method pointLight
   * @param  {Number}     v1
   * @param  {Number}     v2
   * @param  {Number}     v3
   * @param  {p5.Vector}  position position of the light as a
   *                               <a href="#/p5.Vector">p5.Vector</a> object.
   * @chainable
   */

  /**
   * @method pointLight
   * @param  {p5.Color|Number[]|String} color color as a <a href="#/p5.Color">p5.Color</a> object,
   *                                          an array of color values, or a CSS string.
   * @param  {Number}                   x
   * @param  {Number}                   y
   * @param  {Number}                   z
   * @chainable
   */

  /**
   * @method pointLight
   * @param  {p5.Color|Number[]|String} color
   * @param  {p5.Vector}                position
   * @chainable
   */
  fn.pointLight = function (v1, v2, v3, x, y, z) {
    this._assert3d('pointLight');
    // p5._validateParameters('pointLight', arguments);

    //@TODO: check parameters number
    this._renderer.pointLight(...arguments);

    return this;
  };

  /**
   * Creates an ambient light from an image.
   *
   * `imageLight()` simulates a light shining from all directions. The effect is
   * like placing the sketch at the center of a giant sphere that uses the image
   * as its texture. The image's diffuse light will be affected by
   * <a href="#/p5/fill">fill()</a> and the specular reflections will be
   * affected by <a href="#/p5/specularMaterial">specularMaterial()</a> and
   * <a href="#/p5/shininess">shininess()</a>.
   *
   * The parameter, `img`, is the <a href="#/p5.Image">p5.Image</a> object to
   * use as the light source.
   *
   * @method imageLight
   * @param  {p5.image}    img image to use as the light source.
   *
   * @example
   * <div class="notest">
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   *
   * let img;
   *
   * async function setup() {
   *   // Load an image and create a p5.Image object.
   *   img = await loadImage('assets/outdoor_spheremap.jpg');
   *
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A sphere floating above a landscape. The surface of the sphere reflects the landscape.');
   * }
   *
   * function draw() {
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Draw the image as a panorama (360 background).
   *   panorama(img);
   *
   *   // Add a soft ambient light.
   *   ambientLight(50);
   *
   *   // Add light from the image.
   *   imageLight(img);
   *
   *   // Style the sphere.
   *   specularMaterial(20);
   *   shininess(100);
   *   noStroke();
   *
   *   // Draw the sphere.
   *   sphere(30);
   * }
   * </code>
   * </div>
   */
  fn.imageLight = function (img) {
    this._renderer.imageLight(img);
  };

  /**
   * Creates an immersive 3D background.
   *
   * `panorama()` transforms images containing 360 content, such as maps or
   * HDRIs, into immersive 3D backgrounds that surround a sketch. Exploring the
   * space requires changing the camera's perspective with functions such as
   * <a href="#/p5/orbitControl">orbitControl()</a> or
   * <a href="#/p5/camera">camera()</a>.
   *
   * @method panorama
   * @param {p5.Image} img 360 image to use as the background.
   *
   * @example
   * <div class="notest">
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   *
   * let img;
   *
   * async function setup() {
   *   // Load an image and create a p5.Image object.
   *   img = await loadImage('assets/outdoor_spheremap.jpg');
   *
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A sphere floating above a landscape. The surface of the sphere reflects the landscape. The full landscape is viewable in 3D as the user drags the mouse.');
   * }
   *
   * function draw() {
   *   // Add the panorama.
   *   panorama(img);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Use the image as a light source.
   *   imageLight(img);
   *
   *   // Style the sphere.
   *   noStroke();
   *   specularMaterial(50);
   *   shininess(200);
   *   metalness(100);
   *
   *   // Draw the sphere.
   *   sphere(30);
   * }
   * </code>
   * </div>
   */
  fn.panorama = function (img) {
    this.filter(this._renderer._getSphereMapping(img));
  };

  /**
   * Places an ambient and directional light in the scene.
   * The lights are set to ambientLight(128, 128, 128) and
   * directionalLight(128, 128, 128, 0, 0, -1).
   *
   * Note: lights need to be called (whether directly or indirectly)
   * within draw() to remain persistent in a looping program.
   * Placing them in setup() will cause them to only have an effect
   * the first time through the loop.
   *
   * @method lights
   * @chainable
   *
   * @example
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   * // Double-click to turn on the lights.
   *
   * let isLit = false;
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A white box drawn against a gray background. The quality of the light changes when the user double-clicks.');
   * }
   *
   * function draw() {
   *   background(50);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Control the lights.
   *   if (isLit === true) {
   *     lights();
   *   }
   *
   *   // Draw the box.
   *   box();
   * }
   *
   * // Turn on the lights when the user double-clicks.
   * function doubleClicked() {
   *   isLit = true;
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A white box drawn against a gray background.');
   * }
   *
   * function draw() {
   *   background(50);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Turn on the lights.
   *   ambientLight(128, 128, 128);
   *   directionalLight(128, 128, 128, 0, 0, -1);
   *
   *   // Draw the box.
   *   box();
   * }
   * </code>
   * </div>
   */
  fn.lights = function () {
    this._assert3d('lights');
    // Both specify gray by default.
    this._renderer.lights();
    return this;
  };

  /**
   * Sets the falloff rate for <a href="#/p5/pointLight">pointLight()</a>
   * and <a href="#/p5/spotLight">spotLight()</a>.
   *
   * A lights falloff describes the intensity of its beam at a distance. For
   * example, a lantern has a slow falloff, a flashlight has a medium falloff,
   * and a laser pointer has a sharp falloff.
   *
   * `lightFalloff()` has three parameters, `constant`, `linear`, and
   * `quadratic`. Theyre numbers used to calculate falloff at a distance, `d`,
   * as follows:
   *
   * `falloff = 1 / (constant + d * linear + (d * d) * quadratic)`
   *
   * Note: `constant`, `linear`, and `quadratic` should always be set to values
   * greater than 0.
   *
   * @method lightFalloff
   * @param {Number} constant  constant value for calculating falloff.
   * @param {Number} linear    linear value for calculating falloff.
   * @param {Number} quadratic quadratic value for calculating falloff.
   * @chainable
   *
   * @example
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   * // Double-click to change the falloff rate.
   *
   * let useFalloff = false;
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A sphere drawn against a gray background. The intensity of the light changes when the user double-clicks.');
   * }
   *
   * function draw() {
   *   background(50);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Set the light falloff.
   *   if (useFalloff === true) {
   *     lightFalloff(2, 0, 0);
   *   }
   *
   *   // Add a white point light from the front.
   *   pointLight(255, 255, 255, 0, 0, 100);
   *
   *   // Style the sphere.
   *   noStroke();
   *
   *   // Draw the sphere.
   *   sphere(30);
   * }
   *
   * // Change the falloff value when the user double-clicks.
   * function doubleClicked() {
   *   useFalloff = true;
   * }
   * </code>
   * </div>
   */
  fn.lightFalloff = function (
    constantAttenuation,
    linearAttenuation,
    quadraticAttenuation
  ) {
    this._assert3d('lightFalloff');
    // p5._validateParameters('lightFalloff', arguments);

    this._renderer.lightFalloff(
      constantAttenuation,
      linearAttenuation,
      quadraticAttenuation
    );

    return this;
  };

  /**
   * Creates a light that shines from a point in one direction.
   *
   * Spot lights are like flashlights that shine in one direction creating a
   * cone of light. The shape of the cone can be controlled using the angle and
   * concentration parameters. A maximum of 5 spot lights can be active at once.
   *
   * There are eight ways to call `spotLight()` with parameters to set the
   * lights color, position, direction. For example,
   * `spotLight(255, 0, 0, 0, 0, 0, 1, 0, 0)` creates a red `(255, 0, 0)` light
   * at the origin `(0, 0, 0)` that points to the right `(1, 0, 0)`.
   *
   * The `angle` parameter is optional. It sets the radius of the light cone.
   * For example, `spotLight(255, 0, 0, 0, 0, 0, 1, 0, 0, PI / 16)` creates a
   * red `(255, 0, 0)` light at the origin `(0, 0, 0)` that points to the right
   * `(1, 0, 0)` with an angle of `PI / 16` radians. By default, `angle` is
   * `PI / 3` radians.
   *
   * The `concentration` parameter is also optional. It focuses the light
   * towards the center of the light cone. For example,
   * `spotLight(255, 0, 0, 0, 0, 0, 1, 0, 0, PI / 16, 50)` creates a red
   * `(255, 0, 0)` light at the origin `(0, 0, 0)` that points to the right
   * `(1, 0, 0)` with an angle of `PI / 16` radians at concentration of 50. By
   * default, `concentration` is 100.
   *
   * @method spotLight
   * @param  {Number}    v1               red or hue value in the current
   *                                      <a href="#/p5/colorMode">colorMode()</a>.
   * @param  {Number}    v2               green or saturation value in the current
   *                                      <a href="#/p5/colorMode">colorMode()</a>.
   * @param  {Number}    v3               blue, brightness, or lightness value in the current
   *                                      <a href="#/p5/colorMode">colorMode()</a>.
   * @param  {Number}    x                x-coordinate of the light.
   * @param  {Number}    y                y-coordinate of the light.
   * @param  {Number}    z                z-coordinate of the light.
   * @param  {Number}    rx               x-component of light direction between -1 and 1.
   * @param  {Number}    ry               y-component of light direction between -1 and 1.
   * @param  {Number}    rz               z-component of light direction between -1 and 1.
   * @param  {Number}    [angle]          angle of the light cone. Defaults to `PI / 3`.
   * @param  {Number}    [concentration]  concentration of the light. Defaults to 100.
   * @chainable
   *
   * @example
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   * // Double-click to adjust the spotlight.
   *
   * let isLit = false;
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A white sphere drawn on a gray background. A red spotlight starts shining when the user double-clicks.');
   * }
   *
   * function draw() {
   *   background(50);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Turn on the lights.
   *   lights();
   *
   *   // Control the spotlight.
   *   if (isLit === true) {
   *     // Add a red spot light that shines into the screen.
   *     // Set its angle to PI / 32 radians.
   *     spotLight(255, 0, 0, 0, 0, 100, 0, 0, -1, PI / 32);
   *   }
   *
   *   // Draw the sphere.
   *   sphere(30);
   * }
   *
   * // Turn on the spotlight when the user double-clicks.
   * function doubleClicked() {
   *   isLit = true;
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   * // Double-click to adjust the spotlight.
   *
   * let isLit = false;
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A white sphere drawn on a gray background. A red spotlight starts shining when the user double-clicks.');
   * }
   *
   * function draw() {
   *   background(50);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Turn on the lights.
   *   lights();
   *
   *   // Control the spotlight.
   *   if (isLit === true) {
   *     // Add a red spot light that shines into the screen.
   *     // Set its angle to PI / 3 radians (default).
   *     // Set its concentration to 1000.
   *     let c = color(255, 0, 0);
   *     let position = createVector(0, 0, 100);
   *     let direction = createVector(0, 0, -1);
   *     spotLight(c, position, direction, PI / 3, 1000);
   *   }
   *
   *   // Draw the sphere.
   *   sphere(30);
   * }
   *
   * // Turn on the spotlight when the user double-clicks.
   * function doubleClicked() {
   *   isLit = true;
   * }
   * </code>
   * </div>
   */
  /**
   * @method spotLight
   * @param  {p5.Color|Number[]|String} color     color as a <a href="#/p5.Color">p5.Color</a> object,
   *                                              an array of color values, or a CSS string.
   * @param  {p5.Vector}                position  position of the light as a <a href="#/p5.Vector">p5.Vector</a> object.
   * @param  {p5.Vector}                direction direction of light as a <a href="#/p5.Vector">p5.Vector</a> object.
   * @param  {Number}                   [angle]
   * @param  {Number}                   [concentration]
   */
  /**
   * @method spotLight
   * @param  {Number}     v1
   * @param  {Number}     v2
   * @param  {Number}     v3
   * @param  {p5.Vector}  position
   * @param  {p5.Vector}  direction
   * @param  {Number}     [angle]
   * @param  {Number}     [concentration]
   */
  /**
   * @method spotLight
   * @param  {p5.Color|Number[]|String} color
   * @param  {Number}                   x
   * @param  {Number}                   y
   * @param  {Number}                   z
   * @param  {p5.Vector}                direction
   * @param  {Number}                   [angle]
   * @param  {Number}                   [concentration]
   */
  /**
   * @method spotLight
   * @param  {p5.Color|Number[]|String} color
   * @param  {p5.Vector}                position
   * @param  {Number}                   rx
   * @param  {Number}                   ry
   * @param  {Number}                   rz
   * @param  {Number}                   [angle]
   * @param  {Number}                   [concentration]
   */
  /**
   * @method spotLight
   * @param  {Number}     v1
   * @param  {Number}     v2
   * @param  {Number}     v3
   * @param  {Number}     x
   * @param  {Number}     y
   * @param  {Number}     z
   * @param  {p5.Vector}  direction
   * @param  {Number}     [angle]
   * @param  {Number}     [concentration]
   */
  /**
   * @method spotLight
   * @param  {Number}     v1
   * @param  {Number}     v2
   * @param  {Number}     v3
   * @param  {p5.Vector}  position
   * @param  {Number}     rx
   * @param  {Number}     ry
   * @param  {Number}     rz
   * @param  {Number}     [angle]
   * @param  {Number}     [concentration]
   */
  /**
   * @method spotLight
   * @param  {p5.Color|Number[]|String} color
   * @param  {Number}                   x
   * @param  {Number}                   y
   * @param  {Number}                   z
   * @param  {Number}                   rx
   * @param  {Number}                   ry
   * @param  {Number}                   rz
   * @param  {Number}                   [angle]
   * @param  {Number}                   [concentration]
   */
  fn.spotLight = function (
    v1,
    v2,
    v3,
    x,
    y,
    z,
    nx,
    ny,
    nz,
    angle,
    concentration
  ) {
    this._assert3d('spotLight');
    // p5._validateParameters('spotLight', arguments);

    this._renderer.spotLight(...arguments);

    return this;
  };

  /**
   * Removes all lights from the sketch.
   *
   * Calling `noLights()` removes any lights created with
   * <a href="#/p5/lights">lights()</a>,
   * <a href="#/p5/ambientLight">ambientLight()</a>,
   * <a href="#/p5/directionalLight">directionalLight()</a>,
   * <a href="#/p5/pointLight">pointLight()</a>, or
   * <a href="#/p5/spotLight">spotLight()</a>. These functions may be called
   * after `noLights()` to create a new lighting scheme.
   *
   * @method noLights
   * @chainable
   *
   * @example
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('Two spheres drawn against a gray background. The top sphere is white and the bottom sphere is red.');
   * }
   *
   * function draw() {
   *   background(50);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Turn on the lights.
   *   lights();
   *
   *   // Style the spheres.
   *   noStroke();
   *
   *   // Draw the top sphere.
   *   push();
   *   translate(0, -25, 0);
   *   sphere(20);
   *   pop();
   *
   *   // Turn off the lights.
   *   noLights();
   *
   *   // Add a red directional light that points into the screen.
   *   directionalLight(255, 0, 0, 0, 0, -1);
   *
   *   // Draw the bottom sphere.
   *   push();
   *   translate(0, 25, 0);
   *   sphere(20);
   *   pop();
   * }
   * </code>
   * </div>
   */
  fn.noLights = function (...args) {
    this._assert3d('noLights');
    // p5._validateParameters('noLights', args);

    this._renderer.noLights();

    return this;
  };


  RendererGL.prototype.ambientLight = function(v1, v2, v3, a) {
    const color = this._pInst.color(...arguments);

    this.states.setValue('ambientLightColors', [...this.states.ambientLightColors]);
    this.states.ambientLightColors.push(
      color._array[0],
      color._array[1],
      color._array[2]
    );

    this.states.setValue('enableLighting', true);
  };

  RendererGL.prototype.specularColor = function(v1, v2, v3) {
    const color = this._pInst.color(...arguments);

    this.states.setValue('specularColors', [
      color._array[0],
      color._array[1],
      color._array[2]
    ]);
  };

  RendererGL.prototype.directionalLight = function(v1, v2, v3, x, y, z) {
    let color;
    if (v1 instanceof Color) {
      color = v1;
    } else {
      color = this._pInst.color(v1, v2, v3);
    }

    let _x, _y, _z;
    const v = arguments[arguments.length - 1];
    if (typeof v === 'number') {
      _x = arguments[arguments.length - 3];
      _y = arguments[arguments.length - 2];
      _z = arguments[arguments.length - 1];
    } else {
      _x = v.x;
      _y = v.y;
      _z = v.z;
    }

    // normalize direction
    const l = Math.sqrt(_x * _x + _y * _y + _z * _z);
    this.states.setValue('directionalLightDirections', [...this.states.directionalLightDirections]);
    this.states.directionalLightDirections.push(_x / l, _y / l, _z / l);

    this.states.setValue('directionalLightDiffuseColors', [...this.states.directionalLightDiffuseColors]);
    this.states.directionalLightDiffuseColors.push(
      color._array[0],
      color._array[1],
      color._array[2]
    );

    this.states.setValue('directionalLightSpecularColors', [...this.states.directionalLightSpecularColors]);
    Array.prototype.push.apply(
      this.states.directionalLightSpecularColors,
      this.states.specularColors
    );

    this.states.setValue('enableLighting', true);
  };

  RendererGL.prototype.pointLight = function(v1, v2, v3, x, y, z) {
    let color;
    if (v1 instanceof Color) {
      color = v1;
    } else {
      color = this._pInst.color(v1, v2, v3);
    }

    let _x, _y, _z;
    const v = arguments[arguments.length - 1];
    if (typeof v === 'number') {
      _x = arguments[arguments.length - 3];
      _y = arguments[arguments.length - 2];
      _z = arguments[arguments.length - 1];
    } else {
      _x = v.x;
      _y = v.y;
      _z = v.z;
    }

    this.states.setValue('pointLightPositions', [...this.states.pointLightPositions]);
    this.states.pointLightPositions.push(_x, _y, _z);

    this.states.setValue('pointLightDiffuseColors', [...this.states.pointLightDiffuseColors]);
    this.states.pointLightDiffuseColors.push(
      color._array[0],
      color._array[1],
      color._array[2]
    );

    this.states.setValue('pointLightSpecularColors', [...this.states.pointLightSpecularColors]);
    Array.prototype.push.apply(
      this.states.pointLightSpecularColors,
      this.states.specularColors
    );

    this.states.setValue('enableLighting', true);
  };

  RendererGL.prototype.imageLight = function(img) {
    // activeImageLight property is checked by _setFillUniforms
    // for sending uniforms to the fillshader
    this.states.setValue('activeImageLight', img);
    this.states.setValue('enableLighting', true);
  };

  RendererGL.prototype.lights = function() {
    const grayColor = this._pInst.color('rgb(128,128,128)');
    this.ambientLight(grayColor);
    this.directionalLight(grayColor, 0, 0, -1);
  };

  RendererGL.prototype.lightFalloff = function(
    constantAttenuation,
    linearAttenuation,
    quadraticAttenuation
  ) {
    if (constantAttenuation < 0) {
      constantAttenuation = 0;
      console.warn(
        'Value of constant argument in lightFalloff() should be never be negative. Set to 0.'
      );
    }

    if (linearAttenuation < 0) {
      linearAttenuation = 0;
      console.warn(
        'Value of linear argument in lightFalloff() should be never be negative. Set to 0.'
      );
    }

    if (quadraticAttenuation < 0) {
      quadraticAttenuation = 0;
      console.warn(
        'Value of quadratic argument in lightFalloff() should be never be negative. Set to 0.'
      );
    }

    if (
      constantAttenuation === 0 &&
      (linearAttenuation === 0 && quadraticAttenuation === 0)
    ) {
      constantAttenuation = 1;
      console.warn(
        'Either one of the three arguments in lightFalloff() should be greater than zero. Set constant argument to 1.'
      );
    }

    this.states.setValue('constantAttenuation', constantAttenuation);
    this.states.setValue('linearAttenuation', linearAttenuation);
    this.states.setValue('quadraticAttenuation', quadraticAttenuation);
  };

  RendererGL.prototype.spotLight = function(
    v1,
    v2,
    v3,
    x,
    y,
    z,
    nx,
    ny,
    nz,
    angle,
    concentration
  ) {
    let color, position, direction;
    const length = arguments.length;

    switch (length) {
      case 11:
      case 10:
        color = this._pInst.color(v1, v2, v3);
        position = new Vector(x, y, z);
        direction = new Vector(nx, ny, nz);
        break;

      case 9:
        if (v1 instanceof Color) {
          color = v1;
          position = new Vector(v2, v3, x);
          direction = new Vector(y, z, nx);
          angle = ny;
          concentration = nz;
        } else if (x instanceof Vector) {
          color = this._pInst.color(v1, v2, v3);
          position = x;
          direction = new Vector(y, z, nx);
          angle = ny;
          concentration = nz;
        } else if (nx instanceof Vector) {
          color = this._pInst.color(v1, v2, v3);
          position = new Vector(x, y, z);
          direction = nx;
          angle = ny;
          concentration = nz;
        } else {
          color = this._pInst.color(v1, v2, v3);
          position = new Vector(x, y, z);
          direction = new Vector(nx, ny, nz);
        }
        break;

      case 8:
        if (v1 instanceof Color) {
          color = v1;
          position = new Vector(v2, v3, x);
          direction = new Vector(y, z, nx);
          angle = ny;
        } else if (x instanceof Vector) {
          color = this._pInst.color(v1, v2, v3);
          position = x;
          direction = new Vector(y, z, nx);
          angle = ny;
        } else {
          color = this._pInst.color(v1, v2, v3);
          position = new Vector(x, y, z);
          direction = nx;
          angle = ny;
        }
        break;

      case 7:
        if (v1 instanceof Color && v2 instanceof Vector) {
          color = v1;
          position = v2;
          direction = new Vector(v3, x, y);
          angle = z;
          concentration = nx;
        } else if (v1 instanceof Color && y instanceof Vector) {
          color = v1;
          position = new Vector(v2, v3, x);
          direction = y;
          angle = z;
          concentration = nx;
        } else if (x instanceof Vector && y instanceof Vector) {
          color = this._pInst.color(v1, v2, v3);
          position = x;
          direction = y;
          angle = z;
          concentration = nx;
        } else if (v1 instanceof Color) {
          color = v1;
          position = new Vector(v2, v3, x);
          direction = new Vector(y, z, nx);
        } else if (x instanceof Vector) {
          color = this._pInst.color(v1, v2, v3);
          position = x;
          direction = new Vector(y, z, nx);
        } else {
          color = this._pInst.color(v1, v2, v3);
          position = new Vector(x, y, z);
          direction = nx;
        }
        break;

      case 6:
        if (x instanceof Vector && y instanceof Vector) {
          color = this._pInst.color(v1, v2, v3);
          position = x;
          direction = y;
          angle = z;
        } else if (v1 instanceof Color && y instanceof Vector) {
          color = v1;
          position = new Vector(v2, v3, x);
          direction = y;
          angle = z;
        } else if (v1 instanceof Color && v2 instanceof Vector) {
          color = v1;
          position = v2;
          direction = new Vector(v3, x, y);
          angle = z;
        }
        break;

      case 5:
        if (
          v1 instanceof Color &&
          v2 instanceof Vector &&
          v3 instanceof Vector
        ) {
          color = v1;
          position = v2;
          direction = v3;
          angle = x;
          concentration = y;
        } else if (x instanceof Vector && y instanceof Vector) {
          color = this._pInst.color(v1, v2, v3);
          position = x;
          direction = y;
        } else if (v1 instanceof Color && y instanceof Vector) {
          color = v1;
          position = new Vector(v2, v3, x);
          direction = y;
        } else if (v1 instanceof Color && v2 instanceof Vector) {
          color = v1;
          position = v2;
          direction = new Vector(v3, x, y);
        }
        break;

      case 4:
        color = v1;
        position = v2;
        direction = v3;
        angle = x;
        break;

      case 3:
        color = v1;
        position = v2;
        direction = v3;
        break;

      default:
        console.warn(
          `Sorry, input for spotlight() is not in prescribed format. Too ${
            length < 3 ? 'few' : 'many'
          } arguments were provided`
        );
        return;
    }
    this.states.setValue('spotLightDiffuseColors', [
      color._array[0],
      color._array[1],
      color._array[2]
    ]);

    this.states.setValue('spotLightSpecularColors', [
      ...this.states.specularColors
    ]);

    this.states.setValue('spotLightPositions', [position.x, position.y, position.z]);
    direction.normalize();
    this.states.setValue('spotLightDirections', [
      direction.x,
      direction.y,
      direction.z
    ]);

    if (angle === undefined) {
      angle = Math.PI / 3;
    }

    if (concentration !== undefined && concentration < 1) {
      concentration = 1;
      console.warn(
        'Value of concentration needs to be greater than 1. Setting it to 1'
      );
    } else if (concentration === undefined) {
      concentration = 100;
    }

    angle = this._pInst._toRadians(angle);
    this.states.setValue('spotLightAngle', [Math.cos(angle)]);
    this.states.setValue('spotLightConc', [concentration]);

    this.states.setValue('enableLighting', true);
  };

  RendererGL.prototype.noLights = function() {
    this.states.setValue('activeImageLight', null);
    this.states.setValue('enableLighting', false);

    this.states.setValue('ambientLightColors', []);
    this.states.setValue('specularColors', [1, 1, 1]);

    this.states.setValue('directionalLightDirections', []);
    this.states.setValue('directionalLightDiffuseColors', []);
    this.states.setValue('directionalLightSpecularColors', []);

    this.states.setValue('pointLightPositions', []);
    this.states.setValue('pointLightDiffuseColors', []);
    this.states.setValue('pointLightSpecularColors', []);

    this.states.setValue('spotLightPositions', []);
    this.states.setValue('spotLightDirections', []);
    this.states.setValue('spotLightDiffuseColors', []);
    this.states.setValue('spotLightSpecularColors', []);
    this.states.setValue('spotLightAngle', []);
    this.states.setValue('spotLightConc', []);

    this.states.setValue('constantAttenuation', 1);
    this.states.setValue('linearAttenuation', 0);
    this.states.setValue('quadraticAttenuation', 0);
    this.states.setValue('_useShininess', 1);
    this.states.setValue('_useMetalness', 0);
  };
}

if(typeof p5 !== 'undefined'){
  light(p5, p5.prototype);
}

/**
 * @module 3D
 * @submodule Material
 * @for p5
 * @requires core
 */


function material(p5, fn){
  /**
   * Loads vertex and fragment shaders to create a
   * <a href="#/p5.Shader">p5.Shader</a> object.
   *
   * Shaders are programs that run on the graphics processing unit (GPU). They
   * can process many pixels at the same time, making them fast for many
   * graphics tasks. Theyre written in a language called
   * <a href="https://developer.mozilla.org/en-US/docs/Games/Techniques/3D_on_the_web/GLSL_Shaders" target="_blank">GLSL</a>
   * and run along with the rest of the code in a sketch.
   *
   * Once the <a href="#/p5.Shader">p5.Shader</a> object is created, it can be
   * used with the <a href="#/p5/shader">shader()</a> function, as in
   * `shader(myShader)`. A shader program consists of two files, a vertex shader
   * and a fragment shader. The vertex shader affects where 3D geometry is drawn
   * on the screen and the fragment shader affects color.
   *
   * `loadShader()` loads the vertex and fragment shaders from their `.vert` and
   * `.frag` files. For example, calling
   * `loadShader('assets/shader.vert', 'assets/shader.frag')` loads both
   * required shaders and returns a <a href="#/p5.Shader">p5.Shader</a> object.
   *
   * The third parameter, `successCallback`, is optional. If a function is
   * passed, it will be called once the shader has loaded. The callback function
   * can use the new <a href="#/p5.Shader">p5.Shader</a> object as its
   * parameter. The return value of the `successCallback()` function will be used
   * as the final return value of `loadShader()`.
   *
   * The fourth parameter, `failureCallback`, is also optional. If a function is
   * passed, it will be called if the shader fails to load. The callback
   * function can use the event error as its parameter. The return value of the `
   * failureCallback()` function will be used as the final return value of `loadShader()`.
   *
   * This function returns a `Promise` and should be used in an `async` setup with
   * `await`. See the examples for the usage syntax.
   *
   * Note: Shaders can only be used in WebGL mode.
   *
   * @method loadShader
   * @param {String|Request} vertFilename path of the vertex shader to be loaded.
   * @param {String|Request} fragFilename path of the fragment shader to be loaded.
   * @param {Function} [successCallback] function to call once the shader is loaded. Can be passed the
   *                                     <a href="#/p5.Shader">p5.Shader</a> object.
   * @param {Function} [failureCallback] function to call if the shader fails to load. Can be passed an
   *                                     `Error` event object.
   * @return {Promise<p5.Shader>} new shader created from the vertex and fragment shader files.
   *
   * @example
   * <div modernizr='webgl'>
   * <code>
   * // Note: A "uniform" is a global variable within a shader program.
   *
   * let mandelbrot;
   *
   * // Load the shader and create a p5.Shader object.
   * async function setup() {
   *   mandelbrot = await loadShader('assets/shader.vert', 'assets/shader.frag');
   *
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Compile and apply the p5.Shader object.
   *   shader(mandelbrot);
   *
   *   // Set the shader uniform p to an array.
   *   mandelbrot.setUniform('p', [-0.74364388703, 0.13182590421]);
   *
   *   // Set the shader uniform r to the value 1.5.
   *   mandelbrot.setUniform('r', 1.5);
   *
   *   // Add a quad as a display surface for the shader.
   *   quad(-1, -1, 1, -1, 1, 1, -1, 1);
   *
   *   describe('A black fractal image on a magenta background.');
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Note: A "uniform" is a global variable within a shader program.
   *
   * let mandelbrot;
   *
   * // Load the shader and create a p5.Shader object.
   * async function setup() {
   *   mandelbrot = await loadShader('assets/shader.vert', 'assets/shader.frag');
   *
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Use the p5.Shader object.
   *   shader(mandelbrot);
   *
   *   // Set the shader uniform p to an array.
   *   mandelbrot.setUniform('p', [-0.74364388703, 0.13182590421]);
   *
   *   describe('A fractal image zooms in and out of focus.');
   * }
   *
   * function draw() {
   *   // Set the shader uniform r to a value that oscillates between 0 and 2.
   *   mandelbrot.setUniform('r', sin(frameCount * 0.01) + 1);
   *
   *   // Add a quad as a display surface for the shader.
   *   quad(-1, -1, 1, -1, 1, 1, -1, 1);
   * }
   * </code>
   * </div>
   */
  fn.loadShader = async function (
    vertFilename,
    fragFilename,
    successCallback,
    failureCallback
  ) {
    // p5._validateParameters('loadShader', arguments);

    const loadedShader = new Shader();

    try {
      loadedShader._vertSrc = (await request(vertFilename, 'text')).data;
      loadedShader._fragSrc = (await request(fragFilename, 'text')).data;

      if (successCallback) {
        return successCallback(loadedShader);
      } else {
        return loadedShader
      }
    } catch(err) {
      if (failureCallback) {
        return failureCallback(err);
      } else {
        throw err;
      }
    }
  };

  /**
   * Creates a new <a href="#/p5.Shader">p5.Shader</a> object.
   *
   * Shaders are programs that run on the graphics processing unit (GPU). They
   * can process many pixels at the same time, making them fast for many
   * graphics tasks. Theyre written in a language called
   * <a href="https://developer.mozilla.org/en-US/docs/Games/Techniques/3D_on_the_web/GLSL_Shaders" target="_blank">GLSL</a>
   * and run along with the rest of the code in a sketch.
   *
   * Once the <a href="#/p5.Shader">p5.Shader</a> object is created, it can be
   * used with the <a href="#/p5/shader">shader()</a> function, as in
   * `shader(myShader)`. A shader program consists of two parts, a vertex shader
   * and a fragment shader. The vertex shader affects where 3D geometry is drawn
   * on the screen and the fragment shader affects color.
   *
   * The first parameter, `vertSrc`, sets the vertex shader. Its a string that
   * contains the vertex shader program written in GLSL.
   *
   * The second parameter, `fragSrc`, sets the fragment shader. Its a string
   * that contains the fragment shader program written in GLSL.
   *
   * A shader can optionally describe *hooks,* which are functions in GLSL that
   * users may choose to provide to customize the behavior of the shader using the
   * <a href="#/p5.Shader/modify">`modify()`</a> method of `p5.Shader`. These are added by
   * describing the hooks in a third parameter, `options`, and referencing the hooks in
   * your `vertSrc` or `fragSrc`. Hooks for the vertex or fragment shader are described under
   * the `vertex` and `fragment` keys of `options`. Each one is an object. where each key is
   * the type and name of a hook function, and each value is a string with the
   * parameter list and default implementation of the hook. For example, to let users
   * optionally run code at the start of the vertex shader, the options object could
   * include:
   *
   * ```js
   * {
   *   vertex: {
   *     'void beforeVertex': '() {}'
   *   }
   * }
   * ```
   *
   * Then, in your vertex shader source, you can run a hook by calling a function
   * with the same name prefixed by `HOOK_`. If you want to check if the default
   * hook has been replaced, maybe to avoid extra overhead, you can check if the
   * same name prefixed by `AUGMENTED_HOOK_` has been defined:
   *
   * ```glsl
   * void main() {
   *   // In most cases, just calling the hook is fine:
   *   HOOK_beforeVertex();
   *
   *   // Alternatively, for more efficiency:
   *   #ifdef AUGMENTED_HOOK_beforeVertex
   *   HOOK_beforeVertex();
   *   #endif
   *
   *   // Add the rest of your shader code here!
   * }
   * ```
   *
   * Note: Only filter shaders can be used in 2D mode. All shaders can be used
   * in WebGL mode.
   *
   * @method createShader
   * @param {String} vertSrc source code for the vertex shader.
   * @param {String} fragSrc source code for the fragment shader.
   * @param {Object} [options] An optional object describing how this shader can
   * be augmented with hooks. It can include:
   *  - `vertex`: An object describing the available vertex shader hooks.
   *  - `fragment`: An object describing the available frament shader hooks.
   * @returns {p5.Shader} new shader object created from the
   * vertex and fragment shaders.
   *
   * @example
   * <div modernizr='webgl'>
   * <code>
   * // Note: A "uniform" is a global variable within a shader program.
   *
   * // Create a string with the vertex shader program.
   * // The vertex shader is called for each vertex.
   * let vertSrc = `
   * precision highp float;
   * uniform mat4 uModelViewMatrix;
   * uniform mat4 uProjectionMatrix;
   * attribute vec3 aPosition;
   * attribute vec2 aTexCoord;
   * varying vec2 vTexCoord;
   *
   * void main() {
   *   vTexCoord = aTexCoord;
   *   vec4 positionVec4 = vec4(aPosition, 1.0);
   *   gl_Position = uProjectionMatrix * uModelViewMatrix * positionVec4;
   * }
   * `;
   *
   * // Create a string with the fragment shader program.
   * // The fragment shader is called for each pixel.
   * let fragSrc = `
   * precision highp float;
   *
   * void main() {
   *   // Set each pixel's RGBA value to yellow.
   *   gl_FragColor = vec4(1.0, 1.0, 0.0, 1.0);
   * }
   * `;
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Create a p5.Shader object.
   *   let shaderProgram = createShader(vertSrc, fragSrc);
   *
   *   // Compile and apply the p5.Shader object.
   *   shader(shaderProgram);
   *
   *   // Style the drawing surface.
   *   noStroke();
   *
   *   // Add a plane as a drawing surface.
   *   plane(100, 100);
   *
   *   describe('A yellow square.');
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Note: A "uniform" is a global variable within a shader program.
   *
   * // Create a string with the vertex shader program.
   * // The vertex shader is called for each vertex.
   * let vertSrc = `
   * precision highp float;
   * uniform mat4 uModelViewMatrix;
   * uniform mat4 uProjectionMatrix;
   * attribute vec3 aPosition;
   * attribute vec2 aTexCoord;
   * varying vec2 vTexCoord;
   *
   * void main() {
   *   vTexCoord = aTexCoord;
   *   vec4 positionVec4 = vec4(aPosition, 1.0);
   *   gl_Position = uProjectionMatrix * uModelViewMatrix * positionVec4;
   * }
   * `;
   *
   * // Create a string with the fragment shader program.
   * // The fragment shader is called for each pixel.
   * let fragSrc = `
   * precision highp float;
   * uniform vec2 p;
   * uniform float r;
   * const int numIterations = 500;
   * varying vec2 vTexCoord;
   *
   * void main() {
   *   vec2 c = p + gl_FragCoord.xy * r;
   *   vec2 z = c;
   *   float n = 0.0;
   *
   *   for (int i = numIterations; i > 0; i--) {
   *     if (z.x * z.x + z.y * z.y > 4.0) {
   *       n = float(i) / float(numIterations);
   *       break;
   *     }
   *     z = vec2(z.x * z.x - z.y * z.y, 2.0 * z.x * z.y) + c;
   *   }
   *
   *   gl_FragColor = vec4(
   *     0.5 - cos(n * 17.0) / 2.0,
   *     0.5 - cos(n * 13.0) / 2.0,
   *     0.5 - cos(n * 23.0) / 2.0,
   *     1.0
   *   );
   * }
   * `;
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Create a p5.Shader object.
   *   let mandelbrot = createShader(vertSrc, fragSrc);
   *
   *   // Compile and apply the p5.Shader object.
   *   shader(mandelbrot);
   *
   *   // Set the shader uniform p to an array.
   *   // p is the center point of the Mandelbrot image.
   *   mandelbrot.setUniform('p', [-0.74364388703, 0.13182590421]);
   *
   *   // Set the shader uniform r to 0.005.
   *   // r is the size of the image in Mandelbrot-space.
   *   mandelbrot.setUniform('r', 0.005);
   *
   *   // Style the drawing surface.
   *   noStroke();
   *
   *   // Add a plane as a drawing surface.
   *   plane(100, 100);
   *
   *   describe('A black fractal image on a magenta background.');
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Note: A "uniform" is a global variable within a shader program.
   *
   * // Create a string with the vertex shader program.
   * // The vertex shader is called for each vertex.
   * let vertSrc = `
   * precision highp float;
   * uniform mat4 uModelViewMatrix;
   * uniform mat4 uProjectionMatrix;
   *
   * attribute vec3 aPosition;
   * attribute vec2 aTexCoord;
   * varying vec2 vTexCoord;
   *
   * void main() {
   *   vTexCoord = aTexCoord;
   *   vec4 positionVec4 = vec4(aPosition, 1.0);
   *   gl_Position = uProjectionMatrix * uModelViewMatrix * positionVec4;
   * }
   * `;
   *
   * // Create a string with the fragment shader program.
   * // The fragment shader is called for each pixel.
   * let fragSrc = `
   * precision highp float;
   * uniform vec2 p;
   * uniform float r;
   * const int numIterations = 500;
   * varying vec2 vTexCoord;
   *
   * void main() {
   *   vec2 c = p + gl_FragCoord.xy * r;
   *   vec2 z = c;
   *   float n = 0.0;
   *
   *   for (int i = numIterations; i > 0; i--) {
   *     if (z.x * z.x + z.y * z.y > 4.0) {
   *       n = float(i) / float(numIterations);
   *       break;
   *     }
   *
   *     z = vec2(z.x * z.x - z.y * z.y, 2.0 * z.x * z.y) + c;
   *   }
   *
   *   gl_FragColor = vec4(
   *     0.5 - cos(n * 17.0) / 2.0,
   *     0.5 - cos(n * 13.0) / 2.0,
   *     0.5 - cos(n * 23.0) / 2.0,
   *     1.0
   *   );
   * }
   * `;
   *
   * let mandelbrot;
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Create a p5.Shader object.
   *   mandelbrot = createShader(vertSrc, fragSrc);
   *
   *   // Apply the p5.Shader object.
   *   shader(mandelbrot);
   *
   *   // Set the shader uniform p to an array.
   *   // p is the center point of the Mandelbrot image.
   *   mandelbrot.setUniform('p', [-0.74364388703, 0.13182590421]);
   *
   *   describe('A fractal image zooms in and out of focus.');
   * }
   *
   * function draw() {
   *   // Set the shader uniform r to a value that oscillates
   *   // between 0 and 0.005.
   *   // r is the size of the image in Mandelbrot-space.
   *   let radius = 0.005 * (sin(frameCount * 0.01) + 1);
   *   mandelbrot.setUniform('r', radius);
   *
   *   // Style the drawing surface.
   *   noStroke();
   *
   *   // Add a plane as a drawing surface.
   *   plane(100, 100);
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // A shader with hooks.
   * let myShader;
   *
   * // A shader with modified hooks.
   * let modifiedShader;
   *
   * // Create a string with the vertex shader program.
   * // The vertex shader is called for each vertex.
   * let vertSrc = `
   * precision highp float;
   * uniform mat4 uModelViewMatrix;
   * uniform mat4 uProjectionMatrix;
   *
   * attribute vec3 aPosition;
   * attribute vec2 aTexCoord;
   *
   * void main() {
   *   vec4 positionVec4 = vec4(aPosition, 1.0);
   *   gl_Position = uProjectionMatrix * uModelViewMatrix * positionVec4;
   * }
   * `;
   *
   * // Create a fragment shader that uses a hook.
   * let fragSrc = `
   * precision highp float;
   * void main() {
   *   // Let users override the color
   *   gl_FragColor = HOOK_getColor(vec4(1., 0., 0., 1.));
   * }
   * `;
   *
   * function setup() {
   *   createCanvas(50, 50, WEBGL);
   *
   *   // Create a shader with hooks
   *   myShader = createShader(vertSrc, fragSrc, {
   *     fragment: {
   *       'vec4 getColor': '(vec4 color) { return color; }'
   *     }
   *   });
   *
   *   // Make a version of the shader with a hook overridden
   *   modifiedShader = myShader.modify({
   *     'vec4 getColor': `(vec4 color) {
   *       return vec4(0., 0., 1., 1.);
   *     }`
   *   });
   * }
   *
   * function draw() {
   *   noStroke();
   *
   *   push();
   *   shader(myShader);
   *   translate(-width/3, 0);
   *   sphere(10);
   *   pop();
   *
   *   push();
   *   shader(modifiedShader);
   *   translate(width/3, 0);
   *   sphere(10);
   *   pop();
   * }
   * </code>
   * </div>
   */
  fn.createShader = function (vertSrc, fragSrc, options) {
    // p5._validateParameters('createShader', arguments);
    return new Shader(this._renderer, vertSrc, fragSrc, options);
  };

  /**
   * Creates and loads a filter shader from an external file.
   *
   * @method loadFilterShader
   * @param {String} fragFilename path to the fragment shader file
   * @param {Function} [successCallback] callback to be called once the shader is
   *                                     loaded. Will be passed the
   *                                     <a href="#/p5.Shader">p5.Shader</a> object.
   * @param {Function} [failureCallback] callback to be called if there is an error
   *                                     loading the shader. Will be passed the
   *                                     error event.
   * @return {Promise<p5.Shader>} a promise that resolves with a shader object
   *
   * @example
   * <div modernizr='webgl'>
   * <code>
   * let myShader;
   *
   * async function setup() {
   *   myShader = await loadFilterShader('assets/basic.frag');
   *   createCanvas(100, 100, WEBGL);
   *   noStroke();
   * }
   *
   * function draw() {
   *   // shader() sets the active shader with our shader
   *   shader(myShader);
   *
   *   // rect gives us some geometry on the screen
   *   rect(-50, -50, width, height);
   * }
   * </code>
   * </div>
   * @alt
   * A rectangle with a shader applied to it.
   */
  fn.loadFilterShader = async function (fragFilename, successCallback, failureCallback) {
    // p5._validateParameters('loadFilterShader', arguments);
    try {
      // Load the fragment shader
      const fragSrc = await this.loadStrings(fragFilename);
      const fragString = await fragSrc.join('\n');

      // Create the shader using createFilterShader
      const loadedShader = this.createFilterShader(fragString, true);

      if (successCallback) {
        successCallback(loadedShader);
      }

      return loadedShader;
    } catch (err) {
      if (failureCallback) {
        failureCallback(err);
      } else {
        console.error(err);
      }
    }
  };

  /**
   * Creates a <a href="#/p5.Shader">p5.Shader</a> object to be used with the
   * <a href="#/p5/filter">filter()</a> function.
   *
   * `createFilterShader()` works like
   * <a href="#/p5/createShader">createShader()</a> but has a default vertex
   * shader included. `createFilterShader()` is intended to be used along with
   * <a href="#/p5/filter">filter()</a> for filtering the contents of a canvas.
   * A filter shader will be applied to the whole canvas instead of just
   * <a href="#/p5.Geometry">p5.Geometry</a> objects.
   *
   * The parameter, `fragSrc`, sets the fragment shader. Its a string that
   * contains the fragment shader program written in
   * <a href="https://developer.mozilla.org/en-US/docs/Games/Techniques/3D_on_the_web/GLSL_Shaders" target="_blank">GLSL</a>.
   *
   * The <a href="#/p5.Shader">p5.Shader</a> object that's created has some
   * uniforms that can be set:
   * - `sampler2D tex0`, which contains the canvas contents as a texture.
   * - `vec2 canvasSize`, which is the width and height of the canvas, not including pixel density.
   * - `vec2 texelSize`, which is the size of a physical pixel including pixel density. This is calculated as `1.0 / (width * density)` for the pixel width and `1.0 / (height * density)` for the pixel height.
   *
   * The <a href="#/p5.Shader">p5.Shader</a> that's created also provides
   * `varying vec2 vTexCoord`, a coordinate with values between 0 and 1.
   * `vTexCoord` describes where on the canvas the pixel will be drawn.
   *
   * For more info about filters and shaders, see Adam Ferriss' <a href="https://github.com/aferriss/p5jsShaderExamples">repo of shader examples</a>
   * or the <a href="https://p5js.org/learn/getting-started-in-webgl-shaders.html">Introduction to Shaders</a> tutorial.
   *
   * @method createFilterShader
   * @param {String} fragSrc source code for the fragment shader.
   * @returns {p5.Shader} new shader object created from the fragment shader.
   *
   * @example
   * <div modernizr='webgl'>
   * <code>
   * function setup() {
   *   let fragSrc = `precision highp float;
   *   void main() {
   *     gl_FragColor = vec4(1.0, 1.0, 0.0, 1.0);
   *   }`;
   *
   *   createCanvas(100, 100, WEBGL);
   *   let s = createFilterShader(fragSrc);
   *   filter(s);
   *   describe('a yellow canvas');
   * }
   * </code>
   * </div>
   *
   * <div modernizr='webgl'>
   * <code>
   * let img, s;
   * async function setup() {
   *   img = await loadImage('assets/bricks.jpg');
   *   let fragSrc = `precision highp float;
   *
   *   // x,y coordinates, given from the vertex shader
   *   varying vec2 vTexCoord;
   *
   *   // the canvas contents, given from filter()
   *   uniform sampler2D tex0;
   *   // other useful information from the canvas
   *   uniform vec2 texelSize;
   *   uniform vec2 canvasSize;
   *   // a custom variable from this sketch
   *   uniform float darkness;
   *
   *   void main() {
   *     // get the color at current pixel
   *     vec4 color = texture2D(tex0, vTexCoord);
   *     // set the output color
   *     color.b = 1.0;
   *     color *= darkness;
   *     gl_FragColor = vec4(color.rgb, 1.0);
   *   }`;
   *
   *   createCanvas(100, 100, WEBGL);
   *   s = createFilterShader(fragSrc);
   * }
   *
   * function draw() {
   *   image(img, -50, -50);
   *   s.setUniform('darkness', 0.5);
   *   filter(s);
   *   describe('a image of bricks tinted dark blue');
   * }
   * </code>
   * </div>
   */
  fn.createFilterShader = function (fragSrc, skipContextCheck = false) {
    // p5._validateParameters('createFilterShader', arguments);
    let defaultVertV1 = `
      uniform mat4 uModelViewMatrix;
      uniform mat4 uProjectionMatrix;

      attribute vec3 aPosition;
      // texcoords only come from p5 to vertex shader
      // so pass texcoords on to the fragment shader in a varying variable
      attribute vec2 aTexCoord;
      varying vec2 vTexCoord;

      void main() {
        // transferring texcoords for the frag shader
        vTexCoord = aTexCoord;

        // copy position with a fourth coordinate for projection (1.0 is normal)
        vec4 positionVec4 = vec4(aPosition, 1.0);

        // project to 3D space
        gl_Position = uProjectionMatrix * uModelViewMatrix * positionVec4;
      }
    `;
    let defaultVertV2 = `#version 300 es
      uniform mat4 uModelViewMatrix;
      uniform mat4 uProjectionMatrix;

      in vec3 aPosition;
      in vec2 aTexCoord;
      out vec2 vTexCoord;

      void main() {
        // transferring texcoords for the frag shader
        vTexCoord = aTexCoord;

        // copy position with a fourth coordinate for projection (1.0 is normal)
        vec4 positionVec4 = vec4(aPosition, 1.0);

        // project to 3D space
        gl_Position = uProjectionMatrix * uModelViewMatrix * positionVec4;
      }
    `;
    let vertSrc = fragSrc.includes('#version 300 es') ? defaultVertV2 : defaultVertV1;
    const shader = new Shader(this._renderer, vertSrc, fragSrc);
    if (!skipContextCheck) {
      if (this._renderer.GL) {
        shader.ensureCompiledOnContext(this._renderer);
      } else {
        shader.ensureCompiledOnContext(this);
      }
    }
    return shader;
  };

  /**
   * Sets the <a href="#/p5.Shader">p5.Shader</a> object to apply while drawing.
   *
   * Shaders are programs that run on the graphics processing unit (GPU). They
   * can process many pixels or vertices at the same time, making them fast for
   * many graphics tasks. Theyre written in a language called
   * <a href="https://developer.mozilla.org/en-US/docs/Games/Techniques/3D_on_the_web/GLSL_Shaders" target="_blank">GLSL</a>
   * and run along with the rest of the code in a sketch.
   * <a href="#/p5.Shader">p5.Shader</a> objects can be created using the
   * <a href="#/p5/createShader">createShader()</a> and
   * <a href="#/p5/loadShader">loadShader()</a> functions.
   *
   * The parameter, `s`, is the <a href="#/p5.Shader">p5.Shader</a> object to
   * apply. For example, calling `shader(myShader)` applies `myShader` to
   * process each pixel on the canvas. This only changes the fill (the inner part of shapes),
   * but does not affect the outlines (strokes) or any images drawn using the `image()` function.
   * The source code from a <a href="#/p5.Shader">p5.Shader</a> object's
   * fragment and vertex shaders will be compiled the first time it's passed to
   * `shader()`. See
   * <a href="https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/compileShader" target="_blank">MDN</a>
   * for more information about compiling shaders.
   *
   * Calling <a href="#/p5/resetShader">resetShader()</a> restores a sketchs
   * default shaders.
   *
   * Note: Shaders can only be used in WebGL mode.
   *
   * <div>
   * <p>
   *
   * If you want to apply shaders to strokes or images, use the following methods:
   * - <a href="#/p5/strokeShader">strokeShader()</a> : Applies a shader to the stroke (outline) of shapes, allowing independent control over the stroke rendering using shaders.
   * - <a href="#/p5/imageShader">imageShader()</a> : Applies a shader to images or textures, controlling how the shader modifies their appearance during rendering.
   *
   * </p>
   * </div>
   *
   *
   * @method shader
   * @chainable
   * @param {p5.Shader} s <a href="#/p5.Shader">p5.Shader</a> object
   *                      to apply.
   *
   * @example
   * <div modernizr='webgl'>
   * <code>
   * let fillShader;
   *
   * let vertSrc = `
   * precision highp float;
   * attribute vec3 aPosition;
   * uniform mat4 uModelViewMatrix;
   * uniform mat4 uProjectionMatrix;
   * varying vec3 vPosition;
   *
   * void main() {
   *   vPosition = aPosition;
   *   gl_Position = uProjectionMatrix * uModelViewMatrix * vec4(aPosition, 1.0);
   * }
   * `;
   *
   * let fragSrc = `
   * precision highp float;
   * uniform vec3 uLightDir;
   * varying vec3 vPosition;
   *
   * void main() {
   *   vec3 lightDir = normalize(uLightDir);
   *   float brightness = dot(lightDir, normalize(vPosition));
   *   brightness = clamp(brightness, 0.4, 1.0);
   *   vec3 color = vec3(0.3, 0.5, 1.0);
   *   color = color * brightness * 3.0;
   *   gl_FragColor = vec4(color, 1.0);
   * }
   * `;
   *
   * function setup() {
   *   createCanvas(200, 200, WEBGL);
   *   fillShader = createShader(vertSrc, fragSrc);
   *   noStroke();
   *   describe('A rotating torus with simulated directional lighting.');
   * }
   *
   * function draw() {
   *   background(20, 20, 40);
   *   let lightDir = [0.5, 0.5, -1.0];
   *   fillShader.setUniform('uLightDir', lightDir);
   *   shader(fillShader);
   *   rotateY(frameCount * 0.02);
   *   rotateX(frameCount * 0.02);
   *   //lights();
   *   torus(25, 10, 30, 30);
   * }
   * </code>
   * </div>
   *
   * @example
   * <div modernizr='webgl'>
   * <code>
   * let fillShader;
   *
   * let vertSrc = `
   * precision highp float;
   * attribute vec3 aPosition;
   * uniform mat4 uProjectionMatrix;
   * uniform mat4 uModelViewMatrix;
   * varying vec3 vPosition;
   * void main() {
   *   vPosition = aPosition;
   *   gl_Position = uProjectionMatrix * uModelViewMatrix * vec4(aPosition, 1.0);
   * }
   * `;
   *
   * let fragSrc = `
   * precision highp float;
   * uniform vec3 uLightPos;
   * uniform vec3 uFillColor;
   * varying vec3 vPosition;
   * void main() {
   *   float brightness = dot(normalize(uLightPos), normalize(vPosition));
   *   brightness = clamp(brightness, 0.0, 1.0);
   *   vec3 color = uFillColor * brightness;
   *   gl_FragColor = vec4(color, 1.0);
   * }
   * `;
   *
   * function setup() {
   *   createCanvas(200, 200, WEBGL);
   *   fillShader = createShader(vertSrc, fragSrc);
   *   shader(fillShader);
   *   noStroke();
   *   describe('A square affected by both fill color and lighting, with lights controlled by mouse.');
   * }
   *
   * function draw() {
   *   let lightPos = [(mouseX - width / 2) / width,
   *     (mouseY - height / 2) / height, 1.0];
   *   fillShader.setUniform('uLightPos', lightPos);
   *   let fillColor = [map(mouseX, 0, width, 0, 1),
   *     map(mouseY, 0, height, 0, 1), 0.5];
   *   fillShader.setUniform('uFillColor', fillColor);
   *   plane(100, 100);
   * }
   * </code>
   * </div>
   *
   * @example
   * <div modernizr='webgl'>
   * <code>
   * let myShader;
   *
   * function setup() {
   *   createCanvas(200, 200, WEBGL);
   *
   *   myShader = baseMaterialShader().modify({
   *     declarations: 'uniform float time;',
   *     'vec4 getFinalColor': `(vec4 color) {
   *       float r = 0.2 + 0.5 * abs(sin(time + 0.0));
   *       float g = 0.2 + 0.5 * abs(sin(time + 1.0));
   *       float b = 0.2 + 0.5 * abs(sin(time + 2.0));
   *       color.rgb = vec3(r, g, b);
   *       return color;
   *     }`
   *   });
   *
   *   noStroke();
   *   describe('A 3D cube with dynamically changing colors on a beige background.');
   * }
   *
   * function draw() {
   *   background(245, 245, 220);
   *   shader(myShader);
   *   myShader.setUniform('time', millis() / 1000.0);
   *
   *   box(50);
   * }
   * </code>
   * </div>
   *
   */
  fn.shader = function (s) {
    this._assert3d('shader');
    // p5._validateParameters('shader', arguments);

    this._renderer.shader(s);

    return this;
  };

  /**
   * Sets the <a href="#/p5.Shader">p5.Shader</a> object to apply for strokes.
   *
   * This method applies the given shader to strokes, allowing customization of
   * how lines and outlines are drawn in 3D space. The shader will be used for
   * strokes until <a href="#/p5/resetShader">resetShader()</a> is called or another
   * strokeShader is applied.
   *
   * The shader will be used for:
   * - Strokes only, regardless of whether the uniform `uStrokeWeight` is present.
   *
   * To further customize its behavior, refer to the various hooks provided by
   * the <a href="#/p5/baseStrokeShader">baseStrokeShader()</a> method, which allow
   * control over stroke weight, vertex positions, colors, and more.
   *
   * @method strokeShader
   * @chainable
   * @param {p5.Shader} s <a href="#/p5.Shader">p5.Shader</a> object
   *                      to apply for strokes.
   *
   *
   * @example
   * <div modernizr='webgl'>
   * <code>
   * let animatedStrokeShader;
   *
   * let vertSrc = `
   * precision mediump int;
   *
   * uniform mat4 uModelViewMatrix;
   * uniform mat4 uProjectionMatrix;
   * uniform float uStrokeWeight;
   *
   * uniform bool uUseLineColor;
   * uniform vec4 uMaterialColor;
   *
   * uniform vec4 uViewport;
   * uniform int uPerspective;
   * uniform int uStrokeJoin;
   *
   * attribute vec4 aPosition;
   * attribute vec3 aTangentIn;
   * attribute vec3 aTangentOut;
   * attribute float aSide;
   * attribute vec4 aVertexColor;
   *
   * void main() {
   *   vec4 posp = uModelViewMatrix * aPosition;
   *   vec4 posqIn = uModelViewMatrix * (aPosition + vec4(aTangentIn, 0));
   *   vec4 posqOut = uModelViewMatrix * (aPosition + vec4(aTangentOut, 0));
   *
   *   float facingCamera = pow(
   *     abs(normalize(posqIn-posp).z),
   *     0.25
   *   );
   *
   *   float scale = mix(1., 0.995, facingCamera);
   *
   *   posp.xyz = posp.xyz * scale;
   *   posqIn.xyz = posqIn.xyz * scale;
   *   posqOut.xyz = posqOut.xyz * scale;
   *
   *   vec4 p = uProjectionMatrix * posp;
   *   vec4 qIn = uProjectionMatrix * posqIn;
   *   vec4 qOut = uProjectionMatrix * posqOut;
   *
   *   vec2 tangentIn = normalize((qIn.xy*p.w - p.xy*qIn.w) * uViewport.zw);
   *   vec2 tangentOut = normalize((qOut.xy*p.w - p.xy*qOut.w) * uViewport.zw);
   *
   *   vec2 curPerspScale;
   *   if(uPerspective == 1) {
   *     curPerspScale = (uProjectionMatrix * vec4(1, sign(uProjectionMatrix[1][1]), 0, 0)).xy;
   *   } else {
   *     curPerspScale = p.w / (0.5 * uViewport.zw);
   *   }
   *
   *   vec2 offset;
   *   vec2 tangent = aTangentIn == vec3(0.) ? tangentOut : tangentIn;
   *   vec2 normal = vec2(-tangent.y, tangent.x);
   *   float normalOffset = sign(aSide);
   *   float tangentOffset = abs(aSide) - 1.;
   *   offset = (normal * normalOffset + tangent * tangentOffset) *
   *     uStrokeWeight * 0.5;
   *
   *   gl_Position.xy = p.xy + offset.xy * curPerspScale;
   *   gl_Position.zw = p.zw;
   * }
   * `;
   *
   * let fragSrc = `
   * precision mediump float;
   * uniform float uTime;
   *
   * void main() {
   *   float wave = sin(gl_FragCoord.x * 0.1 + uTime) * 0.5 + 0.5;
   *   gl_FragColor = vec4(wave, 0.5, 1.0, 1.0);  // Animated color based on time
   * }
   * `;
   *
   * function setup() {
   *   createCanvas(200, 200, WEBGL);
   *   animatedStrokeShader = createShader(vertSrc, fragSrc);
   *   strokeShader(animatedStrokeShader);
   *   strokeWeight(4);
   *
   *   describe('A hollow cube rotating continuously with its stroke colors changing dynamically over time against a static gray background.');
   * }
   *
   * function draw() {
   *   animatedStrokeShader.setUniform('uTime', millis() / 1000.0);
   *   background(250);
   *   rotateY(frameCount * 0.02);
   *   noFill();
   *   orbitControl();
   *   box(50);
   * }
   * </code>
   * </div>
   *
   *
   * @example
   * <div modernizr='webgl'>
   * <code>
   * let myShader;
   *
   * function setup() {
   *   createCanvas(200, 200, WEBGL);
   *   myShader = baseStrokeShader().modify({
   *     'float random': `(vec2 p) {
   *       vec3 p3  = fract(vec3(p.xyx) * .1471);
   *       p3 += dot(p3, p3.yzx + 32.33);
   *       return fract((p3.x + p3.y) * p3.z);
   *     }`,
   *     'Inputs getPixelInputs': `(Inputs inputs) {
   *       // Modify alpha with dithering effect
   *       float a = inputs.color.a;
   *       inputs.color.a = 1.0;
   *       inputs.color *= random(inputs.position.xy) > a ? 0.0 : 1.0;
   *       return inputs;
   *     }`
   *   });
   * }
   *
   * function draw() {
   *   background(255);
   *   strokeShader(myShader);
   *   strokeWeight(12);
   *   beginShape();
   *   for (let i = 0; i <= 50; i++) {
   *     stroke(
   *       map(i, 0, 50, 150, 255),
   *       100 + 155 * sin(i / 5),
   *       255 * map(i, 0, 50, 1, 0)
   *     );
   *     vertex(
   *       map(i, 0, 50, 1, -1) * width / 3,
   *       50 * cos(i / 10 + frameCount / 80)
   *     );
   *   }
   *   endShape();
   * }
   * </code>
   * </div>
   */
  fn.strokeShader = function (s) {
    this._assert3d('strokeShader');
    // p5._validateParameters('strokeShader', arguments);

    this._renderer.strokeShader(s);

    return this;
  };

  /**
   * Sets the <a href="#/p5.Shader">p5.Shader</a> object to apply for images.
   *
   * This method allows the user to apply a custom shader to images, enabling
   * advanced visual effects such as pixel manipulation, color adjustments,
   * or dynamic behavior. The shader will be applied to the image drawn using
   * the <a href="#/p5/image">image()</a> function.
   *
   * The shader will be used exclusively for:
   * - `image()` calls, applying only when drawing 2D images.
   * - This shader will NOT apply to images used in <a href="#/p5/texture">texture()</a> or other 3D contexts.
   *   Any attempts to use the imageShader in these cases will be ignored.
   *
   * @method imageShader
   * @chainable
   * @param {p5.Shader} s <a href="#/p5.Shader">p5.Shader</a> object
   *                      to apply for images.
   *
   * @example
   * <div modernizr='webgl'>
   * <code>
   * let img;
   * let imgShader;
   *
   * async function setup() {
   *   img = await loadImage('assets/outdoor_image.jpg');
   *
   *   createCanvas(200, 200, WEBGL);
   *   noStroke();
   *
   *   imgShader = createShader(`
   *     precision mediump float;
   *     attribute vec3 aPosition;
   *     attribute vec2 aTexCoord;
   *     varying vec2 vTexCoord;
   *     uniform mat4 uModelViewMatrix;
   *     uniform mat4 uProjectionMatrix;
   *
   *     void main() {
   *       vTexCoord = aTexCoord;
   *       gl_Position = uProjectionMatrix * uModelViewMatrix * vec4(aPosition, 1.0);
   *     }
   *   `, `
   *     precision mediump float;
   *     varying vec2 vTexCoord;
   *     uniform sampler2D uTexture;
   *     uniform vec2 uMousePos;
   *
   *     void main() {
   *       vec4 texColor = texture2D(uTexture, vTexCoord);
   *       // Adjust the color based on mouse position
   *       float r = uMousePos.x * texColor.r;
   *       float g = uMousePos.y * texColor.g;
   *       gl_FragColor = vec4(r, g, texColor.b, texColor.a);
   *     }
   *   `);
   *
   *   describe(
   *     'An image on a gray background where the colors change based on the mouse position.'
   *   );
   * }
   *
   * function draw() {
   *   background(220);
   *
   *   imageShader(imgShader);
   *
   *   // Map the mouse position to a range between 0 and 1
   *   let mousePosX = map(mouseX, 0, width, 0, 1);
   *   let mousePosY = map(mouseY, 0, height, 0, 1);
   *
   *   // Pass the mouse position to the shader as a uniform
   *   imgShader.setUniform('uMousePos', [mousePosX, mousePosY]);
   *
   *   // Bind the image texture to the shader
   *   imgShader.setUniform('uTexture', img);
   *
   *   image(img, -width / 2, -height / 2, width, height);
   * }
   *
   * </code>
   * </div>
   *
   * @example
   * <div modernizr='webgl'>
   * <code>
   * let img;
   * let imgShader;
   *
   * async function setup() {
   *   img = await loadImage('assets/outdoor_image.jpg');
   *
   *   createCanvas(200, 200, WEBGL);
   *   noStroke();
   *
   *   imgShader = createShader(`
   *     precision mediump float;
   *     attribute vec3 aPosition;
   *     attribute vec2 aTexCoord;
   *     varying vec2 vTexCoord;
   *     uniform mat4 uModelViewMatrix;
   *     uniform mat4 uProjectionMatrix;
   *
   *     void main() {
   *       vTexCoord = aTexCoord;
   *       gl_Position = uProjectionMatrix * uModelViewMatrix * vec4(aPosition, 1.0);
   *     }
   *   `, `
   *     precision mediump float;
   *     varying vec2 vTexCoord;
   *     uniform sampler2D uTexture;
   *     uniform vec2 uMousePos;
   *
   *     void main() {
   *       // Distance from the current pixel to the mouse
   *       float distFromMouse = distance(vTexCoord, uMousePos);
   *
   *       // Adjust pixelation based on distance (closer = more detail, farther = blockier)
   *       float pixelSize = mix(0.002, 0.05, distFromMouse);
   *       vec2 pixelatedCoord = vec2(floor(vTexCoord.x / pixelSize) * pixelSize,
   *                                  floor(vTexCoord.y / pixelSize) * pixelSize);
   *
   *       vec4 texColor = texture2D(uTexture, pixelatedCoord);
   *       gl_FragColor = texColor;
   *     }
   *   `);
   *
   *   describe('A static image with a grid-like, pixelated effect created by the shader. Each cell in the grid alternates visibility, producing a dithered visual effect.');
   * }
   *
   * function draw() {
   *   background(220);
   *   imageShader(imgShader);
   *
   *   let mousePosX = map(mouseX, 0, width, 0, 1);
   *   let mousePosY = map(mouseY, 0, height, 0, 1);
   *
   *   imgShader.setUniform('uMousePos', [mousePosX, mousePosY]);
   *   imgShader.setUniform('uTexture', img);
   *   image(img, -width / 2, -height / 2, width, height);
   * }
   * </code>
   * </div>
   */
  fn.imageShader = function (s) {
    this._assert3d('imageShader');
    // p5._validateParameters('imageShader', arguments);

    this._renderer.imageShader(s);

    return this;
  };

  /**
   * Get the default shader used with lights, materials,
   * and textures.
   *
   * You can call <a href="#/p5.Shader/modify">`baseMaterialShader().modify()`</a>
   * and change any of the following hooks:
   *
   * <table>
   * <tr><th>Hook</th><th>Description</th></tr>
   * <tr><td>
   *
   * `void beforeVertex`
   *
   * </td><td>
   *
   * Called at the start of the vertex shader.
   *
   * </td></tr>
   * <tr><td>
   *
   * `Vertex getObjectInputs`
   *
   * </td><td>
   *
   * Update the vertex data of the model being drawn before any positioning has been applied. It takes in a `Vertex` struct, which includes:
   * - `vec3 position`, the position of the vertex
   * - `vec3 normal`, the direction facing out of the surface
   * - `vec2 texCoord`, the texture coordinates associeted with the vertex
   * - `vec4 color`, the per-vertex color
   * The struct can be modified and returned.
   *
   * </td></tr>
   * <tr><td>
   *
   * `Vertex getWorldInputs`
   *
   * </td><td>
   *
   * Update the vertex data of the model being drawn after transformations such as `translate()` and `scale()` have been applied, but before the camera has been applied. It takes in a `Vertex` struct like, in the `getObjectInputs` hook above, that can be modified and returned.
   *
   * </td></tr>
   * <tr><td>
   *
   * `Vertex getCameraInputs`
   *
   * </td><td>
   *
   * Update the vertex data of the model being drawn as they appear relative to the camera. It takes in a `Vertex` struct like, in the `getObjectInputs` hook above, that can be modified and returned.
   *
   * </td></tr>
   * <tr><td>
   *
   * `void afterVertex`
   *
   * </td><td>
   *
   * Called at the end of the vertex shader.
   *
   * </td></tr>
   * <tr><td>
   *
   * `void beforeFragment`
   *
   * </td><td>
   *
   * Called at the start of the fragment shader.
   *
   * </td></tr>
   * <tr><td>
   *
   * `Inputs getPixelInputs`
   *
   * </td><td>
   *
   * Update the per-pixel inputs of the material. It takes in an `Inputs` struct, which includes:
   * - `vec3 normal`, the direction pointing out of the surface
   * - `vec2 texCoord`, a vector where `x` and `y` are between 0 and 1 describing the spot on a texture the pixel is mapped to, as a fraction of the texture size
   * - `vec3 ambientLight`, the ambient light color on the vertex
   * - `vec4 color`, the base material color of the pixel
   * - `vec3 ambientMaterial`, the color of the pixel when affected by ambient light
   * - `vec3 specularMaterial`, the color of the pixel when reflecting specular highlights
   * - `vec3 emissiveMaterial`, the light color emitted by the pixel
   * - `float shininess`, a number representing how sharp specular reflections should be, from 1 to infinity
   * - `float metalness`, a number representing how mirrorlike the material should be, between 0 and 1
   * The struct can be modified and returned.
   * </td></tr>
   * <tr><td>
   *
   * `vec4 combineColors`
   *
   * </td><td>
   *
   * Take in a `ColorComponents` struct containing all the different components of light, and combining them into
   * a single final color. The struct contains:
   * - `vec3 baseColor`, the base color of the pixel
   * - `float opacity`, the opacity between 0 and 1 that it should be drawn at
   * - `vec3 ambientColor`, the color of the pixel when affected by ambient light
   * - `vec3 specularColor`, the color of the pixel when affected by specular reflections
   * - `vec3 diffuse`, the amount of diffused light hitting the pixel
   * - `vec3 ambient`, the amount of ambient light hitting the pixel
   * - `vec3 specular`, the amount of specular reflection hitting the pixel
   * - `vec3 emissive`, the amount of light emitted by the pixel
   *
   * </td></tr>
   * <tr><td>
   *
   * `vec4 getFinalColor`
   *
   * </td><td>
   *
   * Update the final color after mixing. It takes in a `vec4 color` and must return a modified version.
   *
   * </td></tr>
   * <tr><td>
   *
   * `void afterFragment`
   *
   * </td><td>
   *
   * Called at the end of the fragment shader.
   *
   * </td></tr>
   * </table>
   *
   * Most of the time, you will need to write your hooks in GLSL ES version 300. If you
   * are using WebGL 1 instead of 2, write your hooks in GLSL ES 100 instead.
   *
   * Call `baseMaterialShader().inspectHooks()` to see all the possible hooks and
   * their default implementations.
   *
   * @method baseMaterialShader
   * @beta
   * @returns {p5.Shader} The material shader
   *
   * @example
   * <div modernizr='webgl'>
   * <code>
   * let myShader;
   *
   * function setup() {
   *   createCanvas(200, 200, WEBGL);
   *   myShader = baseMaterialShader().modify(() => {
   *     let time = uniformFloat(() => millis());
   *     getWorldInputs((inputs) => {
   *       inputs.position.y +=
   *         20 * sin(time * 0.001 + inputs.position.x * 0.05);
   *       return inputs;
   *     });
   *   });
   * }
   *
   * function draw() {
   *   background(255);
   *   shader(myShader);
   *   lights();
   *   noStroke();
   *   fill('red');
   *   sphere(50);
   * }
   * </code>
   * </div>
   *
   * @example
   * <div modernizr='webgl'>
   * <code>
   * let myShader;
   *
   * function setup() {
   *   createCanvas(200, 200, WEBGL);
   *   myShader = baseMaterialShader().modify({
   *     declarations: 'vec3 myNormal;',
   *     'Inputs getPixelInputs': `(Inputs inputs) {
   *       myNormal = inputs.normal;
   *       return inputs;
   *     }`,
   *     'vec4 getFinalColor': `(vec4 color) {
   *       return mix(
   *         vec4(1.0, 1.0, 1.0, 1.0),
   *         color,
   *         abs(dot(myNormal, vec3(0.0, 0.0, 1.0)))
   *       );
   *     }`
   *   });
   * }
   *
   * function draw() {
   *   background(255);
   *   rotateY(millis() * 0.001);
   *   shader(myShader);
   *   lights();
   *   noStroke();
   *   fill('red');
   *   torus(30);
   * }
   * </code>
   * </div>
   *
   * @example
   * <div modernizr='webgl'>
   * <code>
   * let myShader;
   * let environment;
   *
   * async function setup() {
   *   environment = await loadImage('assets/outdoor_spheremap.jpg');
   *
   *   createCanvas(200, 200, WEBGL);
   *   myShader = baseMaterialShader().modify(() => {
   *     getPixelInputs((inputs) => {
   *       let factor = sin(
   *         TWO_PI * (inputs.texCoord.x + inputs.texCoord.y)
   *       );
   *       inputs.shininess = mix(1, 100, factor);
   *       inputs.metalness = factor;
   *       return inputs;
   *     })
   *   });
   * }
   *
   * function draw() {
   *   panorama(environment);
   *   ambientLight(100);
   *   imageLight(environment);
   *   rotateY(millis() * 0.001);
   *   shader(myShader);
   *   noStroke();
   *   fill(255);
   *   specularMaterial(150);
   *   sphere(50);
   * }
   * </code>
   * </div>
   *
   * @example
   * <div modernizr='webgl'>
   * <code>
   * let myShader;
   *
   * function setup() {
   *   createCanvas(200, 200, WEBGL);
   *   myShader = baseMaterialShader().modify(() => {
   *     getPixelInputs((inputs) => {
   *       inputs.normal.x += 0.2 * sin(
   *         sin(TWO_PI * dot(inputs.texCoord.yx, vec2(10, 25)))
   *       );
   *       inputs.normal.y += 0.2 * sin(
   *         sin(TWO_PI * dot(inputs.texCoord, vec2(10, 25)))
   *       );
   *       inputs.normal = normalize(inputs.normal);
   *       return inputs;
   *     });
   *   });
   * }
   *
   * function draw() {
   *   background(255);
   *   shader(myShader);
   *   ambientLight(150);
   *   pointLight(
   *     255, 255, 255,
   *     100*cos(frameCount*0.04), -50, 100*sin(frameCount*0.04)
   *   );
   *   noStroke();
   *   fill('red');
   *   shininess(200);
   *   specularMaterial(255);
   *   sphere(50);
   * }
   * </code>
   * </div>
   */
  fn.baseMaterialShader = function() {
    this._assert3d('baseMaterialShader');
    return this._renderer.baseMaterialShader();
  };

  /**
   * Get the base shader for filters.
   *
   * You can then call <a href="#/p5.Shader/modify">`baseFilterShader().modify()`</a>
   * and change the following hook:
   *
   * <table>
   * <tr><th>Hook</th><th>Description</th></tr>
   * <tr><td>
   *
   * `vec4 getColor`
   *
   * </td><td>
   *
   * Output the final color for the current pixel. It takes in two parameters:
   * `FilterInputs inputs`, and `in sampler2D canvasContent`, and must return a color
   * as a `vec4`.
   *
   * `FilterInputs inputs` is a scruct with the following properties:
   * - `vec2 texCoord`, the position on the canvas, with coordinates between 0 and 1. Calling
   *   `getTexture(canvasContent, texCoord)` returns the original color of the current pixel.
   * - `vec2 canvasSize`, the width and height of the sketch.
   * - `vec2 texelSize`, the size of one real pixel relative to the size of the whole canvas.
   *   This is equivalent to `1 / (canvasSize * pixelDensity)`.
   *
   * `in sampler2D canvasContent` is a texture with the contents of the sketch, pre-filter. Call
   * `getTexture(canvasContent, someCoordinate)` to retrieve the color of the sketch at that coordinate,
   * with coordinate values between 0 and 1.
   *
   * </td></tr>
   * </table>
   *
   * Most of the time, you will need to write your hooks in GLSL ES version 300. If you
   * are using WebGL 1, write your hooks in GLSL ES 100 instead.
   *
   * @method baseFilterShader
   * @beta
   * @returns {p5.Shader} The filter shader
   *
   * @example
   * <div modernizr='webgl'>
   * <code>
   * let img;
   * let myShader;
   *
   * async function setup() {
   *   img = await loadImage('assets/bricks.jpg');
   *   createCanvas(100, 100, WEBGL);
   *   myShader = baseFilterShader().modify(() => {
   *     let time = uniformFloat(() => millis());
   *     getColor((inputs, canvasContent) => {
   *       inputs.texCoord.y +=
   *         0.02 * sin(time * 0.001 + inputs.texCoord.x * 5);
   *       return texture(canvasContent, inputs.texCoord);
   *     });
   *   });
   * }
   *
   * function draw() {
   *   image(img, -50, -50);
   *   filter(myShader);
   *   describe('an image of bricks, distorting over time');
   * }
   * </code>
   * </div>
   */
  fn.baseFilterShader = function() {
    return (this._renderer.filterRenderer || this._renderer)
      .baseFilterShader();
  };

  /**
   * Get the shader used by <a href="#/p5/normalMaterial">`normalMaterial()`</a>.
   *
   * You can call <a href="#/p5.Shader/modify">`baseNormalShader().modify()`</a>
   * and change any of the following hooks:
   *
   * <table>
   * <tr><th>Hook</th><th>Description</th></tr>
   * <tr><td>
   *
   * `void beforeVertex`
   *
   * </td><td>
   *
   * Called at the start of the vertex shader.
   *
   * </td></tr>
   * <tr><td>
   *
   * `Vertex getObjectInputs`
   *
   * </td><td>
   *
   * Update the vertex data of the model being drawn before any positioning has been applied. It takes in a `Vertex` struct, which includes:
   * - `vec3 position`, the position of the vertex
   * - `vec3 normal`, the direction facing out of the surface
   * - `vec2 texCoord`, the texture coordinates associeted with the vertex
   * - `vec4 color`, the per-vertex color
   * The struct can be modified and returned.
   *
   * </td></tr>
   * <tr><td>
   *
   * `Vertex getWorldInputs`
   *
   * </td><td>
   *
   * Update the vertex data of the model being drawn after transformations such as `translate()` and `scale()` have been applied, but before the camera has been applied. It takes in a `Vertex` struct like, in the `getObjectInputs` hook above, that can be modified and returned.
   *
   * </td></tr>
   * <tr><td>
   *
   * `Vertex getCameraInputs`
   *
   * </td><td>
   *
   * Update the vertex data of the model being drawn as they appear relative to the camera. It takes in a `Vertex` struct like, in the `getObjectInputs` hook above, that can be modified and returned.
   *
   * </td></tr>
   * <tr><td>
   *
   * `void afterVertex`
   *
   * </td><td>
   *
   * Called at the end of the vertex shader.
   *
   * </td></tr>
   * <tr><td>
   *
   * `void beforeFragment`
   *
   * </td><td>
   *
   * Called at the start of the fragment shader.
   *
   * </td></tr>
   * <tr><td>
   *
   * `vec4 getFinalColor`
   *
   * </td><td>
   *
   * Update the final color after mixing. It takes in a `vec4 color` and must return a modified version.
   *
   * </td></tr>
   * <tr><td>
   *
   * `void afterFragment`
   *
   * </td><td>
   *
   * Called at the end of the fragment shader.
   *
   * </td></tr>
   * </table>
   *
   * Most of the time, you will need to write your hooks in GLSL ES version 300. If you
   * are using WebGL 1 instead of 2, write your hooks in GLSL ES 100 instead.
   *
   * Call `baseNormalShader().inspectHooks()` to see all the possible hooks and
   * their default implementations.
   *
   * @method baseNormalShader
   * @beta
   * @returns {p5.Shader} The `normalMaterial` shader
   *
   * @example
   * <div modernizr='webgl'>
   * <code>
   * let myShader;
   *
   * function setup() {
   *   createCanvas(200, 200, WEBGL);
   *   myShader = baseNormalShader().modify({
   *     uniforms: {
   *       'float time': () => millis()
   *     },
   *     'Vertex getWorldInputs': `(Vertex inputs) {
   *       inputs.position.y +=
   *         20. * sin(time * 0.001 + inputs.position.x * 0.05);
   *       return inputs;
   *     }`
   *   });
   * }
   *
   * function draw() {
   *   background(255);
   *   shader(myShader);
   *   noStroke();
   *   sphere(50);
   * }
   * </code>
   * </div>
   *
   * @example
   * <div modernizr='webgl'>
   * <code>
   * let myShader;
   *
   * function setup() {
   *   createCanvas(200, 200, WEBGL);
   *   myShader = baseNormalShader().modify({
   *     'Vertex getCameraInputs': `(Vertex inputs) {
   *       inputs.normal = abs(inputs.normal);
   *       return inputs;
   *     }`,
   *     'vec4 getFinalColor': `(vec4 color) {
   *       // Map the r, g, and b values of the old normal to new colors
   *       // instead of just red, green, and blue:
   *       vec3 newColor =
   *         color.r * vec3(89.0, 240.0, 232.0) / 255.0 +
   *         color.g * vec3(240.0, 237.0, 89.0) / 255.0 +
   *         color.b * vec3(205.0, 55.0, 222.0) / 255.0;
   *       newColor = newColor / (color.r + color.g + color.b);
   *       return vec4(newColor, 1.0) * color.a;
   *     }`
   *   });
   * }
   *
   * function draw() {
   *   background(255);
   *   shader(myShader);
   *   noStroke();
   *   rotateX(frameCount * 0.01);
   *   rotateY(frameCount * 0.015);
   *   box(100);
   * }
   * </code>
   * </div>
   */
  fn.baseNormalShader = function() {
    this._assert3d('baseNormalShader');
    return this._renderer.baseNormalShader();
  };

  /**
   * Get the shader used when no lights or materials are applied.
   *
   * You can call <a href="#/p5.Shader/modify">`baseColorShader().modify()`</a>
   * and change any of the following hooks:
   *
   * <table>
   * <tr><th>Hook</th><th>Description</th></tr>
   * <tr><td>
   *
   * `void beforeVertex`
   *
   * </td><td>
   *
   * Called at the start of the vertex shader.
   *
   * </td></tr>
   * <tr><td>
   *
   * `Vertex getObjectInputs`
   *
   * </td><td>
   *
   * Update the vertex data of the model being drawn before any positioning has been applied. It takes in a `Vertex` struct, which includes:
   * - `vec3 position`, the position of the vertex
   * - `vec3 normal`, the direction facing out of the surface
   * - `vec2 texCoord`, the texture coordinates associeted with the vertex
   * - `vec4 color`, the per-vertex color
   * The struct can be modified and returned.
   *
   * </td></tr>
   * <tr><td>
   *
   * `Vertex getWorldInputs`
   *
   * </td><td>
   *
   * Update the vertex data of the model being drawn after transformations such as `translate()` and `scale()` have been applied, but before the camera has been applied. It takes in a `Vertex` struct like, in the `getObjectInputs` hook above, that can be modified and returned.
   *
   * </td></tr>
   * <tr><td>
   *
   * `Vertex getCameraInputs`
   *
   * </td><td>
   *
   * Update the vertex data of the model being drawn as they appear relative to the camera. It takes in a `Vertex` struct like, in the `getObjectInputs` hook above, that can be modified and returned.
   *
   * </td></tr>
   * <tr><td>
   *
   * `void afterVertex`
   *
   * </td><td>
   *
   * Called at the end of the vertex shader.
   *
   * </td></tr>
   * <tr><td>
   *
   * `void beforeFragment`
   *
   * </td><td>
   *
   * Called at the start of the fragment shader.
   *
   * </td></tr>
   * <tr><td>
   *
   * `vec4 getFinalColor`
   *
   * </td><td>
   *
   * Update the final color after mixing. It takes in a `vec4 color` and must return a modified version.
   *
   * </td></tr>
   * <tr><td>
   *
   * `void afterFragment`
   *
   * </td><td>
   *
   * Called at the end of the fragment shader.
   *
   * </td></tr>
   * </table>
   *
   * Most of the time, you will need to write your hooks in GLSL ES version 300. If you
   * are using WebGL 1 instead of 2, write your hooks in GLSL ES 100 instead.
   *
   * Call `baseColorShader().inspectHooks()` to see all the possible hooks and
   * their default implementations.
   *
   * @method baseColorShader
   * @beta
   * @returns {p5.Shader} The color shader
   *
   * @example
   * <div modernizr='webgl'>
   * <code>
   * let myShader;
   *
   * function setup() {
   *   createCanvas(200, 200, WEBGL);
   *   myShader = baseColorShader().modify({
   *     uniforms: {
   *       'float time': () => millis()
   *     },
   *     'Vertex getWorldInputs': `(Vertex inputs) {
   *       inputs.position.y +=
   *         20. * sin(time * 0.001 + inputs.position.x * 0.05);
   *       return inputs;
   *     }`
   *   });
   * }
   *
   * function draw() {
   *   background(255);
   *   shader(myShader);
   *   noStroke();
   *   fill('red');
   *   circle(0, 0, 50);
   * }
   * </code>
   * </div>
   */
  fn.baseColorShader = function() {
    this._assert3d('baseColorShader');
    return this._renderer.baseColorShader();
  };

  /**
   * Get the shader used when drawing the strokes of shapes.
   *
   * You can call <a href="#/p5.Shader/modify">`baseStrokeShader().modify()`</a>
   * and change any of the following hooks:
   *
   * <table>
   * <tr><th>Hook</th><th>Description</th></tr>
   * <tr><td>
   *
   * `void beforeVertex`
   *
   * </td><td>
   *
   * Called at the start of the vertex shader.
   *
   * </td></tr>
   * <tr><td>
   *
   * `StrokeVertex getObjectInputs`
   *
   * </td><td>
   *
   * Update the vertex data of the stroke being drawn before any positioning has been applied. It takes in a `StrokeVertex` struct, which includes:
   * - `vec3 position`, the position of the vertex
   * - `vec3 tangentIn`, the tangent coming in to the vertex
   * - `vec3 tangentOut`, the tangent coming out of the vertex. In straight segments, this will be the same as `tangentIn`. In joins, it will be different. In caps, one of the tangents will be 0.
   * - `vec4 color`, the per-vertex color
   * - `float weight`, the stroke weight
   * The struct can be modified and returned.
   *
   * </td></tr>
   * <tr><td>
   *
   * `StrokeVertex getWorldInputs`
   *
   * </td><td>
   *
   * Update the vertex data of the model being drawn after transformations such as `translate()` and `scale()` have been applied, but before the camera has been applied. It takes in a `StrokeVertex` struct like, in the `getObjectInputs` hook above, that can be modified and returned.
   *
   * </td></tr>
   * <tr><td>
   *
   * `StrokeVertex getCameraInputs`
   *
   * </td><td>
   *
   * Update the vertex data of the model being drawn as they appear relative to the camera. It takes in a `StrokeVertex` struct like, in the `getObjectInputs` hook above, that can be modified and returned.
   *
   * </td></tr>
   * <tr><td>
   *
   * `void afterVertex`
   *
   * </td><td>
   *
   * Called at the end of the vertex shader.
   *
   * </td></tr>
   * <tr><td>
   *
   * `void beforeFragment`
   *
   * </td><td>
   *
   * Called at the start of the fragment shader.
   *
   * </td></tr>
   * <tr><td>
   *
   * `Inputs getPixelInputs`
   *
   * </td><td>
   *
   * Update the inputs to the shader. It takes in a struct `Inputs inputs`, which includes:
   * - `vec4 color`, the color of the stroke
   * - `vec2 tangent`, the direction of the stroke in screen space
   * - `vec2 center`, the coordinate of the center of the stroke in screen space p5.js pixels
   * - `vec2 position`, the coordinate of the current pixel in screen space p5.js pixels
   * - `float strokeWeight`, the thickness of the stroke in p5.js pixels
   *
   * </td></tr>
   * <tr><td>
   *
   * `bool shouldDiscard`
   *
   * </td><td>
   *
   * Caps and joins are made by discarded pixels in the fragment shader to carve away unwanted areas. Use this to change this logic. It takes in a `bool willDiscard` and must return a modified version.
   *
   * </td></tr>
   * <tr><td>
   *
   * `vec4 getFinalColor`
   *
   * </td><td>
   *
   * Update the final color after mixing. It takes in a `vec4 color` and must return a modified version.
   *
   * </td></tr>
   * <tr><td>
   *
   * `void afterFragment`
   *
   * </td><td>
   *
   * Called at the end of the fragment shader.
   *
   * </td></tr>
   * </table>
   *
   * Most of the time, you will need to write your hooks in GLSL ES version 300. If you
   * are using WebGL 1 instead of 2, write your hooks in GLSL ES 100 instead.
   *
   * Call `baseStrokeShader().inspectHooks()` to see all the possible hooks and
   * their default implementations.
   *
   * @method baseStrokeShader
   * @beta
   * @returns {p5.Shader} The stroke shader
   *
   * @example
   * <div modernizr='webgl'>
   * <code>
   * let myShader;
   *
   * function setup() {
   *   createCanvas(200, 200, WEBGL);
   *   myShader = baseStrokeShader().modify({
   *     'Inputs getPixelInputs': `(Inputs inputs) {
   *       float opacity = 1.0 - smoothstep(
   *         0.0,
   *         15.0,
   *         length(inputs.position - inputs.center)
   *       );
   *       inputs.color *= opacity;
   *       return inputs;
   *     }`
   *   });
   * }
   *
   * function draw() {
   *   background(255);
   *   strokeShader(myShader);
   *   strokeWeight(30);
   *   line(
   *     -width/3,
   *     sin(millis()*0.001) * height/4,
   *     width/3,
   *     sin(millis()*0.001 + 1) * height/4
   *   );
   * }
   * </code>
   * </div>
   *
   * @example
   * <div modernizr='webgl'>
   * <code>
   * let myShader;
   *
   * function setup() {
   *   createCanvas(200, 200, WEBGL);
   *   myShader = baseStrokeShader().modify({
   *     uniforms: {
   *       'float time': () => millis()
   *     },
   *     'StrokeVertex getWorldInputs': `(StrokeVertex inputs) {
   *       // Add a somewhat random offset to the weight
   *       // that varies based on position and time
   *       float scale = 0.8 + 0.2*sin(10.0 * sin(
   *         floor(time/250.) +
   *         inputs.position.x*0.01 +
   *         inputs.position.y*0.01
   *       ));
   *       inputs.weight *= scale;
   *       return inputs;
   *     }`
   *   });
   * }
   *
   * function draw() {
   *   background(255);
   *   strokeShader(myShader);
   *   myShader.setUniform('time', millis());
   *   strokeWeight(10);
   *   beginShape();
   *   for (let i = 0; i <= 50; i++) {
   *     let r = map(i, 0, 50, 0, width/3);
   *     let x = r*cos(i*0.2);
   *     let y = r*sin(i*0.2);
   *     vertex(x, y);
   *   }
   *   endShape();
   * }
   * </code>
   * </div>
   *
   * @example
   * <div modernizr='webgl'>
   * <code>
   * let myShader;
   *
   * function setup() {
   *   createCanvas(200, 200, WEBGL);
   *   myShader = baseStrokeShader().modify({
   *     'float random': `(vec2 p) {
   *       vec3 p3  = fract(vec3(p.xyx) * .1031);
   *       p3 += dot(p3, p3.yzx + 33.33);
   *       return fract((p3.x + p3.y) * p3.z);
   *     }`,
   *     'Inputs getPixelInputs': `(Inputs inputs) {
   *       // Replace alpha in the color with dithering by
   *       // randomly setting pixel colors to 0 based on opacity
   *       float a = inputs.color.a;
   *       inputs.color.a = 1.0;
   *       inputs.color *= random(inputs.position.xy) > a ? 0.0 : 1.0;
   *       return inputs;
   *     }`
   *   });
   * }
   *
   * function draw() {
   *   background(255);
   *   strokeShader(myShader);
   *   strokeWeight(10);
   *   beginShape();
   *   for (let i = 0; i <= 50; i++) {
   *     stroke(
   *       0,
   *       255
   *         * map(i, 0, 20, 0, 1, true)
   *         * map(i, 30, 50, 1, 0, true)
   *     );
   *     vertex(
   *       map(i, 0, 50, -1, 1) * width/3,
   *       50 * sin(i/10 + frameCount/100)
   *     );
   *   }
   *   endShape();
   * }
   * </code>
   * </div>
   */
  fn.baseStrokeShader = function() {
    this._assert3d('baseStrokeShader');
    return this._renderer.baseStrokeShader();
  };

  /**
   * Restores the default shaders.
   *
   * `resetShader()` deactivates any shaders previously applied by
   * <a href="#/p5/shader">shader()</a>, <a href="#/p5/strokeShader">strokeShader()</a>,
   * or <a href="#/p5/imageShader">imageShader()</a>.
   *
   * Note: Shaders can only be used in WebGL mode.
   *
   * @method resetShader
   * @chainable
   *
   * @example
   * <div>
   * <code>
   * // Create a string with the vertex shader program.
   * // The vertex shader is called for each vertex.
   * let vertSrc = `
   * attribute vec3 aPosition;
   * attribute vec2 aTexCoord;
   * uniform mat4 uProjectionMatrix;
   * uniform mat4 uModelViewMatrix;
   * varying vec2 vTexCoord;
   *
   * void main() {
   *   vTexCoord = aTexCoord;
   *   vec4 position = vec4(aPosition, 1.0);
   *   gl_Position = uProjectionMatrix * uModelViewMatrix * position;
   * }
   * `;
   *
   * // Create a string with the fragment shader program.
   * // The fragment shader is called for each pixel.
   * let fragSrc = `
   * precision mediump float;
   * varying vec2 vTexCoord;
   *
   * void main() {
   *   vec2 uv = vTexCoord;
   *   vec3 color = vec3(uv.x, uv.y, min(uv.x + uv.y, 1.0));
   *   gl_FragColor = vec4(color, 1.0);
   * }
   * `;
   *
   * let myShader;
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Create a p5.Shader object.
   *   myShader = createShader(vertSrc, fragSrc);
   *
   *   describe(
   *     'Two rotating cubes on a gray background. The left one has a blue-purple gradient on each face. The right one is red.'
   *   );
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Draw a box using the p5.Shader.
   *   // shader() sets the active shader to myShader.
   *   shader(myShader);
   *   push();
   *   translate(-25, 0, 0);
   *   rotateX(frameCount * 0.01);
   *   rotateY(frameCount * 0.01);
   *   box(width / 4);
   *   pop();
   *
   *   // Draw a box using the default fill shader.
   *   // resetShader() restores the default fill shader.
   *   resetShader();
   *   fill(255, 0, 0);
   *   push();
   *   translate(25, 0, 0);
   *   rotateX(frameCount * 0.01);
   *   rotateY(frameCount * 0.01);
   *   box(width / 4);
   *   pop();
   * }
   * </code>
   * </div>
   */
  fn.resetShader = function () {
    this._renderer.resetShader();
    return this;
  };

  /**
   * Sets the texture that will be used on shapes.
   *
   * A texture is like a skin that wraps around a shape. `texture()` works with
   * built-in shapes, such as <a href="#/p5/square">square()</a> and
   * <a href="#/p5/sphere">sphere()</a>, and custom shapes created with
   * functions such as <a href="#/p5/buildGeometry">buildGeometry()</a>. To
   * texture a geometry created with <a href="#/p5/beginShape">beginShape()</a>,
   * uv coordinates must be passed to each
   * <a href="#/p5/vertex">vertex()</a> call.
   *
   * The parameter, `tex`, is the texture to apply. `texture()` can use a range
   * of sources including images, videos, and offscreen renderers such as
   * <a href="#/p5.Graphics">p5.Graphics</a> and
   * <a href="#/p5.Framebuffer">p5.Framebuffer</a> objects.
   *
   * To texture a geometry created with <a href="#/p5/beginShape">beginShape()</a>,
   * you will need to specify uv coordinates in <a href="#/p5/vertex">vertex()</a>.
   *
   * Note: `texture()` can only be used in WebGL mode.
   *
   * @method texture
   * @param {p5.Image|p5.MediaElement|p5.Graphics|p5.Texture|p5.Framebuffer|p5.FramebufferTexture} tex media to use as the texture.
   * @chainable
   *
   * @example
   * <div>
   * <code>
   * let img;
   *
   * async function setup() {
   *   // Load an image and create a p5.Image object.
   *   img = await loadImage('assets/laDefense.jpg');
   *
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A spinning cube with an image of a ceiling on each face.');
   * }
   *
   * function draw() {
   *   background(0);
   *
   *   // Rotate around the x-, y-, and z-axes.
   *   rotateZ(frameCount * 0.01);
   *   rotateX(frameCount * 0.01);
   *   rotateY(frameCount * 0.01);
   *
   *   // Apply the image as a texture.
   *   texture(img);
   *
   *   // Draw the box.
   *   box(50);
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * let pg;
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Create a p5.Graphics object.
   *   pg = createGraphics(100, 100);
   *
   *   // Draw a circle to the p5.Graphics object.
   *   pg.background(200);
   *   pg.circle(50, 50, 30);
   *
   *   describe('A spinning cube with circle at the center of each face.');
   * }
   *
   * function draw() {
   *   background(0);
   *
   *   // Rotate around the x-, y-, and z-axes.
   *   rotateZ(frameCount * 0.01);
   *   rotateX(frameCount * 0.01);
   *   rotateY(frameCount * 0.01);
   *
   *   // Apply the p5.Graphics object as a texture.
   *   texture(pg);
   *
   *   // Draw the box.
   *   box(50);
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * let vid;
   *
   * function setup() {
   *   // Load a video and create a p5.MediaElement object.
   *   vid = createVideo('assets/fingers.mov');
   *
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Hide the video.
   *   vid.hide();
   *
   *   // Set the video to loop.
   *   vid.loop();
   *
   *   describe('A rectangle with video as texture');
   * }
   *
   * function draw() {
   *   background(0);
   *
   *   // Rotate around the y-axis.
   *   rotateY(frameCount * 0.01);
   *
   *   // Apply the video as a texture.
   *   texture(vid);
   *
   *   // Draw the rectangle.
   *   rect(-40, -40, 80, 80);
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * let vid;
   *
   * function setup() {
   *   // Load a video and create a p5.MediaElement object.
   *   vid = createVideo('assets/fingers.mov');
   *
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Hide the video.
   *   vid.hide();
   *
   *   // Set the video to loop.
   *   vid.loop();
   *
   *   describe('A rectangle with video as texture');
   * }
   *
   * function draw() {
   *   background(0);
   *
   *   // Rotate around the y-axis.
   *   rotateY(frameCount * 0.01);
   *
   *   // Set the texture mode.
   *   textureMode(NORMAL);
   *
   *   // Apply the video as a texture.
   *   texture(vid);
   *
   *   // Draw a custom shape using uv coordinates.
   *   beginShape();
   *   vertex(-40, -40, 0, 0);
   *   vertex(40, -40, 1, 0);
   *   vertex(40, 40, 1, 1);
   *   vertex(-40, 40, 0, 1);
   *   endShape();
   * }
   * </code>
   * </div>
   */
  fn.texture = function (tex) {
    this._assert3d('texture');
    // p5._validateParameters('texture', arguments);

    // NOTE: make generic or remove need for
    if (tex.gifProperties) {
      tex._animateGif(this);
    }

    this._renderer.texture(tex);

    return this;
  };

  /**
   * Changes the coordinate system used for textures when theyre applied to
   * custom shapes.
   *
   * In order for <a href="#/p5/texture">texture()</a> to work, a shape needs a
   * way to map the points on its surface to the pixels in an image. Built-in
   * shapes such as <a href="#/p5/rect">rect()</a> and
   * <a href="#/p5/box">box()</a> already have these texture mappings based on
   * their vertices. Custom shapes created with
   * <a href="#/p5/vertex">vertex()</a> require texture mappings to be passed as
   * uv coordinates.
   *
   * Each call to <a href="#/p5/vertex">vertex()</a> must include 5 arguments,
   * as in `vertex(x, y, z, u, v)`, to map the vertex at coordinates `(x, y, z)`
   * to the pixel at coordinates `(u, v)` within an image. For example, the
   * corners of a rectangular image are mapped to the corners of a rectangle by default:
   *
   * ```js
   * // Apply the image as a texture.
   * texture(img);
   *
   * // Draw the rectangle.
   * rect(0, 0, 30, 50);
   * ```
   *
   * If the image in the code snippet above has dimensions of 300 x 500 pixels,
   * the same result could be achieved as follows:
   *
   * ```js
   * // Apply the image as a texture.
   * texture(img);
   *
   * // Draw the rectangle.
   * beginShape();
   *
   * // Top-left.
   * // u: 0, v: 0
   * vertex(0, 0, 0, 0, 0);
   *
   * // Top-right.
   * // u: 300, v: 0
   * vertex(30, 0, 0, 300, 0);
   *
   * // Bottom-right.
   * // u: 300, v: 500
   * vertex(30, 50, 0, 300, 500);
   *
   * // Bottom-left.
   * // u: 0, v: 500
   * vertex(0, 50, 0, 0, 500);
   *
   * endShape();
   * ```
   *
   * `textureMode()` changes the coordinate system for uv coordinates.
   *
   * The parameter, `mode`, accepts two possible constants. If `NORMAL` is
   * passed, as in `textureMode(NORMAL)`, then the textures uv coordinates can
   * be provided in the range 0 to 1 instead of the images dimensions. This can
   * be helpful for using the same code for multiple images of different sizes.
   * For example, the code snippet above could be rewritten as follows:
   *
   * ```js
   * // Set the texture mode to use normalized coordinates.
   * textureMode(NORMAL);
   *
   * // Apply the image as a texture.
   * texture(img);
   *
   * // Draw the rectangle.
   * beginShape();
   *
   * // Top-left.
   * // u: 0, v: 0
   * vertex(0, 0, 0, 0, 0);
   *
   * // Top-right.
   * // u: 1, v: 0
   * vertex(30, 0, 0, 1, 0);
   *
   * // Bottom-right.
   * // u: 1, v: 1
   * vertex(30, 50, 0, 1, 1);
   *
   * // Bottom-left.
   * // u: 0, v: 1
   * vertex(0, 50, 0, 0, 1);
   *
   * endShape();
   * ```
   *
   * By default, `mode` is `IMAGE`, which scales uv coordinates to the
   * dimensions of the image. Calling `textureMode(IMAGE)` applies the default.
   *
   * Note: `textureMode()` can only be used in WebGL mode.
   *
   * @method  textureMode
   * @param {(IMAGE|NORMAL)} mode either IMAGE or NORMAL.
   *
   * @example
   * <div>
   * <code>
   * let img;
   *
   * async function setup() {
   *   // Load an image and create a p5.Image object.
   *   img = await loadImage('assets/laDefense.jpg');
   *
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('An image of a ceiling against a black background.');
   * }
   *
   * function draw() {
   *   background(0);
   *
   *   // Apply the image as a texture.
   *   texture(img);
   *
   *   // Draw the custom shape.
   *   // Use the image's width and height as uv coordinates.
   *   beginShape();
   *   vertex(-30, -30, 0, 0);
   *   vertex(30, -30, img.width, 0);
   *   vertex(30, 30, img.width, img.height);
   *   vertex(-30, 30, 0, img.height);
   *   endShape();
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * let img;
   *
   * async function setup() {
   *   // Load an image and create a p5.Image object.
   *   img = await loadImage('assets/laDefense.jpg');
   *
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('An image of a ceiling against a black background.');
   * }
   *
   * function draw() {
   *   background(0);
   *
   *   // Set the texture mode.
   *   textureMode(NORMAL);
   *
   *   // Apply the image as a texture.
   *   texture(img);
   *
   *   // Draw the custom shape.
   *   // Use normalized uv coordinates.
   *   beginShape();
   *   vertex(-30, -30, 0, 0);
   *   vertex(30, -30, 1, 0);
   *   vertex(30, 30, 1, 1);
   *   vertex(-30, 30, 0, 1);
   *   endShape();
   * }
   * </code>
   * </div>
   */
  fn.textureMode = function (mode) {
    if (mode !== IMAGE && mode !== NORMAL) {
      console.warn(
        `You tried to set ${mode} textureMode only supports IMAGE & NORMAL `
      );
    } else {
      this._renderer.states.setValue('textureMode', mode);
    }
  };

  /**
   * Changes the way textures behave when a shapes uv coordinates go beyond the
   * texture.
   *
   * In order for <a href="#/p5/texture">texture()</a> to work, a shape needs a
   * way to map the points on its surface to the pixels in an image. Built-in
   * shapes such as <a href="#/p5/rect">rect()</a> and
   * <a href="#/p5/box">box()</a> already have these texture mappings based on
   * their vertices. Custom shapes created with
   * <a href="#/p5/vertex">vertex()</a> require texture mappings to be passed as
   * uv coordinates.
   *
   * Each call to <a href="#/p5/vertex">vertex()</a> must include 5 arguments,
   * as in `vertex(x, y, z, u, v)`, to map the vertex at coordinates `(x, y, z)`
   * to the pixel at coordinates `(u, v)` within an image. For example, the
   * corners of a rectangular image are mapped to the corners of a rectangle by default:
   *
   * ```js
   * // Apply the image as a texture.
   * texture(img);
   *
   * // Draw the rectangle.
   * rect(0, 0, 30, 50);
   * ```
   *
   * If the image in the code snippet above has dimensions of 300 x 500 pixels,
   * the same result could be achieved as follows:
   *
   * ```js
   * // Apply the image as a texture.
   * texture(img);
   *
   * // Draw the rectangle.
   * beginShape();
   *
   * // Top-left.
   * // u: 0, v: 0
   * vertex(0, 0, 0, 0, 0);
   *
   * // Top-right.
   * // u: 300, v: 0
   * vertex(30, 0, 0, 300, 0);
   *
   * // Bottom-right.
   * // u: 300, v: 500
   * vertex(30, 50, 0, 300, 500);
   *
   * // Bottom-left.
   * // u: 0, v: 500
   * vertex(0, 50, 0, 0, 500);
   *
   * endShape();
   * ```
   *
   * `textureWrap()` controls how textures behave when their uv's go beyond the
   * texture. Doing so can produce interesting visual effects such as tiling.
   * For example, the custom shape above could have u-coordinates are greater
   * than the images width:
   *
   * ```js
   * // Apply the image as a texture.
   * texture(img);
   *
   * // Draw the rectangle.
   * beginShape();
   * vertex(0, 0, 0, 0, 0);
   *
   * // Top-right.
   * // u: 600
   * vertex(30, 0, 0, 600, 0);
   *
   * // Bottom-right.
   * // u: 600
   * vertex(30, 50, 0, 600, 500);
   *
   * vertex(0, 50, 0, 0, 500);
   * endShape();
   * ```
   *
   * The u-coordinates of 600 are greater than the texture images width of 300.
   * This creates interesting possibilities.
   *
   * The first parameter, `wrapX`, accepts three possible constants. If `CLAMP`
   * is passed, as in `textureWrap(CLAMP)`, the pixels at the edge of the
   * texture will extend to the shapes edges. If `REPEAT` is passed, as in
   * `textureWrap(REPEAT)`, the texture will tile repeatedly until reaching the
   * shapes edges. If `MIRROR` is passed, as in `textureWrap(MIRROR)`, the
   * texture will tile repeatedly until reaching the shapes edges, flipping
   * its orientation between tiles. By default, textures `CLAMP`.
   *
   * The second parameter, `wrapY`, is optional. It accepts the same three
   * constants, `CLAMP`, `REPEAT`, and `MIRROR`. If one of these constants is
   * passed, as in `textureWRAP(MIRROR, REPEAT)`, then the texture will `MIRROR`
   * horizontally and `REPEAT` vertically. By default, `wrapY` will be set to
   * the same value as `wrapX`.
   *
   * Note: `textureWrap()` can only be used in WebGL mode.
   *
   * @method textureWrap
   * @param {(CLAMP|REPEAT|MIRROR)} wrapX either CLAMP, REPEAT, or MIRROR
   * @param {(CLAMP|REPEAT|MIRROR)} [wrapY=wrapX] either CLAMP, REPEAT, or MIRROR
   *
   * @example
   * <div>
   * <code>
   * let img;
   *
   * async function setup() {
   *   img = await loadImage('assets/rockies128.jpg');
   *
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe(
   *     'An image of a landscape occupies the top-left corner of a square. Its edge colors smear to cover the other thre quarters of the square.'
   *   );
   * }
   *
   * function draw() {
   *   background(0);
   *
   *   // Set the texture mode.
   *   textureMode(NORMAL);
   *
   *   // Set the texture wrapping.
   *   // Note: CLAMP is the default mode.
   *   textureWrap(CLAMP);
   *
   *   // Apply the image as a texture.
   *   texture(img);
   *
   *   // Style the shape.
   *   noStroke();
   *
   *   // Draw the shape.
   *   // Use uv coordinates > 1.
   *   beginShape();
   *   vertex(-30, -30, 0, 0, 0);
   *   vertex(30, -30, 0, 2, 0);
   *   vertex(30, 30, 0, 2, 2);
   *   vertex(-30, 30, 0, 0, 2);
   *   endShape();
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * let img;
   *
   * async function setup() {
   *   img = await loadImage('assets/rockies128.jpg');
   *
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('Four identical images of a landscape arranged in a grid.');
   * }
   *
   * function draw() {
   *   background(0);
   *
   *   // Set the texture mode.
   *   textureMode(NORMAL);
   *
   *   // Set the texture wrapping.
   *   textureWrap(REPEAT);
   *
   *   // Apply the image as a texture.
   *   texture(img);
   *
   *   // Style the shape.
   *   noStroke();
   *
   *   // Draw the shape.
   *   // Use uv coordinates > 1.
   *   beginShape();
   *   vertex(-30, -30, 0, 0, 0);
   *   vertex(30, -30, 0, 2, 0);
   *   vertex(30, 30, 0, 2, 2);
   *   vertex(-30, 30, 0, 0, 2);
   *   endShape();
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * let img;
   *
   * async function setup() {
   *   img = await loadImage('assets/rockies128.jpg');
   *
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe(
   *     'Four identical images of a landscape arranged in a grid. The images are reflected horizontally and vertically, creating a kaleidoscope effect.'
   *   );
   * }
   *
   * function draw() {
   *   background(0);
   *
   *   // Set the texture mode.
   *   textureMode(NORMAL);
   *
   *   // Set the texture wrapping.
   *   textureWrap(MIRROR);
   *
   *   // Apply the image as a texture.
   *   texture(img);
   *
   *   // Style the shape.
   *   noStroke();
   *
   *   // Draw the shape.
   *   // Use uv coordinates > 1.
   *   beginShape();
   *   vertex(-30, -30, 0, 0, 0);
   *   vertex(30, -30, 0, 2, 0);
   *   vertex(30, 30, 0, 2, 2);
   *   vertex(-30, 30, 0, 0, 2);
   *   endShape();
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * let img;
   *
   * async function setup() {
   *   img = await loadImage('assets/rockies128.jpg');
   *
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe(
   *     'Four identical images of a landscape arranged in a grid. The top row and bottom row are reflections of each other.'
   *   );
   * }
   *
   * function draw() {
   *   background(0);
   *
   *   // Set the texture mode.
   *   textureMode(NORMAL);
   *
   *   // Set the texture wrapping.
   *   textureWrap(REPEAT, MIRROR);
   *
   *   // Apply the image as a texture.
   *   texture(img);
   *
   *   // Style the shape.
   *   noStroke();
   *
   *   // Draw the shape.
   *   // Use uv coordinates > 1.
   *   beginShape();
   *   vertex(-30, -30, 0, 0, 0);
   *   vertex(30, -30, 0, 2, 0);
   *   vertex(30, 30, 0, 2, 2);
   *   vertex(-30, 30, 0, 0, 2);
   *   endShape();
   * }
   * </code>
   * </div>
   */
  fn.textureWrap = function (wrapX, wrapY = wrapX) {
    this._renderer.states.setValue('textureWrapX', wrapX);
    this._renderer.states.setValue('textureWrapY', wrapY);

    for (const texture of this._renderer.textures.values()) {
      texture.setWrapMode(wrapX, wrapY);
    }
  };

  /**
   * Sets the current material as a normal material.
   *
   * A normal material sets surfaces facing the x-axis to red, those facing the
   * y-axis to green, and those facing the z-axis to blue. Normal material isn't
   * affected by light. Its often used as a placeholder material when debugging.
   *
   * Note: `normalMaterial()` can only be used in WebGL mode.
   *
   * @method normalMaterial
   * @chainable
   *
   * @example
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A multicolor torus drawn on a gray background.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Style the torus.
   *   normalMaterial();
   *
   *   // Draw the torus.
   *   torus(30);
   * }
   * </code>
   * </div>
   */
  fn.normalMaterial = function (...args) {
    this._assert3d('normalMaterial');
    // p5._validateParameters('normalMaterial', args);

    this._renderer.normalMaterial(...args);

    return this;
  };

  /**
   * Sets the ambient color of shapes surface material.
   *
   * The `ambientMaterial()` color sets the components of the
   * <a href="#/p5/ambientLight">ambientLight()</a> color that shapes will
   * reflect. For example, calling `ambientMaterial(255, 255, 0)` would cause a
   * shape to reflect red and green light, but not blue light.
   *
   * `ambientMaterial()` can be called three ways with different parameters to
   * set the materials color.
   *
   * The first way to call `ambientMaterial()` has one parameter, `gray`.
   * Grayscale values between 0 and 255, as in `ambientMaterial(50)`, can be
   * passed to set the materials color. Higher grayscale values make shapes
   * appear brighter.
   *
   * The second way to call `ambientMaterial()` has one parameter, `color`. A
   * <a href="#/p5.Color">p5.Color</a> object, an array of color values, or a
   * CSS color string, as in `ambientMaterial('magenta')`, can be passed to set
   * the materials color.
   *
   * The third way to call `ambientMaterial()` has three parameters, `v1`, `v2`,
   * and `v3`. RGB, HSB, or HSL values, as in `ambientMaterial(255, 0, 0)`, can
   * be passed to set the materials colors. Color values will be interpreted
   * using the current <a href="#/p5/colorMode">colorMode()</a>.
   *
   * Note: `ambientMaterial()` can only be used in WebGL mode.
   *
   * @method ambientMaterial
   * @param  {Number} v1  red or hue value in the current
   *                       <a href="#/p5/colorMode">colorMode()</a>.
   * @param  {Number} v2  green or saturation value in the
   *                      current <a href="#/p5/colorMode">colorMode()</a>.
   * @param  {Number} v3  blue, brightness, or lightness value in the
   *                      current <a href="#/p5/colorMode">colorMode()</a>.
   * @chainable
   *
   * @example
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A magenta cube drawn on a gray background.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Turn on a magenta ambient light.
   *   ambientLight(255, 0, 255);
   *
   *   // Draw the box.
   *   box();
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A purple cube drawn on a gray background.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Turn on a magenta ambient light.
   *   ambientLight(255, 0, 255);
   *
   *   // Add a dark gray ambient material.
   *   ambientMaterial(150);
   *
   *   // Draw the box.
   *   box();
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A red cube drawn on a gray background.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Turn on a magenta ambient light.
   *   ambientLight(255, 0, 255);
   *
   *   // Add a yellow ambient material using RGB values.
   *   ambientMaterial(255, 255, 0);
   *
   *   // Draw the box.
   *   box();
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A red cube drawn on a gray background.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Turn on a magenta ambient light.
   *   ambientLight(255, 0, 255);
   *
   *   // Add a yellow ambient material using a p5.Color object.
   *   let c = color(255, 255, 0);
   *   ambientMaterial(c);
   *
   *   // Draw the box.
   *   box();
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A red cube drawn on a gray background.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Turn on a magenta ambient light.
   *   ambientLight(255, 0, 255);
   *
   *   // Add a yellow ambient material using a color string.
   *   ambientMaterial('yellow');
   *
   *   // Draw the box.
   *   box();
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A yellow cube drawn on a gray background.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Turn on a white ambient light.
   *   ambientLight(255, 255, 255);
   *
   *   // Add a yellow ambient material using a color string.
   *   ambientMaterial('yellow');
   *
   *   // Draw the box.
   *   box();
   * }
   * </code>
   * </div>
   */

  /**
   * @method ambientMaterial
   * @param  {Number} gray grayscale value between 0 (black) and 255 (white).
   * @chainable
   */

  /**
   * @method ambientMaterial
   * @param  {p5.Color|Number[]|String} color
   *           color as a <a href="#/p5.Color">p5.Color</a> object,
   *            an array of color values, or a CSS string.
   * @chainable
   */
  fn.ambientMaterial = function (v1, v2, v3) {
    this._assert3d('ambientMaterial');
    // p5._validateParameters('ambientMaterial', arguments);

    const color = fn.color.apply(this, arguments);
    this._renderer.states.setValue('_hasSetAmbient', true);
    this._renderer.states.setValue('curAmbientColor', color._array);
    this._renderer.states.setValue('_useNormalMaterial', false);
    this._renderer.states.setValue('enableLighting', true);
    if (!this._renderer.states.fillColor) {
      this._renderer.states.setValue('fillColor', new Color([1, 1, 1]));
    }
    return this;
  };

  /**
   * Sets the emissive color of shapes surface material.
   *
   * The `emissiveMaterial()` color sets a color shapes display at full
   * strength, regardless of lighting. This can give the appearance that a shape
   * is glowing. However, emissive materials dont actually emit light that
   * can affect surrounding objects.
   *
   * `emissiveMaterial()` can be called three ways with different parameters to
   * set the materials color.
   *
   * The first way to call `emissiveMaterial()` has one parameter, `gray`.
   * Grayscale values between 0 and 255, as in `emissiveMaterial(50)`, can be
   * passed to set the materials color. Higher grayscale values make shapes
   * appear brighter.
   *
   * The second way to call `emissiveMaterial()` has one parameter, `color`. A
   * <a href="#/p5.Color">p5.Color</a> object, an array of color values, or a
   * CSS color string, as in `emissiveMaterial('magenta')`, can be passed to set
   * the materials color.
   *
   * The third way to call `emissiveMaterial()` has four parameters, `v1`, `v2`,
   * `v3`, and `alpha`. `alpha` is optional. RGBA, HSBA, or HSLA values can be
   * passed to set the materials colors, as in `emissiveMaterial(255, 0, 0)` or
   * `emissiveMaterial(255, 0, 0, 30)`. Color values will be interpreted using
   * the current <a href="#/p5/colorMode">colorMode()</a>.
   *
   * Note: `emissiveMaterial()` can only be used in WebGL mode.
   *
   * @method emissiveMaterial
   * @param  {Number} v1       red or hue value in the current
   *                           <a href="#/p5/colorMode">colorMode()</a>.
   * @param  {Number} v2       green or saturation value in the
   *                           current <a href="#/p5/colorMode">colorMode()</a>.
   * @param  {Number} v3       blue, brightness, or lightness value in the
   *                           current <a href="#/p5/colorMode">colorMode()</a>.
   * @param  {Number} [alpha]  alpha value in the current
   *                           <a href="#/p5/colorMode">colorMode()</a>.
   * @chainable
   *
   * @example
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A red cube drawn on a gray background.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Turn on a white ambient light.
   *   ambientLight(255, 255, 255);
   *
   *   // Add a red emissive material using RGB values.
   *   emissiveMaterial(255, 0, 0);
   *
   *   // Draw the box.
   *   box();
   * }
   * </code>
   * </div>
   */

  /**
   * @method emissiveMaterial
   * @param  {Number} gray grayscale value between 0 (black) and 255 (white).
   * @chainable
   */

  /**
   * @method emissiveMaterial
   * @param  {p5.Color|Number[]|String} color
   *           color as a <a href="#/p5.Color">p5.Color</a> object,
   *            an array of color values, or a CSS string.
   * @chainable
   */
  fn.emissiveMaterial = function (v1, v2, v3, a) {
    this._assert3d('emissiveMaterial');
    // p5._validateParameters('emissiveMaterial', arguments);

    const color = fn.color.apply(this, arguments);
    this._renderer.states.setValue('curEmissiveColor', color._array);
    this._renderer.states.setValue('_useEmissiveMaterial', true);
    this._renderer.states.setValue('_useNormalMaterial', false);
    this._renderer.states.setValue('enableLighting', true);

    return this;
  };

  /**
   * Sets the specular color of shapes surface material.
   *
   * The `specularMaterial()` color sets the components of light color that
   * glossy coats on shapes will reflect. For example, calling
   * `specularMaterial(255, 255, 0)` would cause a shape to reflect red and
   * green light, but not blue light.
   *
   * Unlike <a href="#/p5/ambientMaterial">ambientMaterial()</a>,
   * `specularMaterial()` will reflect the full color of light sources including
   * <a href="#/p5/directionalLight">directionalLight()</a>,
   * <a href="#/p5/pointLight">pointLight()</a>,
   * and <a href="#/p5/spotLight">spotLight()</a>. This is what gives it shapes
   * their "shiny" appearance. The materials shininess can be controlled by the
   * <a href="#/p5/shininess">shininess()</a> function.
   *
   * `specularMaterial()` can be called three ways with different parameters to
   * set the materials color.
   *
   * The first way to call `specularMaterial()` has one parameter, `gray`.
   * Grayscale values between 0 and 255, as in `specularMaterial(50)`, can be
   * passed to set the materials color. Higher grayscale values make shapes
   * appear brighter.
   *
   * The second way to call `specularMaterial()` has one parameter, `color`. A
   * <a href="#/p5.Color">p5.Color> object, an array of color values, or a CSS
   * color string, as in `specularMaterial('magenta')`, can be passed to set the
   * materials color.
   *
   * The third way to call `specularMaterial()` has four parameters, `v1`, `v2`,
   * `v3`, and `alpha`. `alpha` is optional. RGBA, HSBA, or HSLA values can be
   * passed to set the materials colors, as in `specularMaterial(255, 0, 0)` or
   * `specularMaterial(255, 0, 0, 30)`. Color values will be interpreted using
   * the current <a href="#/p5/colorMode">colorMode()</a>.
   *
   * @method specularMaterial
   * @param  {Number} gray grayscale value between 0 (black) and 255 (white).
   * @param  {Number} [alpha] alpha value in the current current
   *                          <a href="#/p5/colorMode">colorMode()</a>.
   * @chainable
   *
   * @example
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   * // Double-click the canvas to apply a specular material.
   *
   * let isGlossy = false;
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe('A red torus drawn on a gray background. It becomes glossy when the user double-clicks.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Turn on a white point light at the top-right.
   *   pointLight(255, 255, 255, 30, -40, 30);
   *
   *   // Add a glossy coat if the user has double-clicked.
   *   if (isGlossy === true) {
   *     specularMaterial(255);
   *     shininess(50);
   *   }
   *
   *   // Style the torus.
   *   noStroke();
   *   fill(255, 0, 0);
   *
   *   // Draw the torus.
   *   torus(30);
   * }
   *
   * // Make the torus glossy when the user double-clicks.
   * function doubleClicked() {
   *   isGlossy = true;
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   * // Double-click the canvas to apply a specular material.
   *
   * let isGlossy = false;
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe(
   *     'A red torus drawn on a gray background. It becomes glossy and reflects green light when the user double-clicks.'
   *   );
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Turn on a white point light at the top-right.
   *   pointLight(255, 255, 255, 30, -40, 30);
   *
   *   // Add a glossy green coat if the user has double-clicked.
   *   if (isGlossy === true) {
   *     specularMaterial(0, 255, 0);
   *     shininess(50);
   *   }
   *
   *   // Style the torus.
   *   noStroke();
   *   fill(255, 0, 0);
   *
   *   // Draw the torus.
   *   torus(30);
   * }
   *
   * // Make the torus glossy when the user double-clicks.
   * function doubleClicked() {
   *   isGlossy = true;
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   * // Double-click the canvas to apply a specular material.
   *
   * let isGlossy = false;
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe(
   *     'A red torus drawn on a gray background. It becomes glossy and reflects green light when the user double-clicks.'
   *   );
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Turn on a white point light at the top-right.
   *   pointLight(255, 255, 255, 30, -40, 30);
   *
   *   // Add a glossy green coat if the user has double-clicked.
   *   if (isGlossy === true) {
   *     // Create a p5.Color object.
   *     let c = color('green');
   *     specularMaterial(c);
   *     shininess(50);
   *   }
   *
   *   // Style the torus.
   *   noStroke();
   *   fill(255, 0, 0);
   *
   *   // Draw the torus.
   *   torus(30);
   * }
   *
   * // Make the torus glossy when the user double-clicks.
   * function doubleClicked() {
   *   isGlossy = true;
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   * // Double-click the canvas to apply a specular material.
   *
   * let isGlossy = false;
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe(
   *     'A red torus drawn on a gray background. It becomes glossy and reflects green light when the user double-clicks.'
   *   );
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Turn on a white point light at the top-right.
   *   pointLight(255, 255, 255, 30, -40, 30);
   *
   *   // Add a glossy green coat if the user has double-clicked.
   *   if (isGlossy === true) {
   *     specularMaterial('#00FF00');
   *     shininess(50);
   *   }
   *
   *   // Style the torus.
   *   noStroke();
   *   fill(255, 0, 0);
   *
   *   // Draw the torus.
   *   torus(30);
   * }
   *
   * // Make the torus glossy when the user double-clicks.
   * function doubleClicked() {
   *   isGlossy = true;
   * }
   * </code>
   * </div>
   */

  /**
   * @method specularMaterial
   * @param  {Number}        v1      red or hue value in
   *                                 the current <a href="#/p5/colorMode">colorMode()</a>.
   * @param  {Number}        v2      green or saturation value
   *                                 in the current <a href="#/p5/colorMode">colorMode()</a>.
   * @param  {Number}        v3      blue, brightness, or lightness value
   *                                 in the current <a href="#/p5/colorMode">colorMode()</a>.
   * @param  {Number}        [alpha]
   * @chainable
   */

  /**
   * @method specularMaterial
   * @param  {p5.Color|Number[]|String} color
   *           color as a <a href="#/p5.Color">p5.Color</a> object,
   *            an array of color values, or a CSS string.
   * @chainable
   */
  fn.specularMaterial = function (v1, v2, v3, alpha) {
    this._assert3d('specularMaterial');
    // p5._validateParameters('specularMaterial', arguments);

    const color = fn.color.apply(this, arguments);
    this._renderer.states.setValue('curSpecularColor', color._array);
    this._renderer.states.setValue('_useSpecularMaterial', true);
    this._renderer.states.setValue('_useNormalMaterial', false);
    this._renderer.states.setValue('enableLighting', true);

    return this;
  };

  /**
   * Sets the amount of gloss ("shininess") of a
   * <a href="#/p5/specularMaterial">specularMaterial()</a>.
   *
   * Shiny materials focus reflected light more than dull materials.
   * `shininess()` affects the way materials reflect light sources including
   * <a href="#/p5/directionalLight">directionalLight()</a>,
   * <a href="#/p5/pointLight">pointLight()</a>,
   * and <a href="#/p5/spotLight">spotLight()</a>.
   *
   * The parameter, `shine`, is a number that sets the amount of shininess.
   * `shine` must be greater than 1, which is its default value.
   *
   * @method shininess
   * @param {Number} shine amount of shine.
   * @chainable
   *
   * @example
   * <div>
   * <code>
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe(
   *     'Two red spheres drawn on a gray background. White light reflects from their surfaces as the mouse moves. The right sphere is shinier than the left sphere.'
   *   );
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Turn on a red ambient light.
   *   ambientLight(255, 0, 0);
   *
   *   // Get the mouse's coordinates.
   *   let mx = mouseX - 50;
   *   let my = mouseY - 50;
   *
   *   // Turn on a white point light that follows the mouse.
   *   pointLight(255, 255, 255, mx, my, 50);
   *
   *   // Style the sphere.
   *   noStroke();
   *
   *   // Add a specular material with a grayscale value.
   *   specularMaterial(255);
   *
   *   // Draw the left sphere with low shininess.
   *   translate(-25, 0, 0);
   *   shininess(10);
   *   sphere(20);
   *
   *   // Draw the right sphere with high shininess.
   *   translate(50, 0, 0);
   *   shininess(100);
   *   sphere(20);
   * }
   * </code>
   * </div>
   */
  fn.shininess = function (shine) {
    this._assert3d('shininess');
    // p5._validateParameters('shininess', arguments);

    this._renderer.shininess(shine);

    return this;
  };

  /**
   * Sets the amount of "metalness" of a
   * <a href="#/p5/specularMaterial">specularMaterial()</a>.
   *
   * `metalness()` can make materials appear more metallic. It affects the way
   * materials reflect light sources including
   * affects the way materials reflect light sources including
   * <a href="#/p5/directionalLight">directionalLight()</a>,
   * <a href="#/p5/pointLight">pointLight()</a>,
   * <a href="#/p5/spotLight">spotLight()</a>, and
   * <a href="#/p5/imageLight">imageLight()</a>.
   *
   * The parameter, `metallic`, is a number that sets the amount of metalness.
   * `metallic` must be greater than 1, which is its default value. Higher
   * values, such as `metalness(100)`, make specular materials appear more
   * metallic.
   *
   * @method metalness
   * @param {Number} metallic amount of metalness.
   *
   * @example
   * <div>
   * <code>
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   describe(
   *     'Two blue spheres drawn on a gray background. White light reflects from their surfaces as the mouse moves. The right sphere is more metallic than the left sphere.'
   *   );
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Turn on an ambient light.
   *   ambientLight(200);
   *
   *   // Get the mouse's coordinates.
   *   let mx = mouseX - 50;
   *   let my = mouseY - 50;
   *
   *   // Turn on a white point light that follows the mouse.
   *   pointLight(255, 255, 255, mx, my, 50);
   *
   *   // Style the spheres.
   *   noStroke();
   *   fill(30, 30, 255);
   *   specularMaterial(255);
   *   shininess(20);
   *
   *   // Draw the left sphere with low metalness.
   *   translate(-25, 0, 0);
   *   metalness(1);
   *   sphere(20);
   *
   *   // Draw the right sphere with high metalness.
   *   translate(50, 0, 0);
   *   metalness(50);
   *   sphere(20);
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Click and drag the mouse to view the scene from different angles.
   *
   * let img;
   *
   * async function setup() {
   *   img = await loadImage('assets/outdoor_spheremap.jpg');
   *
   *   createCanvas(100 ,100 ,WEBGL);
   *
   *   describe(
   *     'Two spheres floating above a landscape. The surface of the spheres reflect the landscape. The right sphere is more reflective than the left sphere.'
   *   );
   * }
   *
   * function draw() {
   *   // Add the panorama.
   *   panorama(img);
   *
   *   // Enable orbiting with the mouse.
   *   orbitControl();
   *
   *   // Use the image as a light source.
   *   imageLight(img);
   *
   *   // Style the spheres.
   *   noStroke();
   *   specularMaterial(50);
   *   shininess(200);
   *
   *   // Draw the left sphere with low metalness.
   *   translate(-25, 0, 0);
   *   metalness(1);
   *   sphere(20);
   *
   *   // Draw the right sphere with high metalness.
   *   translate(50, 0, 0);
   *   metalness(50);
   *   sphere(20);
   * }
   * </code>
   * </div>
   */
  fn.metalness = function (metallic) {
    this._assert3d('metalness');

    this._renderer.metalness(metallic);

    return this;
  };


  /**
   * @private blends colors according to color components.
   * If alpha value is less than 1, or non-standard blendMode
   * we need to enable blending on our gl context.
   * @param  {Number[]} color The currently set color, with values in 0-1 range
   * @param  {Boolean} [hasTransparency] Whether the shape being drawn has other
   * transparency internally, e.g. via vertex colors
   * @return {Number[]}  Normalized numbers array
   */
  RendererGL.prototype._applyColorBlend = function (colors, hasTransparency) {
    const gl = this.GL;

    const isTexture = this.states.drawMode === TEXTURE;
    const doBlend =
      hasTransparency ||
      this.states.userFillShader ||
      this.states.userStrokeShader ||
      this.states.userPointShader ||
      isTexture ||
      this.states.curBlendMode !== BLEND ||
      colors[colors.length - 1] < 1.0 ||
      this._isErasing;

    if (doBlend !== this._isBlending) {
      if (
        doBlend ||
        (this.states.curBlendMode !== BLEND &&
          this.states.curBlendMode !== ADD)
      ) {
        gl.enable(gl.BLEND);
      } else {
        gl.disable(gl.BLEND);
      }
      gl.depthMask(true);
      this._isBlending = doBlend;
    }
    this._applyBlendMode();
    return colors;
  };

  /**
   * @private sets blending in gl context to curBlendMode
   * @param  {Number[]} color [description]
   * @return {Number[]}  Normalized numbers array
   */
  RendererGL.prototype._applyBlendMode = function () {
    if (this._cachedBlendMode === this.states.curBlendMode) {
      return;
    }
    const gl = this.GL;
    switch (this.states.curBlendMode) {
      case BLEND:
        gl.blendEquation(gl.FUNC_ADD);
        gl.blendFunc(gl.ONE, gl.ONE_MINUS_SRC_ALPHA);
        break;
      case ADD:
        gl.blendEquation(gl.FUNC_ADD);
        gl.blendFunc(gl.ONE, gl.ONE);
        break;
      case REMOVE:
        gl.blendEquation(gl.FUNC_ADD);
        gl.blendFunc(gl.ZERO, gl.ONE_MINUS_SRC_ALPHA);
        break;
      case MULTIPLY:
        gl.blendEquation(gl.FUNC_ADD);
        gl.blendFunc(gl.DST_COLOR, gl.ONE_MINUS_SRC_ALPHA);
        break;
      case SCREEN:
        gl.blendEquation(gl.FUNC_ADD);
        gl.blendFunc(gl.ONE, gl.ONE_MINUS_SRC_COLOR);
        break;
      case EXCLUSION:
        gl.blendEquationSeparate(gl.FUNC_ADD, gl.FUNC_ADD);
        gl.blendFuncSeparate(
          gl.ONE_MINUS_DST_COLOR,
          gl.ONE_MINUS_SRC_COLOR,
          gl.ONE,
          gl.ONE
        );
        break;
      case REPLACE:
        gl.blendEquation(gl.FUNC_ADD);
        gl.blendFunc(gl.ONE, gl.ZERO);
        break;
      case SUBTRACT:
        gl.blendEquationSeparate(gl.FUNC_REVERSE_SUBTRACT, gl.FUNC_ADD);
        gl.blendFuncSeparate(gl.ONE, gl.ONE, gl.ONE, gl.ONE_MINUS_SRC_ALPHA);
        break;
      case DARKEST:
        if (this.blendExt) {
          gl.blendEquationSeparate(
            this.blendExt.MIN || this.blendExt.MIN_EXT,
            gl.FUNC_ADD
          );
          gl.blendFuncSeparate(gl.ONE, gl.ONE, gl.ONE, gl.ONE);
        } else {
          console.warn(
            'blendMode(DARKEST) does not work in your browser in WEBGL mode.'
          );
        }
        break;
      case LIGHTEST:
        if (this.blendExt) {
          gl.blendEquationSeparate(
            this.blendExt.MAX || this.blendExt.MAX_EXT,
            gl.FUNC_ADD
          );
          gl.blendFuncSeparate(gl.ONE, gl.ONE, gl.ONE, gl.ONE);
        } else {
          console.warn(
            'blendMode(LIGHTEST) does not work in your browser in WEBGL mode.'
          );
        }
        break;
      default:
        console.error(
          'Oops! Somehow RendererGL set curBlendMode to an unsupported mode.'
        );
        break;
    }
    this._cachedBlendMode = this.states.curBlendMode;
  };

  RendererGL.prototype.shader = function(s) {
    // Always set the shader as a fill shader
    this.states.setValue('userFillShader', s);
    this.states.setValue('_useNormalMaterial', false);
    s.ensureCompiledOnContext(this);
    s.setDefaultUniforms();
  };

  RendererGL.prototype.strokeShader = function(s) {
    this.states.setValue('userStrokeShader', s);
    s.ensureCompiledOnContext(this);
    s.setDefaultUniforms();
  };

  RendererGL.prototype.imageShader = function(s) {
    this.states.setValue('userImageShader', s);
    s.ensureCompiledOnContext(this);
    s.setDefaultUniforms();
  };

  RendererGL.prototype.resetShader = function() {
    this.states.setValue('userFillShader', null);
    this.states.setValue('userStrokeShader', null);
    this.states.setValue('userImageShader', null);
  };

  RendererGL.prototype.texture = function(tex) {
    this.states.setValue('drawMode', TEXTURE);
    this.states.setValue('_useNormalMaterial', false);
    this.states.setValue('_tex', tex);
    this.states.setValue('fillColor', new Color([1, 1, 1]));
  };

  RendererGL.prototype.normalMaterial = function(...args) {
    this.states.setValue('drawMode', FILL);
    this.states.setValue('_useSpecularMaterial', false);
    this.states.setValue('_useEmissiveMaterial', false);
    this.states.setValue('_useNormalMaterial', true);
    this.states.setValue('curFillColor', [1, 1, 1, 1]);
    this.states.setValue('fillColor', new Color([1, 1, 1]));
    this.states.setValue('strokeColor', null);
  };

  // RendererGL.prototype.ambientMaterial = function(v1, v2, v3) {
  // }

  // RendererGL.prototype.emissiveMaterial = function(v1, v2, v3, a) {
  // }

  // RendererGL.prototype.specularMaterial = function(v1, v2, v3, alpha) {
  // }

  RendererGL.prototype.shininess = function(shine) {
    if (shine < 1) {
      shine = 1;
    }
    this.states.setValue('_useShininess', shine);
  };

  RendererGL.prototype.metalness = function(metallic) {
    const metalMix = 1 - Math.exp(-metallic / 100);
    this.states.setValue('_useMetalness', metalMix);
  };
}

if(typeof p5 !== 'undefined'){
  loading(p5, p5.prototype);
}

/**
 * @module Rendering
 * @submodule Rendering
 * @for p5
 */


class Graphics {
  constructor(w, h, renderer, pInst, canvas) {
    const r = renderer || P2D;

    this._pInst = pInst;
    this._renderer = new renderers[r](this, w, h, false, canvas);

    this._initializeInstanceVariables(this);

    this._renderer._applyDefaults();
    return this;
  }

  get deltaTime(){
    return this._pInst.deltaTime;
  }

  get canvas(){
    return this._renderer?.canvas;
  }

  get drawingContext(){
    return this._renderer.drawingContext;
  }

  get width(){
    return this._renderer?.width;
  }

  get height(){
    return this._renderer?.height;
  }

  get pixels(){
    return this._renderer?.pixels;
  }

  pixelDensity(val){
    let returnValue;
    if (typeof val === 'number') {
      if (val !== this._renderer._pixelDensity) {
        this._renderer._pixelDensity = val;
      }
      returnValue = this;
      this.resizeCanvas(this.width, this.height, true); // as a side effect, it will clear the canvas
    } else {
      returnValue = this._renderer._pixelDensity;
    }
    return returnValue;
  }

  resizeCanvas(w, h){
    this._renderer.resize(w, h);
  }

  /**
   * Resets the graphics buffer's transformations and lighting.
   *
   * By default, the main canvas resets certain transformation and lighting
   * values each time <a href="#/p5/draw">draw()</a> executes. `p5.Graphics`
   * objects must reset these values manually by calling `myGraphics.reset()`.
   *
   *
   * @example
   * <div>
   * <code>
   * let pg;
   *
   * function setup() {
   *   createCanvas(100, 100);
   *
   *   // Create a p5.Graphics object.
   *   pg = createGraphics(60, 60);
   *
   *   describe('A white circle moves downward slowly within a dark square. The circle resets at the top of the dark square when the user presses the mouse.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Translate the p5.Graphics object's coordinate system.
   *   // The translation accumulates; the white circle moves.
   *   pg.translate(0, 0.1);
   *
   *   // Draw to the p5.Graphics object.
   *   pg.background(100);
   *   pg.circle(30, 0, 10);
   *
   *   // Display the p5.Graphics object.
   *   image(pg, 20, 20);
   *
   *   // Translate the main canvas' coordinate system.
   *   // The translation doesn't accumulate; the dark
   *   // square is always in the same place.
   *   translate(0, 0.1);
   *
   *   // Reset the p5.Graphics object when the
   *   // user presses the mouse.
   *   if (mouseIsPressed === true) {
   *     pg.reset();
   *   }
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * let pg;
   *
   * function setup() {
   *   createCanvas(100, 100);
   *
   *   // Create a p5.Graphics object.
   *   pg = createGraphics(60, 60);
   *
   *   describe('A white circle at the center of a dark gray square. The image is drawn on a light gray background.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Translate the p5.Graphics object's coordinate system.
   *   pg.translate(30, 30);
   *
   *   // Draw to the p5.Graphics object.
   *   pg.background(100);
   *   pg.circle(0, 0, 10);
   *
   *   // Display the p5.Graphics object.
   *   image(pg, 20, 20);
   *
   *   // Reset the p5.Graphics object automatically.
   *   pg.reset();
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * let pg;
   *
   * function setup() {
   *   createCanvas(100, 100);
   *
   *   // Create a p5.Graphics object using WebGL mode.
   *   pg = createGraphics(100, 100, WEBGL);
   *
   *   describe("A sphere lit from above with a red light. The sphere's surface becomes glossy while the user clicks and holds the mouse.");
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Add a red point light from the top-right.
   *   pg.pointLight(255, 0, 0, 50, -100, 50);
   *
   *   // Style the sphere.
   *   // It should appear glossy when the
   *   // lighting values are reset.
   *   pg.noStroke();
   *   pg.specularMaterial(255);
   *   pg.shininess(100);
   *
   *   // Draw the sphere.
   *   pg.sphere(30);
   *
   *   // Display the p5.Graphics object.
   *   image(pg, -50, -50);
   *
   *   // Reset the p5.Graphics object when
   *   // the user presses the mouse.
   *   if (mouseIsPressed === true) {
   *     pg.reset();
   *   }
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * let pg;
   *
   * function setup() {
   *   createCanvas(100, 100);
   *
   *   // Create a p5.Graphics object using WebGL mode.
   *   pg = createGraphics(100, 100, WEBGL);
   *
   *   describe('A sphere with a glossy surface is lit from the top-right by a red light.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Add a red point light from the top-right.
   *   pg.pointLight(255, 0, 0, 50, -100, 50);
   *
   *   // Style the sphere.
   *   pg.noStroke();
   *   pg.specularMaterial(255);
   *   pg.shininess(100);
   *
   *   // Draw the sphere.
   *   pg.sphere(30);
   *
   *   // Display the p5.Graphics object.
   *   image(pg, 0, 0);
   *
   *   // Reset the p5.Graphics object automatically.
   *   pg.reset();
   * }
   * </code>
   * </div>
   */
  reset() {
    this._renderer.resetMatrix();
    if (this._renderer.isP3D) {
      this._renderer._update();
    }
  }

  /**
   * Removes the graphics buffer from the web page.
   *
   * Calling `myGraphics.remove()` removes the graphics buffer's
   * `&lt;canvas&gt;` element from the web page. The graphics buffer also uses
   * a bit of memory on the CPU that can be freed like so:
   *
   * ```js
   * // Remove the graphics buffer from the web page.
   * myGraphics.remove();
   *
   * // Delete the graphics buffer from CPU memory.
   * myGraphics = undefined;
   * ```
   *
   * Note: All variables that reference the graphics buffer must be assigned
   * the value `undefined` to delete the graphics buffer from CPU memory. If any
   * variable still refers to the graphics buffer, then it won't be garbage
   * collected.
   *
   * @example
   * <div>
   * <code>
   * // Double-click to remove the p5.Graphics object.
   *
   * let pg;
   *
   * function setup() {
   *   createCanvas(100, 100);
   *
   *   // Create a p5.Graphics object.
   *   pg = createGraphics(60, 60);
   *
   *   // Draw to the p5.Graphics object.
   *   pg.background(100);
   *   pg.circle(30, 30, 20);
   *
   *   describe('A white circle at the center of a dark gray square disappears when the user double-clicks.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Display the p5.Graphics object if
   *   // it's available.
   *   if (pg) {
   *     image(pg, 20, 20);
   *   }
   * }
   *
   * // Remove the p5.Graphics object when the
   * // the user double-clicks.
   * function doubleClicked() {
   *   // Remove the p5.Graphics object from the web page.
   *   pg.remove();
   *   pg = undefined;
   * }
   * </code>
   * </div>
   */
  remove() {
    this._renderer.remove();
    this._renderer = undefined;
  }


  /**
   * Creates a new <a href="#/p5.Framebuffer">p5.Framebuffer</a> object with
   * the same WebGL context as the graphics buffer.
   *
   * <a href="#/p5.Framebuffer">p5.Framebuffer</a> objects are separate drawing
   * surfaces that can be used as textures in WebGL mode. They're similar to
   * <a href="#/p5.Graphics">p5.Graphics</a> objects and generally run much
   * faster when used as textures. Creating a
   * <a href="#/p5.Framebuffer">p5.Framebuffer</a> object in the same context
   * as the graphics buffer makes this speedup possible.
   *
   * The parameter, `options`, is optional. An object can be passed to configure
   * the <a href="#/p5.Framebuffer">p5.Framebuffer</a> object. The available
   * properties are:
   *
   * - `format`: data format of the texture, either `UNSIGNED_BYTE`, `FLOAT`, or `HALF_FLOAT`. Default is `UNSIGNED_BYTE`.
   * - `channels`: whether to store `RGB` or `RGBA` color channels. Default is to match the graphics buffer which is `RGBA`.
   * - `depth`: whether to include a depth buffer. Default is `true`.
   * - `depthFormat`: data format of depth information, either `UNSIGNED_INT` or `FLOAT`. Default is `FLOAT`.
   * - `stencil`: whether to include a stencil buffer for masking. `depth` must be `true` for this feature to work. Defaults to the value of `depth` which is `true`.
   * - `antialias`: whether to perform anti-aliasing. If set to `true`, as in `{ antialias: true }`, 2 samples will be used by default. The number of samples can also be set, as in `{ antialias: 4 }`. Default is to match <a href="#/p5/setAttributes">setAttributes()</a> which is `false` (`true` in Safari).
   * - `width`: width of the <a href="#/p5.Framebuffer">p5.Framebuffer</a> object. Default is to always match the graphics buffer width.
   * - `height`: height of the <a href="#/p5.Framebuffer">p5.Framebuffer</a> object. Default is to always match the graphics buffer height.
   * - `density`: pixel density of the <a href="#/p5.Framebuffer">p5.Framebuffer</a> object. Default is to always match the graphics buffer pixel density.
   * - `textureFiltering`: how to read values from the <a href="#/p5.Framebuffer">p5.Framebuffer</a> object. Either `LINEAR` (nearby pixels will be interpolated) or `NEAREST` (no interpolation). Generally, use `LINEAR` when using the texture as an image and `NEAREST` if reading the texture as data. Default is `LINEAR`.
   *
   * If the `width`, `height`, or `density` attributes are set, they won't
   * automatically match the graphics buffer and must be changed manually.
   *
   * @param {Object} [options] configuration options.
   * @return {p5.Framebuffer} new framebuffer.
   *
   * @example
   * <div>
   * <code>
   * // Click and hold a mouse button to change shapes.
   *
   * let pg;
   * let torusLayer;
   * let boxLayer;
   *
   * function setup() {
   *   createCanvas(100, 100);
   *
   *   // Create a p5.Graphics object using WebGL mode.
   *   pg = createGraphics(100, 100, WEBGL);
   *
   *   // Create the p5.Framebuffer objects.
   *   torusLayer = pg.createFramebuffer();
   *   boxLayer = pg.createFramebuffer();
   *
   *   describe('A grid of white toruses rotating against a dark gray background. The shapes become boxes while the user holds a mouse button.');
   * }
   *
   * function draw() {
   *   // Update and draw the layers offscreen.
   *   drawTorus();
   *   drawBox();
   *
   *   // Choose the layer to display.
   *   let layer;
   *   if (mouseIsPressed === true) {
   *     layer = boxLayer;
   *   } else {
   *     layer = torusLayer;
   *   }
   *
   *   // Draw to the p5.Graphics object.
   *   pg.background(50);
   *
   *   // Iterate from left to right.
   *   for (let x = -50; x < 50; x += 25) {
   *     // Iterate from top to bottom.
   *     for (let y = -50; y < 50; y += 25) {
   *       // Draw the layer to the p5.Graphics object
   *       pg.image(layer, x, y, 25, 25);
   *     }
   *   }
   *
   *   // Display the p5.Graphics object.
   *   image(pg, 0, 0);
   * }
   *
   * // Update and draw the torus layer offscreen.
   * function drawTorus() {
   *   // Start drawing to the torus p5.Framebuffer.
   *   torusLayer.begin();
   *
   *   // Clear the drawing surface.
   *   pg.clear();
   *
   *   // Turn on the lights.
   *   pg.lights();
   *
   *   // Rotate the coordinate system.
   *   pg.rotateX(frameCount * 0.01);
   *   pg.rotateY(frameCount * 0.01);
   *
   *   // Style the torus.
   *   pg.noStroke();
   *
   *   // Draw the torus.
   *   pg.torus(20);
   *
   *   // Start drawing to the torus p5.Framebuffer.
   *   torusLayer.end();
   * }
   *
   * // Update and draw the box layer offscreen.
   * function drawBox() {
   *   // Start drawing to the box p5.Framebuffer.
   *   boxLayer.begin();
   *
   *   // Clear the drawing surface.
   *   pg.clear();
   *
   *   // Turn on the lights.
   *   pg.lights();
   *
   *   // Rotate the coordinate system.
   *   pg.rotateX(frameCount * 0.01);
   *   pg.rotateY(frameCount * 0.01);
   *
   *   // Style the box.
   *   pg.noStroke();
   *
   *   // Draw the box.
   *   pg.box(30);
   *
   *   // Start drawing to the box p5.Framebuffer.
   *   boxLayer.end();
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Click and hold a mouse button to change shapes.
   *
   * let pg;
   * let torusLayer;
   * let boxLayer;
   *
   * function setup() {
   *   createCanvas(100, 100);
   *
   *   // Create an options object.
   *   let options = { width: 25, height: 25 };
   *
   *   // Create a p5.Graphics object using WebGL mode.
   *   pg = createGraphics(100, 100, WEBGL);
   *
   *   // Create the p5.Framebuffer objects.
   *   // Use options for configuration.
   *   torusLayer = pg.createFramebuffer(options);
   *   boxLayer = pg.createFramebuffer(options);
   *
   *   describe('A grid of white toruses rotating against a dark gray background. The shapes become boxes while the user holds a mouse button.');
   * }
   *
   * function draw() {
   *   // Update and draw the layers offscreen.
   *   drawTorus();
   *   drawBox();
   *
   *   // Choose the layer to display.
   *   let layer;
   *   if (mouseIsPressed === true) {
   *     layer = boxLayer;
   *   } else {
   *     layer = torusLayer;
   *   }
   *
   *   // Draw to the p5.Graphics object.
   *   pg.background(50);
   *
   *   // Iterate from left to right.
   *   for (let x = -50; x < 50; x += 25) {
   *     // Iterate from top to bottom.
   *     for (let y = -50; y < 50; y += 25) {
   *       // Draw the layer to the p5.Graphics object
   *       pg.image(layer, x, y);
   *     }
   *   }
   *
   *   // Display the p5.Graphics object.
   *   image(pg, 0, 0);
   * }
   *
   * // Update and draw the torus layer offscreen.
   * function drawTorus() {
   *   // Start drawing to the torus p5.Framebuffer.
   *   torusLayer.begin();
   *
   *   // Clear the drawing surface.
   *   pg.clear();
   *
   *   // Turn on the lights.
   *   pg.lights();
   *
   *   // Rotate the coordinate system.
   *   pg.rotateX(frameCount * 0.01);
   *   pg.rotateY(frameCount * 0.01);
   *
   *   // Style the torus.
   *   pg.noStroke();
   *
   *   // Draw the torus.
   *   pg.torus(5, 2.5);
   *
   *   // Start drawing to the torus p5.Framebuffer.
   *   torusLayer.end();
   * }
   *
   * // Update and draw the box layer offscreen.
   * function drawBox() {
   *   // Start drawing to the box p5.Framebuffer.
   *   boxLayer.begin();
   *
   *   // Clear the drawing surface.
   *   pg.clear();
   *
   *   // Turn on the lights.
   *   pg.lights();
   *
   *   // Rotate the coordinate system.
   *   pg.rotateX(frameCount * 0.01);
   *   pg.rotateY(frameCount * 0.01);
   *
   *   // Style the box.
   *   pg.noStroke();
   *
   *   // Draw the box.
   *   pg.box(7.5);
   *
   *   // Start drawing to the box p5.Framebuffer.
   *   boxLayer.end();
   * }
   * </code>
   * </div>
   */
  createFramebuffer(options) {
    return new Framebuffer(this._renderer, options);
  }

  _assert3d(name) {
    if (!this._renderer.isP3D)
      throw new Error(
        `${name}() is only supported in WEBGL mode. If you'd like to use 3D graphics and WebGL, see  https://p5js.org/examples/form-3d-primitives.html for more information.`
      );
  };

  _initializeInstanceVariables() {
    this._accessibleOutputs = {
      text: false,
      grid: false,
      textLabel: false,
      gridLabel: false
    };

    this._styles = [];

    // this._colorMode = RGB;
    // this._colorMaxes = {
    //   rgb: [255, 255, 255, 255],
    //   hsb: [360, 100, 100, 1],
    //   hsl: [360, 100, 100, 1]
    // };

    this._downKeys = {}; //Holds the key codes of currently pressed keys
  }
}
function graphics(p5, fn){
  /**
   * A class to describe a drawing surface that's separate from the main canvas.
   *
   * Each `p5.Graphics` object provides a dedicated drawing surface called a
   * *graphics buffer*. Graphics buffers are helpful when drawing should happen
   * offscreen. For example, separate scenes can be drawn offscreen and
   * displayed only when needed.
   *
   * `p5.Graphics` objects have nearly all the drawing features of the main
   * canvas. For example, calling the method `myGraphics.circle(50, 50, 20)`
   * draws to the graphics buffer. The resulting image can be displayed on the
   * main canvas by passing the `p5.Graphics` object to the
   * <a href="#/p5/image">image()</a> function, as in `image(myGraphics, 0, 0)`.
   *
   * Note: <a href="#/p5/createGraphics">createGraphics()</a> is the recommended
   * way to create an instance of this class.
   *
   * @class p5.Graphics
   * @extends p5.Element
   * @param {Number} w            width width of the graphics buffer in pixels.
   * @param {Number} h            height height of the graphics buffer in pixels.
   * @param {(P2D|WEBGL|P2DHDR)} renderer   the renderer to use, either P2D or WEBGL.
   * @param {p5} [pInst]          sketch instance.
   * @param {HTMLCanvasElement} [canvas]     existing `&lt;canvas&gt;` element to use.
   *
   * @example
   * <div>
   * <code>
   * let pg;
   *
   * function setup() {
   *   createCanvas(100, 100);
   *
   *   // Create a p5.Graphics object.
   *   pg = createGraphics(50, 50);
   *
   *   // Draw to the p5.Graphics object.
   *   pg.background(100);
   *   pg.circle(25, 25, 20);
   *
   *   describe('A dark gray square with a white circle at its center drawn on a gray background.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Display the p5.Graphics object.
   *   image(pg, 25, 25);
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Click the canvas to display the graphics buffer.
   *
   * let pg;
   *
   * function setup() {
   *   createCanvas(100, 100);
   *
   *   // Create a p5.Graphics object.
   *   pg = createGraphics(50, 50);
   *
   *   describe('A square appears on a gray background when the user presses the mouse. The square cycles between white and black.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Calculate the background color.
   *   let bg = frameCount % 255;
   *
   *   // Draw to the p5.Graphics object.
   *   pg.background(bg);
   *
   *   // Display the p5.Graphics object while
   *   // the user presses the mouse.
   *   if (mouseIsPressed === true) {
   *     image(pg, 25, 25);
   *   }
   * }
   * </code>
   * </div>
   */
  p5.Graphics = Graphics;

  // Shapes
  primitives(p5, p5.Graphics.prototype);
  attributes(p5, p5.Graphics.prototype);
  curves(p5, p5.Graphics.prototype);
  vertex(p5, p5.Graphics.prototype);
  customShapes(p5, p5.Graphics.prototype);

  setting(p5, p5.Graphics.prototype);
  loadingDisplaying(p5, p5.Graphics.prototype);
  image(p5, p5.Graphics.prototype);
  pixels(p5, p5.Graphics.prototype);

  transform(p5, p5.Graphics.prototype);

  primitives3D(p5, p5.Graphics.prototype);
  light(p5, p5.Graphics.prototype);
  material(p5, p5.Graphics.prototype);
  creatingReading(p5, p5.Graphics.prototype);
  trigonometry(p5, p5.Graphics.prototype);
}

/**
 * This module defines the p5.Texture class
 * @module 3D
 * @submodule Material
 * @for p5
 * @requires core
 */


class Texture {
  constructor (renderer, obj, settings) {
    this._renderer = renderer;

    const gl = this._renderer.GL;

    settings = settings || {};

    this.src = obj;
    this.glTex = undefined;
    this.glTarget = gl.TEXTURE_2D;
    this.glFormat = settings.format || gl.RGBA;
    this.mipmaps = false;
    this.glMinFilter = settings.minFilter || gl.LINEAR;
    this.glMagFilter = settings.magFilter || gl.LINEAR;
    this.glWrapS = settings.wrapS || gl.CLAMP_TO_EDGE;
    this.glWrapT = settings.wrapT || gl.CLAMP_TO_EDGE;
    this.glDataType = settings.dataType || gl.UNSIGNED_BYTE;

    const support = checkWebGLCapabilities(renderer);
    if (this.glFormat === gl.HALF_FLOAT && !support.halfFloat) {
      console.log('This device does not support dataType HALF_FLOAT. Falling back to FLOAT.');
      this.glDataType = gl.FLOAT;
    }
    if (
      this.glFormat === gl.HALF_FLOAT &&
      (this.glMinFilter === gl.LINEAR || this.glMagFilter === gl.LINEAR) &&
      !support.halfFloatLinear
    ) {
      console.log('This device does not support linear filtering for dataType FLOAT. Falling back to NEAREST.');
      if (this.glMinFilter === gl.LINEAR) this.glMinFilter = gl.NEAREST;
      if (this.glMagFilter === gl.LINEAR) this.glMagFilter = gl.NEAREST;
    }
    if (this.glFormat === gl.FLOAT && !support.float) {
      console.log('This device does not support dataType FLOAT. Falling back to UNSIGNED_BYTE.');
      this.glDataType = gl.UNSIGNED_BYTE;
    }
    if (
      this.glFormat === gl.FLOAT &&
      (this.glMinFilter === gl.LINEAR || this.glMagFilter === gl.LINEAR) &&
      !support.floatLinear
    ) {
      console.log('This device does not support linear filtering for dataType FLOAT. Falling back to NEAREST.');
      if (this.glMinFilter === gl.LINEAR) this.glMinFilter = gl.NEAREST;
      if (this.glMagFilter === gl.LINEAR) this.glMagFilter = gl.NEAREST;
    }

    // used to determine if this texture might need constant updating
    // because it is a video or gif.
    this.isSrcMediaElement = false;
    this._videoPrevUpdateTime = 0;
    this.isSrcHTMLElement =
      typeof Element !== 'undefined' &&
      obj instanceof Element &&
      !(obj instanceof Graphics) &&
      !(obj instanceof Renderer);
    this.isSrcP5Image = obj instanceof Image;
    this.isSrcP5Graphics = obj instanceof Graphics;
    this.isSrcP5Renderer = obj instanceof Renderer;
    this.isImageData =
      typeof ImageData !== 'undefined' && obj instanceof ImageData;
    this.isFramebufferTexture = obj instanceof FramebufferTexture;

    const textureData = this._getTextureDataFromSource();
    this.width = textureData.width;
    this.height = textureData.height;

    this.init(textureData);
    return this;
  }

  remove() {
    if (this.glTex) {
      const gl = this._renderer.GL;
      gl.deleteTexture(this.glTex);
      this.glTex = undefined;
    }
  }

  _getTextureDataFromSource () {
    let textureData;
    if (this.isFramebufferTexture) {
      textureData = this.src.rawTexture();
    } else if (this.isSrcP5Image) {
    // param is a p5.Image
      textureData = this.src.canvas;
    } else if (
      this.isSrcMediaElement ||
      this.isSrcHTMLElement
    ) {
      // if param is a video HTML element
      if (this.src._ensureCanvas) {
        this.src._ensureCanvas();
      }
      textureData = this.src.elt;
    } else if (this.isSrcP5Graphics || this.isSrcP5Renderer) {
      textureData = this.src.canvas;
    } else if (this.isImageData) {
      textureData = this.src;
    }
    return textureData;
  }

  /**
   * Initializes common texture parameters, creates a gl texture,
   * tries to upload the texture for the first time if data is
   * already available.
   */
  init (data) {
    const gl = this._renderer.GL;
    if (!this.isFramebufferTexture) {
      this.glTex = gl.createTexture();
    }

    this.glWrapS = this._renderer.states.textureWrapX;
    this.glWrapT = this._renderer.states.textureWrapY;

    this.setWrapMode(this.glWrapS, this.glWrapT);
    this.bindTexture();

    //gl.pixelStorei(gl.UNPACK_FLIP_Y_WEBGL, true);
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, this.glMagFilter);
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, this.glMinFilter);

    if (this.isFramebufferTexture) ; else if (
      this.width === 0 ||
      this.height === 0 ||
      (this.isSrcMediaElement && !this.src.loadedmetadata)
    ) {
    // assign a 11 empty texture initially, because data is not yet ready,
    // so that no errors occur in gl console!
      const tmpdata = new Uint8Array([1, 1, 1, 1]);
      gl.texImage2D(
        this.glTarget,
        0,
        gl.RGBA,
        1,
        1,
        0,
        this.glFormat,
        this.glDataType,
        tmpdata
      );
    } else {
    // data is ready: just push the texture!
      gl.texImage2D(
        this.glTarget,
        0,
        this.glFormat,
        this.glFormat,
        this.glDataType,
        data
      );
    }
  }

  /**
   * Checks if the source data for this texture has changed (if it's
   * easy to do so) and reuploads the texture if necessary. If it's not
   * possible or to expensive to do a calculation to determine wheter or
   * not the data has occurred, this method simply re-uploads the texture.
   */
  update () {
    const data = this.src;
    if (data.width === 0 || data.height === 0) {
      return false; // nothing to do!
    }

    // FramebufferTexture instances wrap raw WebGL textures already, which
    // don't need any extra updating, as they already live on the GPU
    if (this.isFramebufferTexture) {
      this.src.update();
      return false;
    }

    const textureData = this._getTextureDataFromSource();
    let updated = false;

    const gl = this._renderer.GL;
    // pull texture from data, make sure width & height are appropriate
    if (
      textureData.width !== this.width ||
      textureData.height !== this.height
    ) {
      updated = true;

      // make sure that if the width and height of this.src have changed
      // for some reason, we update our metadata and upload the texture again
      this.width = textureData.width || data.width;
      this.height = textureData.height || data.height;

      if (this.isSrcP5Image) {
        data.setModified(false);
      } else if (this.isSrcMediaElement || this.isSrcHTMLElement) {
        // on the first frame the metadata comes in, the size will be changed
        // from 0 to actual size, but pixels may not be available.
        // flag for update in a future frame.
        // if we don't do this, a paused video, for example, may not
        // send the first frame to texture memory.
        data.setModified && data.setModified(true);
      }
    } else if (this.isSrcP5Image) {
      // for an image, we only update if the modified field has been set,
      // for example, by a call to p5.Image.set
      if (data.isModified()) {
        updated = true;
        data.setModified(false);
      }
    } else if (this.isSrcMediaElement) {
      // for a media element (video), we'll check if the current time in
      // the video frame matches the last time. if it doesn't match, the
      // video has advanced or otherwise been taken to a new frame,
      // and we need to upload it.
      if (data.isModified()) {
        // p5.MediaElement may have also had set/updatePixels, etc. called
        // on it and should be updated, or may have been set for the first
        // time!
        updated = true;
        data.setModified(false);
      } else if (data.loadedmetadata) {
        // if the meta data has been loaded, we can ask the video
        // what it's current position (in time) is.
        if (this._videoPrevUpdateTime !== data.time()) {
          // update the texture in gpu mem only if the current
          // video timestamp does not match the timestamp of the last
          // time we uploaded this texture (and update the time we
          // last uploaded, too)
          this._videoPrevUpdateTime = data.time();
          updated = true;
        }
      }
    } else if (this.isImageData) {
      if (data._dirty) {
        data._dirty = false;
        updated = true;
      }
    } else {
      /* data instanceof p5.Graphics, probably */
      // there is not enough information to tell if the texture can be
      // conditionally updated; so to be safe, we just go ahead and upload it.
      updated = true;
    }

    if (updated) {
      this.bindTexture();
      gl.texImage2D(
        this.glTarget,
        0,
        this.glFormat,
        this.glFormat,
        this.glDataType,
        textureData
      );
    }

    return updated;
  }

  /**
   * Binds the texture to the appropriate GL target.
   */
  bindTexture () {
    // bind texture using gl context + glTarget and
    // generated gl texture object
    const gl = this._renderer.GL;
    gl.bindTexture(this.glTarget, this.getTexture());

    return this;
  }

  /**
   * Unbinds the texture from the appropriate GL target.
   */
  unbindTexture () {
    // unbind per above, disable texturing on glTarget
    const gl = this._renderer.GL;
    gl.bindTexture(this.glTarget, null);
  }

  getTexture() {
    if (this.isFramebufferTexture) {
      return this.src.rawTexture();
    } else {
      return this.glTex;
    }
  }

  /**
   * Sets how a texture is be interpolated when upscaled or downscaled.
   * Nearest filtering uses nearest neighbor scaling when interpolating
   * Linear filtering uses WebGL's linear scaling when interpolating
   * @param {String} downScale Specifies the texture filtering when
   *                           textures are shrunk. Options are LINEAR or NEAREST
   * @param {String} upScale Specifies the texture filtering when
   *                         textures are magnified. Options are LINEAR or NEAREST
   * @todo implement mipmapping filters
   */
  setInterpolation (downScale, upScale) {
    const gl = this._renderer.GL;

    this.glMinFilter = this.glFilter(downScale);
    this.glMagFilter = this.glFilter(upScale);

    this.bindTexture();
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, this.glMinFilter);
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, this.glMagFilter);
    this.unbindTexture();
  }

  glFilter(filter) {
    const gl = this._renderer.GL;
    if (filter === NEAREST) {
      return gl.NEAREST;
    } else {
      return gl.LINEAR;
    }
  }

  /**
   * Sets the texture wrapping mode. This controls how textures behave
   * when their uv's go outside of the 0 - 1 range. There are three options:
   * CLAMP, REPEAT, and MIRROR. REPEAT & MIRROR are only available if the texture
   * is a power of two size (128, 256, 512, 1024, etc.).
   * @param {String} wrapX Controls the horizontal texture wrapping behavior
   * @param {String} wrapY Controls the vertical texture wrapping behavior
   */
  setWrapMode (wrapX, wrapY) {
    const gl = this._renderer.GL;

    // for webgl 1 we need to check if the texture is power of two
    // if it isn't we will set the wrap mode to CLAMP
    // webgl2 will support npot REPEAT and MIRROR but we don't check for it yet
    const isPowerOfTwo = x => (x & (x - 1)) === 0;
    const textureData = this._getTextureDataFromSource();

    let wrapWidth;
    let wrapHeight;

    if (textureData.naturalWidth && textureData.naturalHeight) {
      wrapWidth = textureData.naturalWidth;
      wrapHeight = textureData.naturalHeight;
    } else {
      wrapWidth = this.width;
      wrapHeight = this.height;
    }

    const widthPowerOfTwo = isPowerOfTwo(wrapWidth);
    const heightPowerOfTwo = isPowerOfTwo(wrapHeight);

    if (wrapX === REPEAT) {
      if (
        this._renderer.webglVersion === WEBGL2 ||
      (widthPowerOfTwo && heightPowerOfTwo)
      ) {
        this.glWrapS = gl.REPEAT;
      } else {
        console.warn(
          'You tried to set the wrap mode to REPEAT but the texture size is not a power of two. Setting to CLAMP instead'
        );
        this.glWrapS = gl.CLAMP_TO_EDGE;
      }
    } else if (wrapX === MIRROR) {
      if (
        this._renderer.webglVersion === WEBGL2 ||
      (widthPowerOfTwo && heightPowerOfTwo)
      ) {
        this.glWrapS = gl.MIRRORED_REPEAT;
      } else {
        console.warn(
          'You tried to set the wrap mode to MIRROR but the texture size is not a power of two. Setting to CLAMP instead'
        );
        this.glWrapS = gl.CLAMP_TO_EDGE;
      }
    } else {
      // falling back to default if didn't get a proper mode
      this.glWrapS = gl.CLAMP_TO_EDGE;
    }

    if (wrapY === REPEAT) {
      if (
        this._renderer.webglVersion === WEBGL2 ||
      (widthPowerOfTwo && heightPowerOfTwo)
      ) {
        this.glWrapT = gl.REPEAT;
      } else {
        console.warn(
          'You tried to set the wrap mode to REPEAT but the texture size is not a power of two. Setting to CLAMP instead'
        );
        this.glWrapT = gl.CLAMP_TO_EDGE;
      }
    } else if (wrapY === MIRROR) {
      if (
        this._renderer.webglVersion === WEBGL2 ||
      (widthPowerOfTwo && heightPowerOfTwo)
      ) {
        this.glWrapT = gl.MIRRORED_REPEAT;
      } else {
        console.warn(
          'You tried to set the wrap mode to MIRROR but the texture size is not a power of two. Setting to CLAMP instead'
        );
        this.glWrapT = gl.CLAMP_TO_EDGE;
      }
    } else {
      // falling back to default if didn't get a proper mode
      this.glWrapT = gl.CLAMP_TO_EDGE;
    }

    this.bindTexture();
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, this.glWrapS);
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, this.glWrapT);
    this.unbindTexture();
  }
}

class MipmapTexture extends Texture {
  constructor(renderer, levels, settings) {
    super(renderer, levels, settings);
    const gl = this._renderer.GL;
    if (this.glMinFilter === gl.LINEAR) {
      this.glMinFilter = gl.LINEAR_MIPMAP_LINEAR;
    }
  }

  glFilter(_filter) {
    const gl = this._renderer.GL;
    // TODO: support others
    return gl.LINEAR_MIPMAP_LINEAR;
  }

  _getTextureDataFromSource() {
    return this.src;
  }

  init(levels) {
    const gl = this._renderer.GL;
    this.glTex = gl.createTexture();

    this.bindTexture();
    for (let level = 0; level < levels.length; level++) {
      gl.texImage2D(
        this.glTarget,
        level,
        this.glFormat,
        this.glFormat,
        this.glDataType,
        levels[level]
      );
    }

    this.glMinFilter = gl.LINEAR_MIPMAP_LINEAR;
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, this.glMagFilter);
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, this.glMinFilter);

    this.unbindTexture();
  }

  update() {}
}

function texture(p5, fn){
  /**
   * Texture class for WEBGL Mode
   * @private
   * @class p5.Texture
   * @param {p5.RendererGL} renderer an instance of p5.RendererGL that
   * will provide the GL context for this new p5.Texture
   * @param {p5.Image|p5.Graphics|p5.Element|p5.MediaElement|ImageData|p5.Framebuffer|p5.FramebufferTexture|ImageData} [obj] the
   * object containing the image data to store in the texture.
   * @param {Object} [settings] optional A javascript object containing texture
   * settings.
   * @param {Number} [settings.format] optional The internal color component
   * format for the texture. Possible values for format include gl.RGBA,
   * gl.RGB, gl.ALPHA, gl.LUMINANCE, gl.LUMINANCE_ALPHA. Defaults to gl.RBGA
   * @param {Number} [settings.minFilter] optional The texture minification
   * filter setting. Possible values are gl.NEAREST or gl.LINEAR. Defaults
   * to gl.LINEAR. Note, Mipmaps are not implemented in p5.
   * @param {Number} [settings.magFilter] optional The texture magnification
   * filter setting. Possible values are gl.NEAREST or gl.LINEAR. Defaults
   * to gl.LINEAR. Note, Mipmaps are not implemented in p5.
   * @param {Number} [settings.wrapS] optional The texture wrap settings for
   * the s coordinate, or x axis. Possible values are gl.CLAMP_TO_EDGE,
   * gl.REPEAT, and gl.MIRRORED_REPEAT. The mirror settings are only available
   * when using a power of two sized texture. Defaults to gl.CLAMP_TO_EDGE
   * @param {Number} [settings.wrapT] optional The texture wrap settings for
   * the t coordinate, or y axis. Possible values are gl.CLAMP_TO_EDGE,
   * gl.REPEAT, and gl.MIRRORED_REPEAT. The mirror settings are only available
   * when using a power of two sized texture. Defaults to gl.CLAMP_TO_EDGE
   * @param {Number} [settings.dataType] optional The data type of the texel
   * data. Possible values are gl.UNSIGNED_BYTE or gl.FLOAT. There are more
   * formats that are not implemented in p5. Defaults to gl.UNSIGNED_BYTE.
   */
  p5.Texture = Texture;

  p5.MipmapTexture = MipmapTexture;
}

function checkWebGLCapabilities({ GL, webglVersion }) {
  const gl = GL;
  const supportsFloat = webglVersion === WEBGL2
    ? (gl.getExtension('EXT_color_buffer_float') &&
        gl.getExtension('EXT_float_blend'))
    : gl.getExtension('OES_texture_float');
  const supportsFloatLinear = supportsFloat &&
    gl.getExtension('OES_texture_float_linear');
  const supportsHalfFloat = webglVersion === WEBGL2
    ? gl.getExtension('EXT_color_buffer_float')
    : gl.getExtension('OES_texture_half_float');
  const supportsHalfFloatLinear = supportsHalfFloat &&
    gl.getExtension('OES_texture_half_float_linear');
  return {
    float: supportsFloat,
    floatLinear: supportsFloatLinear,
    halfFloat: supportsHalfFloat,
    halfFloatLinear: supportsHalfFloatLinear
  };
}

if(typeof p5 !== 'undefined'){
  texture(p5, p5.prototype);
}

/**
 * @module Rendering
 * @requires constants
 */


const constrain = (n, low, high) => Math.max(Math.min(n, high), low);

class FramebufferCamera extends Camera {
  constructor(framebuffer) {
    super(framebuffer.renderer);
    this.fbo = framebuffer;

    // WebGL textures are upside-down compared to textures that come from
    // images and graphics. Framebuffer cameras need to invert their y
    // axes when being rendered to so that the texture comes out rightway up
    // when read in shaders or image().
    this.yScale = -1;
  }

  _computeCameraDefaultSettings() {
    super._computeCameraDefaultSettings();
    this.defaultAspectRatio = this.fbo.width / this.fbo.height;
    this.defaultCameraFOV =
      2 * Math.atan(this.fbo.height / 2 / this.defaultEyeZ);
  }
}

class FramebufferTexture {
  constructor(framebuffer, property) {
    this.framebuffer = framebuffer;
    this.property = property;
  }

  get width() {
    return this.framebuffer.width * this.framebuffer.density;
  }

  get height() {
    return this.framebuffer.height * this.framebuffer.density;
  }

  update() {
    this.framebuffer._update(this.property);
  }

  rawTexture() {
    return this.framebuffer[this.property];
  }
}

class Framebuffer {
  constructor(renderer, settings = {}) {
    this.renderer = renderer;
    this.renderer.framebuffers.add(this);

    this._isClipApplied = false;

    this.dirty = { colorTexture: false, depthTexture: false };

    this.pixels = [];

    this.format = settings.format || UNSIGNED_BYTE;
    this.channels = settings.channels || (
      this.renderer._pInst._glAttributes.alpha
        ? RGBA
        : RGB
    );
    this.useDepth = settings.depth === undefined ? true : settings.depth;
    this.depthFormat = settings.depthFormat || FLOAT;
    this.textureFiltering = settings.textureFiltering || LINEAR;
    if (settings.antialias === undefined) {
      this.antialiasSamples = this.renderer._pInst._glAttributes.antialias
        ? 2
        : 0;
    } else if (typeof settings.antialias === 'number') {
      this.antialiasSamples = settings.antialias;
    } else {
      this.antialiasSamples = settings.antialias ? 2 : 0;
    }
    this.antialias = this.antialiasSamples > 0;
    if (this.antialias && this.renderer.webglVersion !== WEBGL2) {
      console.warn('Antialiasing is unsupported in a WebGL 1 context');
      this.antialias = false;
    }
    this.density = settings.density || this.renderer._pixelDensity;
    const gl = this.renderer.GL;
    this.gl = gl;
    if (settings.width && settings.height) {
      const dimensions =
        this.renderer._adjustDimensions(settings.width, settings.height);
      this.width = dimensions.adjustedWidth;
      this.height = dimensions.adjustedHeight;
      this._autoSized = false;
    } else {
      if ((settings.width === undefined) !== (settings.height === undefined)) {
        console.warn(
          'Please supply both width and height for a framebuffer to give it a ' +
            'size. Only one was given, so the framebuffer will match the size ' +
            'of its canvas.'
        );
      }
      this.width = this.renderer.width;
      this.height = this.renderer.height;
      this._autoSized = true;
    }
    this._checkIfFormatsAvailable();

    if (settings.stencil && !this.useDepth) {
      console.warn('A stencil buffer can only be used if also using depth. Since the framebuffer has no depth buffer, the stencil buffer will be ignored.');
    }
    this.useStencil = this.useDepth &&
      (settings.stencil === undefined ? true : settings.stencil);

    this.framebuffer = gl.createFramebuffer();
    if (!this.framebuffer) {
      throw new Error('Unable to create a framebuffer');
    }
    if (this.antialias) {
      this.aaFramebuffer = gl.createFramebuffer();
      if (!this.aaFramebuffer) {
        throw new Error('Unable to create a framebuffer for antialiasing');
      }
    }

    this._recreateTextures();

    const prevCam = this.renderer.states.curCamera;
    this.defaultCamera = this.createCamera();
    this.filterCamera = this.createCamera();
    this.renderer.states.setValue('curCamera', prevCam);

    this.draw(() => this.renderer.clear());
  }

  /**
   * Resizes the framebuffer to a given width and height.
   *
   * The parameters, `width` and `height`, set the dimensions of the
   * framebuffer. For example, calling `myBuffer.resize(300, 500)` resizes
   * the framebuffer to 300500 pixels, then sets `myBuffer.width` to 300
   * and `myBuffer.height` 500.
   *
   * @param {Number} width width of the framebuffer.
   * @param {Number} height height of the framebuffer.
   *
   * @example
   * <div>
   * <code>
   * let myBuffer;
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Create a p5.Framebuffer object.
   *   myBuffer = createFramebuffer();
   *
   *   describe('A multicolor sphere on a white surface. The image grows larger or smaller when the user moves the mouse, revealing a gray background.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Draw to the p5.Framebuffer object.
   *   myBuffer.begin();
   *   background(255);
   *   normalMaterial();
   *   sphere(20);
   *   myBuffer.end();
   *
   *   // Display the p5.Framebuffer object.
   *   image(myBuffer, -50, -50);
   * }
   *
   * // Resize the p5.Framebuffer object when the
   * // user moves the mouse.
   * function mouseMoved() {
   *   myBuffer.resize(mouseX, mouseY);
   * }
   * </code>
   * </div>
   */
  resize(width, height) {
    this._autoSized = false;
    const dimensions =
      this.renderer._adjustDimensions(width, height);
    width = dimensions.adjustedWidth;
    height = dimensions.adjustedHeight;
    this.width = width;
    this.height = height;
    this._handleResize();
  }

  /**
   * Sets the framebuffer's pixel density or returns its current density.
   *
   * Computer displays are grids of little lights called pixels. A display's
   * pixel density describes how many pixels it packs into an area. Displays
   * with smaller pixels have a higher pixel density and create sharper
   * images.
   *
   * The parameter, `density`, is optional. If a number is passed, as in
   * `myBuffer.pixelDensity(1)`, it sets the framebuffer's pixel density. By
   * default, the framebuffer's pixel density will match that of the canvas
   * where it was created. All canvases default to match the display's pixel
   * density.
   *
   * Calling `myBuffer.pixelDensity()` without an argument returns its current
   * pixel density.
   *
   * @param {Number} [density] pixel density to set.
   * @returns {Number} current pixel density.
   *
   * @example
   * <div>
   * <code>
   * let myBuffer;
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Create a p5.Framebuffer object.
   *   myBuffer = createFramebuffer();
   *
   *   describe("A white circle on a gray canvas. The circle's edge become fuzzy while the user presses and holds the mouse.");
   * }
   *
   * function draw() {
   *   // Draw to the p5.Framebuffer object.
   *   myBuffer.begin();
   *   background(200);
   *   circle(0, 0, 40);
   *   myBuffer.end();
   *
   *   // Display the p5.Framebuffer object.
   *   image(myBuffer, -50, -50);
   * }
   *
   * // Decrease the pixel density when the user
   * // presses the mouse.
   * function mousePressed() {
   *   myBuffer.pixelDensity(1);
   * }
   *
   * // Increase the pixel density when the user
   * // releases the mouse.
   * function mouseReleased() {
   *   myBuffer.pixelDensity(2);
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * let myBuffer;
   * let myFont;
   *
   * async function setup() {
   *   // Load a font and create a p5.Font object.
   *   myFont = await loadFont('assets/inconsolata.otf');
   *
   *   createCanvas(100, 100, WEBGL);
   *
   *   background(200);
   *
   *   // Create a p5.Framebuffer object.
   *   myBuffer = createFramebuffer();
   *
   *   // Get the p5.Framebuffer object's pixel density.
   *   let d = myBuffer.pixelDensity();
   *
   *   // Style the text.
   *   textAlign(CENTER, CENTER);
   *   textFont(myFont);
   *   textSize(16);
   *   fill(0);
   *
   *   // Display the pixel density.
   *   text(`Density: ${d}`, 0, 0);
   *
   *   describe(`The text "Density: ${d}" written in black on a gray background.`);
   * }
   * </code>
   * </div>
   */
  pixelDensity(density) {
    if (density) {
      this._autoSized = false;
      this.density = density;
      this._handleResize();
    } else {
      return this.density;
    }
  }

  /**
   * Toggles the framebuffer's autosizing mode or returns the current mode.
   *
   * By default, the framebuffer automatically resizes to match the canvas
   * that created it. Calling `myBuffer.autoSized(false)` disables this
   * behavior and calling `myBuffer.autoSized(true)` re-enables it.
   *
   * Calling `myBuffer.autoSized()` without an argument returns `true` if
   * the framebuffer automatically resizes and `false` if not.
   *
   * @param {Boolean} [autoSized] whether to automatically resize the framebuffer to match the canvas.
   * @returns {Boolean} current autosize setting.
   *
   * @example
   * <div>
   * <code>
   * // Double-click to toggle the autosizing mode.
   *
   * let myBuffer;
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Create a p5.Framebuffer object.
   *   myBuffer = createFramebuffer();
   *
   *   describe('A multicolor sphere on a gray background. The image resizes when the user moves the mouse.');
   * }
   *
   * function draw() {
   *   background(50);
   *
   *   // Draw to the p5.Framebuffer object.
   *   myBuffer.begin();
   *   background(200);
   *   normalMaterial();
   *   sphere(width / 4);
   *   myBuffer.end();
   *
   *   // Display the p5.Framebuffer object.
   *   image(myBuffer, -width / 2, -height / 2);
   * }
   *
   * // Resize the canvas when the user moves the mouse.
   * function mouseMoved() {
   *   let w = constrain(mouseX, 0, 100);
   *   let h = constrain(mouseY, 0, 100);
   *   resizeCanvas(w, h);
   * }
   *
   * // Toggle autoSizing when the user double-clicks.
   * // Note: opened an issue to fix(?) this.
   * function doubleClicked() {
   *   let isAuto = myBuffer.autoSized();
   *   myBuffer.autoSized(!isAuto);
   * }
   * </code>
   * </div>
   */
  autoSized(autoSized) {
    if (autoSized === undefined) {
      return this._autoSized;
    } else {
      this._autoSized = autoSized;
      this._handleResize();
    }
  }

  /**
   * Checks the capabilities of the current WebGL environment to see if the
   * settings supplied by the user are capable of being fulfilled. If they
   * are not, warnings will be logged and the settings will be changed to
   * something close that can be fulfilled.
   *
   * @private
   */
  _checkIfFormatsAvailable() {
    const gl = this.gl;

    if (
      this.useDepth &&
      this.renderer.webglVersion === WEBGL &&
      !gl.getExtension('WEBGL_depth_texture')
    ) {
      console.warn(
        'Unable to create depth textures in this environment. Falling back ' +
          'to a framebuffer without depth.'
      );
      this.useDepth = false;
    }

    if (
      this.useDepth &&
      this.renderer.webglVersion === WEBGL &&
      this.depthFormat === FLOAT
    ) {
      console.warn(
        'FLOAT depth format is unavailable in WebGL 1. ' +
          'Defaulting to UNSIGNED_INT.'
      );
      this.depthFormat = UNSIGNED_INT;
    }

    if (![
      UNSIGNED_BYTE,
      FLOAT,
      HALF_FLOAT
    ].includes(this.format)) {
      console.warn(
        'Unknown Framebuffer format. ' +
          'Please use UNSIGNED_BYTE, FLOAT, or HALF_FLOAT. ' +
          'Defaulting to UNSIGNED_BYTE.'
      );
      this.format = UNSIGNED_BYTE;
    }
    if (this.useDepth && ![
      UNSIGNED_INT,
      FLOAT
    ].includes(this.depthFormat)) {
      console.warn(
        'Unknown Framebuffer depth format. ' +
          'Please use UNSIGNED_INT or FLOAT. Defaulting to FLOAT.'
      );
      this.depthFormat = FLOAT;
    }

    const support = checkWebGLCapabilities(this.renderer);
    if (!support.float && this.format === FLOAT) {
      console.warn(
        'This environment does not support FLOAT textures. ' +
          'Falling back to UNSIGNED_BYTE.'
      );
      this.format = UNSIGNED_BYTE;
    }
    if (
      this.useDepth &&
      !support.float &&
      this.depthFormat === FLOAT
    ) {
      console.warn(
        'This environment does not support FLOAT depth textures. ' +
          'Falling back to UNSIGNED_INT.'
      );
      this.depthFormat = UNSIGNED_INT;
    }
    if (!support.halfFloat && this.format === HALF_FLOAT) {
      console.warn(
        'This environment does not support HALF_FLOAT textures. ' +
          'Falling back to UNSIGNED_BYTE.'
      );
      this.format = UNSIGNED_BYTE;
    }

    if (
      this.channels === RGB &&
      [FLOAT, HALF_FLOAT].includes(this.format)
    ) {
      console.warn(
        'FLOAT and HALF_FLOAT formats do not work cross-platform with only ' +
          'RGB channels. Falling back to RGBA.'
      );
      this.channels = RGBA;
    }
  }

  /**
   * Creates new textures and renderbuffers given the current size of the
   * framebuffer.
   *
   * @private
   */
  _recreateTextures() {
    const gl = this.gl;

    this._updateSize();

    const prevBoundTexture = gl.getParameter(gl.TEXTURE_BINDING_2D);
    const prevBoundFramebuffer = gl.getParameter(gl.FRAMEBUFFER_BINDING);

    const colorTexture = gl.createTexture();
    if (!colorTexture) {
      throw new Error('Unable to create color texture');
    }
    gl.bindTexture(gl.TEXTURE_2D, colorTexture);
    const colorFormat = this._glColorFormat();
    gl.texImage2D(
      gl.TEXTURE_2D,
      0,
      colorFormat.internalFormat,
      this.width * this.density,
      this.height * this.density,
      0,
      colorFormat.format,
      colorFormat.type,
      null
    );
    this.colorTexture = colorTexture;
    gl.bindFramebuffer(gl.FRAMEBUFFER, this.framebuffer);
    gl.framebufferTexture2D(
      gl.FRAMEBUFFER,
      gl.COLOR_ATTACHMENT0,
      gl.TEXTURE_2D,
      colorTexture,
      0
    );

    if (this.useDepth) {
      // Create the depth texture
      const depthTexture = gl.createTexture();
      if (!depthTexture) {
        throw new Error('Unable to create depth texture');
      }
      const depthFormat = this._glDepthFormat();
      gl.bindTexture(gl.TEXTURE_2D, depthTexture);
      gl.texImage2D(
        gl.TEXTURE_2D,
        0,
        depthFormat.internalFormat,
        this.width * this.density,
        this.height * this.density,
        0,
        depthFormat.format,
        depthFormat.type,
        null
      );

      gl.framebufferTexture2D(
        gl.FRAMEBUFFER,
        this.useStencil ? gl.DEPTH_STENCIL_ATTACHMENT : gl.DEPTH_ATTACHMENT,
        gl.TEXTURE_2D,
        depthTexture,
        0
      );
      this.depthTexture = depthTexture;
    }

    // Create separate framebuffer for antialiasing
    if (this.antialias) {
      this.colorRenderbuffer = gl.createRenderbuffer();
      gl.bindRenderbuffer(gl.RENDERBUFFER, this.colorRenderbuffer);
      gl.renderbufferStorageMultisample(
        gl.RENDERBUFFER,
        Math.max(
          0,
          Math.min(this.antialiasSamples, gl.getParameter(gl.MAX_SAMPLES))
        ),
        colorFormat.internalFormat,
        this.width * this.density,
        this.height * this.density
      );

      if (this.useDepth) {
        const depthFormat = this._glDepthFormat();
        this.depthRenderbuffer = gl.createRenderbuffer();
        gl.bindRenderbuffer(gl.RENDERBUFFER, this.depthRenderbuffer);
        gl.renderbufferStorageMultisample(
          gl.RENDERBUFFER,
          Math.max(
            0,
            Math.min(this.antialiasSamples, gl.getParameter(gl.MAX_SAMPLES))
          ),
          depthFormat.internalFormat,
          this.width * this.density,
          this.height * this.density
        );
      }

      gl.bindFramebuffer(gl.FRAMEBUFFER, this.aaFramebuffer);
      gl.framebufferRenderbuffer(
        gl.FRAMEBUFFER,
        gl.COLOR_ATTACHMENT0,
        gl.RENDERBUFFER,
        this.colorRenderbuffer
      );
      if (this.useDepth) {
        gl.framebufferRenderbuffer(
          gl.FRAMEBUFFER,
          this.useStencil ? gl.DEPTH_STENCIL_ATTACHMENT : gl.DEPTH_ATTACHMENT,
          gl.RENDERBUFFER,
          this.depthRenderbuffer
        );
      }
    }

    if (this.useDepth) {
      this.depth = new FramebufferTexture(this, 'depthTexture');
      const depthFilter = gl.NEAREST;
      this.depthP5Texture = new Texture(
        this.renderer,
        this.depth,
        {
          minFilter: depthFilter,
          magFilter: depthFilter
        }
      );
      this.renderer.textures.set(this.depth, this.depthP5Texture);
    }

    this.color = new FramebufferTexture(this, 'colorTexture');
    const filter = this.textureFiltering === LINEAR
      ? gl.LINEAR
      : gl.NEAREST;
    this.colorP5Texture = new Texture(
      this.renderer,
      this.color,
      {
        minFilter: filter,
        magFilter: filter
      }
    );
    this.renderer.textures.set(this.color, this.colorP5Texture);

    gl.bindTexture(gl.TEXTURE_2D, prevBoundTexture);
    gl.bindFramebuffer(gl.FRAMEBUFFER, prevBoundFramebuffer);
  }

  /**
   * To create a WebGL texture, one needs to supply three pieces of information:
   * the type (the data type each channel will be stored as, e.g. int or float),
   * the format (the color channels that will each be stored in the previously
   * specified type, e.g. rgb or rgba), and the internal format (the specifics
   * of how data for each channel, in the aforementioned type, will be packed
   * together, such as how many bits to use, e.g. RGBA32F or RGB565.)
   *
   * The format and channels asked for by the user hint at what these values
   * need to be, and the WebGL version affects what options are avaiable.
   * This method returns the values for these three properties, given the
   * framebuffer's settings.
   *
   * @private
   */
  _glColorFormat() {
    let type, format, internalFormat;
    const gl = this.gl;

    if (this.format === FLOAT) {
      type = gl.FLOAT;
    } else if (this.format === HALF_FLOAT) {
      type = this.renderer.webglVersion === WEBGL2
        ? gl.HALF_FLOAT
        : gl.getExtension('OES_texture_half_float').HALF_FLOAT_OES;
    } else {
      type = gl.UNSIGNED_BYTE;
    }

    if (this.channels === RGBA) {
      format = gl.RGBA;
    } else {
      format = gl.RGB;
    }

    if (this.renderer.webglVersion === WEBGL2) {
      // https://webgl2fundamentals.org/webgl/lessons/webgl-data-textures.html
      const table = {
        [gl.FLOAT]: {
          [gl.RGBA]: gl.RGBA32F
          // gl.RGB32F is not available in Firefox without an alpha channel
        },
        [gl.HALF_FLOAT]: {
          [gl.RGBA]: gl.RGBA16F
          // gl.RGB16F is not available in Firefox without an alpha channel
        },
        [gl.UNSIGNED_BYTE]: {
          [gl.RGBA]: gl.RGBA8, // gl.RGBA4
          [gl.RGB]: gl.RGB8 // gl.RGB565
        }
      };
      internalFormat = table[type][format];
    } else if (this.format === HALF_FLOAT) {
      internalFormat = gl.RGBA;
    } else {
      internalFormat = format;
    }

    return { internalFormat, format, type };
  }

  /**
   * To create a WebGL texture, one needs to supply three pieces of information:
   * the type (the data type each channel will be stored as, e.g. int or float),
   * the format (the color channels that will each be stored in the previously
   * specified type, e.g. rgb or rgba), and the internal format (the specifics
   * of how data for each channel, in the aforementioned type, will be packed
   * together, such as how many bits to use, e.g. RGBA32F or RGB565.)
   *
   * This method takes into account the settings asked for by the user and
   * returns values for these three properties that can be used for the
   * texture storing depth information.
   *
   * @private
   */
  _glDepthFormat() {
    let type, format, internalFormat;
    const gl = this.gl;

    if (this.useStencil) {
      if (this.depthFormat === FLOAT) {
        type = gl.FLOAT_32_UNSIGNED_INT_24_8_REV;
      } else if (this.renderer.webglVersion === WEBGL2) {
        type = gl.UNSIGNED_INT_24_8;
      } else {
        type = gl.getExtension('WEBGL_depth_texture').UNSIGNED_INT_24_8_WEBGL;
      }
    } else {
      if (this.depthFormat === FLOAT) {
        type = gl.FLOAT;
      } else {
        type = gl.UNSIGNED_INT;
      }
    }

    if (this.useStencil) {
      format = gl.DEPTH_STENCIL;
    } else {
      format = gl.DEPTH_COMPONENT;
    }

    if (this.useStencil) {
      if (this.depthFormat === FLOAT) {
        internalFormat = gl.DEPTH32F_STENCIL8;
      } else if (this.renderer.webglVersion === WEBGL2) {
        internalFormat = gl.DEPTH24_STENCIL8;
      } else {
        internalFormat = gl.DEPTH_STENCIL;
      }
    } else if (this.renderer.webglVersion === WEBGL2) {
      if (this.depthFormat === FLOAT) {
        internalFormat = gl.DEPTH_COMPONENT32F;
      } else {
        internalFormat = gl.DEPTH_COMPONENT24;
      }
    } else {
      internalFormat = gl.DEPTH_COMPONENT;
    }

    return { internalFormat, format, type };
  }

  /**
   * A method that will be called when recreating textures. If the framebuffer
   * is auto-sized, it will update its width, height, and density properties.
   *
   * @private
   */
  _updateSize() {
    if (this._autoSized) {
      this.width = this.renderer.width;
      this.height = this.renderer.height;
      this.density = this.renderer._pixelDensity;
    }
  }

  /**
   * Called when the canvas that the framebuffer is attached to resizes. If the
   * framebuffer is auto-sized, it will update its textures to match the new
   * size.
   *
   * @private
   */
  _canvasSizeChanged() {
    if (this._autoSized) {
      this._handleResize();
    }
  }

  /**
   * Called when the size of the framebuffer has changed (either by being
   * manually updated or from auto-size updates when its canvas changes size.)
   * Old textures and renderbuffers will be deleted, and then recreated with the
   * new size.
   *
   * @private
   */
  _handleResize() {
    const oldColor = this.color;
    const oldDepth = this.depth;
    const oldColorRenderbuffer = this.colorRenderbuffer;
    const oldDepthRenderbuffer = this.depthRenderbuffer;

    this._deleteTexture(oldColor);
    if (oldDepth) this._deleteTexture(oldDepth);
    const gl = this.gl;
    if (oldColorRenderbuffer) gl.deleteRenderbuffer(oldColorRenderbuffer);
    if (oldDepthRenderbuffer) gl.deleteRenderbuffer(oldDepthRenderbuffer);

    this._recreateTextures();
    this.defaultCamera._resize();
  }

  /**
   * Creates a new
   * <a href="#/p5.Camera">p5.Camera</a> object to use with the framebuffer.
   *
   * The new camera is initialized with a default position `(0, 0, 800)` and a
   * default perspective projection. Its properties can be controlled with
   * <a href="#/p5.Camera">p5.Camera</a> methods such as `myCamera.lookAt(0, 0, 0)`.
   *
   * Framebuffer cameras should be created between calls to
   * <a href="#/p5.Framebuffer/begin">myBuffer.begin()</a> and
   * <a href="#/p5.Framebuffer/end">myBuffer.end()</a> like so:
   *
   * ```js
   * let myCamera;
   *
   * myBuffer.begin();
   *
   * // Create the camera for the framebuffer.
   * myCamera = myBuffer.createCamera();
   *
   * myBuffer.end();
   * ```
   *
   * Calling <a href="#/p5/setCamera">setCamera()</a> updates the
   * framebuffer's projection using the camera.
   * <a href="#/p5/resetMatrix">resetMatrix()</a> must also be called for the
   * view to change properly:
   *
   * ```js
   * myBuffer.begin();
   *
   * // Set the camera for the framebuffer.
   * setCamera(myCamera);
   *
   * // Reset all transformations.
   * resetMatrix();
   *
   * // Draw stuff...
   *
   * myBuffer.end();
   * ```
   *
   * @returns {p5.Camera} new camera.
   *
   * @example
   * <div>
   * <code>
   * // Double-click to toggle between cameras.
   *
   * let myBuffer;
   * let cam1;
   * let cam2;
   * let usingCam1 = true;
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Create a p5.Framebuffer object.
   *   myBuffer = createFramebuffer();
   *
   *   // Create the cameras between begin() and end().
   *   myBuffer.begin();
   *
   *   // Create the first camera.
   *   // Keep its default settings.
   *   cam1 = myBuffer.createCamera();
   *
   *   // Create the second camera.
   *   // Place it at the top-left.
   *   // Point it at the origin.
   *   cam2 = myBuffer.createCamera();
   *   cam2.setPosition(400, -400, 800);
   *   cam2.lookAt(0, 0, 0);
   *
   *   myBuffer.end();
   *
   *   describe(
   *     'A white cube on a gray background. The camera toggles between frontal and aerial views when the user double-clicks.'
   *   );
   * }
   *
   * function draw() {
   *   // Draw to the p5.Framebuffer object.
   *   myBuffer.begin();
   *   background(200);
   *
   *   // Set the camera.
   *   if (usingCam1 === true) {
   *     setCamera(cam1);
   *   } else {
   *     setCamera(cam2);
   *   }
   *
   *   // Reset all transformations.
   *   resetMatrix();
   *
   *   // Draw the box.
   *   box();
   *
   *   myBuffer.end();
   *
   *   // Display the p5.Framebuffer object.
   *   image(myBuffer, -50, -50);
   * }
   *
   * // Toggle the current camera when the user double-clicks.
   * function doubleClicked() {
   *   if (usingCam1 === true) {
   *     usingCam1 = false;
   *   } else {
   *     usingCam1 = true;
   *   }
   * }
   * </code>
   * </div>
   */
  createCamera() {
    const cam = new FramebufferCamera(this);
    cam._computeCameraDefaultSettings();
    cam._setDefaultCamera();
    return cam;
  }

  /**
   * Given a raw texture wrapper, delete its stored texture from WebGL memory,
   * and remove it from p5's list of active textures.
   *
   * @param {p5.FramebufferTexture} texture
   * @private
   */
  _deleteTexture(texture) {
    const gl = this.gl;
    gl.deleteTexture(texture.rawTexture());

    this.renderer.textures.delete(texture);
  }

  /**
   * Deletes the framebuffer from GPU memory.
   *
   * Calling `myBuffer.remove()` frees the GPU memory used by the framebuffer.
   * The framebuffer also uses a bit of memory on the CPU which can be freed
   * like so:
   *
   * ```js
   * // Delete the framebuffer from GPU memory.
   * myBuffer.remove();
   *
   * // Delete the framebuffer from CPU memory.
   * myBuffer = undefined;
   * ```
   *
   * Note: All variables that reference the framebuffer must be assigned
   * the value `undefined` to delete the framebuffer from CPU memory. If any
   * variable still refers to the framebuffer, then it won't be garbage
   * collected.
   *
   * @example
   * <div>
   * <code>
   * // Double-click to remove the p5.Framebuffer object.
   *
   * let myBuffer;
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Create an options object.
   *   let options = { width: 60, height: 60 };
   *
   *   // Create a p5.Framebuffer object and
   *   // configure it using options.
   *   myBuffer = createFramebuffer(options);
   *
   *   describe('A white circle at the center of a dark gray square disappears when the user double-clicks.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Display the p5.Framebuffer object if
   *   // it's available.
   *   if (myBuffer) {
   *     // Draw to the p5.Framebuffer object.
   *     myBuffer.begin();
   *     background(100);
   *     circle(0, 0, 20);
   *     myBuffer.end();
   *
   *     image(myBuffer, -30, -30);
   *   }
   * }
   *
   * // Remove the p5.Framebuffer object when the
   * // the user double-clicks.
   * function doubleClicked() {
   *   // Delete the framebuffer from GPU memory.
   *   myBuffer.remove();
   *
   *   // Delete the framebuffer from CPU memory.
   *   myBuffer = undefined;
   * }
   * </code>
   * </div>
   */
  remove() {
    const gl = this.gl;
    this._deleteTexture(this.color);
    if (this.depth) this._deleteTexture(this.depth);
    gl.deleteFramebuffer(this.framebuffer);
    if (this.aaFramebuffer) {
      gl.deleteFramebuffer(this.aaFramebuffer);
    }
    if (this.depthRenderbuffer) {
      gl.deleteRenderbuffer(this.depthRenderbuffer);
    }
    if (this.colorRenderbuffer) {
      gl.deleteRenderbuffer(this.colorRenderbuffer);
    }
    this.renderer.framebuffers.delete(this);
  }

  /**
   * Begins drawing shapes to the framebuffer.
   *
   * `myBuffer.begin()` and <a href="#/p5.Framebuffer/end">myBuffer.end()</a>
   * allow shapes to be drawn to the framebuffer. `myBuffer.begin()` begins
   * drawing to the framebuffer and
   * <a href="#/p5.Framebuffer/end">myBuffer.end()</a> stops drawing to the
   * framebuffer. Changes won't be visible until the framebuffer is displayed
   * as an image or texture.
   *
   * @example
   * <div>
   * <code>
   * let myBuffer;
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Create a p5.Framebuffer object.
   *   myBuffer = createFramebuffer();
   *
   *   describe('An empty gray canvas. The canvas gets darker and a rotating, multicolor torus appears while the user presses and holds the mouse.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Start drawing to the p5.Framebuffer object.
   *   myBuffer.begin();
   *
   *   background(50);
   *   rotateY(frameCount * 0.01);
   *   normalMaterial();
   *   torus(30);
   *
   *   // Stop drawing to the p5.Framebuffer object.
   *   myBuffer.end();
   *
   *   // Display the p5.Framebuffer object while
   *   // the user presses the mouse.
   *   if (mouseIsPressed === true) {
   *     image(myBuffer, -50, -50);
   *   }
   * }
   * </code>
   * </div>
   */
  begin() {
    this.prevFramebuffer = this.renderer.activeFramebuffer();
    if (this.prevFramebuffer) {
      this.prevFramebuffer._beforeEnd();
    }
    this.renderer.activeFramebuffers.push(this);
    this._beforeBegin();
    this.renderer.push();
    // Apply the framebuffer's camera. This does almost what
    // RendererGL.reset() does, but this does not try to clear any buffers;
    // it only sets the camera.
    // this.renderer.setCamera(this.defaultCamera);
    this.renderer.states.setValue('curCamera', this.defaultCamera);
    // set the projection matrix (which is not normally updated each frame)
    this.renderer.states.setValue('uPMatrix', this.renderer.states.uPMatrix.clone());
    this.renderer.states.uPMatrix.set(this.defaultCamera.projMatrix);
    this.renderer.states.setValue('uViewMatrix', this.renderer.states.uViewMatrix.clone());
    this.renderer.states.uViewMatrix.set(this.defaultCamera.cameraMatrix);

    this.renderer.resetMatrix();
    this.renderer.states.uViewMatrix
      .set(this.renderer.states.curCamera.cameraMatrix);
    this.renderer.states.uModelMatrix.reset();
    this.renderer._applyStencilTestIfClipping();
  }

  /**
   * When making a p5.Framebuffer active so that it may be drawn to, this method
   * returns the underlying WebGL framebuffer that needs to be active to
   * support this. Antialiased framebuffers first write to a multisampled
   * renderbuffer, while other framebuffers can write directly to their main
   * framebuffers.
   *
   * @private
   */
  _framebufferToBind() {
    if (this.antialias) {
      // If antialiasing, draw to an antialiased renderbuffer rather
      // than directly to the texture. In end() we will copy from the
      // renderbuffer to the texture.
      return this.aaFramebuffer;
    } else {
      return this.framebuffer;
    }
  }

  /**
   * Ensure all readable textures are up-to-date.
   * @private
   * @property {'colorTexutre'|'depthTexture'} property The property to update
   */
  _update(property) {
    if (this.dirty[property] && this.antialias) {
      const gl = this.gl;
      gl.bindFramebuffer(gl.READ_FRAMEBUFFER, this.aaFramebuffer);
      gl.bindFramebuffer(gl.DRAW_FRAMEBUFFER, this.framebuffer);
      const partsToCopy = {
        colorTexture: [gl.COLOR_BUFFER_BIT, this.colorP5Texture.glMagFilter],
      };
      if (this.useDepth) {
        partsToCopy.depthTexture = [
          gl.DEPTH_BUFFER_BIT,
          this.depthP5Texture.glMagFilter
        ];
      }
      const [flag, filter] = partsToCopy[property];
      gl.blitFramebuffer(
        0,
        0,
        this.width * this.density,
        this.height * this.density,
        0,
        0,
        this.width * this.density,
        this.height * this.density,
        flag,
        filter
      );
      this.dirty[property] = false;

      const activeFbo = this.renderer.activeFramebuffer();
      if (activeFbo) {
        gl.bindFramebuffer(gl.FRAMEBUFFER, activeFbo._framebufferToBind());
      } else {
        gl.bindFramebuffer(gl.FRAMEBUFFER, null);
      }
    }
  }

  /**
   * Ensures that the framebuffer is ready to be drawn to
   *
   * @private
   */
  _beforeBegin() {
    const gl = this.gl;
    gl.bindFramebuffer(gl.FRAMEBUFFER, this._framebufferToBind());
    this.renderer.viewport(
      this.width * this.density,
      this.height * this.density
    );
  }

  /**
   * Ensures that the framebuffer is ready to be read by other framebuffers.
   *
   * @private
   */
  _beforeEnd() {
    if (this.antialias) {
      this.dirty = { colorTexture: true, depthTexture: true };
    }
  }

  /**
   * Stops drawing shapes to the framebuffer.
   *
   * <a href="#/p5.Framebuffer/begin">myBuffer.begin()</a> and `myBuffer.end()`
   * allow shapes to be drawn to the framebuffer.
   * <a href="#/p5.Framebuffer/begin">myBuffer.begin()</a> begins drawing to
   * the framebuffer and `myBuffer.end()` stops drawing to the framebuffer.
   * Changes won't be visible until the framebuffer is displayed as an image
   * or texture.
   *
   * @example
   * <div>
   * <code>
   * let myBuffer;
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Create a p5.Framebuffer object.
   *   myBuffer = createFramebuffer();
   *
   *   describe('An empty gray canvas. The canvas gets darker and a rotating, multicolor torus appears while the user presses and holds the mouse.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Start drawing to the p5.Framebuffer object.
   *   myBuffer.begin();
   *
   *   background(50);
   *   rotateY(frameCount * 0.01);
   *   normalMaterial();
   *   torus(30);
   *
   *   // Stop drawing to the p5.Framebuffer object.
   *   myBuffer.end();
   *
   *   // Display the p5.Framebuffer object while
   *   // the user presses the mouse.
   *   if (mouseIsPressed === true) {
   *     image(myBuffer, -50, -50);
   *   }
   * }
   * </code>
   * </div>
   */
  end() {
    const gl = this.gl;
    this.renderer.pop();
    const fbo = this.renderer.activeFramebuffers.pop();
    if (fbo !== this) {
      throw new Error("It looks like you've called end() while another Framebuffer is active.");
    }
    this._beforeEnd();
    if (this.prevFramebuffer) {
      this.prevFramebuffer._beforeBegin();
    } else {
      gl.bindFramebuffer(gl.FRAMEBUFFER, null);
      this.renderer.viewport(
        this.renderer._origViewport.width,
        this.renderer._origViewport.height
      );
    }
    this.renderer._applyStencilTestIfClipping();
  }

  /**
   * Draws to the framebuffer by calling a function that contains drawing
   * instructions.
   *
   * The parameter, `callback`, is a function with the drawing instructions
   * for the framebuffer. For example, calling `myBuffer.draw(myFunction)`
   * will call a function named `myFunction()` to draw to the framebuffer.
   * Doing so has the same effect as the following:
   *
   * ```js
   * myBuffer.begin();
   * myFunction();
   * myBuffer.end();
   * ```
   *
   * @param {Function} callback function that draws to the framebuffer.
   *
   * @example
   * <div>
   * <code>
   * // Click the canvas to display the framebuffer.
   *
   * let myBuffer;
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Create a p5.Framebuffer object.
   *   myBuffer = createFramebuffer();
   *
   *   describe('An empty gray canvas. The canvas gets darker and a rotating, multicolor torus appears while the user presses and holds the mouse.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Draw to the p5.Framebuffer object.
   *   myBuffer.draw(bagel);
   *
   *   // Display the p5.Framebuffer object while
   *   // the user presses the mouse.
   *   if (mouseIsPressed === true) {
   *     image(myBuffer, -50, -50);
   *   }
   * }
   *
   * // Draw a rotating, multicolor torus.
   * function bagel() {
   *   background(50);
   *   rotateY(frameCount * 0.01);
   *   normalMaterial();
   *   torus(30);
   * }
   * </code>
   * </div>
   */
  draw(callback) {
    this.begin();
    callback();
    this.end();
  }

  /**
   * Loads the current value of each pixel in the framebuffer into its
   * <a href="#/p5.Framebuffer/pixels">pixels</a> array.
   *
   * `myBuffer.loadPixels()` must be called before reading from or writing to
   * <a href="#/p5.Framebuffer/pixels">myBuffer.pixels</a>.
   *
   * @method loadPixels
   *
   * @example
   * <div>
   * <code>
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   background(200);
   *
   *   // Create a p5.Framebuffer object.
   *   let myBuffer = createFramebuffer();
   *
   *   // Load the pixels array.
   *   myBuffer.loadPixels();
   *
   *   // Get the number of pixels in the
   *   // top half of the framebuffer.
   *   let numPixels = myBuffer.pixels.length / 2;
   *
   *   // Set the framebuffer's top half to pink.
   *   for (let i = 0; i < numPixels; i += 4) {
   *     myBuffer.pixels[i] = 255;
   *     myBuffer.pixels[i + 1] = 102;
   *     myBuffer.pixels[i + 2] = 204;
   *     myBuffer.pixels[i + 3] = 255;
   *   }
   *
   *   // Update the pixels array.
   *   myBuffer.updatePixels();
   *
   *   // Draw the p5.Framebuffer object to the canvas.
   *   image(myBuffer, -50, -50);
   *
   *   describe('A pink rectangle above a gray rectangle.');
   * }
   * </code>
   * </div>
   */
  loadPixels() {
    this._update('colorTexture');
    const gl = this.gl;
    const prevFramebuffer = this.renderer.activeFramebuffer();
    gl.bindFramebuffer(gl.FRAMEBUFFER, this.framebuffer);
    const colorFormat = this._glColorFormat();
    this.pixels = readPixelsWebGL(
      this.pixels,
      gl,
      this.framebuffer,
      0,
      0,
      this.width * this.density,
      this.height * this.density,
      colorFormat.format,
      colorFormat.type
    );
    if (prevFramebuffer) {
      gl.bindFramebuffer(gl.FRAMEBUFFER, prevFramebuffer._framebufferToBind());
    } else {
      gl.bindFramebuffer(gl.FRAMEBUFFER, null);
    }
  }

  /**
   * Gets a pixel or a region of pixels from the framebuffer.
   *
   * `myBuffer.get()` is easy to use but it's not as fast as
   * <a href="#/p5.Framebuffer/pixels">myBuffer.pixels</a>. Use
   * <a href="#/p5.Framebuffer/pixels">myBuffer.pixels</a> to read many pixel
   * values.
   *
   * The version of `myBuffer.get()` with no parameters returns the entire
   * framebuffer as a a <a href="#/p5.Image">p5.Image</a> object.
   *
   * The version of `myBuffer.get()` with two parameters interprets them as
   * coordinates. It returns an array with the `[R, G, B, A]` values of the
   * pixel at the given point.
   *
   * The version of `myBuffer.get()` with four parameters interprets them as
   * coordinates and dimensions. It returns a subsection of the framebuffer as
   * a <a href="#/p5.Image">p5.Image</a> object. The first two parameters are
   * the coordinates for the upper-left corner of the subsection. The last two
   * parameters are the width and height of the subsection.
   *
   * @param  {Number} x x-coordinate of the pixel. Defaults to 0.
   * @param  {Number} y y-coordinate of the pixel. Defaults to 0.
   * @param  {Number} w width of the subsection to be returned.
   * @param  {Number} h height of the subsection to be returned.
   * @return {p5.Image} subsection as a <a href="#/p5.Image">p5.Image</a> object.
   */
  /**
   * @return {p5.Image} entire framebuffer as a <a href="#/p5.Image">p5.Image</a> object.
   */
  /**
   * @param  {Number} x
   * @param  {Number} y
   * @return {Number[]}  color of the pixel at `(x, y)` as an array of color values `[R, G, B, A]`.
   */
  get(x, y, w, h) {
    this._update('colorTexture');
    // p5._validateParameters('p5.Framebuffer.get', arguments);
    const colorFormat = this._glColorFormat();
    if (x === undefined && y === undefined) {
      x = 0;
      y = 0;
      w = this.width;
      h = this.height;
    } else if (w === undefined && h === undefined) {
      if (x < 0 || y < 0 || x >= this.width || y >= this.height) {
        console.warn(
          'The x and y values passed to p5.Framebuffer.get are outside of its range and will be clamped.'
        );
        x = constrain(x, 0, this.width - 1);
        y = constrain(y, 0, this.height - 1);
      }

      return readPixelWebGL(
        this.gl,
        this.framebuffer,
        x * this.density,
        y * this.density,
        colorFormat.format,
        colorFormat.type
      );
    }

    x = constrain(x, 0, this.width - 1);
    y = constrain(y, 0, this.height - 1);
    w = constrain(w, 1, this.width - x);
    h = constrain(h, 1, this.height - y);

    const rawData = readPixelsWebGL(
      undefined,
      this.gl,
      this.framebuffer,
      x * this.density,
      y * this.density,
      w * this.density,
      h * this.density,
      colorFormat.format,
      colorFormat.type
    );
    // Framebuffer data might be either a Uint8Array or Float32Array
    // depending on its format, and it may or may not have an alpha channel.
    // To turn it into an image, we have to normalize the data into a
    // Uint8ClampedArray with alpha.
    const fullData = new Uint8ClampedArray(
      w * h * this.density * this.density * 4
    );

    // Default channels that aren't in the framebuffer (e.g. alpha, if the
    // framebuffer is in RGB mode instead of RGBA) to 255
    fullData.fill(255);

    const channels = colorFormat.type === this.gl.RGB ? 3 : 4;
    for (let y = 0; y < h * this.density; y++) {
      for (let x = 0; x < w * this.density; x++) {
        for (let channel = 0; channel < 4; channel++) {
          const idx = (y * w * this.density + x) * 4 + channel;
          if (channel < channels) {
            // Find the index of this pixel in `rawData`, which might have a
            // different number of channels
            const rawDataIdx = channels === 4
              ? idx
              : (y * w * this.density + x) * channels + channel;
            fullData[idx] = rawData[rawDataIdx];
          }
        }
      }
    }

    // Create an image from the data
    const region = new Image(w * this.density, h * this.density);
    region.imageData = region.canvas.getContext('2d').createImageData(
      region.width,
      region.height
    );
    region.imageData.data.set(fullData);
    region.pixels = region.imageData.data;
    region.updatePixels();
    if (this.density !== 1) {
      // TODO: support get() at a pixel density > 1
      region.resize(w, h);
    }
    return region;
  }

  /**
   * Updates the framebuffer with the RGBA values in the
   * <a href="#/p5.Framebuffer/pixels">pixels</a> array.
   *
   * `myBuffer.updatePixels()` only needs to be called after changing values
   * in the <a href="#/p5.Framebuffer/pixels">myBuffer.pixels</a> array. Such
   * changes can be made directly after calling
   * <a href="#/p5.Framebuffer/loadPixels">myBuffer.loadPixels()</a>.
   *
   * @method updatePixels
   *
   * @example
   * <div>
   * <code>
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   background(200);
   *
   *   // Create a p5.Framebuffer object.
   *   let myBuffer = createFramebuffer();
   *
   *   // Load the pixels array.
   *   myBuffer.loadPixels();
   *
   *   // Get the number of pixels in the
   *   // top half of the framebuffer.
   *   let numPixels = myBuffer.pixels.length / 2;
   *
   *   // Set the framebuffer's top half to pink.
   *   for (let i = 0; i < numPixels; i += 4) {
   *     myBuffer.pixels[i] = 255;
   *     myBuffer.pixels[i + 1] = 102;
   *     myBuffer.pixels[i + 2] = 204;
   *     myBuffer.pixels[i + 3] = 255;
   *   }
   *
   *   // Update the pixels array.
   *   myBuffer.updatePixels();
   *
   *   // Draw the p5.Framebuffer object to the canvas.
   *   image(myBuffer, -50, -50);
   *
   *   describe('A pink rectangle above a gray rectangle.');
   * }
   * </code>
   * </div>
   */
  updatePixels() {
    const gl = this.gl;
    this.colorP5Texture.bindTexture();
    const colorFormat = this._glColorFormat();

    const channels = colorFormat.format === gl.RGBA ? 4 : 3;
    const len =
      this.width * this.height * this.density * this.density * channels;
    const TypedArrayClass = colorFormat.type === gl.UNSIGNED_BYTE
      ? Uint8Array
      : Float32Array;
    if (
      !(this.pixels instanceof TypedArrayClass) || this.pixels.length !== len
    ) {
      throw new Error(
        'The pixels array has not been set correctly. Please call loadPixels() before updatePixels().'
      );
    }

    gl.texImage2D(
      gl.TEXTURE_2D,
      0,
      colorFormat.internalFormat,
      this.width * this.density,
      this.height * this.density,
      0,
      colorFormat.format,
      colorFormat.type,
      this.pixels
    );
    this.colorP5Texture.unbindTexture();
    this.dirty.colorTexture = false;

    const prevFramebuffer = this.renderer.activeFramebuffer();
    if (this.antialias) {
      // We need to make sure the antialiased framebuffer also has the updated
      // pixels so that if more is drawn to it, it goes on top of the updated
      // pixels instead of replacing them.
      // We can't blit the framebuffer to the multisampled antialias
      // framebuffer to leave both in the same state, so instead we have
      // to use image() to put the framebuffer texture onto the antialiased
      // framebuffer.
      this.begin();
      this.renderer.push();
      // this.renderer.imageMode(constants.CENTER);
      this.renderer.states.setValue('imageMode', CORNER);
      this.renderer.setCamera(this.filterCamera);
      this.renderer.resetMatrix();
      this.renderer.states.setValue('strokeColor', null);
      this.renderer.clear();
      this.renderer._drawingFilter = true;
      this.renderer.image(
        this,
        0, 0,
        this.width, this.height,
        -this.renderer.width / 2, -this.renderer.height / 2,
        this.renderer.width, this.renderer.height
      );
      this.renderer._drawingFilter = false;
      this.renderer.pop();
      if (this.useDepth) {
        gl.clearDepth(1);
        gl.clear(gl.DEPTH_BUFFER_BIT);
      }
      this.end();
    } else {
      gl.bindFramebuffer(gl.FRAMEBUFFER, this.framebuffer);
      if (this.useDepth) {
        gl.clearDepth(1);
        gl.clear(gl.DEPTH_BUFFER_BIT);
      }
      if (prevFramebuffer) {
        gl.bindFramebuffer(
          gl.FRAMEBUFFER,
          prevFramebuffer._framebufferToBind()
        );
      } else {
        gl.bindFramebuffer(gl.FRAMEBUFFER, null);
      }
    }
  }
}

function framebuffer(p5, fn){
  /**
   * A <a href="#/p5.Camera">p5.Camera</a> attached to a
   * <a href="#/p5.Framebuffer">p5.Framebuffer</a>.
   *
   * @class p5.FramebufferCamera
   * @param {p5.Framebuffer} framebuffer The framebuffer this camera is
   * attached to
   * @private
   */
  p5.FramebufferCamera = FramebufferCamera;

  /**
   * A <a href="#/p5.Texture">p5.Texture</a> corresponding to a property of a
   * <a href="#/p5.Framebuffer">p5.Framebuffer</a>.
   *
   * @class p5.FramebufferTexture
   * @param {p5.Framebuffer} framebuffer The framebuffer represented by this
   * texture
   * @param {String} property The property of the framebuffer represented by
   * this texture, either `color` or `depth`
   * @private
   */
  p5.FramebufferTexture = FramebufferTexture;

  /**
   * A class to describe a high-performance drawing surface for textures.
   *
   * Each `p5.Framebuffer` object provides a dedicated drawing surface called
   * a *framebuffer*. They're similar to
   * <a href="#/p5.Graphics">p5.Graphics</a> objects but can run much faster.
   * Performance is improved because the framebuffer shares the same WebGL
   * context as the canvas used to create it.
   *
   * `p5.Framebuffer` objects have all the drawing features of the main
   * canvas. Drawing instructions meant for the framebuffer must be placed
   * between calls to
   * <a href="#/p5.Framebuffer/begin">myBuffer.begin()</a> and
   * <a href="#/p5.Framebuffer/end">myBuffer.end()</a>. The resulting image
   * can be applied as a texture by passing the `p5.Framebuffer` object to the
   * <a href="#/p5/texture">texture()</a> function, as in `texture(myBuffer)`.
   * It can also be displayed on the main canvas by passing it to the
   * <a href="#/p5/image">image()</a> function, as in `image(myBuffer, 0, 0)`.
   *
   * Note: <a href="#/p5/createFramebuffer">createFramebuffer()</a> is the
   * recommended way to create an instance of this class.
   *
   * @class p5.Framebuffer
   * @param {p5.Graphics|p5} target sketch instance or
   *                                <a href="#/p5.Graphics">p5.Graphics</a>
   *                                object.
   * @param {Object} [settings] configuration options.
   */
  p5.Framebuffer = Framebuffer;

  /**
   * An object that stores the framebuffer's color data.
   *
   * Each framebuffer uses a
   * <a href="https://developer.mozilla.org/en-US/docs/Web/API/WebGLTexture" target="_blank">WebGLTexture</a>
   * object internally to store its color data. The `myBuffer.color` property
   * makes it possible to pass this data directly to other functions. For
   * example, calling `texture(myBuffer.color)` or
   * `myShader.setUniform('colorTexture', myBuffer.color)`  may be helpful for
   * advanced use cases.
   *
   * Note: By default, a framebuffer's y-coordinates are flipped compared to
   * images and videos. It's easy to flip a framebuffer's y-coordinates as
   * needed when applying it as a texture. For example, calling
   * `plane(myBuffer.width, -myBuffer.height)` will flip the framebuffer.
   *
   * @property {p5.FramebufferTexture} color
   * @for p5.Framebuffer
   *
   * @example
   * <div>
   * <code>
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   background(200);
   *
   *   // Create a p5.Framebuffer object.
   *   let myBuffer = createFramebuffer();
   *
   *   // Start drawing to the p5.Framebuffer object.
   *   myBuffer.begin();
   *
   *   triangle(-25, 25, 0, -25, 25, 25);
   *
   *   // Stop drawing to the p5.Framebuffer object.
   *   myBuffer.end();
   *
   *   // Use the p5.Framebuffer object's WebGLTexture.
   *   texture(myBuffer.color);
   *
   *   // Style the plane.
   *   noStroke();
   *
   *   // Draw the plane.
   *   plane(myBuffer.width, myBuffer.height);
   *
   *   describe('A white triangle on a gray background.');
   * }
   * </code>
   * </div>
   */

  /**
   * An object that stores the framebuffer's depth data.
   *
   * Each framebuffer uses a
   * <a href="https://developer.mozilla.org/en-US/docs/Web/API/WebGLTexture" target="_blank">WebGLTexture</a>
   * object internally to store its depth data. The `myBuffer.depth` property
   * makes it possible to pass this data directly to other functions. For
   * example, calling `texture(myBuffer.depth)` or
   * `myShader.setUniform('depthTexture', myBuffer.depth)`  may be helpful for
   * advanced use cases.
   *
   * Note: By default, a framebuffer's y-coordinates are flipped compared to
   * images and videos. It's easy to flip a framebuffer's y-coordinates as
   * needed when applying it as a texture. For example, calling
   * `plane(myBuffer.width, -myBuffer.height)` will flip the framebuffer.
   *
   * @property {p5.FramebufferTexture} depth
   * @for p5.Framebuffer
   *
   * @example
   * <div>
   * <code>
   * // Note: A "uniform" is a global variable within a shader program.
   *
   * // Create a string with the vertex shader program.
   * // The vertex shader is called for each vertex.
   * let vertSrc = `
   * precision highp float;
   * attribute vec3 aPosition;
   * attribute vec2 aTexCoord;
   * uniform mat4 uModelViewMatrix;
   * uniform mat4 uProjectionMatrix;
   * varying vec2 vTexCoord;
   *
   * void main() {
   *   vec4 viewModelPosition = uModelViewMatrix * vec4(aPosition, 1.0);
   *   gl_Position = uProjectionMatrix * viewModelPosition;
   *   vTexCoord = aTexCoord;
   * }
   * `;
   *
   * // Create a string with the fragment shader program.
   * // The fragment shader is called for each pixel.
   * let fragSrc = `
   * precision highp float;
   * varying vec2 vTexCoord;
   * uniform sampler2D depth;
   *
   * void main() {
   *   // Get the pixel's depth value.
   *   float depthVal = texture2D(depth, vTexCoord).r;
   *
   *   // Set the pixel's color based on its depth.
   *   gl_FragColor = mix(
   *     vec4(0., 0., 0., 1.),
   *     vec4(1., 0., 1., 1.),
   *     depthVal);
   * }
   * `;
   *
   * let myBuffer;
   * let myShader;
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Create a p5.Framebuffer object.
   *   myBuffer = createFramebuffer();
   *
   *   // Create a p5.Shader object.
   *   myShader = createShader(vertSrc, fragSrc);
   *
   *   // Compile and apply the shader.
   *   shader(myShader);
   *
   *   describe('The shadow of a box rotates slowly against a magenta background.');
   * }
   *
   * function draw() {
   *   // Draw to the p5.Framebuffer object.
   *   myBuffer.begin();
   *   background(255);
   *   rotateX(frameCount * 0.01);
   *   box(20, 20, 80);
   *   myBuffer.end();
   *
   *   // Set the shader's depth uniform using
   *   // the framebuffer's depth texture.
   *   myShader.setUniform('depth', myBuffer.depth);
   *
   *   // Style the plane.
   *   noStroke();
   *
   *   // Draw the plane.
   *   plane(myBuffer.width, myBuffer.height);
   * }
   * </code>
   * </div>
   */

  /**
   * An array containing the color of each pixel in the framebuffer.
   *
   * <a href="#/p5.Framebuffer/loadPixels">myBuffer.loadPixels()</a> must be
   * called before accessing the `myBuffer.pixels` array.
   * <a href="#/p5.Framebuffer/updatePixels">myBuffer.updatePixels()</a>
   * must be called after any changes are made.
   *
   * Note: Updating pixels via this property is slower than drawing to the
   * framebuffer directly. Consider using a
   * <a href="#/p5.Shader">p5.Shader</a> object instead of looping over
   * `myBuffer.pixels`.
   *
   * @property {Number[]} pixels
   * @for p5.Framebuffer
   *
   * @example
   * <div>
   * <code>
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   background(200);
   *
   *   // Create a p5.Framebuffer object.
   *   let myBuffer = createFramebuffer();
   *
   *   // Load the pixels array.
   *   myBuffer.loadPixels();
   *
   *   // Get the number of pixels in the
   *   // top half of the framebuffer.
   *   let numPixels = myBuffer.pixels.length / 2;
   *
   *   // Set the framebuffer's top half to pink.
   *   for (let i = 0; i < numPixels; i += 4) {
   *     myBuffer.pixels[i] = 255;
   *     myBuffer.pixels[i + 1] = 102;
   *     myBuffer.pixels[i + 2] = 204;
   *     myBuffer.pixels[i + 3] = 255;
   *   }
   *
   *   // Update the pixels array.
   *   myBuffer.updatePixels();
   *
   *   // Draw the p5.Framebuffer object to the canvas.
   *   image(myBuffer, -50, -50);
   *
   *   describe('A pink rectangle above a gray rectangle.');
   * }
   * </code>
   * </div>
   */
}

if(typeof p5 !== 'undefined'){
  framebuffer(p5, p5.prototype);
}

/**
 * @module Rendering
 * @submodule Rendering
 * @for p5
 */


let renderers;
function rendering(p5, fn){
  // Extend additional renderers object to p5 class, new renderer can be similarly attached
  renderers = p5.renderers = {};

  /**
   * Creates a canvas element on the web page.
   *
   * `createCanvas()` creates the main drawing canvas for a sketch. It should
   * only be called once at the beginning of <a href="#/p5/setup">setup()</a>.
   * Calling `createCanvas()` more than once causes unpredictable behavior.
   *
   * The first two parameters, `width` and `height`, are optional. They set the
   * dimensions of the canvas and the values of the
   * <a href="#/p5/width">width</a> and <a href="#/p5/height">height</a> system
   * variables. For example, calling `createCanvas(900, 500)` creates a canvas
   * that's 900500 pixels. By default, `width` and `height` are both 100.
   *
   * The third parameter is also optional. If either of the constants `P2D` or
   * `WEBGL` is passed, as in `createCanvas(900, 500, WEBGL)`, then it will set
   * the sketch's rendering mode. If an existing
   * <a href="https://developer.mozilla.org/en-US/docs/Web/API/HTMLCanvasElement" target="_blank">HTMLCanvasElement</a>
   * is passed, as in `createCanvas(900, 500, myCanvas)`, then it will be used
   * by the sketch.
   *
   * The fourth parameter is also optional. If an existing
   * <a href="https://developer.mozilla.org/en-US/docs/Web/API/HTMLCanvasElement" target="_blank">HTMLCanvasElement</a>
   * is passed, as in `createCanvas(900, 500, WEBGL, myCanvas)`, then it will be
   * used by the sketch.
   *
   * Note: In WebGL mode, the canvas will use a WebGL2 context if it's supported
   * by the browser. Check the <a href="#/p5/webglVersion">webglVersion</a>
   * system variable to check what version is being used, or call
   * `setAttributes({ version: 1 })` to create a WebGL1 context.
   *
   * @method createCanvas
   * @param  {Number} [width] width of the canvas. Defaults to 100.
   * @param  {Number} [height] height of the canvas. Defaults to 100.
   * @param  {(P2D|WEBGL|P2DHDR)} [renderer] either P2D or WEBGL. Defaults to `P2D`.
   * @param  {HTMLCanvasElement} [canvas] existing canvas element that should be used for the sketch.
   * @return {p5.Renderer} new `p5.Renderer` that holds the canvas.
   *
   * @example
   * <div>
   * <code>
   * function setup() {
   *   createCanvas(100, 100);
   *
   *   background(200);
   *
   *   // Draw a diagonal line.
   *   line(0, 0, width, height);
   *
   *   describe('A diagonal line drawn from top-left to bottom-right on a gray background.');
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * function setup() {
   *   createCanvas(100, 50);
   *
   *   background(200);
   *
   *   // Draw a diagonal line.
   *   line(0, 0, width, height);
   *
   *   describe('A diagonal line drawn from top-left to bottom-right on a gray background.');
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Use WebGL mode.
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   background(200);
   *
   *   // Draw a diagonal line.
   *   line(-width / 2, -height / 2, width / 2, height / 2);
   *
   *   describe('A diagonal line drawn from top-left to bottom-right on a gray background.');
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * function setup() {
   *   // Create a p5.Render object.
   *   let cnv = createCanvas(50, 50);
   *
   *   // Position the canvas.
   *   cnv.position(10, 20);
   *
   *   background(200);
   *
   *   // Draw a diagonal line.
   *   line(0, 0, width, height);
   *
   *   describe('A diagonal line drawn from top-left to bottom-right on a gray background.');
   * }
   * </code>
   * </div>
   */
  /**
   * @method createCanvas
   * @param  {Number} [width]
   * @param  {Number} [height]
   * @param  {HTMLCanvasElement} [canvas]
   * @return {p5.Renderer}
   */
  fn.createCanvas = function (w, h, renderer, ...args) {
    // p5._validateParameters('createCanvas', arguments);
    //optional: renderer, otherwise defaults to p2d

    let selectedRenderer = P2D;
    // Check third argument whether it is renderer constants
    if(Reflect.ownKeys(renderers).includes(renderer)){
      selectedRenderer = renderer;
    }else {
      args.unshift(renderer);
    }

    // Init our graphics renderer
    if(this._renderer) this._renderer.remove();
    this._renderer = new renderers[selectedRenderer](this, w, h, true, ...args);
    this._defaultGraphicsCreated = true;
    this._elements.push(this._renderer);
    this._renderer._applyDefaults();

    // Make the renderer own `pixels`
    if (!Object.hasOwn(this, 'pixels')) {
      Object.defineProperty(this, 'pixels', {
        get(){
          return this._renderer?.pixels;
        }
      });
    }

    return this._renderer;
  };

  /**
   * Resizes the canvas to a given width and height.
   *
   * `resizeCanvas()` immediately clears the canvas and calls
   * <a href="#/p5/redraw">redraw()</a>. It's common to call `resizeCanvas()`
   * within the body of <a href="#/p5/windowResized">windowResized()</a> like
   * so:
   *
   * ```js
   * function windowResized() {
   *   resizeCanvas(windowWidth, windowHeight);
   * }
   * ```
   *
   * The first two parameters, `width` and `height`, set the dimensions of the
   * canvas. They also the values of the <a href="#/p5/width">width</a> and
   * <a href="#/p5/height">height</a> system variables. For example, calling
   * `resizeCanvas(300, 500)` resizes the canvas to 300500 pixels, then sets
   * <a href="#/p5/width">width</a> to 300 and
   * <a href="#/p5/height">height</a> 500.
   *
   * The third parameter, `noRedraw`, is optional. If `true` is passed, as in
   * `resizeCanvas(300, 500, true)`, then the canvas will be canvas to 300500
   * pixels but the <a href="#/p5/redraw">redraw()</a> function won't be called
   * immediately. By default, <a href="#/p5/redraw">redraw()</a> is called
   * immediately when `resizeCanvas()` finishes executing.
   *
   * @method resizeCanvas
   * @param  {Number} width width of the canvas.
   * @param  {Number} height height of the canvas.
   * @param  {Boolean} [noRedraw] whether to delay calling
   *                              <a href="#/p5/redraw">redraw()</a>. Defaults
   *                              to `false`.
   *
   * @example
   * <div>
   * <code>
   * // Double-click to resize the canvas.
   *
   * function setup() {
   *   createCanvas(100, 100);
   *
   *   describe(
   *     'A white circle drawn on a gray background. The canvas shrinks by half the first time the user double-clicks.'
   *   );
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Draw a circle at the center of the canvas.
   *   circle(width / 2, height / 2, 20);
   * }
   *
   * // Resize the canvas when the user double-clicks.
   * function doubleClicked() {
   *   resizeCanvas(50, 50);
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * // Resize the web browser to change the canvas size.
   *
   * function setup() {
   *   createCanvas(windowWidth, windowHeight);
   *
   *   describe('A white circle drawn on a gray background.');
   * }
   *
   * function draw() {
   *   background(200);
   *
   *   // Draw a circle at the center of the canvas.
   *   circle(width / 2, height / 2, 20);
   * }
   *
   * // Always resize the canvas to fill the browser window.
   * function windowResized() {
   *   resizeCanvas(windowWidth, windowHeight);
   * }
   * </code>
   * </div>
   */
  fn.resizeCanvas = function (w, h, noRedraw) {
    // p5._validateParameters('resizeCanvas', arguments);
    if (this._renderer) {
      // Make sure width and height are updated before the renderer resizes so
      // that framebuffers updated from the resize read the correct size
      this._renderer.resize(w, h);

      if (!noRedraw) {
        this.redraw();
      }
    }
    //accessible Outputs
    if (this._addAccsOutput()) {
      this._updateAccsOutput();
    }
  };

  /**
   * Removes the default canvas.
   *
   * By default, a 100100 pixels canvas is created without needing to call
   * <a href="#/p5/createCanvas">createCanvas()</a>. `noCanvas()` removes the
   * default canvas for sketches that don't need it.
   *
   * @method noCanvas
   *
   * @example
   * <div>
   * <code>
   * function setup() {
   *   noCanvas();
   * }
   * </code>
   * </div>
   */
  fn.noCanvas = function () {
    if (this.canvas) {
      this.canvas.parentNode.removeChild(this.canvas);
    }
  };

  /**
   * Creates a <a href="#/p5.Graphics">p5.Graphics</a> object.
   *
   * `createGraphics()` creates an offscreen drawing canvas (graphics buffer)
   * and returns it as a <a href="#/p5.Graphics">p5.Graphics</a> object. Drawing
   * to a separate graphics buffer can be helpful for performance and for
   * organizing code.
   *
   * The first two parameters, `width` and `height`, are optional. They set the
   * dimensions of the <a href="#/p5.Graphics">p5.Graphics</a> object. For
   * example, calling `createGraphics(900, 500)` creates a graphics buffer
   * that's 900500 pixels.
   *
   * The third parameter is also optional. If either of the constants `P2D` or
   * `WEBGL` is passed, as in `createGraphics(900, 500, WEBGL)`, then it will set
   * the <a href="#/p5.Graphics">p5.Graphics</a> object's rendering mode. If an
   * existing
   * <a href="https://developer.mozilla.org/en-US/docs/Web/API/HTMLCanvasElement" target="_blank">HTMLCanvasElement</a>
   * is passed, as in `createGraphics(900, 500, myCanvas)`, then it will be used
   * by the graphics buffer.
   *
   * The fourth parameter is also optional. If an existing
   * <a href="https://developer.mozilla.org/en-US/docs/Web/API/HTMLCanvasElement" target="_blank">HTMLCanvasElement</a>
   * is passed, as in `createGraphics(900, 500, WEBGL, myCanvas)`, then it will be
   * used by the graphics buffer.
   *
   * Note: In WebGL mode, the <a href="#/p5.Graphics">p5.Graphics</a> object
   * will use a WebGL2 context if it's supported by the browser. Check the
   * <a href="#/p5/webglVersion">webglVersion</a> system variable to check what
   * version is being used, or call `setAttributes({ version: 1 })` to create a
   * WebGL1 context.
   *
   * @method createGraphics
   * @param  {Number} width width of the graphics buffer.
   * @param  {Number} height height of the graphics buffer.
   * @param  {(P2D|WEBGL)} [renderer] either P2D or WEBGL. Defaults to P2D.
   * @param  {HTMLCanvasElement} [canvas] existing canvas element that should be
   *                                      used for the graphics buffer..
   * @return {p5.Graphics} new graphics buffer.
   *
   * @example
   * <div>
   * <code>
   * //  Double-click to draw the contents of the graphics buffer.
   *
   * let pg;
   *
   * function setup() {
   *   createCanvas(100, 100);
   *
   *   background(200);
   *
   *   // Create the p5.Graphics object.
   *   pg = createGraphics(50, 50);
   *
   *   // Draw to the graphics buffer.
   *   pg.background(100);
   *   pg.circle(pg.width / 2, pg.height / 2, 20);
   *
   *   describe('A gray square. A smaller, darker square with a white circle at its center appears when the user double-clicks.');
   * }
   *
   * // Display the graphics buffer when the user double-clicks.
   * function doubleClicked() {
   *   if (mouseX > 0 && mouseX < 100 && mouseY > 0 && mouseY < 100) {
   *     image(pg, 25, 25);
   *   }
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * //  Double-click to draw the contents of the graphics buffer.
   *
   * let pg;
   *
   * function setup() {
   *   createCanvas(100, 100);
   *
   *   background(200);
   *
   *   // Create the p5.Graphics object in WebGL mode.
   *   pg = createGraphics(50, 50, WEBGL);
   *
   *   // Draw to the graphics buffer.
   *   pg.background(100);
   *   pg.lights();
   *   pg.noStroke();
   *   pg.rotateX(QUARTER_PI);
   *   pg.rotateY(QUARTER_PI);
   *   pg.torus(15, 5);
   *
   *   describe('A gray square. A smaller, darker square with a white torus at its center appears when the user double-clicks.');
   * }
   *
   * // Display the graphics buffer when the user double-clicks.
   * function doubleClicked() {
   *   if (mouseX > 0 && mouseX < 100 && mouseY > 0 && mouseY < 100) {
   *     image(pg, 25, 25);
   *   }
   * }
   * </code>
   * </div>
   */
  /**
   * @method createGraphics
   * @param  {Number} width
   * @param  {Number} height
   * @param  {HTMLCanvasElement} [canvas]
   * @return {p5.Graphics}
   */
  fn.createGraphics = function (w, h, ...args) {
    /**
      * args[0] is expected to be renderer
      * args[1] is expected to be canvas
      */
    if (args[0] instanceof HTMLCanvasElement) {
      args[1] = args[0];
      args[0] = P2D;
    }
    // p5._validateParameters('createGraphics', arguments);
    return new p5.Graphics(w, h, args[0], this, args[1]);
  };

  /**
   * Creates and a new <a href="#/p5.Framebuffer">p5.Framebuffer</a> object.
   *
   * <a href="#/p5.Framebuffer">p5.Framebuffer</a> objects are separate drawing
   * surfaces that can be used as textures in WebGL mode. They're similar to
   * <a href="#/p5.Graphics">p5.Graphics</a> objects and generally run much
   * faster when used as textures.
   *
   * The parameter, `options`, is optional. An object can be passed to configure
   * the <a href="#/p5.Framebuffer">p5.Framebuffer</a> object. The available
   * properties are:
   *
   * - `format`: data format of the texture, either `UNSIGNED_BYTE`, `FLOAT`, or `HALF_FLOAT`. Default is `UNSIGNED_BYTE`.
   * - `channels`: whether to store `RGB` or `RGBA` color channels. Default is to match the main canvas which is `RGBA`.
   * - `depth`: whether to include a depth buffer. Default is `true`.
   * - `depthFormat`: data format of depth information, either `UNSIGNED_INT` or `FLOAT`. Default is `FLOAT`.
   * - `stencil`: whether to include a stencil buffer for masking. `depth` must be `true` for this feature to work. Defaults to the value of `depth` which is `true`.
   * - `antialias`: whether to perform anti-aliasing. If set to `true`, as in `{ antialias: true }`, 2 samples will be used by default. The number of samples can also be set, as in `{ antialias: 4 }`. Default is to match <a href="#/p5/setAttributes">setAttributes()</a> which is `false` (`true` in Safari).
   * - `width`: width of the <a href="#/p5.Framebuffer">p5.Framebuffer</a> object. Default is to always match the main canvas width.
   * - `height`: height of the <a href="#/p5.Framebuffer">p5.Framebuffer</a> object. Default is to always match the main canvas height.
   * - `density`: pixel density of the <a href="#/p5.Framebuffer">p5.Framebuffer</a> object. Default is to always match the main canvas pixel density.
   * - `textureFiltering`: how to read values from the <a href="#/p5.Framebuffer">p5.Framebuffer</a> object. Either `LINEAR` (nearby pixels will be interpolated) or `NEAREST` (no interpolation). Generally, use `LINEAR` when using the texture as an image and `NEAREST` if reading the texture as data. Default is `LINEAR`.
   *
   * If the `width`, `height`, or `density` attributes are set, they won't automatically match the main canvas and must be changed manually.
   *
   * Note: `createFramebuffer()` can only be used in WebGL mode.
   *
   * @method createFramebuffer
   * @param {Object} [options] configuration options.
   * @return {p5.Framebuffer} new framebuffer.
   *
   * @example
   * <div>
   * <code>
   * let myBuffer;
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Create a p5.Framebuffer object.
   *   myBuffer = createFramebuffer();
   *
   *   describe('A grid of white toruses rotating against a dark gray background.');
   * }
   *
   * function draw() {
   *   background(50);
   *
   *   // Start drawing to the p5.Framebuffer object.
   *   myBuffer.begin();
   *
   *   // Clear the drawing surface.
   *   clear();
   *
   *   // Turn on the lights.
   *   lights();
   *
   *   // Rotate the coordinate system.
   *   rotateX(frameCount * 0.01);
   *   rotateY(frameCount * 0.01);
   *
   *   // Style the torus.
   *   noStroke();
   *
   *   // Draw the torus.
   *   torus(20);
   *
   *   // Stop drawing to the p5.Framebuffer object.
   *   myBuffer.end();
   *
   *   // Iterate from left to right.
   *   for (let x = -50; x < 50; x += 25) {
   *     // Iterate from top to bottom.
   *     for (let y = -50; y < 50; y += 25) {
   *       // Draw the p5.Framebuffer object to the canvas.
   *       image(myBuffer, x, y, 25, 25);
   *     }
   *   }
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * let myBuffer;
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Create an options object.
   *   let options = { width: 25, height: 25 };
   *
   *   // Create a p5.Framebuffer object.
   *   // Use options for configuration.
   *   myBuffer = createFramebuffer(options);
   *
   *   describe('A grid of white toruses rotating against a dark gray background.');
   * }
   *
   * function draw() {
   *   background(50);
   *
   *   // Start drawing to the p5.Framebuffer object.
   *   myBuffer.begin();
   *
   *   // Clear the drawing surface.
   *   clear();
   *
   *   // Turn on the lights.
   *   lights();
   *
   *   // Rotate the coordinate system.
   *   rotateX(frameCount * 0.01);
   *   rotateY(frameCount * 0.01);
   *
   *   // Style the torus.
   *   noStroke();
   *
   *   // Draw the torus.
   *   torus(5, 2.5);
   *
   *   // Stop drawing to the p5.Framebuffer object.
   *   myBuffer.end();
   *
   *   // Iterate from left to right.
   *   for (let x = -50; x < 50; x += 25) {
   *     // Iterate from top to bottom.
   *     for (let y = -50; y < 50; y += 25) {
   *       // Draw the p5.Framebuffer object to the canvas.
   *       image(myBuffer, x, y);
   *     }
   *   }
   * }
   * </code>
   * </div>
   */
  fn.createFramebuffer = function (options) {
    return new Framebuffer(this._renderer, options);
  };

  /**
   * Clears the depth buffer in WebGL mode.
   *
   * `clearDepth()` clears information about how far objects are from the camera
   * in 3D space. This information is stored in an object called the
   * *depth buffer*. Clearing the depth buffer ensures new objects aren't drawn
   * behind old ones. Doing so can be useful for feedback effects in which the
   * previous frame serves as the background for the current frame.
   *
   * The parameter, `depth`, is optional. If a number is passed, as in
   * `clearDepth(0.5)`, it determines the range of objects to clear from the
   * depth buffer. 0 doesn't clear any depth information, 0.5 clears depth
   * information halfway between the near and far clipping planes, and 1 clears
   * depth information all the way to the far clipping plane. By default,
   * `depth` is 1.
   *
   * Note: `clearDepth()` can only be used in WebGL mode.
   *
   * @method clearDepth
   * @param {Number} [depth] amount of the depth buffer to clear between 0
   *                         (none) and 1 (far clipping plane). Defaults to 1.
   *
   * @example
   * <div>
   * <code>
   * let previous;
   * let current;
   *
   * function setup() {
   *   createCanvas(100, 100, WEBGL);
   *
   *   // Create the p5.Framebuffer objects.
   *   previous = createFramebuffer({ format: FLOAT });
   *   current = createFramebuffer({ format: FLOAT });
   *
   *   describe(
   *     'A multicolor box drifts from side to side on a white background. It leaves a trail that fades over time.'
   *   );
   * }
   *
   * function draw() {
   *   // Swap the previous p5.Framebuffer and the
   *   // current one so it can be used as a texture.
   *   [previous, current] = [current, previous];
   *
   *   // Start drawing to the current p5.Framebuffer.
   *   current.begin();
   *
   *   // Paint the background.
   *   background(255);
   *
   *   // Draw the previous p5.Framebuffer.
   *   // Clear the depth buffer so the previous
   *   // frame doesn't block the current one.
   *   push();
   *   tint(255, 250);
   *   image(previous, -50, -50);
   *   clearDepth();
   *   pop();
   *
   *   // Draw the box on top of the previous frame.
   *   push();
   *   let x = 25 * sin(frameCount * 0.01);
   *   let y = 25 * sin(frameCount * 0.02);
   *   translate(x, y, 0);
   *   rotateX(frameCount * 0.01);
   *   rotateY(frameCount * 0.01);
   *   normalMaterial();
   *   box(12);
   *   pop();
   *
   *   // Stop drawing to the current p5.Framebuffer.
   *   current.end();
   *
   *   // Display the current p5.Framebuffer.
   *   image(current, -50, -50);
   * }
   * </code>
   * </div>
   */
  fn.clearDepth = function (depth) {
    this._assert3d('clearDepth');
    this._renderer.clearDepth(depth);
  };

  /**
   * A system variable that provides direct access to the sketch's
   * `&lt;canvas&gt;` element.
   *
   * The `&lt;canvas&gt;` element provides many specialized features that aren't
   * included in the p5.js library. The `drawingContext` system variable
   * provides access to these features by exposing the sketch's
   * <a href="https://developer.mozilla.org/en-US/docs/Web/API/CanvasRenderingContext2D">CanvasRenderingContext2D</a>
   * object.
   *
   * @property drawingContext
   *
   * @example
   * <div>
   * <code>
   * function setup() {
   *   createCanvas(100, 100);
   *
   *   background(200);
   *
   *   // Style the circle using shadows.
   *   drawingContext.shadowOffsetX = 5;
   *   drawingContext.shadowOffsetY = -5;
   *   drawingContext.shadowBlur = 10;
   *   drawingContext.shadowColor = 'black';
   *
   *   // Draw the circle.
   *   circle(50, 50, 40);
   *
   *   describe("A white circle on a gray background. The circle's edges are shadowy.");
   * }
   * </code>
   * </div>
   *
   * <div>
   * <code>
   * function setup() {
   *   createCanvas(100, 100);
   *
   *   background('skyblue');
   *
   *   // Style the circle using a color gradient.
   *   let myGradient = drawingContext.createRadialGradient(50, 50, 3, 50, 50, 40);
   *   myGradient.addColorStop(0, 'yellow');
   *   myGradient.addColorStop(0.6, 'orangered');
   *   myGradient.addColorStop(1, 'yellow');
   *   drawingContext.fillStyle = myGradient;
   *   drawingContext.strokeStyle = 'rgba(0, 0, 0, 0)';
   *
   *   // Draw the circle.
   *   circle(50, 50, 40);
   *
   *   describe('A fiery sun drawn on a light blue background.');
   * }
   * </code>
   * </div>
   */
}

if(typeof p5 !== 'undefined'){
  rendering(p5, p5.prototype);
}

export { readPixelsWebGL as A, readPixelWebGL as B, Camera as C, checkWebGLCapabilities as D, FramebufferCamera as E, FramebufferTexture as F, Graphics as G, Framebuffer as H, renderers as I, MipmapTexture as M, RendererGL as R, Shader as S, Texture as T, request as a, loadingDisplaying as b, camera as c, files as d, filterOpaqueFrag as e, framebuffer as f, filterPosterizeFrag as g, filterDilateFrag as h, image as i, filterGrayFrag as j, filterErodeFrag as k, light as l, material as m, filterThresholdFrag as n, filterInvertFrag as o, primitives3D as p, filterBlurFrag as q, rendererGL as r, shader as s, texture as t, filterBaseVert as u, filterBaseFrag as v, webgl2CompatibilityShader as w, filterShaderVert as x, rendering as y, graphics as z };
